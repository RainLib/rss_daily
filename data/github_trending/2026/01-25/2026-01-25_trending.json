{
  "date": "2026-01-25",
  "name": "trending",
  "repositories": [
    {
      "id": 274495425,
      "name": "remotion",
      "full_name": "remotion-dev/remotion",
      "description": "ğŸ¥      Make videos programmatically with React",
      "html_url": "https://github.com/remotion-dev/remotion",
      "stars": 29598,
      "forks": 1780,
      "language": "TypeScript",
      "topics": [
        "javascript",
        "react",
        "video"
      ],
      "created_at": "2020-06-23T19:49:10Z",
      "updated_at": "2026-01-25T02:28:34Z",
      "pushed_at": "2026-01-24T12:59:18Z",
      "open_issues": 95,
      "owner": {
        "login": "remotion-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/85344006?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://github.com/remotion-dev/logo\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-dark.apng\">\n      <img alt=\"Animated Remotion Logo\" src=\"https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-light.gif\">\n    </picture>\n  </a>\n</p>\n\n[![Discord Shield](https://img.shields.io/discord/809501355504959528?color=000000&label=Discord&logo=fdgssdf)](https://remotion.dev/discord)\n[![NPM Version](https://img.shields.io/npm/v/remotion.svg?style=flat&color=black)](https://www.npmjs.org/package/remotion)\n[![NPM Downloads](https://img.shields.io/npm/dm/remotion.svg?style=flat&color=black&label=Downloads)](https://npmcharts.com/compare/remotion?minimal=true)\n[![Open Bounties](https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2Fremotion%2Fbounties%3Fstatus%3Dopen&style=flat&color=black&labelColor=grey&label=Open+Bounties)](https://github.com/remotion-dev/remotion/issues?q=is%3Aopen+label%3A%22%F0%9F%92%8E+Bounty%22+sort%3Aupdated-desc)\n<a href=\"https://twitter.com/remotion\"><img src=\"https://img.shields.io/twitter/follow/remotion?label=Twitter&color=black\" alt=\"Twitter\"></a>\n\nRemotion is a framework for **creating videos programmatically using React.**\n\n## Why create videos in React?\n\n- **Leverage web technologies**: Use all of CSS, Canvas, SVG, WebGL, etc.\n- **Leverage programming**: Use variables, functions, APIs, math and algorithms to create new effects\n- **Leverage React**: Reusable components, Powerful composition, Fast Refresh, Package ecosystem\n\n## Created with Remotion\n\n<table>\n<tr>\n<td align=\"center\">\n<img style=\"width: 290px\" src=\"https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/fireship-quick.gif\" />\n<p>\"This video was made with code\" <em>- Fireship</em> <a href=\"https://youtu.be/deg8bOoziaE\">Watch</a> â€¢ <a href=\"https://github.com/wcandillon/remotion-fireship\">Source</a></p>\n</td>\n<td align=\"center\">\n<img style=\"width: 240px\" src=\"https://pub-646d808d9cb240cea53bedc76dd3cd0c.r2.dev/unwrapped-2023.gif\" />\n<p>GitHub Unwrapped - Personalized Year in Review <a href=\"https://www.githubunwrapped.com\">Try</a> â€¢ <a href=\"https://github.com/remotion-dev/github-unwrapped\">Source</a></p>\n</td>\n<td align=\"center\">\n<em>View more in the <a href=\"https://remotion.dev/showcase\">Remotion Showcase</a>!</em>\n</td>\n</tr>\n</table>\n\n## Get started\n\nIf you already have Node.JS installed, type\n\n```console\nnpx create-video@latest\n```\n\nto get started. Otherwise, read the [installation page](https://www.remotion.dev/docs/) in the documentation.\n\n## Documentation\n\nDocumentation: [**remotion.dev/docs**](https://www.remotion.dev/docs)  \nAPI Reference: [**remotion.dev/api**](https://www.remotion.dev/api)\n\n## License\n\nBe aware of that Remotion has a special license and requires obtaining a company license in some cases. Read the [LICENSE](LICENSE.md) page for more information.\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](CONTRIBUTING.md) to learn about contributing to this project.\n",
      "stars_today": 1171
    },
    {
      "id": 846698999,
      "name": "goose",
      "full_name": "block/goose",
      "description": "an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM",
      "html_url": "https://github.com/block/goose",
      "stars": 28393,
      "forks": 2552,
      "language": "Rust",
      "topics": [
        "mcp"
      ],
      "created_at": "2024-08-23T19:03:36Z",
      "updated_at": "2026-01-25T02:15:19Z",
      "pushed_at": "2026-01-24T18:12:42Z",
      "open_issues": 320,
      "owner": {
        "login": "block",
        "avatar_url": "https://avatars.githubusercontent.com/u/185116535?v=4"
      },
      "readme": "<div align=\"center\">\n\n# goose\n\n_a local, extensible, open source AI agent that automates engineering tasks_\n\n<p align=\"center\">\n  <a href=\"https://opensource.org/licenses/Apache-2.0\">\n    <img src=\"https://img.shields.io/badge/License-Apache_2.0-blue.svg\">\n  </a>\n  <a href=\"https://discord.gg/goose-oss\">\n    <img src=\"https://img.shields.io/discord/1287729918100246654?logo=discord&logoColor=white&label=Join+Us&color=blueviolet\" alt=\"Discord\">\n  </a>\n  <a href=\"https://github.com/block/goose/actions/workflows/ci.yml\">\n     <img src=\"https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main\" alt=\"CI\">\n  </a>\n</p>\n</div>\n\ngoose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.\n\nWhether you're prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.\n\nDesigned for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.\n\n[![Watch the video](https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a)](https://youtu.be/D-DpDunrbpo)\n\n# Quick Links\n- [Quickstart](https://block.github.io/goose/docs/quickstart)\n- [Installation](https://block.github.io/goose/docs/getting-started/installation)\n- [Tutorials](https://block.github.io/goose/docs/category/tutorials)\n- [Documentation](https://block.github.io/goose/docs/category/getting-started)\n- [Responsible AI-Assisted Coding Guide](https://github.com/block/goose/blob/main/HOWTOAI.md)\n- [Governance](https://github.com/block/goose/blob/main/GOVERNANCE.md)\n\n## Need Help?\n- [Diagnostics & Reporting](https://block.github.io/goose/docs/troubleshooting/diagnostics-and-reporting)\n- [Known Issues](https://block.github.io/goose/docs/troubleshooting/known-issues)\n\n# a little goose humor ğŸ¦¢\n\n> Why did the developer choose goose as their AI agent?\n> \n> Because it always helps them \"migrate\" their code to production! ğŸš€\n\n# goose around with us  \n- [Discord](https://discord.gg/goose-oss)\n- [YouTube](https://www.youtube.com/@goose-oss)\n- [LinkedIn](https://www.linkedin.com/company/goose-oss)\n- [Twitter/X](https://x.com/goose_oss)\n- [Bluesky](https://bsky.app/profile/opensource.block.xyz)\n- [Nostr](https://njump.me/opensource@block.xyz)\n",
      "stars_today": 407
    },
    {
      "id": 1081230042,
      "name": "VidBee",
      "full_name": "nexmoe/VidBee",
      "description": "Download videos from almost any website worldwide",
      "html_url": "https://github.com/nexmoe/VidBee",
      "stars": 5548,
      "forks": 370,
      "language": "TypeScript",
      "topics": [
        "downloader",
        "facebook",
        "tiktok",
        "twitter",
        "youtube"
      ],
      "created_at": "2025-10-22T13:43:42Z",
      "updated_at": "2026-01-25T02:23:24Z",
      "pushed_at": "2026-01-24T14:23:37Z",
      "open_issues": 28,
      "owner": {
        "login": "nexmoe",
        "avatar_url": "https://avatars.githubusercontent.com/u/16796652?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://github.com/nexmoe/VidBee\">\n    <img src=\"build/icon.png\" alt=\"Logo\" width=\"80\" height=\"80\">\n  </a>\n\n  <h3>VidBee</h3>\n  <p>\n    <a href=\"https://github.com/nexmoe/VidBee/stargazers\"><img src=\"https://img.shields.io/github/stars/nexmoe/VidBee?color=ffcb47&labelColor=black&logo=github&label=Stars\" /></a>\n    <a href=\"https://github.com/nexmoe/VidBee/graphs/contributors\"><img src=\"https://img.shields.io/github/contributors/nexmoe/VidBee?ogo=github&label=Contributors&labelColor=black\" /></a>\n    <a href=\"https://github.com/nexmoe/VidBee/releases\"><img src=\"https://img.shields.io/github/downloads/nexmoe/VidBee/total?color=369eff&labelColor=black&logo=github&label=Downloads\" /></a>\n    <a href=\"https://github.com/nexmoe/VidBee/releases/latest\"><img src=\"https://img.shields.io/github/v/release/nexmoe/VidBee?color=369eff&labelColor=black&logo=github&label=Latest%20Release\" /></a>\n    <a href=\"https://x.com/intent/follow?screen_name=nexmoex\"><img src=\"https://img.shields.io/badge/Follow-blue?color=1d9bf0&logo=x&labelColor=black\" /></a>\n    <a href=\"https://deepwiki.com/nexmoe/VidBee\"><img src=\"https://deepwiki.com/badge.svg\" alt=\"Ask DeepWiki\"></a>\n    <br />\n    <br />\n    <a href=\"https://github.com/nexmoe/VidBee/releases/latest\" target=\"_blank\"><img src=\"screenshots/main-interface.png\" alt=\"VidBee Desktop\" width=\"46%\"/></a>\n    <a href=\"https://github.com/nexmoe/VidBee/releases/latest\" target=\"_blank\"><img src=\"screenshots/download-queue.png\" alt=\"VidBee Download Queue\" width=\"46%\"/></a>\n    <br />\n    <br />\n  </p>\n</div>\n\nVidBee is a modern, open-source video downloader that lets you download videos and audios from 1000+ websites worldwide. Built with Electron and powered by yt-dlp, VidBee offers a clean, intuitive interface with powerful features for all your downloading needs, including RSS auto-download automation that automatically subscribes to feeds and downloads new videos from your favorite creators in the background.\n\n## ğŸ‘‹ğŸ» Getting Started\n\nVidBee is currently under active development, and feedback is welcome for any [issue](https://github.com/nexmoe/VidBee/issues) encountered.\n\n[ğŸ“¥ Download VidBee](https://vidbee.org/download/) | [ğŸ“š Documentation](https://docs.vidbee.org)\n\n> [!IMPORTANT]\n>\n> **Star Us**, You will receive all release notifications from GitHub without any delay ~\n\n<a href=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats?repo_id=1081230042\" target=\"_blank\" style=\"display: block\" align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=1081230042&image_size=auto&color_scheme=dark\" width=\"655\" height=\"auto\">\n    <img alt=\"Performance Stats of nexmoe/VidBee - Last 28 days\" src=\"https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=1081230042&image_size=auto&color_scheme=light\" width=\"655\" height=\"auto\">\n  </picture>\n</a>\n\n<!-- Made with [OSS Insight](https://ossinsight.io/) -->\n\n## âœ¨ Features\n\n### ğŸŒ Global Video Download Support\n\nDownload videos from almost any website worldwide through the powerful yt-dlp engine. Support for 1000+ sites including YouTube, TikTok, Instagram, Twitter, and many more.\n\n![VidBee Main Interface](screenshots/main-interface.png)\n\n### ğŸ¨ Best-in-class UI Experience\n\nModern, clean interface with intuitive operations. One-click pause/resume/retry, real-time progress tracking, and comprehensive download queue management.\n\n![VidBee Download Queue](screenshots/download-queue.png)\n\n### ğŸ“¡ RSS Auto Download\n\nAutomatically subscribe to RSS feeds and auto-download new videos in the background from your favorite creators across YouTube, TikTok, and more. Set up RSS subscriptions once, and VidBee will automatically download new uploads without manual intervention, perfect for keeping up with your favorite channels and creators.\n\n## ğŸŒ Supported Sites\n\nVidBee supports 1000+ video and audio platforms through yt-dlp. For the complete list of supported sites, visit [https://vidbee.org/supported-sites/](https://vidbee.org/supported-sites/)\n\n## ğŸ¤ Contributing\n\nYou are welcome to join the open source community to build together. For more details, check out:\n\n- [Contributing Guide](./CONTRIBUTING.md)\n- [DeepWiki Documentation](https://deepwiki.com/nexmoe/VidBee)\n\n## ğŸ“„ License\n\nThis project is distributed under the MIT License. See [`LICENSE`](LICENSE) for details.\n\n## ğŸ™ Thanks\n\n- [yt-dlp](https://github.com/yt-dlp/yt-dlp) - The powerful video downloader engine\n- [FFmpeg](https://ffmpeg.org/) - The multimedia framework for video and audio processing\n- [Electron](https://www.electronjs.org/) - Build cross-platform desktop apps\n- [React](https://react.dev/) - The UI library\n- [Vite](https://vitejs.dev/) - Next generation frontend tooling\n- [Tailwind CSS](https://tailwindcss.com/) - Utility-first CSS framework\n- [shadcn/ui](https://ui.shadcn.com/) - Beautifully designed components\n",
      "stars_today": 291
    },
    {
      "id": 685877018,
      "name": "res-downloader",
      "full_name": "putyy/res-downloader",
      "description": "è§†é¢‘å·ã€å°ç¨‹åºã€æŠ–éŸ³ã€å¿«æ‰‹ã€å°çº¢ä¹¦ã€ç›´æ’­æµã€m3u8ã€é…·ç‹—ã€QQéŸ³ä¹ç­‰å¸¸è§ç½‘ç»œèµ„æºä¸‹è½½!",
      "html_url": "https://github.com/putyy/res-downloader",
      "stars": 14386,
      "forks": 1789,
      "language": "Go",
      "topics": [
        "douyin",
        "kuaishou",
        "res-downloader",
        "wechat",
        "wechat-video",
        "xiaohongshu"
      ],
      "created_at": "2023-09-01T08:03:47Z",
      "updated_at": "2026-01-25T02:18:10Z",
      "pushed_at": "2025-12-31T02:24:50Z",
      "open_issues": 38,
      "owner": {
        "login": "putyy",
        "avatar_url": "https://avatars.githubusercontent.com/u/31536789?v=4"
      },
      "readme": "<div align=\"center\">\n\n<a href=\"https://github.com/putyy/res-downloader\"><img src=\"build/appicon.png\" width=\"120\"/></a>\n<h1>res-downloader</h1>\n<h4>ğŸ“– ä¸­æ–‡ | <a href=\"https://github.com/putyy/res-downloader/blob/master/README-EN.md\">English</a></h4>\n\n[![GitHub stars](https://img.shields.io/github/stars/putyy/res-downloader)](https://github.com/putyy/res-downloader/stargazers)\n[![GitHub forks](https://img.shields.io/github/forks/putyy/res-downloader)](https://github.com/putyy/res-downloader/fork)\n[![GitHub release](https://img.shields.io/github/release/putyy/res-downloader)](https://github.com/putyy/res-downloader/releases)\n![GitHub All Releases](https://img.shields.io/github/downloads/putyy/res-downloader/total)\n[![License](https://img.shields.io/github/license/putyy/res-downloader)](https://github.com/putyy/res-downloader/blob/master/LICENSE)\n\n</div>\n\n---\n\n### ğŸ‰ çˆ±äº«ç´ æä¸‹è½½å™¨\n\n> ä¸€æ¬¾åŸºäº Go + [Wails](https://github.com/wailsapp/wails) çš„è·¨å¹³å°èµ„æºä¸‹è½½å·¥å…·ï¼Œç®€æ´æ˜“ç”¨ï¼Œæ”¯æŒå¤šç§èµ„æºå—…æ¢ä¸ä¸‹è½½ã€‚\n\n## âœ¨ åŠŸèƒ½ç‰¹è‰²\n\n- ğŸš€ **ç®€å•æ˜“ç”¨**ï¼šæ“ä½œç®€å•ï¼Œç•Œé¢æ¸…æ™°ç¾è§‚\n- ğŸ–¥ï¸ **å¤šå¹³å°æ”¯æŒ**ï¼šWindows / macOS / Linux\n- ğŸŒ **å¤šèµ„æºç±»å‹æ”¯æŒ**ï¼šè§†é¢‘ / éŸ³é¢‘ / å›¾ç‰‡ / m3u8 / ç›´æ’­æµç­‰\n- ğŸ“± **å¹³å°å…¼å®¹å¹¿æ³›**ï¼šæ”¯æŒå¾®ä¿¡è§†é¢‘å·ã€å°ç¨‹åºã€æŠ–éŸ³ã€å¿«æ‰‹ã€å°çº¢ä¹¦ã€é…·ç‹—éŸ³ä¹ã€QQéŸ³ä¹ç­‰\n- ğŸŒ **ä»£ç†æŠ“åŒ…**ï¼šæ”¯æŒè®¾ç½®ä»£ç†è·å–å—é™ç½‘ç»œä¸‹çš„èµ„æº\n\n## ğŸ“š æ–‡æ¡£ & ç‰ˆæœ¬\n\n- ğŸ“˜ [åœ¨çº¿æ–‡æ¡£](https://res.putyy.com/)\n- ğŸ’¬ [åŠ å…¥äº¤æµç¾¤](https://www.putyy.com/app/admin/upload/img/20250418/6801d9554dc7.webp)\n- ğŸ§© [æœ€æ–°ç‰ˆ](https://github.com/putyy/res-downloader/releases) ï½œ [Miniç‰ˆ ä½¿ç”¨é»˜è®¤æµè§ˆå™¨å±•ç¤ºUI](https://github.com/putyy/resd-mini) ï½œ [Electronæ—§ç‰ˆ æ”¯æŒWin7](https://github.com/putyy/res-downloader/tree/old)\n  > *ç¾¤æ»¡æ—¶å¯åŠ å¾®ä¿¡ `AmorousWorld`ï¼Œè¯·å¤‡æ³¨â€œgithubâ€*\n\n## ğŸ§© ä¸‹è½½åœ°å€\n\n- ğŸ†• [GitHub ä¸‹è½½](https://github.com/putyy/res-downloader/releases)\n- ğŸ†• [è“å¥äº‘ä¸‹è½½ï¼ˆå¯†ç ï¼š9vs5ï¼‰](https://wwjv.lanzoum.com/b04wgtfyb)\n- âš ï¸ *Win7 ç”¨æˆ·è¯·ä¸‹è½½ `2.3.0` ç‰ˆæœ¬*\n\n\n## ğŸ–¼ï¸ é¢„è§ˆ\n\n![é¢„è§ˆ](docs/images/show.webp)\n--- \n\n## ğŸš€ ä½¿ç”¨æ–¹æ³•\n\n> è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œä»¥æ­£ç¡®ä½¿ç”¨è½¯ä»¶ï¼š\n\n1. å®‰è£…æ—¶åŠ¡å¿… **å…è®¸å®‰è£…è¯ä¹¦æ–‡ä»¶** å¹¶ **å…è®¸ç½‘ç»œè®¿é—®**\n2. æ‰“å¼€è½¯ä»¶ â†’ é¦–é¡µå·¦ä¸Šè§’ç‚¹å‡» **â€œå¯åŠ¨ä»£ç†â€**\n3. é€‰æ‹©è¦è·å–çš„èµ„æºç±»å‹ï¼ˆé»˜è®¤å…¨éƒ¨ï¼‰\n4. åœ¨å¤–éƒ¨æ‰“å¼€èµ„æºé¡µé¢ï¼ˆå¦‚è§†é¢‘å·ã€å°ç¨‹åºã€ç½‘é¡µç­‰ï¼‰\n5. è¿”å›è½¯ä»¶é¦–é¡µï¼Œå³å¯çœ‹åˆ°èµ„æºåˆ—è¡¨\n\n## â“ å¸¸è§é—®é¢˜\n\n### ğŸ“º m3u8 è§†é¢‘èµ„æº\n\n- åœ¨çº¿é¢„è§ˆï¼š[m3u8play](https://m3u8play.com/)\n- è§†é¢‘ä¸‹è½½ï¼š[m3u8-down](https://m3u8-down.gowas.cn/)\n\n### ğŸ“¡ ç›´æ’­æµèµ„æº\n\n- æ¨èä½¿ç”¨ [OBS](https://obsproject.com/) è¿›è¡Œå½•åˆ¶ï¼ˆæ•™ç¨‹è¯·ç™¾åº¦ï¼‰\n\n### ğŸ¢ ä¸‹è½½æ…¢ã€å¤§æ–‡ä»¶å¤±è´¥ï¼Ÿ\n\n- æ¨èå·¥å…·ï¼š\n  - [Neat Download Manager](https://www.neatdownloadmanager.com/index.php/en/)\n  - [Motrix](https://motrix.app/download)\n- è§†é¢‘å·èµ„æºä¸‹è½½åå¯åœ¨æ“ä½œé¡¹ç‚¹å‡» `è§†é¢‘è§£å¯†ï¼ˆè§†é¢‘å·ï¼‰`\n\n### ğŸ§© è½¯ä»¶æ— æ³•æ‹¦æˆªèµ„æºï¼Ÿ\n\n- æ£€æŸ¥æ˜¯å¦æ­£ç¡®è®¾ç½®ç³»ç»Ÿä»£ç†ï¼š  \n  åœ°å€ï¼š127.0.0.1\n  ç«¯å£ï¼š8899\n\n### ğŸŒ å…³é—­è½¯ä»¶åæ— æ³•ä¸Šç½‘ï¼Ÿ\n\n- æ‰‹åŠ¨å…³é—­ç³»ç»Ÿä»£ç†è®¾ç½®\n\n### ğŸ§  æ›´å¤šé—®é¢˜\n\n- [GitHub Issues](https://github.com/putyy/res-downloader/issues)\n- [çˆ±äº«è®ºå›è®¨è®ºå¸–](https://s.gowas.cn/d/4089)\n\n## ğŸ’¡ å®ç°åŸç† & åˆè¡·\n\næœ¬å·¥å…·é€šè¿‡ä»£ç†æ–¹å¼å®ç°ç½‘ç»œæŠ“åŒ…ï¼Œå¹¶ç­›é€‰å¯ç”¨èµ„æºã€‚ä¸ Fiddlerã€Charlesã€æµè§ˆå™¨ DevTools åŸç†ç±»ä¼¼ï¼Œä½†å¯¹èµ„æºè¿›è¡Œäº†æ›´å‹å¥½çš„ç­›é€‰ã€å±•ç¤ºå’Œå¤„ç†ï¼Œå¤§å¹…åº¦é™ä½äº†ä½¿ç”¨é—¨æ§›ï¼Œæ›´é€‚åˆå¤§ä¼—ç”¨æˆ·ä½¿ç”¨ã€‚\n\n---\n\n## âš ï¸ å…è´£å£°æ˜\n\n> æœ¬è½¯ä»¶ä»…ä¾›å­¦ä¹ ä¸ç ”ç©¶ç”¨é€”ï¼Œç¦æ­¢ç”¨äºä»»ä½•å•†ä¸šæˆ–è¿æ³•ç”¨é€”ã€‚  \nå¦‚å› æ­¤äº§ç”Ÿçš„ä»»ä½•æ³•å¾‹è´£ä»»ï¼Œæ¦‚ä¸ä½œè€…æ— å…³ï¼\n",
      "stars_today": 211
    },
    {
      "id": 965415649,
      "name": "codex",
      "full_name": "openai/codex",
      "description": "Lightweight coding agent that runs in your terminal",
      "html_url": "https://github.com/openai/codex",
      "stars": 57178,
      "forks": 7412,
      "language": "Rust",
      "topics": [],
      "created_at": "2025-04-13T05:37:54Z",
      "updated_at": "2026-01-25T02:21:39Z",
      "pushed_at": "2026-01-25T01:54:11Z",
      "open_issues": 864,
      "owner": {
        "login": "openai",
        "avatar_url": "https://avatars.githubusercontent.com/u/14957082?v=4"
      },
      "readme": "<p align=\"center\"><code>npm i -g @openai/codex</code><br />or <code>brew install --cask codex</code></p>\n<p align=\"center\"><strong>Codex CLI</strong> is a coding agent from OpenAI that runs locally on your computer.\n<p align=\"center\">\n  <img src=\"./.github/codex-cli-splash.png\" alt=\"Codex CLI splash\" width=\"80%\" />\n</p>\n</br>\nIf you want Codex in your code editor (VS Code, Cursor, Windsurf), <a href=\"https://developers.openai.com/codex/ide\">install in your IDE.</a>\n</br>If you are looking for the <em>cloud-based agent</em> from OpenAI, <strong>Codex Web</strong>, go to <a href=\"https://chatgpt.com/codex\">chatgpt.com/codex</a>.</p>\n\n---\n\n## Quickstart\n\n### Installing and running Codex CLI\n\nInstall globally with your preferred package manager:\n\n```shell\n# Install using npm\nnpm install -g @openai/codex\n```\n\n```shell\n# Install using Homebrew\nbrew install --cask codex\n```\n\nThen simply run `codex` to get started.\n\n<details>\n<summary>You can also go to the <a href=\"https://github.com/openai/codex/releases/latest\">latest GitHub Release</a> and download the appropriate binary for your platform.</summary>\n\nEach GitHub Release contains many executables, but in practice, you likely want one of these:\n\n- macOS\n  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`\n  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`\n- Linux\n  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`\n  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`\n\nEach archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.\n\n</details>\n\n### Using Codex with your ChatGPT plan\n\nRun `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what's included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).\n\nYou can also use Codex with an API key, but this requires [additional setup](https://developers.openai.com/codex/auth#sign-in-with-an-api-key).\n\n## Docs\n\n- [**Codex Documentation**](https://developers.openai.com/codex)\n- [**Contributing**](./docs/contributing.md)\n- [**Installing & building**](./docs/install.md)\n- [**Open source fund**](./docs/open-source-fund.md)\n\nThis repository is licensed under the [Apache-2.0 License](LICENSE).\n",
      "stars_today": 193
    },
    {
      "id": 1031912724,
      "name": "cc-switch",
      "full_name": "farion1231/cc-switch",
      "description": "A cross-platform desktop All-in-One assistant tool for Claude Code, Codex, OpenCode & Gemini CLI.",
      "html_url": "https://github.com/farion1231/cc-switch",
      "stars": 13473,
      "forks": 870,
      "language": "Rust",
      "topics": [
        "ai-tools",
        "claude-code",
        "codex",
        "desktop-app",
        "kimi-k2-thiking",
        "mcp",
        "minimax",
        "open-source",
        "opencode",
        "provider-management",
        "rust",
        "skills",
        "skills-management",
        "tauri",
        "typescript",
        "wsl-support"
      ],
      "created_at": "2025-08-04T14:16:16Z",
      "updated_at": "2026-01-25T02:23:02Z",
      "pushed_at": "2026-01-25T01:38:21Z",
      "open_issues": 139,
      "owner": {
        "login": "farion1231",
        "avatar_url": "https://avatars.githubusercontent.com/u/44939412?v=4"
      },
      "readme": "<div align=\"center\">\n\n# All-in-One Assistant for Claude Code, Codex & Gemini CLI\n\n[![Version](https://img.shields.io/badge/version-3.10.2-blue.svg)](https://github.com/farion1231/cc-switch/releases)\n[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)](https://github.com/farion1231/cc-switch/releases)\n[![Built with Tauri](https://img.shields.io/badge/built%20with-Tauri%202-orange.svg)](https://tauri.app/)\n[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/farion1231/cc-switch/total)](https://github.com/farion1231/cc-switch/releases/latest)\n\n<a href=\"https://trendshift.io/repositories/15372\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/15372\" alt=\"farion1231%2Fcc-switch | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\nEnglish | [ä¸­æ–‡](README_ZH.md) | [æ—¥æœ¬èª](README_JA.md) | [Changelog](CHANGELOG.md)\n\n</div>\n\n## â¤ï¸Sponsor\n\n[![Zhipu GLM](assets/partners/banners/glm-en.jpg)](https://z.ai/subscribe?ic=8JVLJQFSKB)\n\nThis project is sponsored by Z.ai, supporting us with their GLM CODING PLAN.GLM CODING PLAN is a subscription service designed for AI coding, starting at just $3/month. It provides access to their flagship GLM-4.6 model across 10+ popular AI coding tools (Claude Code, Cline, Roo Code, etc.), offering developers top-tier, fast, and stable coding experiences.Get 10% OFF the GLM CODING PLAN with [this link](https://z.ai/subscribe?ic=8JVLJQFSKB)!\n\n---\n\n<table>\n<tr>\n<td width=\"180\"><a href=\"https://www.packyapi.com/register?aff=cc-switch\"><img src=\"assets/partners/logos/packycode.png\" alt=\"PackyCode\" width=\"150\"></a></td>\n<td>Thanks to PackyCode for sponsoring this project! PackyCode is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more. PackyCode provides special discounts for our software users: register using <a href=\"https://www.packyapi.com/register?aff=cc-switch\">this link</a> and enter the \"cc-switch\" promo code during recharge to get 10% off.</td>\n</tr>\n\n<tr>\n<td width=\"180\"><a href=\"https://aigocode.com/invite/CC-SWITCH\"><img src=\"assets/partners/logos/aigocode.png\" alt=\"AIGoCode\" width=\"150\"></a></td>\n<td>Thanks to AIGoCode for sponsoring this project! AIGoCode is an all-in-one platform that integrates Claude Code, Codex, and the latest Gemini models, providing you with stable, efficient, and highly cost-effective AI coding services. The platform offers flexible subscription plans, zero risk of account suspension, direct access with no VPN required, and lightning-fast responses. AIGoCode has prepared a special benefit for CC Switch users: if you register via <a href=\"https://aigocode.com/invite/CC-SWITCH\">this link</a>, you'll receive an extra 10% bonus credit on your first top-up!</td>\n</tr>\n\n<tr>\n<td width=\"180\"><a href=\"https://www.dmxapi.cn/register?aff=bUHu\"><img src=\"assets/partners/logos/dmx-en.jpg\" alt=\"DMXAPI\" width=\"150\"></a></td>\n<td>Thanks to DMXAPI for sponsoring this project! DMXAPI provides global large model API services to 200+ enterprise users. One API key for all global models. Features include: instant invoicing, unlimited concurrency, starting from $0.15, 24/7 technical support. GPT/Claude/Gemini all at 32% off, domestic models 20-50% off, Claude Code exclusive models at 66% off! <a href=\"https://www.dmxapi.cn/register?aff=bUHu\">Register here</a></td>\n</tr>\n\n<tr>\n<td width=\"180\"><a href=\"https://cubence.com/signup?code=CCSWITCH&source=ccs\"><img src=\"assets/partners/logos/cubence.png\" alt=\"Cubence\" width=\"150\"></a></td>\n<td>Thanks to Cubence for sponsoring this project! Cubence is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more with flexible billing options including pay-as-you-go and monthly plans. Cubence provides special discounts for CC Switch users: register using <a href=\"https://cubence.com/signup?code=CCSWITCH&source=ccs\">this link</a> and enter the \"CCSWITCH\" promo code during recharge to get 10% off every top-up!</td>\n</tr>\n\n</table>\n\n## Screenshots\n\n|                  Main Interface                   |                  Add Provider                  |\n| :-----------------------------------------------: | :--------------------------------------------: |\n| ![Main Interface](assets/screenshots/main-en.png) | ![Add Provider](assets/screenshots/add-en.png) |\n\n## Features\n\n### Current Version: v3.10.2 | [Full Changelog](CHANGELOG.md) | [Release Notes](docs/release-note-v3.9.0-en.md)\n\n**v3.8.0 Major Update (2025-11-28)**\n\n**Persistence Architecture Upgrade & Brand New UI**\n\n- **SQLite + JSON Dual-layer Architecture**\n  - Migrated from JSON file storage to SQLite + JSON dual-layer structure\n  - Syncable data (providers, MCP, Prompts, Skills) stored in SQLite\n  - Device-level data (window state, local paths) stored in JSON\n  - Lays the foundation for future cloud sync functionality\n  - Schema version management for database migrations\n\n- **Brand New User Interface**\n  - Completely redesigned interface layout\n  - Unified component styles and smoother animations\n  - Optimized visual hierarchy\n  - Tailwind CSS downgraded from v4 to v3.4 for better browser compatibility\n\n- **Japanese Language Support**\n  - Added Japanese interface support (now supports Chinese/English/Japanese)\n\n- **Auto Launch on Startup**\n  - One-click enable/disable in settings\n  - Platform-native APIs (Registry/LaunchAgent/XDG autostart)\n\n- **Skills Recursive Scanning**\n  - Support for multi-level directory structures\n  - Allow same-named skills from different repositories\n\n- **Critical Bug Fixes**\n  - Fixed custom endpoints lost when updating providers\n  - Fixed Gemini configuration write issues\n  - Fixed Linux WebKitGTK rendering issues\n\n**v3.7.0 Highlights**\n\n**Six Core Features, 18,000+ Lines of New Code**\n\n- **Gemini CLI Integration**\n  - Third supported AI CLI (Claude Code / Codex / Gemini)\n  - Dual-file configuration support (`.env` + `settings.json`)\n  - Complete MCP server management\n  - Presets: Google Official (OAuth) / PackyCode / Custom\n\n- **Claude Skills Management System**\n  - Auto-scan skills from GitHub repositories (3 pre-configured curated repos)\n  - One-click install/uninstall to `~/.claude/skills/`\n  - Custom repository support + subdirectory scanning\n  - Complete lifecycle management (discover/install/update)\n\n- **Prompts Management System**\n  - Multi-preset system prompt management (unlimited presets, quick switching)\n  - Cross-app support (Claude: `CLAUDE.md` / Codex: `AGENTS.md` / Gemini: `GEMINI.md`)\n  - Markdown editor (CodeMirror 6 + real-time preview)\n  - Smart backfill protection, preserves manual modifications\n\n- **MCP v3.7.0 Unified Architecture**\n  - Single panel manages MCP servers across three applications\n  - New SSE (Server-Sent Events) transport type\n  - Smart JSON parser + Codex TOML format auto-correction\n  - Unified import/export + bidirectional sync\n\n- **Deep Link Protocol**\n  - `ccswitch://` protocol registration (all platforms)\n  - One-click import provider configs via shared links\n  - Security validation + lifecycle integration\n\n- **Environment Variable Conflict Detection**\n  - Auto-detect cross-app configuration conflicts (Claude/Codex/Gemini/MCP)\n  - Visual conflict indicators + resolution suggestions\n  - Override warnings + backup before changes\n\n**Core Capabilities**\n\n- **Provider Management**: One-click switching between Claude Code, Codex, and Gemini API configurations\n- **Speed Testing**: Measure API endpoint latency with visual quality indicators\n- **Import/Export**: Backup and restore configs with auto-rotation (keep 10 most recent)\n- **i18n Support**: Complete Chinese/English localization (UI, errors, tray)\n- **Claude Plugin Sync**: One-click apply/restore Claude plugin configurations\n\n**v3.6 Highlights**\n\n- Provider duplication & drag-and-drop sorting\n- Multi-endpoint management & custom config directory (cloud sync ready)\n- Granular model configuration (4-tier: Haiku/Sonnet/Opus/Custom)\n- WSL environment support with auto-sync on directory change\n- 100% hooks test coverage & complete architecture refactoring\n\n**System Features**\n\n- System tray with quick switching\n- Single instance daemon\n- Built-in auto-updater\n- Atomic writes with rollback protection\n\n## Download & Installation\n\n### System Requirements\n\n- **Windows**: Windows 10 and above\n- **macOS**: macOS 10.15 (Catalina) and above\n- **Linux**: Ubuntu 22.04+ / Debian 11+ / Fedora 34+ and other mainstream distributions\n\n### Windows Users\n\nDownload the latest `CC-Switch-v{version}-Windows.msi` installer or `CC-Switch-v{version}-Windows-Portable.zip` portable version from the [Releases](../../releases) page.\n\n### macOS Users\n\n**Method 1: Install via Homebrew (Recommended)**\n\n```bash\nbrew tap farion1231/ccswitch\nbrew install --cask cc-switch\n```\n\nUpdate:\n\n```bash\nbrew upgrade --cask cc-switch\n```\n\n**Method 2: Manual Download**\n\nDownload `CC-Switch-v{version}-macOS.zip` from the [Releases](../../releases) page and extract to use.\n\n> **Note**: Since the author doesn't have an Apple Developer account, you may see an \"unidentified developer\" warning on first launch. Please close it first, then go to \"System Settings\" â†’ \"Privacy & Security\" â†’ click \"Open Anyway\", and you'll be able to open it normally afterwards.\n\n### Arch Linux Users\n\n**Install via paru (Recommended)**\n\n```bash\nparu -S cc-switch-bin\n```\n\n### Linux Users\n\nDownload the latest Linux build from the [Releases](../../releases) page:\n\n- `CC-Switch-v{version}-Linux.deb` (Debian/Ubuntu)\n- `CC-Switch-v{version}-Linux.rpm` (Fedora/RHEL/openSUSE)\n- `CC-Switch-v{version}-Linux.AppImage` (Universal)\n- `CC-Switch-v{version}-Linux.flatpak` (Flatpak)\n\nFlatpak install & run:\n\n```bash\nflatpak install --user ./CC-Switch-v{version}-Linux.flatpak\nflatpak run com.ccswitch.desktop\n```\n\n## Quick Start\n\n### Basic Usage\n\n1. **Add Provider**: Click \"Add Provider\" â†’ Choose preset or create custom configuration\n2. **Switch Provider**:\n   - Main UI: Select provider â†’ Click \"Enable\"\n   - System Tray: Click provider name directly (instant effect)\n3. **Takes Effect**: Restart your terminal or Claude Code / Codex / Gemini clients to apply changes\n4. **Back to Official**: Select the \"Official Login\" preset (Claude/Codex) or \"Google Official\" preset (Gemini), restart the corresponding client, then follow its login/OAuth flow\n\n### MCP Management\n\n- **Location**: Click \"MCP\" button in top-right corner\n- **Add Server**:\n  - Use built-in templates (mcp-fetch, mcp-filesystem, etc.)\n  - Support stdio / http / sse transport types\n  - Configure independent MCP servers for different apps\n- **Enable/Disable**: Toggle switches to control which servers sync to live config\n- **Sync**: Enabled servers auto-sync to each app's live files\n- **Import/Export**: Import existing MCP servers from Claude/Codex/Gemini config files\n\n### Skills Management (v3.7.0 New)\n\n- **Location**: Click \"Skills\" button in top-right corner\n- **Discover Skills**:\n  - Auto-scan pre-configured GitHub repositories (Anthropic official, ComposioHQ, community, etc.)\n  - Add custom repositories (supports subdirectory scanning)\n- **Install Skills**: Click \"Install\" to one-click install to `~/.claude/skills/`\n- **Uninstall Skills**: Click \"Uninstall\" to safely remove and clean up state\n- **Manage Repositories**: Add/remove custom GitHub repositories\n\n### Prompts Management (v3.7.0 New)\n\n- **Location**: Click \"Prompts\" button in top-right corner\n- **Create Presets**:\n  - Create unlimited system prompt presets\n  - Use Markdown editor to write prompts (syntax highlighting + real-time preview)\n- **Switch Presets**: Select preset â†’ Click \"Activate\" to apply immediately\n- **Sync Mechanism**:\n  - Claude: `~/.claude/CLAUDE.md`\n  - Codex: `~/.codex/AGENTS.md`\n  - Gemini: `~/.gemini/GEMINI.md`\n- **Protection Mechanism**: Auto-save current prompt content before switching, preserves manual modifications\n\n### Configuration Files\n\n**Claude Code**\n\n- Live config: `~/.claude/settings.json` (or `claude.json`)\n- API key field: `env.ANTHROPIC_AUTH_TOKEN` or `env.ANTHROPIC_API_KEY`\n- MCP servers: `~/.claude.json` â†’ `mcpServers`\n\n**Codex**\n\n- Live config: `~/.codex/auth.json` (required) + `config.toml` (optional)\n- API key field: `OPENAI_API_KEY` in `auth.json`\n- MCP servers: `~/.codex/config.toml` â†’ `[mcp_servers]` tables\n\n**Gemini**\n\n- Live config: `~/.gemini/.env` (API key) + `~/.gemini/settings.json` (auth mode)\n- API key field: `GEMINI_API_KEY` or `GOOGLE_GEMINI_API_KEY` in `.env`\n- Environment variables: Support `GOOGLE_GEMINI_BASE_URL`, `GEMINI_MODEL`, etc.\n- MCP servers: `~/.gemini/settings.json` â†’ `mcpServers`\n- Tray quick switch: Each provider switch rewrites `~/.gemini/.env`, no need to restart Gemini CLI\n\n**CC Switch Storage (v3.8.0 New Architecture)**\n\n- Database (SSOT): `~/.cc-switch/cc-switch.db` (SQLite, stores providers, MCP, Prompts, Skills)\n- Local settings: `~/.cc-switch/settings.json` (device-level settings)\n- Backups: `~/.cc-switch/backups/` (auto-rotate, keep 10)\n\n### Cloud Sync Setup\n\n1. Go to Settings â†’ \"Custom Configuration Directory\"\n2. Choose your cloud sync folder (Dropbox, OneDrive, iCloud, etc.)\n3. Restart app to apply\n4. Repeat on other devices to enable cross-device sync\n\n> **Note**: First launch auto-imports existing Claude/Codex configs as default provider.\n\n## Architecture Overview\n\n### Design Principles\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    Frontend (React + TS)                    â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚  â”‚ Components  â”‚  â”‚    Hooks     â”‚  â”‚  TanStack Query  â”‚    â”‚\nâ”‚  â”‚   (UI)      â”‚â”€â”€â”‚ (Bus. Logic) â”‚â”€â”€â”‚   (Cache/Sync)   â”‚    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                         â”‚ Tauri IPC\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                  Backend (Tauri + Rust)                     â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚  â”‚  Commands   â”‚  â”‚   Services   â”‚  â”‚  Models/Config   â”‚    â”‚\nâ”‚  â”‚ (API Layer) â”‚â”€â”€â”‚ (Bus. Layer) â”‚â”€â”€â”‚     (Data)       â”‚    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Core Design Patterns**\n\n- **SSOT** (Single Source of Truth): All data stored in `~/.cc-switch/cc-switch.db` (SQLite)\n- **Dual-layer Storage**: SQLite for syncable data, JSON for device-level settings\n- **Dual-way Sync**: Write to live files on switch, backfill from live when editing active provider\n- **Atomic Writes**: Temp file + rename pattern prevents config corruption\n- **Concurrency Safe**: Mutex-protected database connection avoids race conditions\n- **Layered Architecture**: Clear separation (Commands â†’ Services â†’ DAO â†’ Database)\n\n**Key Components**\n\n- **ProviderService**: Provider CRUD, switching, backfill, sorting\n- **McpService**: MCP server management, import/export, live file sync\n- **ConfigService**: Config import/export, backup rotation\n- **SpeedtestService**: API endpoint latency measurement\n\n**v3.6 Refactoring**\n\n- Backend: 5-phase refactoring (error handling â†’ command split â†’ tests â†’ services â†’ concurrency)\n- Frontend: 4-stage refactoring (test infra â†’ hooks â†’ components â†’ cleanup)\n- Testing: 100% hooks coverage + integration tests (vitest + MSW)\n\n## Development\n\n### Environment Requirements\n\n- Node.js 18+\n- pnpm 8+\n- Rust 1.85+\n- Tauri CLI 2.8+\n\n### Development Commands\n\n```bash\n# Install dependencies\npnpm install\n\n# Dev mode (hot reload)\npnpm dev\n\n# Type check\npnpm typecheck\n\n# Format code\npnpm format\n\n# Check code format\npnpm format:check\n\n# Run frontend unit tests\npnpm test:unit\n\n# Run tests in watch mode (recommended for development)\npnpm test:unit:watch\n\n# Build application\npnpm build\n\n# Build debug version\npnpm tauri build --debug\n```\n\n### Rust Backend Development\n\n```bash\ncd src-tauri\n\n# Format Rust code\ncargo fmt\n\n# Run clippy checks\ncargo clippy\n\n# Run backend tests\ncargo test\n\n# Run specific tests\ncargo test test_name\n\n# Run tests with test-hooks feature\ncargo test --features test-hooks\n```\n\n### Testing Guide (v3.6 New)\n\n**Frontend Testing**:\n\n- Uses **vitest** as test framework\n- Uses **MSW (Mock Service Worker)** to mock Tauri API calls\n- Uses **@testing-library/react** for component testing\n\n**Test Coverage**:\n\n- Hooks unit tests (100% coverage)\n  - `useProviderActions` - Provider operations\n  - `useMcpActions` - MCP management\n  - `useSettings` series - Settings management\n  - `useImportExport` - Import/export\n- Integration tests\n  - App main application flow\n  - SettingsDialog complete interaction\n  - MCP panel functionality\n\n**Running Tests**:\n\n```bash\n# Run all tests\npnpm test:unit\n\n# Watch mode (auto re-run)\npnpm test:unit:watch\n\n# With coverage report\npnpm test:unit --coverage\n```\n\n## Tech Stack\n\n**Frontend**: React 18 Â· TypeScript Â· Vite Â· TailwindCSS 4 Â· TanStack Query v5 Â· react-i18next Â· react-hook-form Â· zod Â· shadcn/ui Â· @dnd-kit\n\n**Backend**: Tauri 2.8 Â· Rust Â· serde Â· tokio Â· thiserror Â· tauri-plugin-updater/process/dialog/store/log\n\n**Testing**: vitest Â· MSW Â· @testing-library/react\n\n## Project Structure\n\n```\nâ”œâ”€â”€ src/                      # Frontend (React + TypeScript)\nâ”‚   â”œâ”€â”€ components/           # UI components (providers/settings/mcp/ui)\nâ”‚   â”œâ”€â”€ hooks/                # Custom hooks (business logic)\nâ”‚   â”œâ”€â”€ lib/\nâ”‚   â”‚   â”œâ”€â”€ api/              # Tauri API wrapper (type-safe)\nâ”‚   â”‚   â””â”€â”€ query/            # TanStack Query config\nâ”‚   â”œâ”€â”€ i18n/locales/         # Translations (zh/en)\nâ”‚   â”œâ”€â”€ config/               # Presets (providers/mcp)\nâ”‚   â””â”€â”€ types/                # TypeScript definitions\nâ”œâ”€â”€ src-tauri/                # Backend (Rust)\nâ”‚   â””â”€â”€ src/\nâ”‚       â”œâ”€â”€ commands/         # Tauri command layer (by domain)\nâ”‚       â”œâ”€â”€ services/         # Business logic layer\nâ”‚       â”œâ”€â”€ app_config.rs     # Config data models\nâ”‚       â”œâ”€â”€ provider.rs       # Provider domain models\nâ”‚       â”œâ”€â”€ mcp.rs            # MCP sync & validation\nâ”‚       â””â”€â”€ lib.rs            # App entry & tray menu\nâ”œâ”€â”€ tests/                    # Frontend tests\nâ”‚   â”œâ”€â”€ hooks/                # Unit tests\nâ”‚   â””â”€â”€ components/           # Integration tests\nâ””â”€â”€ assets/                   # Screenshots & partner resources\n```\n\n## Changelog\n\nSee [CHANGELOG.md](CHANGELOG.md) for version update details.\n\n## Legacy Electron Version\n\n[Releases](../../releases) retains v2.0.3 legacy Electron version\n\nIf you need legacy Electron code, you can pull the electron-legacy branch\n\n## Contributing\n\nIssues and suggestions are welcome!\n\nBefore submitting PRs, please ensure:\n\n- Pass type check: `pnpm typecheck`\n- Pass format check: `pnpm format:check`\n- Pass unit tests: `pnpm test:unit`\n- ğŸ’¡ For new features, please open an issue for discussion before submitting a PR\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=farion1231/cc-switch&type=Date)](https://www.star-history.com/#farion1231/cc-switch&Date)\n\n## License\n\nMIT Â© Jason Young\n",
      "stars_today": 185
    },
    {
      "id": 955620917,
      "name": "context7",
      "full_name": "upstash/context7",
      "description": "Context7 MCP Server -- Up-to-date code documentation for LLMs and AI code editors",
      "html_url": "https://github.com/upstash/context7",
      "stars": 43364,
      "forks": 2087,
      "language": "TypeScript",
      "topics": [
        "llm",
        "mcp",
        "mcp-server",
        "vibe-coding"
      ],
      "created_at": "2025-03-26T23:40:39Z",
      "updated_at": "2026-01-25T02:27:22Z",
      "pushed_at": "2026-01-24T22:27:07Z",
      "open_issues": 98,
      "owner": {
        "login": "upstash",
        "avatar_url": "https://avatars.githubusercontent.com/u/74989412?v=4"
      },
      "readme": "![Cover](https://github.com/upstash/context7/blob/master/public/cover.png?raw=true)\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=context7&config=eyJ1cmwiOiJodHRwczovL21jcC5jb250ZXh0Ny5jb20vbWNwIn0%3D)\n\n# Context7 MCP - Up-to-date Code Docs For Any Prompt\n\n[![Website](https://img.shields.io/badge/Website-context7.com-blue)](https://context7.com) [![smithery badge](https://smithery.ai/badge/@upstash/context7-mcp)](https://smithery.ai/server/@upstash/context7-mcp) [![NPM Version](https://img.shields.io/npm/v/%40upstash%2Fcontext7-mcp?color=red)](https://www.npmjs.com/package/@upstash/context7-mcp) [![MIT licensed](https://img.shields.io/npm/l/%40upstash%2Fcontext7-mcp)](./LICENSE)\n\n[![ç¹é«”ä¸­æ–‡](https://img.shields.io/badge/docs-ç¹é«”ä¸­æ–‡-yellow)](./i18n/README.zh-TW.md) [![ç®€ä½“ä¸­æ–‡](https://img.shields.io/badge/docs-ç®€ä½“ä¸­æ–‡-yellow)](./i18n/README.zh-CN.md) [![æ—¥æœ¬èª](https://img.shields.io/badge/docs-æ—¥æœ¬èª-b7003a)](./i18n/README.ja.md) [![í•œêµ­ì–´ ë¬¸ì„œ](https://img.shields.io/badge/docs-í•œêµ­ì–´-green)](./i18n/README.ko.md) [![DocumentaciÃ³n en EspaÃ±ol](https://img.shields.io/badge/docs-EspaÃ±ol-orange)](./i18n/README.es.md) [![Documentation en FranÃ§ais](https://img.shields.io/badge/docs-FranÃ§ais-blue)](./i18n/README.fr.md) [![DocumentaÃ§Ã£o em PortuguÃªs (Brasil)](<https://img.shields.io/badge/docs-PortuguÃªs%20(Brasil)-purple>)](./i18n/README.pt-BR.md) [![Documentazione in italiano](https://img.shields.io/badge/docs-Italian-red)](./i18n/README.it.md) [![Dokumentasi Bahasa Indonesia](https://img.shields.io/badge/docs-Bahasa%20Indonesia-pink)](./i18n/README.id-ID.md) [![Dokumentation auf Deutsch](https://img.shields.io/badge/docs-Deutsch-darkgreen)](./i18n/README.de.md) [![Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ](https://img.shields.io/badge/docs-Ğ ÑƒÑÑĞºĞ¸Ğ¹-darkblue)](./i18n/README.ru.md) [![Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ° Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ñ–Ñ](https://img.shields.io/badge/docs-Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°-lightblue)](./i18n/README.uk.md) [![TÃ¼rkÃ§e DokÃ¼man](https://img.shields.io/badge/docs-TÃ¼rkÃ§e-blue)](./i18n/README.tr.md) [![Arabic Documentation](https://img.shields.io/badge/docs-Arabic-white)](./i18n/README.ar.md) [![Tiáº¿ng Viá»‡t](https://img.shields.io/badge/docs-Tiáº¿ng%20Viá»‡t-red)](./i18n/README.vi.md)\n\n## âŒ Without Context7\n\nLLMs rely on outdated or generic information about the libraries you use. You get:\n\n- âŒ Code examples are outdated and based on year-old training data\n- âŒ Hallucinated APIs that don't even exist\n- âŒ Generic answers for old package versions\n\n## âœ… With Context7\n\nContext7 MCP pulls up-to-date, version-specific documentation and code examples straight from the source â€” and places them directly into your prompt.\n\nAdd `use context7` to your prompt (or [set up a rule](#add-a-rule) to auto-invoke):\n\n```txt\nCreate a Next.js middleware that checks for a valid JWT in cookies\nand redirects unauthenticated users to `/login`. use context7\n```\n\n```txt\nConfigure a Cloudflare Worker script to cache\nJSON API responses for five minutes. use context7\n```\n\nContext7 fetches up-to-date code examples and documentation right into your LLM's context. No tab-switching, no hallucinated APIs that don't exist, no outdated code generation.\n\n## Installation\n\n> [!NOTE]\n> **API Key Recommended**: Get a free API key at [context7.com/dashboard](https://context7.com/dashboard) for higher rate limits.\n\n<details>\n<summary><b>Install in Cursor</b></summary>\n\nGo to: `Settings` -> `Cursor Settings` -> `MCP` -> `Add new global MCP server`\n\nPasting the following configuration into your Cursor `~/.cursor/mcp.json` file is the recommended approach. You may also install in a specific project by creating `.cursor/mcp.json` in your project folder. See [Cursor MCP docs](https://docs.cursor.com/context/model-context-protocol) for more info.\n\n> Since Cursor 1.0, you can click the install button below for instant one-click installation.\n\n#### Cursor Remote Server Connection\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=context7&config=eyJ1cmwiOiJodHRwczovL21jcC5jb250ZXh0Ny5jb20vbWNwIn0%3D)\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"url\": \"https://mcp.context7.com/mcp\",\n      \"headers\": {\n        \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n      }\n    }\n  }\n}\n```\n\n#### Cursor Local Server Connection\n\n[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=context7&config=eyJjb21tYW5kIjoibnB4IC15IEB1cHN0YXNoL2NvbnRleHQ3LW1jcCJ9)\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary><b>Install in Claude Code</b></summary>\n\nRun this command. See [Claude Code MCP docs](https://code.claude.com/docs/en/mcp) for more info.\n\n#### Claude Code Local Server Connection\n\n```sh\nclaude mcp add context7 -- npx -y @upstash/context7-mcp --api-key YOUR_API_KEY\n```\n\n#### Claude Code Remote Server Connection\n\n```sh\nclaude mcp add --header \"CONTEXT7_API_KEY: YOUR_API_KEY\" --transport http context7 https://mcp.context7.com/mcp\n```\n\n</details>\n\n<details>\n<summary><b>Install in Opencode</b></summary>\n\nAdd this to your Opencode configuration file. See [Opencode MCP docs](https://opencode.ai/docs/mcp-servers) for more info.\n\n#### Opencode Remote Server Connection\n\n```json\n\"mcp\": {\n  \"context7\": {\n    \"type\": \"remote\",\n    \"url\": \"https://mcp.context7.com/mcp\",\n    \"headers\": {\n      \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n    },\n    \"enabled\": true\n  }\n}\n```\n\n#### Opencode Local Server Connection\n\n```json\n{\n  \"mcp\": {\n    \"context7\": {\n      \"type\": \"local\",\n      \"command\": [\"npx\", \"-y\", \"@upstash/context7-mcp\", \"--api-key\", \"YOUR_API_KEY\"],\n      \"enabled\": true\n    }\n  }\n}\n```\n\n</details>\n\n**[Other IDEs and Clients â†’](https://context7.com/docs/resources/all-clients)**\n\n<details>\n<summary><b>OAuth Authentication</b></summary>\n\nContext7 MCP server supports OAuth 2.0 authentication for MCP clients that implement the [MCP OAuth specification](https://modelcontextprotocol.io/specification/2025-03-26/basic/authorization).\n\nTo use OAuth, change the endpoint from `/mcp` to `/mcp/oauth` in your client configuration:\n\n```diff\n- \"url\": \"https://mcp.context7.com/mcp\"\n+ \"url\": \"https://mcp.context7.com/mcp/oauth\"\n```\n\nOAuth is only available for remote HTTP connections. For local MCP connections using stdio transport, use API key authentication instead.\n\n</details>\n\n## Important Tips\n\n### Add a Rule\n\nTo avoid typing `use context7` in every prompt, add a rule to your MCP client to automatically invoke Context7 for code-related questions:\n\n- **Cursor**: `Cursor Settings > Rules`\n- **Claude Code**: `CLAUDE.md`\n- Or the equivalent in your MCP client\n\n**Example rule:**\n\n```txt\nAlways use Context7 MCP when I need library/API documentation, code generation, setup or configuration steps without me having to explicitly ask.\n```\n\n### Use Library Id\n\nIf you already know exactly which library you want to use, add its Context7 ID to your prompt. That way, Context7 MCP server can skip the library-matching step and directly continue with retrieving docs.\n\n```txt\nImplement basic authentication with Supabase. use library /supabase/supabase for API and docs.\n```\n\nThe slash syntax tells the MCP tool exactly which library to load docs for.\n\n### Specify a Version\n\nTo get documentation for a specific library version, just mention the version in your prompt:\n\n```txt\nHow do I set up Next.js 14 middleware? use context7\n```\n\nContext7 will automatically match the appropriate version.\n\n## Available Tools\n\nContext7 MCP provides the following tools that LLMs can use:\n\n- `resolve-library-id`: Resolves a general library name into a Context7-compatible library ID.\n  - `query` (required): The user's question or task (used to rank results by relevance)\n  - `libraryName` (required): The name of the library to search for\n\n- `query-docs`: Retrieves documentation for a library using a Context7-compatible library ID.\n  - `libraryId` (required): Exact Context7-compatible library ID (e.g., `/mongodb/docs`, `/vercel/next.js`)\n  - `query` (required): The question or task to get relevant documentation for\n\n## More Documentation\n\n- [More MCP Clients](https://context7.com/docs/resources/all-clients) - Installation for 30+ clients\n- [Adding Libraries](https://context7.com/docs/adding-libraries) - Submit your library to Context7\n- [Troubleshooting](https://context7.com/docs/resources/troubleshooting) - Common issues and solutions\n- [API Reference](https://context7.com/docs/api-guide) - REST API documentation\n- [Developer Guide](https://context7.com/docs/resources/developer) - Run Context7 MCP locally\n\n## Disclaimer\n\n1- Context7 projects are community-contributed and while we strive to maintain high quality, we cannot guarantee the accuracy, completeness, or security of all library documentation. Projects listed in Context7 are developed and maintained by their respective owners, not by Context7. If you encounter any suspicious, inappropriate, or potentially harmful content, please use the \"Report\" button on the project page to notify us immediately. We take all reports seriously and will review flagged content promptly to maintain the integrity and safety of our platform. By using Context7, you acknowledge that you do so at your own discretion and risk.\n\n2- This repository hosts the MCP serverâ€™s source code. The supporting components â€” API backend, parsing engine, and crawling engine â€” are private and not part of this repository.\n\n## ğŸ¤ Connect with Us\n\nStay updated and join our community:\n\n- ğŸ“¢ Follow us on [X](https://x.com/context7ai) for the latest news and updates\n- ğŸŒ Visit our [Website](https://context7.com)\n- ğŸ’¬ Join our [Discord Community](https://upstash.com/discord)\n\n## ğŸ“º Context7 In Media\n\n- [Better Stack: \"Free Tool Makes Cursor 10x Smarter\"](https://youtu.be/52FC3qObp9E)\n- [Cole Medin: \"This is Hands Down the BEST MCP Server for AI Coding Assistants\"](https://www.youtube.com/watch?v=G7gK8H6u7Rs)\n- [Income Stream Surfers: \"Context7 + SequentialThinking MCPs: Is This AGI?\"](https://www.youtube.com/watch?v=-ggvzyLpK6o)\n- [Julian Goldie SEO: \"Context7: New MCP AI Agent Update\"](https://www.youtube.com/watch?v=CTZm6fBYisc)\n- [JeredBlu: \"Context 7 MCP: Get Documentation Instantly + VS Code Setup\"](https://www.youtube.com/watch?v=-ls0D-rtET4)\n- [Income Stream Surfers: \"Context7: The New MCP Server That Will CHANGE AI Coding\"](https://www.youtube.com/watch?v=PS-2Azb-C3M)\n- [AICodeKing: \"Context7 + Cline & RooCode: This MCP Server Makes CLINE 100X MORE EFFECTIVE!\"](https://www.youtube.com/watch?v=qZfENAPMnyo)\n- [Sean Kochel: \"5 MCP Servers For Vibe Coding Glory (Just Plug-In & Go)\"](https://www.youtube.com/watch?v=LqTQi8qexJM)\n\n## â­ Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=upstash/context7&type=Date)](https://www.star-history.com/#upstash/context7&Date)\n\n## ğŸ“„ License\n\nMIT\n",
      "stars_today": 166
    },
    {
      "id": 1000362065,
      "name": "awesome-copilot",
      "full_name": "github/awesome-copilot",
      "description": "Community-contributed instructions, prompts, and configurations to help you make the most of GitHub Copilot.",
      "html_url": "https://github.com/github/awesome-copilot",
      "stars": 18825,
      "forks": 2148,
      "language": "JavaScript",
      "topics": [
        "ai",
        "github-copilot",
        "hacktoberfest",
        "prompt-engineering"
      ],
      "created_at": "2025-06-11T16:57:39Z",
      "updated_at": "2026-01-25T02:27:13Z",
      "pushed_at": "2026-01-23T00:07:45Z",
      "open_issues": 14,
      "owner": {
        "login": "github",
        "avatar_url": "https://avatars.githubusercontent.com/u/9919?v=4"
      },
      "readme": "# ğŸ¤– Awesome GitHub Copilot Customizations\n[![Powered by Awesome Copilot](https://img.shields.io/badge/Powered_by-Awesome_Copilot-blue?logo=githubcopilot)](https://aka.ms/awesome-github-copilot) [![GitHub contributors from allcontributors.org](https://img.shields.io/github/all-contributors/github/awesome-copilot?color=ee8449)](#contributors-)\n\n\nA community created collection of custom agents, prompts, and instructions to supercharge your GitHub Copilot experience across different domains, languages, and use cases.\n\n## ğŸš€ What is Awesome GitHub Copilot?\n\nThis repository provides a comprehensive toolkit for enhancing GitHub Copilot with specialized:\n\n- **ğŸ‘‰ [Awesome Agents](docs/README.agents.md)** - Specialized GitHub Copilot agents that integrate with MCP servers to provide enhanced capabilities for specific workflows and tools\n- **ğŸ‘‰ [Awesome Prompts](docs/README.prompts.md)** - Focused, task-specific prompts for generating code, documentation, and solving specific problems\n- **ğŸ‘‰ [Awesome Instructions](docs/README.instructions.md)** - Comprehensive coding standards and best practices that apply to specific file patterns or entire projects\n- **ğŸ‘‰ [Awesome Skills](docs/README.skills.md)** - Self-contained folders with instructions and bundled resources that enhance AI capabilities for specialized tasks\n- **ğŸ‘‰ [Awesome Collections](docs/README.collections.md)** - Curated collections of related prompts, instructions, agents, and skills organized around specific themes and workflows\n\n## ğŸŒŸ Featured Collections\n\nDiscover our curated collections of prompts, instructions, and agents organized around specific themes and workflows.\n\n| Name | Description | Items | Tags |\n| ---- | ----------- | ----- | ---- |\n| [Awesome Copilot](collections/awesome-copilot.md) | Meta prompts that help you discover and generate curated GitHub Copilot agents, collections, instructions, prompts, and skills. | 5 items | github-copilot, discovery, meta, prompt-engineering, agents |\n| [Copilot SDK](collections/copilot-sdk.md) | Build applications with the GitHub Copilot SDK across multiple programming languages. Includes comprehensive instructions for C#, Go, Node.js/TypeScript, and Python to help you create AI-powered applications. | 4 items | copilot-sdk, sdk, csharp, go, nodejs, typescript, python, ai, github-copilot |\n| [Partners](collections/partners.md) | Custom agents that have been created by GitHub partners | 20 items | devops, security, database, cloud, infrastructure, observability, feature-flags, cicd, migration, performance |\n\n\n## MCP Server\n\nTo make it easy to add these customizations to your editor, we have created a [MCP Server](https://developer.microsoft.com/blog/announcing-awesome-copilot-mcp-server) that provides a prompt for searching and installing prompts, instructions, agents, and skills directly from this repository. You'll need to have Docker installed and running to run the server.\n\n[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install-0098FF?logo=visualstudiocode&logoColor=white)](https://aka.ms/awesome-copilot/mcp/vscode) [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install-24bfa5?logo=visualstudiocode&logoColor=white)](https://aka.ms/awesome-copilot/mcp/vscode-insiders) [![Install in Visual Studio](https://img.shields.io/badge/Visual_Studio-Install-C16FDE?logo=visualstudio&logoColor=white)](https://aka.ms/awesome-copilot/mcp/vs)\n\n<details>\n<summary>Show MCP Server JSON configuration</summary>\n\n```json\n{\n  \"servers\": {\n    \"awesome-copilot\": {\n      \"type\": \"stdio\",\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"ghcr.io/microsoft/mcp-dotnet-samples/awesome-copilot:latest\"\n      ]\n    }\n  }\n}\n```\n\n</details>\n\n## ğŸ”§ How to Use\n\n### ğŸ¤– Custom Agents\n\nCustom agents can be used in Copilot coding agent (CCA), VS Code, and Copilot CLI (coming soon). For CCA, when assigning an issue to Copilot, select the custom agent from the provided list. In VS Code, you can activate the custom agent in the agents session, alongside built-in agents like Plan and Agent.\n\n### ğŸ¯ Prompts\n\nUse the `/` command in GitHub Copilot Chat to access prompts:\n\n```plaintext\n/awesome-copilot create-readme\n```\n\n### ğŸ“‹ Instructions\n\nInstructions automatically apply to files based on their patterns and provide contextual guidance for coding standards, frameworks, and best practices.\n\n## ğŸ¯ Why Use Awesome GitHub Copilot?\n\n- **Productivity**: Pre-built agents, prompts and instructions save time and provide consistent results.\n- **Best Practices**: Benefit from community-curated coding standards and patterns.\n- **Specialized Assistance**: Access expert-level guidance through specialized custom agents.\n- **Continuous Learning**: Stay updated with the latest patterns and practices across technologies.\n\n## ğŸ¤ Contributing\n\nWe welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details on how to:\n\n- Add new prompts, instructions, agents, or skills\n- Improve existing content\n- Report issues or suggest enhancements\n\nFor AI coding agents working with this project, refer to [AGENTS.md](AGENTS.md) for detailed technical guidance on development workflows, setup commands, and contribution standards.\n\n### Quick Contribution Guide\n\n1. Follow our file naming conventions and frontmatter requirements\n2. Test your contributions thoroughly\n3. Update the appropriate README tables\n4. Submit a pull request with a clear description\n\n## ğŸ“– Repository Structure\n\n```plaintext\nâ”œâ”€â”€ prompts/          # Task-specific prompts (.prompt.md)\nâ”œâ”€â”€ instructions/     # Coding standards and best practices (.instructions.md)\nâ”œâ”€â”€ agents/           # AI personas and specialized modes (.agent.md)\nâ”œâ”€â”€ collections/      # Curated collections of related items (.collection.yml)\nâ”œâ”€â”€ scripts/          # Utility scripts for maintenance\nâ””â”€â”€ skills/           # AI capabilities for specialized tasks\n```\n\n## ğŸ“„ License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## ğŸ›¡ï¸ Security & Support\n\n- **Security Issues**: Please see our [Security Policy](SECURITY.md)\n- **Support**: Check our [Support Guide](SUPPORT.md) for getting help\n- **Code of Conduct**: We follow the [Contributor Covenant](CODE_OF_CONDUCT.md)\n\n## â„¹ï¸ Disclaimer\n\nThe customizations in this repository are sourced from and created by third-party developers. GitHub does not verify, endorse, or guarantee the functionality or security of these agents. Please carefully inspect any agent and its documentation before installing to understand permissions it may require and actions it may perform.\n\n---\n\n**Ready to supercharge your coding experience?** Start exploring our [prompts](docs/README.prompts.md), [instructions](docs/README.instructions.md), and [custom agents](docs/README.agents.md)!\n\n## Contributors âœ¨\n\nThanks goes to these wonderful people ([emoji key](./CONTRIBUTING.md#contributors-recognition)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.aaron-powell.com/\"><img src=\"https://avatars.githubusercontent.com/u/434140?v=4?s=100\" width=\"100px;\" alt=\"Aaron Powell\"/><br /><sub><b>Aaron Powell</b></sub></a><br /><a href=\"#agents-aaronpowell\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=aaronpowell\" title=\"Code\">ğŸ’»</a> <a href=\"#collections-aaronpowell\" title=\"Curated collections of related content\">ğŸ</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=aaronpowell\" title=\"Documentation\">ğŸ“–</a> <a href=\"#infra-aaronpowell\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">ğŸš‡</a> <a href=\"#instructions-aaronpowell\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#maintenance-aaronpowell\" title=\"Maintenance\">ğŸš§</a> <a href=\"#prompts-aaronpowell\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://codemilltech.com/\"><img src=\"https://avatars.githubusercontent.com/u/2053639?v=4?s=100\" width=\"100px;\" alt=\"Matt Soucoup\"/><br /><sub><b>Matt Soucoup</b></sub></a><br /><a href=\"#infra-codemillmatt\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">ğŸš‡</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.buymeacoffee.com/troystaylor\"><img src=\"https://avatars.githubusercontent.com/u/44444967?v=4?s=100\" width=\"100px;\" alt=\"Troy Simeon Taylor\"/><br /><sub><b>Troy Simeon Taylor</b></sub></a><br /><a href=\"#agents-troystaylor\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#collections-troystaylor\" title=\"Curated collections of related content\">ğŸ</a> <a href=\"#instructions-troystaylor\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-troystaylor\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/abbas133\"><img src=\"https://avatars.githubusercontent.com/u/7757139?v=4?s=100\" width=\"100px;\" alt=\"Abbas\"/><br /><sub><b>Abbas</b></sub></a><br /><a href=\"#agents-abbas133\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#instructions-abbas133\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://calva.io/\"><img src=\"https://avatars.githubusercontent.com/u/30010?v=4?s=100\" width=\"100px;\" alt=\"Peter StrÃ¶mberg\"/><br /><sub><b>Peter StrÃ¶mberg</b></sub></a><br /><a href=\"#agents-PEZ\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#collections-PEZ\" title=\"Curated collections of related content\">ğŸ</a> <a href=\"#instructions-PEZ\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-PEZ\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://danielscottraynsford.com/\"><img src=\"https://avatars.githubusercontent.com/u/7589164?v=4?s=100\" width=\"100px;\" alt=\"Daniel Scott-Raynsford\"/><br /><sub><b>Daniel Scott-Raynsford</b></sub></a><br /><a href=\"#agents-PlagueHO\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#collections-PlagueHO\" title=\"Curated collections of related content\">ğŸ</a> <a href=\"#instructions-PlagueHO\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-PlagueHO\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jhauga\"><img src=\"https://avatars.githubusercontent.com/u/10998676?v=4?s=100\" width=\"100px;\" alt=\"John Haugabook\"/><br /><sub><b>John Haugabook</b></sub></a><br /><a href=\"#instructions-jhauga\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-jhauga\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://witter.cz/@pavel\"><img src=\"https://avatars.githubusercontent.com/u/7853836?v=4?s=100\" width=\"100px;\" alt=\"Pavel Simsa\"/><br /><sub><b>Pavel Simsa</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=psimsa\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://digitarald.de/\"><img src=\"https://avatars.githubusercontent.com/u/8599?v=4?s=100\" width=\"100px;\" alt=\"Harald Kirschner\"/><br /><sub><b>Harald Kirschner</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=digitarald\" title=\"Code\">ğŸ’»</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=digitarald\" title=\"Documentation\">ğŸ“–</a> <a href=\"#maintenance-digitarald\" title=\"Maintenance\">ğŸš§</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://mubaidr.js.org/\"><img src=\"https://avatars.githubusercontent.com/u/2222702?v=4?s=100\" width=\"100px;\" alt=\"Muhammad Ubaid Raza\"/><br /><sub><b>Muhammad Ubaid Raza</b></sub></a><br /><a href=\"#agents-mubaidr\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#instructions-mubaidr\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tmeschter\"><img src=\"https://avatars.githubusercontent.com/u/10506730?v=4?s=100\" width=\"100px;\" alt=\"Tom Meschter\"/><br /><sub><b>Tom Meschter</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=tmeschter\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.aungmyokyaw.com/\"><img src=\"https://avatars.githubusercontent.com/u/9404824?v=4?s=100\" width=\"100px;\" alt=\"Aung Myo Kyaw\"/><br /><sub><b>Aung Myo Kyaw</b></sub></a><br /><a href=\"#agents-AungMyoKyaw\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#prompts-AungMyoKyaw\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/JasonYeMSFT\"><img src=\"https://avatars.githubusercontent.com/u/39359541?v=4?s=100\" width=\"100px;\" alt=\"JasonYeMSFT\"/><br /><sub><b>JasonYeMSFT</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=JasonYeMSFT\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/jrc356/\"><img src=\"https://avatars.githubusercontent.com/u/37387479?v=4?s=100\" width=\"100px;\" alt=\"Jon Corbin\"/><br /><sub><b>Jon Corbin</b></sub></a><br /><a href=\"#agents-Jrc356\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#prompts-Jrc356\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/troytaylor-msft\"><img src=\"https://avatars.githubusercontent.com/u/248058374?v=4?s=100\" width=\"100px;\" alt=\"troytaylor-msft\"/><br /><sub><b>troytaylor-msft</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=troytaylor-msft\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://delatorre.dev/\"><img src=\"https://avatars.githubusercontent.com/u/38289677?v=4?s=100\" width=\"100px;\" alt=\"Emerson Delatorre\"/><br /><sub><b>Emerson Delatorre</b></sub></a><br /><a href=\"#instructions-fazedordecodigo\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/burkeholland\"><img src=\"https://avatars.githubusercontent.com/u/686963?v=4?s=100\" width=\"100px;\" alt=\"Burke Holland\"/><br /><sub><b>Burke Holland</b></sub></a><br /><a href=\"#agents-burkeholland\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#infra-burkeholland\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">ğŸš‡</a> <a href=\"#instructions-burkeholland\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-burkeholland\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://yaooqinn.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/8326978?v=4?s=100\" width=\"100px;\" alt=\"Kent Yao\"/><br /><sub><b>Kent Yao</b></sub></a><br /><a href=\"#instructions-yaooqinn\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-yaooqinn\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.devprodlogs.com/\"><img src=\"https://avatars.githubusercontent.com/u/51440732?v=4?s=100\" width=\"100px;\" alt=\"Daniel Meppiel\"/><br /><sub><b>Daniel Meppiel</b></sub></a><br /><a href=\"#prompts-danielmeppiel\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yeelam-gordon\"><img src=\"https://avatars.githubusercontent.com/u/73506701?v=4?s=100\" width=\"100px;\" alt=\"Gordon Lam\"/><br /><sub><b>Gordon Lam</b></sub></a><br /><a href=\"#instructions-yeelam-gordon\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.madskristensen.net/\"><img src=\"https://avatars.githubusercontent.com/u/1258877?v=4?s=100\" width=\"100px;\" alt=\"Mads Kristensen\"/><br /><sub><b>Mads Kristensen</b></sub></a><br /><a href=\"#instructions-madskristensen\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://ks6088ts.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/1254960?v=4?s=100\" width=\"100px;\" alt=\"Shinji Takenaka\"/><br /><sub><b>Shinji Takenaka</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=ks6088ts\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/spectatora\"><img src=\"https://avatars.githubusercontent.com/u/1385755?v=4?s=100\" width=\"100px;\" alt=\"spectatora\"/><br /><sub><b>spectatora</b></sub></a><br /><a href=\"#agents-spectatora\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=spectatora\" title=\"Code\">ğŸ’»</a> <a href=\"#maintenance-spectatora\" title=\"Maintenance\">ğŸš§</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sinedied\"><img src=\"https://avatars.githubusercontent.com/u/593151?v=4?s=100\" width=\"100px;\" alt=\"Yohan Lasorsa\"/><br /><sub><b>Yohan Lasorsa</b></sub></a><br /><a href=\"#instructions-sinedied\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-sinedied\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/VamshiVerma\"><img src=\"https://avatars.githubusercontent.com/u/21999324?v=4?s=100\" width=\"100px;\" alt=\"Vamshi Verma\"/><br /><sub><b>Vamshi Verma</b></sub></a><br /><a href=\"#instructions-VamshiVerma\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-VamshiVerma\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://montemagno.com/\"><img src=\"https://avatars.githubusercontent.com/u/1676321?v=4?s=100\" width=\"100px;\" alt=\"James Montemagno\"/><br /><sub><b>James Montemagno</b></sub></a><br /><a href=\"#agents-jamesmontemagno\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=jamesmontemagno\" title=\"Documentation\">ğŸ“–</a> <a href=\"#instructions-jamesmontemagno\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-jamesmontemagno\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://twitter.com/alefragnani\"><img src=\"https://avatars.githubusercontent.com/u/3781424?v=4?s=100\" width=\"100px;\" alt=\"Alessandro Fragnani\"/><br /><sub><b>Alessandro Fragnani</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=alefragnani\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/ambilykk/\"><img src=\"https://avatars.githubusercontent.com/u/10282550?v=4?s=100\" width=\"100px;\" alt=\"Ambily\"/><br /><sub><b>Ambily</b></sub></a><br /><a href=\"#agents-ambilykk\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#instructions-ambilykk\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/krushideep\"><img src=\"https://avatars.githubusercontent.com/u/174652083?v=4?s=100\" width=\"100px;\" alt=\"krushideep\"/><br /><sub><b>krushideep</b></sub></a><br /><a href=\"#prompts-krushideep\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mihsoft\"><img src=\"https://avatars.githubusercontent.com/u/53946345?v=4?s=100\" width=\"100px;\" alt=\"devopsfan\"/><br /><sub><b>devopsfan</b></sub></a><br /><a href=\"#agents-mihsoft\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://tgrall.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/541250?v=4?s=100\" width=\"100px;\" alt=\"Tugdual Grall\"/><br /><sub><b>Tugdual Grall</b></sub></a><br /><a href=\"#instructions-tgrall\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-tgrall\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.promptboost.dev/\"><img src=\"https://avatars.githubusercontent.com/u/5461862?v=4?s=100\" width=\"100px;\" alt=\"Oren Me\"/><br /><sub><b>Oren Me</b></sub></a><br /><a href=\"#agents-OrenMe\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#instructions-OrenMe\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mjrousos\"><img src=\"https://avatars.githubusercontent.com/u/10077254?v=4?s=100\" width=\"100px;\" alt=\"Mike Rousos\"/><br /><sub><b>Mike Rousos</b></sub></a><br /><a href=\"#instructions-mjrousos\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-mjrousos\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://devkimchi.com/\"><img src=\"https://avatars.githubusercontent.com/u/1538528?v=4?s=100\" width=\"100px;\" alt=\"Justin Yoo\"/><br /><sub><b>Justin Yoo</b></sub></a><br /><a href=\"#instructions-justinyoo\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/guiopen\"><img src=\"https://avatars.githubusercontent.com/u/94094527?v=4?s=100\" width=\"100px;\" alt=\"Guilherme do Amaral Alves \"/><br /><sub><b>Guilherme do Amaral Alves </b></sub></a><br /><a href=\"#instructions-guiopen\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/griffinashe/\"><img src=\"https://avatars.githubusercontent.com/u/6391612?v=4?s=100\" width=\"100px;\" alt=\"Griffin Ashe\"/><br /><sub><b>Griffin Ashe</b></sub></a><br /><a href=\"#agents-griffinashe\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#collections-griffinashe\" title=\"Curated collections of related content\">ğŸ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anchildress1\"><img src=\"https://avatars.githubusercontent.com/u/6563688?v=4?s=100\" width=\"100px;\" alt=\"Ashley Childress\"/><br /><sub><b>Ashley Childress</b></sub></a><br /><a href=\"#agents-anchildress1\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=anchildress1\" title=\"Documentation\">ğŸ“–</a> <a href=\"#instructions-anchildress1\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#infra-anchildress1\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">ğŸš‡</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=anchildress1\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.senseof.tech/\"><img src=\"https://avatars.githubusercontent.com/u/50712277?v=4?s=100\" width=\"100px;\" alt=\"Adrien Clerbois\"/><br /><sub><b>Adrien Clerbois</b></sub></a><br /><a href=\"#agents-AClerbois\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"https://github.com/github/awesome-copilot/commits?author=AClerbois\" title=\"Documentation\">ğŸ“–</a> <a href=\"#prompts-AClerbois\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Vhivi\"><img src=\"https://avatars.githubusercontent.com/u/38220028?v=4?s=100\" width=\"100px;\" alt=\"ANGELELLI David\"/><br /><sub><b>ANGELELLI David</b></sub></a><br /><a href=\"#agents-Vhivi\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://markdav.is/\"><img src=\"https://avatars.githubusercontent.com/u/311063?v=4?s=100\" width=\"100px;\" alt=\"Mark Davis\"/><br /><sub><b>Mark Davis</b></sub></a><br /><a href=\"#instructions-markdav-is\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MattVevang\"><img src=\"https://avatars.githubusercontent.com/u/20714898?v=4?s=100\" width=\"100px;\" alt=\"Matt Vevang\"/><br /><sub><b>Matt Vevang</b></sub></a><br /><a href=\"#instructions-MattVevang\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://max.irro.at/\"><img src=\"https://avatars.githubusercontent.com/u/589073?v=4?s=100\" width=\"100px;\" alt=\"Maximilian Irro\"/><br /><sub><b>Maximilian Irro</b></sub></a><br /><a href=\"#instructions-mpgirro\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nullchimp\"><img src=\"https://avatars.githubusercontent.com/u/58362593?v=4?s=100\" width=\"100px;\" alt=\"NULLchimp\"/><br /><sub><b>NULLchimp</b></sub></a><br /><a href=\"#agents-nullchimp\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pkarda\"><img src=\"https://avatars.githubusercontent.com/u/12649718?v=4?s=100\" width=\"100px;\" alt=\"Peter Karda\"/><br /><sub><b>Peter Karda</b></sub></a><br /><a href=\"#prompts-pkarda\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sdolgin\"><img src=\"https://avatars.githubusercontent.com/u/576449?v=4?s=100\" width=\"100px;\" alt=\"Saul Dolgin\"/><br /><sub><b>Saul Dolgin</b></sub></a><br /><a href=\"#agents-sdolgin\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#instructions-sdolgin\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-sdolgin\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shubham070\"><img src=\"https://avatars.githubusercontent.com/u/5480589?v=4?s=100\" width=\"100px;\" alt=\"Shubham Gaikwad\"/><br /><sub><b>Shubham Gaikwad</b></sub></a><br /><a href=\"#agents-shubham070\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#instructions-shubham070\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-shubham070\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TheovanKraay\"><img src=\"https://avatars.githubusercontent.com/u/24420698?v=4?s=100\" width=\"100px;\" alt=\"Theo van Kraay\"/><br /><sub><b>Theo van Kraay</b></sub></a><br /><a href=\"#instructions-TheovanKraay\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TianqiZhang\"><img src=\"https://avatars.githubusercontent.com/u/5326582?v=4?s=100\" width=\"100px;\" alt=\"Tianqi Zhang\"/><br /><sub><b>Tianqi Zhang</b></sub></a><br /><a href=\"#agents-TianqiZhang\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://blog.miniasp.com/\"><img src=\"https://avatars.githubusercontent.com/u/88981?v=4?s=100\" width=\"100px;\" alt=\"Will ä¿å“¥\"/><br /><sub><b>Will ä¿å“¥</b></sub></a><br /><a href=\"#agents-doggy8088\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#prompts-doggy8088\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tsubalog.hatenablog.com/\"><img src=\"https://avatars.githubusercontent.com/u/1592808?v=4?s=100\" width=\"100px;\" alt=\"Yuta Matsumura\"/><br /><sub><b>Yuta Matsumura</b></sub></a><br /><a href=\"#instructions-tsubakimoto\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anschnapp\"><img src=\"https://avatars.githubusercontent.com/u/17565996?v=4?s=100\" width=\"100px;\" alt=\"anschnapp\"/><br /><sub><b>anschnapp</b></sub></a><br /><a href=\"#agents-anschnapp\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hizahizi-hizumi\"><img src=\"https://avatars.githubusercontent.com/u/163728895?v=4?s=100\" width=\"100px;\" alt=\"hizahizi-hizumi\"/><br /><sub><b>hizahizi-hizumi</b></sub></a><br /><a href=\"#instructions-hizahizi-hizumi\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jianminhuang.cc/\"><img src=\"https://avatars.githubusercontent.com/u/6296280?v=4?s=100\" width=\"100px;\" alt=\"é»ƒå¥æ—» Vincent Huang\"/><br /><sub><b>é»ƒå¥æ—» Vincent Huang</b></sub></a><br /><a href=\"#prompts-Jian-Min-Huang\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://brunoborges.io/\"><img src=\"https://avatars.githubusercontent.com/u/129743?v=4?s=100\" width=\"100px;\" alt=\"Bruno Borges\"/><br /><sub><b>Bruno Borges</b></sub></a><br /><a href=\"#collections-brunoborges\" title=\"Curated collections of related content\">ğŸ</a> <a href=\"#instructions-brunoborges\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.movinglive.ca/\"><img src=\"https://avatars.githubusercontent.com/u/14792628?v=4?s=100\" width=\"100px;\" alt=\"Steve Magne\"/><br /><sub><b>Steve Magne</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=MovingLive\" title=\"Documentation\">ğŸ“–</a> <a href=\"#instructions-MovingLive\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://shaneneuville.com/\"><img src=\"https://avatars.githubusercontent.com/u/5375137?v=4?s=100\" width=\"100px;\" alt=\"Shane Neuville\"/><br /><sub><b>Shane Neuville</b></sub></a><br /><a href=\"#agents-PureWeen\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#instructions-PureWeen\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://asilva.dev/\"><img src=\"https://avatars.githubusercontent.com/u/2493377?v=4?s=100\" width=\"100px;\" alt=\"AndrÃ© Silva\"/><br /><sub><b>AndrÃ© Silva</b></sub></a><br /><a href=\"#agents-askpt\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#instructions-askpt\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/agreaves-ms\"><img src=\"https://avatars.githubusercontent.com/u/111466195?v=4?s=100\" width=\"100px;\" alt=\"Allen Greaves\"/><br /><sub><b>Allen Greaves</b></sub></a><br /><a href=\"#agents-agreaves-ms\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#instructions-agreaves-ms\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AmeliaRose802\"><img src=\"https://avatars.githubusercontent.com/u/26167931?v=4?s=100\" width=\"100px;\" alt=\"Amelia Payne\"/><br /><sub><b>Amelia Payne</b></sub></a><br /><a href=\"#agents-AmeliaRose802\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/BBoyBen\"><img src=\"https://avatars.githubusercontent.com/u/34445365?v=4?s=100\" width=\"100px;\" alt=\"BBoyBen\"/><br /><sub><b>BBoyBen</b></sub></a><br /><a href=\"#instructions-BBoyBen\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://azureincubations.io/\"><img src=\"https://avatars.githubusercontent.com/u/45323234?v=4?s=100\" width=\"100px;\" alt=\"Brooke Hamilton\"/><br /><sub><b>Brooke Hamilton</b></sub></a><br /><a href=\"#instructions-brooke-hamilton\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/GeekTrainer\"><img src=\"https://avatars.githubusercontent.com/u/6109729?v=4?s=100\" width=\"100px;\" alt=\"Christopher Harrison\"/><br /><sub><b>Christopher Harrison</b></sub></a><br /><a href=\"#instructions-GeekTrainer\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/breakid\"><img src=\"https://avatars.githubusercontent.com/u/1446918?v=4?s=100\" width=\"100px;\" alt=\"Dan\"/><br /><sub><b>Dan</b></sub></a><br /><a href=\"#instructions-breakid\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://blog.codewithdan.com/\"><img src=\"https://avatars.githubusercontent.com/u/1767249?v=4?s=100\" width=\"100px;\" alt=\"Dan Wahlin\"/><br /><sub><b>Dan Wahlin</b></sub></a><br /><a href=\"#agents-DanWahlin\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://debbie.codes/\"><img src=\"https://avatars.githubusercontent.com/u/13063165?v=4?s=100\" width=\"100px;\" alt=\"Debbie O'Brien\"/><br /><sub><b>Debbie O'Brien</b></sub></a><br /><a href=\"#agents-debs-obrien\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#instructions-debs-obrien\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-debs-obrien\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/echarrod\"><img src=\"https://avatars.githubusercontent.com/u/1381991?v=4?s=100\" width=\"100px;\" alt=\"Ed Harrod\"/><br /><sub><b>Ed Harrod</b></sub></a><br /><a href=\"#prompts-echarrod\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://learn.microsoft.com/dotnet\"><img src=\"https://avatars.githubusercontent.com/u/24882762?v=4?s=100\" width=\"100px;\" alt=\"Genevieve Warren\"/><br /><sub><b>Genevieve Warren</b></sub></a><br /><a href=\"#prompts-gewarren\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/guigui42\"><img src=\"https://avatars.githubusercontent.com/u/2376010?v=4?s=100\" width=\"100px;\" alt=\"Guillaume\"/><br /><sub><b>Guillaume</b></sub></a><br /><a href=\"#agents-guigui42\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#prompts-guigui42\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/riqueufmg\"><img src=\"https://avatars.githubusercontent.com/u/108551585?v=4?s=100\" width=\"100px;\" alt=\"Henrique Nunes\"/><br /><sub><b>Henrique Nunes</b></sub></a><br /><a href=\"#prompts-riqueufmg\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jeremiah-snee-openx\"><img src=\"https://avatars.githubusercontent.com/u/113928685?v=4?s=100\" width=\"100px;\" alt=\"Jeremiah Snee\"/><br /><sub><b>Jeremiah Snee</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=jeremiah-snee-openx\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kartikdhiman\"><img src=\"https://avatars.githubusercontent.com/u/59189590?v=4?s=100\" width=\"100px;\" alt=\"Kartik Dhiman\"/><br /><sub><b>Kartik Dhiman</b></sub></a><br /><a href=\"#instructions-kartikdhiman\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://kristiyanvelkov.com/\"><img src=\"https://avatars.githubusercontent.com/u/40764277?v=4?s=100\" width=\"100px;\" alt=\"Kristiyan Velkov\"/><br /><sub><b>Kristiyan Velkov</b></sub></a><br /><a href=\"#agents-kristiyan-velkov\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/msalaman\"><img src=\"https://avatars.githubusercontent.com/u/28122166?v=4?s=100\" width=\"100px;\" alt=\"msalaman\"/><br /><sub><b>msalaman</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=msalaman\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://soderlind.no/\"><img src=\"https://avatars.githubusercontent.com/u/1649452?v=4?s=100\" width=\"100px;\" alt=\"Per SÃ¸derlind\"/><br /><sub><b>Per SÃ¸derlind</b></sub></a><br /><a href=\"#instructions-soderlind\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://dotneteers.net/\"><img src=\"https://avatars.githubusercontent.com/u/28162552?v=4?s=100\" width=\"100px;\" alt=\"Peter Smulovics\"/><br /><sub><b>Peter Smulovics</b></sub></a><br /><a href=\"#instructions-psmulovics\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/madvimer\"><img src=\"https://avatars.githubusercontent.com/u/3188898?v=4?s=100\" width=\"100px;\" alt=\"Ravish Rathod\"/><br /><sub><b>Ravish Rathod</b></sub></a><br /><a href=\"#instructions-madvimer\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://ricksm.it/\"><img src=\"https://avatars.githubusercontent.com/u/7207783?v=4?s=100\" width=\"100px;\" alt=\"Rick Smit\"/><br /><sub><b>Rick Smit</b></sub></a><br /><a href=\"#agents-ricksmit3000\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pertrai1\"><img src=\"https://avatars.githubusercontent.com/u/442374?v=4?s=100\" width=\"100px;\" alt=\"Rob Simpson\"/><br /><sub><b>Rob Simpson</b></sub></a><br /><a href=\"#instructions-pertrai1\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/inquinity\"><img src=\"https://avatars.githubusercontent.com/u/406234?v=4?s=100\" width=\"100px;\" alt=\"Robert Altman\"/><br /><sub><b>Robert Altman</b></sub></a><br /><a href=\"#instructions-inquinity\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://salih.guru/\"><img src=\"https://avatars.githubusercontent.com/u/76786120?v=4?s=100\" width=\"100px;\" alt=\"Salih\"/><br /><sub><b>Salih</b></sub></a><br /><a href=\"#instructions-salihguru\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://graef.io/\"><img src=\"https://avatars.githubusercontent.com/u/19261257?v=4?s=100\" width=\"100px;\" alt=\"Sebastian GrÃ¤f\"/><br /><sub><b>Sebastian GrÃ¤f</b></sub></a><br /><a href=\"#agents-segraef\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#instructions-segraef\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/SebastienDegodez\"><img src=\"https://avatars.githubusercontent.com/u/2349146?v=4?s=100\" width=\"100px;\" alt=\"Sebastien DEGODEZ\"/><br /><sub><b>Sebastien DEGODEZ</b></sub></a><br /><a href=\"#instructions-SebastienDegodez\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sesmyrnov\"><img src=\"https://avatars.githubusercontent.com/u/59627981?v=4?s=100\" width=\"100px;\" alt=\"Sergiy Smyrnov\"/><br /><sub><b>Sergiy Smyrnov</b></sub></a><br /><a href=\"#prompts-sesmyrnov\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/SomeSolutionsArchitect\"><img src=\"https://avatars.githubusercontent.com/u/139817767?v=4?s=100\" width=\"100px;\" alt=\"SomeSolutionsArchitect\"/><br /><sub><b>SomeSolutionsArchitect</b></sub></a><br /><a href=\"#agents-SomeSolutionsArchitect\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kewalaka\"><img src=\"https://avatars.githubusercontent.com/u/3146590?v=4?s=100\" width=\"100px;\" alt=\"Stu Mace\"/><br /><sub><b>Stu Mace</b></sub></a><br /><a href=\"#agents-kewalaka\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#collections-kewalaka\" title=\"Curated collections of related content\">ğŸ</a> <a href=\"#instructions-kewalaka\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/STRUDSO\"><img src=\"https://avatars.githubusercontent.com/u/1543732?v=4?s=100\" width=\"100px;\" alt=\"SÃ¸ren TrudsÃ¸ Mahon\"/><br /><sub><b>SÃ¸ren TrudsÃ¸ Mahon</b></sub></a><br /><a href=\"#instructions-STRUDSO\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://enakdesign.com/\"><img src=\"https://avatars.githubusercontent.com/u/14024037?v=4?s=100\" width=\"100px;\" alt=\"Tj Vita\"/><br /><sub><b>Tj Vita</b></sub></a><br /><a href=\"#agents-semperteneo\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pelikhan\"><img src=\"https://avatars.githubusercontent.com/u/4175913?v=4?s=100\" width=\"100px;\" alt=\"Peli de Halleux\"/><br /><sub><b>Peli de Halleux</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=pelikhan\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.paulomorgado.net/\"><img src=\"https://avatars.githubusercontent.com/u/470455?v=4?s=100\" width=\"100px;\" alt=\"Paulo Morgado\"/><br /><sub><b>Paulo Morgado</b></sub></a><br /><a href=\"#prompts-paulomorgado\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://paul.crane.net.nz/\"><img src=\"https://avatars.githubusercontent.com/u/808676?v=4?s=100\" width=\"100px;\" alt=\"Paul Crane\"/><br /><sub><b>Paul Crane</b></sub></a><br /><a href=\"#agents-pcrane\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.pamelafox.org/\"><img src=\"https://avatars.githubusercontent.com/u/297042?v=4?s=100\" width=\"100px;\" alt=\"Pamela Fox\"/><br /><sub><b>Pamela Fox</b></sub></a><br /><a href=\"#prompts-pamelafox\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://oskarthornblad.se/\"><img src=\"https://avatars.githubusercontent.com/u/640102?v=4?s=100\" width=\"100px;\" alt=\"Oskar Thornblad\"/><br /><sub><b>Oskar Thornblad</b></sub></a><br /><a href=\"#instructions-prewk\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nischays\"><img src=\"https://avatars.githubusercontent.com/u/54121853?v=4?s=100\" width=\"100px;\" alt=\"Nischay Sharma\"/><br /><sub><b>Nischay Sharma</b></sub></a><br /><a href=\"#agents-nischays\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Naikabg\"><img src=\"https://avatars.githubusercontent.com/u/19915620?v=4?s=100\" width=\"100px;\" alt=\"Nikolay Marinov\"/><br /><sub><b>Nikolay Marinov</b></sub></a><br /><a href=\"#agents-Naikabg\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/niksac\"><img src=\"https://avatars.githubusercontent.com/u/20246918?v=4?s=100\" width=\"100px;\" alt=\"Nik Sachdeva\"/><br /><sub><b>Nik Sachdeva</b></sub></a><br /><a href=\"#agents-niksacdev\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#collections-niksacdev\" title=\"Curated collections of related content\">ğŸ</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://onetipaweek.com/\"><img src=\"https://avatars.githubusercontent.com/u/833231?v=4?s=100\" width=\"100px;\" alt=\"Nick Taylor\"/><br /><sub><b>Nick Taylor</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=nickytonline\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://nicholasdbrady.github.io/cookbook/\"><img src=\"https://avatars.githubusercontent.com/u/18353756?v=4?s=100\" width=\"100px;\" alt=\"Nick Brady\"/><br /><sub><b>Nick Brady</b></sub></a><br /><a href=\"#agents-nicholasdbrady\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nastanford\"><img src=\"https://avatars.githubusercontent.com/u/1755947?v=4?s=100\" width=\"100px;\" alt=\"Nathan Stanford Sr\"/><br /><sub><b>Nathan Stanford Sr</b></sub></a><br /><a href=\"#instructions-nastanford\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/matebarabas\"><img src=\"https://avatars.githubusercontent.com/u/22733424?v=4?s=100\" width=\"100px;\" alt=\"MÃ¡tÃ© BarabÃ¡s\"/><br /><sub><b>MÃ¡tÃ© BarabÃ¡s</b></sub></a><br /><a href=\"#instructions-matebarabas\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mikeparker104\"><img src=\"https://avatars.githubusercontent.com/u/12763221?v=4?s=100\" width=\"100px;\" alt=\"Mike Parker\"/><br /><sub><b>Mike Parker</b></sub></a><br /><a href=\"#instructions-mikeparker104\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mikekistler\"><img src=\"https://avatars.githubusercontent.com/u/85643503?v=4?s=100\" width=\"100px;\" alt=\"Mike Kistler\"/><br /><sub><b>Mike Kistler</b></sub></a><br /><a href=\"#prompts-mikekistler\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/giomartinsdev\"><img src=\"https://avatars.githubusercontent.com/u/125399281?v=4?s=100\" width=\"100px;\" alt=\"Giovanni de Almeida Martins\"/><br /><sub><b>Giovanni de Almeida Martins</b></sub></a><br /><a href=\"#instructions-giomartinsdev\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dgh06175\"><img src=\"https://avatars.githubusercontent.com/u/77305722?v=4?s=100\" width=\"100px;\" alt=\"ì´ìƒí˜„\"/><br /><sub><b>ì´ìƒí˜„</b></sub></a><br /><a href=\"#instructions-dgh06175\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/zooav\"><img src=\"https://avatars.githubusercontent.com/u/12625412?v=4?s=100\" width=\"100px;\" alt=\"Ankur Sharma\"/><br /><sub><b>Ankur Sharma</b></sub></a><br /><a href=\"#prompts-zooav\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/webreidi\"><img src=\"https://avatars.githubusercontent.com/u/55603905?v=4?s=100\" width=\"100px;\" alt=\"Wendy Breiding\"/><br /><sub><b>Wendy Breiding</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=webreidi\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/voidfnc\"><img src=\"https://avatars.githubusercontent.com/u/194750710?v=4?s=100\" width=\"100px;\" alt=\"voidfnc\"/><br /><sub><b>voidfnc</b></sub></a><br /><a href=\"#agents-voidfnc\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://about.me/shane-lee\"><img src=\"https://avatars.githubusercontent.com/u/5466825?v=4?s=100\" width=\"100px;\" alt=\"shane lee\"/><br /><sub><b>shane lee</b></sub></a><br /><a href=\"#instructions-shavo007\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/sdanzo-hrb\"><img src=\"https://avatars.githubusercontent.com/u/136493100?v=4?s=100\" width=\"100px;\" alt=\"sdanzo-hrb\"/><br /><sub><b>sdanzo-hrb</b></sub></a><br /><a href=\"#agents-sdanzo-hrb\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nativebpm\"><img src=\"https://avatars.githubusercontent.com/u/33398121?v=4?s=100\" width=\"100px;\" alt=\"sauran\"/><br /><sub><b>sauran</b></sub></a><br /><a href=\"#instructions-isauran\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/samqbush\"><img src=\"https://avatars.githubusercontent.com/u/74389839?v=4?s=100\" width=\"100px;\" alt=\"samqbush\"/><br /><sub><b>samqbush</b></sub></a><br /><a href=\"#prompts-samqbush\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/pareenaverma\"><img src=\"https://avatars.githubusercontent.com/u/59843121?v=4?s=100\" width=\"100px;\" alt=\"pareenaverma\"/><br /><sub><b>pareenaverma</b></sub></a><br /><a href=\"#agents-pareenaverma\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/oleksiyyurchyna\"><img src=\"https://avatars.githubusercontent.com/u/10256765?v=4?s=100\" width=\"100px;\" alt=\"oleksiyyurchyna\"/><br /><sub><b>oleksiyyurchyna</b></sub></a><br /><a href=\"#collections-oleksiyyurchyna\" title=\"Curated collections of related content\">ğŸ</a> <a href=\"#prompts-oleksiyyurchyna\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/time-by-waves\"><img src=\"https://avatars.githubusercontent.com/u/34587654?v=4?s=100\" width=\"100px;\" alt=\"oceans-of-time\"/><br /><sub><b>oceans-of-time</b></sub></a><br /><a href=\"#instructions-time-by-waves\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kshashank57\"><img src=\"https://avatars.githubusercontent.com/u/57212456?v=4?s=100\" width=\"100px;\" alt=\"kshashank57\"/><br /><sub><b>kshashank57</b></sub></a><br /><a href=\"#agents-kshashank57\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#instructions-kshashank57\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hueanmy\"><img src=\"https://avatars.githubusercontent.com/u/20430626?v=4?s=100\" width=\"100px;\" alt=\"Meii\"/><br /><sub><b>Meii</b></sub></a><br /><a href=\"#agents-hueanmy\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/factory-davidgu\"><img src=\"https://avatars.githubusercontent.com/u/229352262?v=4?s=100\" width=\"100px;\" alt=\"factory-davidgu\"/><br /><sub><b>factory-davidgu</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=factory-davidgu\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dangelov-qa\"><img src=\"https://avatars.githubusercontent.com/u/92313553?v=4?s=100\" width=\"100px;\" alt=\"dangelov-qa\"/><br /><sub><b>dangelov-qa</b></sub></a><br /><a href=\"#agents-dangelov-qa\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/BenoitMaucotel\"><img src=\"https://avatars.githubusercontent.com/u/54392431?v=4?s=100\" width=\"100px;\" alt=\"BenoitMaucotel\"/><br /><sub><b>BenoitMaucotel</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=BenoitMaucotel\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/benjisho-aidome\"><img src=\"https://avatars.githubusercontent.com/u/218995725?v=4?s=100\" width=\"100px;\" alt=\"benjisho-aidome\"/><br /><sub><b>benjisho-aidome</b></sub></a><br /><a href=\"#agents-benjisho-aidome\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#instructions-benjisho-aidome\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-benjisho-aidome\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yukiomoto\"><img src=\"https://avatars.githubusercontent.com/u/38450410?v=4?s=100\" width=\"100px;\" alt=\"Yuki Omoto\"/><br /><sub><b>Yuki Omoto</b></sub></a><br /><a href=\"#instructions-yukiomoto\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/wschultz-boxboat\"><img src=\"https://avatars.githubusercontent.com/u/110492948?v=4?s=100\" width=\"100px;\" alt=\"Will Schultz\"/><br /><sub><b>Will Schultz</b></sub></a><br /><a href=\"#agents-wschultz-boxboat\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://bio.warengonzaga.com/\"><img src=\"https://avatars.githubusercontent.com/u/15052701?v=4?s=100\" width=\"100px;\" alt=\"Waren Gonzaga\"/><br /><sub><b>Waren Gonzaga</b></sub></a><br /><a href=\"#agents-warengonzaga\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://linktr.ee/vincentkoc\"><img src=\"https://avatars.githubusercontent.com/u/25068?v=4?s=100\" width=\"100px;\" alt=\"Vincent Koc\"/><br /><sub><b>Vincent Koc</b></sub></a><br /><a href=\"#agents-vincentkoc\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Vaporjawn\"><img src=\"https://avatars.githubusercontent.com/u/15694665?v=4?s=100\" width=\"100px;\" alt=\"Victor Williams\"/><br /><sub><b>Victor Williams</b></sub></a><br /><a href=\"#agents-Vaporjawn\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://vesharma.dev/\"><img src=\"https://avatars.githubusercontent.com/u/62218708?v=4?s=100\" width=\"100px;\" alt=\"Ve Sharma\"/><br /><sub><b>Ve Sharma</b></sub></a><br /><a href=\"#agents-VeVarunSharma\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.ferryhopper.com/\"><img src=\"https://avatars.githubusercontent.com/u/19361558?v=4?s=100\" width=\"100px;\" alt=\"Vasileios Lahanas\"/><br /><sub><b>Vasileios Lahanas</b></sub></a><br /><a href=\"#instructions-vlahanas\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tinyurl.com/3p5j9mwe\"><img src=\"https://avatars.githubusercontent.com/u/9591887?v=4?s=100\" width=\"100px;\" alt=\"Udaya Veeramreddygari\"/><br /><sub><b>Udaya Veeramreddygari</b></sub></a><br /><a href=\"#instructions-udayakumarreddyv\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/iletai\"><img src=\"https://avatars.githubusercontent.com/u/26614687?v=4?s=100\" width=\"100px;\" alt=\"TÃ i LÃª\"/><br /><sub><b>TÃ i LÃª</b></sub></a><br /><a href=\"#prompts-iletai\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tsubasaogawa.me/\"><img src=\"https://avatars.githubusercontent.com/u/7788821?v=4?s=100\" width=\"100px;\" alt=\"Tsubasa Ogawa\"/><br /><sub><b>Tsubasa Ogawa</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=tsubasaogawa\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://glsauto.com/\"><img src=\"https://avatars.githubusercontent.com/u/132710946?v=4?s=100\" width=\"100px;\" alt=\"Troy Witthoeft (glsauto)\"/><br /><sub><b>Troy Witthoeft (glsauto)</b></sub></a><br /><a href=\"#instructions-twitthoeft-gls\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jfversluis.dev/\"><img src=\"https://avatars.githubusercontent.com/u/939291?v=4?s=100\" width=\"100px;\" alt=\"Gerald Versluis\"/><br /><sub><b>Gerald Versluis</b></sub></a><br /><a href=\"#instructions-jfversluis\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/geoder101\"><img src=\"https://avatars.githubusercontent.com/u/145904?v=4?s=100\" width=\"100px;\" alt=\"George Dernikos\"/><br /><sub><b>George Dernikos</b></sub></a><br /><a href=\"#prompts-geoder101\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gautambaghel\"><img src=\"https://avatars.githubusercontent.com/u/22324290?v=4?s=100\" width=\"100px;\" alt=\"Gautam\"/><br /><sub><b>Gautam</b></sub></a><br /><a href=\"#agents-gautambaghel\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/feapaydin\"><img src=\"https://avatars.githubusercontent.com/u/19946639?v=4?s=100\" width=\"100px;\" alt=\"Furkan Enes\"/><br /><sub><b>Furkan Enes</b></sub></a><br /><a href=\"#instructions-feapaydin\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/fmuecke\"><img src=\"https://avatars.githubusercontent.com/u/7921024?v=4?s=100\" width=\"100px;\" alt=\"Florian MÃ¼cke\"/><br /><sub><b>Florian MÃ¼cke</b></sub></a><br /><a href=\"#agents-fmuecke\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.felixarjuna.dev/\"><img src=\"https://avatars.githubusercontent.com/u/79026094?v=4?s=100\" width=\"100px;\" alt=\"Felix Arjuna\"/><br /><sub><b>Felix Arjuna</b></sub></a><br /><a href=\"#instructions-felixarjuna\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ewega\"><img src=\"https://avatars.githubusercontent.com/u/26189114?v=4?s=100\" width=\"100px;\" alt=\"Eldrick Wega\"/><br /><sub><b>Eldrick Wega</b></sub></a><br /><a href=\"#prompts-ewega\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danchev\"><img src=\"https://avatars.githubusercontent.com/u/12420863?v=4?s=100\" width=\"100px;\" alt=\"Dobri Danchev\"/><br /><sub><b>Dobri Danchev</b></sub></a><br /><a href=\"#prompts-danchev\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://dgamboa.com/\"><img src=\"https://avatars.githubusercontent.com/u/7052267?v=4?s=100\" width=\"100px;\" alt=\"Diego Gamboa\"/><br /><sub><b>Diego Gamboa</b></sub></a><br /><a href=\"#prompts-difegam\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/derekclair\"><img src=\"https://avatars.githubusercontent.com/u/5247629?v=4?s=100\" width=\"100px;\" alt=\"Derek Clair\"/><br /><sub><b>Derek Clair</b></sub></a><br /><a href=\"#agents-derekclair\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#prompts-derekclair\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://dev.to/davidortinau\"><img src=\"https://avatars.githubusercontent.com/u/41873?v=4?s=100\" width=\"100px;\" alt=\"David Ortinau\"/><br /><sub><b>David Ortinau</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=davidortinau\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/danielabbatt\"><img src=\"https://avatars.githubusercontent.com/u/8926756?v=4?s=100\" width=\"100px;\" alt=\"Daniel Abbatt\"/><br /><sub><b>Daniel Abbatt</b></sub></a><br /><a href=\"#instructions-danielabbatt\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/CypherHK\"><img src=\"https://avatars.githubusercontent.com/u/230935834?v=4?s=100\" width=\"100px;\" alt=\"CypherHK\"/><br /><sub><b>CypherHK</b></sub></a><br /><a href=\"#agents-CypherHK\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a> <a href=\"#prompts-CypherHK\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/craigbekker\"><img src=\"https://avatars.githubusercontent.com/u/1115912?v=4?s=100\" width=\"100px;\" alt=\"Craig Bekker\"/><br /><sub><b>Craig Bekker</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=craigbekker\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.peug.net/\"><img src=\"https://avatars.githubusercontent.com/u/3845786?v=4?s=100\" width=\"100px;\" alt=\"Christophe Peugnet\"/><br /><sub><b>Christophe Peugnet</b></sub></a><br /><a href=\"#instructions-tossnet\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lechnerc77\"><img src=\"https://avatars.githubusercontent.com/u/22294087?v=4?s=100\" width=\"100px;\" alt=\"Christian Lechner\"/><br /><sub><b>Christian Lechner</b></sub></a><br /><a href=\"#instructions-lechnerc77\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/charris-msft\"><img src=\"https://avatars.githubusercontent.com/u/74415662?v=4?s=100\" width=\"100px;\" alt=\"Chris Harris\"/><br /><sub><b>Chris Harris</b></sub></a><br /><a href=\"#agents-charris-msft\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/artemsaveliev\"><img src=\"https://avatars.githubusercontent.com/u/15679218?v=4?s=100\" width=\"100px;\" alt=\"Artem Saveliev\"/><br /><sub><b>Artem Saveliev</b></sub></a><br /><a href=\"#instructions-artemsaveliev\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://javaetmoi.com/\"><img src=\"https://avatars.githubusercontent.com/u/838318?v=4?s=100\" width=\"100px;\" alt=\"Antoine Rey\"/><br /><sub><b>Antoine Rey</b></sub></a><br /><a href=\"#prompts-arey\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/PiKa919\"><img src=\"https://avatars.githubusercontent.com/u/96786190?v=4?s=100\" width=\"100px;\" alt=\"Ankit Das\"/><br /><sub><b>Ankit Das</b></sub></a><br /><a href=\"#instructions-PiKa919\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alineavila\"><img src=\"https://avatars.githubusercontent.com/u/24813256?v=4?s=100\" width=\"100px;\" alt=\"Aline Ãvila\"/><br /><sub><b>Aline Ãvila</b></sub></a><br /><a href=\"#instructions-alineavila\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/martin-cod\"><img src=\"https://avatars.githubusercontent.com/u/33550246?v=4?s=100\" width=\"100px;\" alt=\"Alexander Martinkevich\"/><br /><sub><b>Alexander Martinkevich</b></sub></a><br /><a href=\"#agents-martin-cod\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/aldunchev\"><img src=\"https://avatars.githubusercontent.com/u/4631021?v=4?s=100\" width=\"100px;\" alt=\"Aleksandar Dunchev\"/><br /><sub><b>Aleksandar Dunchev</b></sub></a><br /><a href=\"#agents-aldunchev\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.qreate.it/\"><img src=\"https://avatars.githubusercontent.com/u/1868590?v=4?s=100\" width=\"100px;\" alt=\"Alan Sprecacenere\"/><br /><sub><b>Alan Sprecacenere</b></sub></a><br /><a href=\"#instructions-tegola\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/akashxlr8\"><img src=\"https://avatars.githubusercontent.com/u/58072860?v=4?s=100\" width=\"100px;\" alt=\"Akash Kumar Shaw\"/><br /><sub><b>Akash Kumar Shaw</b></sub></a><br /><a href=\"#instructions-akashxlr8\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/abdidaudpropel\"><img src=\"https://avatars.githubusercontent.com/u/51310019?v=4?s=100\" width=\"100px;\" alt=\"Abdi Daud\"/><br /><sub><b>Abdi Daud</b></sub></a><br /><a href=\"#agents-abdidaudpropel\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/AIAlchemyForge\"><img src=\"https://avatars.githubusercontent.com/u/253636689?v=4?s=100\" width=\"100px;\" alt=\"AIAlchemyForge\"/><br /><sub><b>AIAlchemyForge</b></sub></a><br /><a href=\"#instructions-AIAlchemyForge\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/4regab\"><img src=\"https://avatars.githubusercontent.com/u/178603515?v=4?s=100\" width=\"100px;\" alt=\"4regab\"/><br /><sub><b>4regab</b></sub></a><br /><a href=\"#instructions-4regab\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/MiguelElGallo\"><img src=\"https://avatars.githubusercontent.com/u/60221874?v=4?s=100\" width=\"100px;\" alt=\"Miguel P Z\"/><br /><sub><b>Miguel P Z</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=MiguelElGallo\" title=\"Documentation\">ğŸ“–</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://a11ysupport.io/\"><img src=\"https://avatars.githubusercontent.com/u/498678?v=4?s=100\" width=\"100px;\" alt=\"Michael Fairchild\"/><br /><sub><b>Michael Fairchild</b></sub></a><br /><a href=\"#instructions-mfairchild365\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.linkedin.com/in/michael-volz/\"><img src=\"https://avatars.githubusercontent.com/u/129928?v=4?s=100\" width=\"100px;\" alt=\"Michael A. Volz (Flynn)\"/><br /><sub><b>Michael A. Volz (Flynn)</b></sub></a><br /><a href=\"#prompts-michaelvolz\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Mike-Hanna\"><img src=\"https://avatars.githubusercontent.com/u/50142889?v=4?s=100\" width=\"100px;\" alt=\"Michael\"/><br /><sub><b>Michael</b></sub></a><br /><a href=\"#instructions-Mike-Hanna\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.mehmetalierol.com/\"><img src=\"https://avatars.githubusercontent.com/u/16721723?v=4?s=100\" width=\"100px;\" alt=\"Mehmet Ali EROL\"/><br /><sub><b>Mehmet Ali EROL</b></sub></a><br /><a href=\"#agents-mehmetalierol\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://maxprilutskiy.com/\"><img src=\"https://avatars.githubusercontent.com/u/5614659?v=4?s=100\" width=\"100px;\" alt=\"Max Prilutskiy\"/><br /><sub><b>Max Prilutskiy</b></sub></a><br /><a href=\"#agents-maxprilutskiy\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mbianchidev\"><img src=\"https://avatars.githubusercontent.com/u/37507190?v=4?s=100\" width=\"100px;\" alt=\"Matteo Bianchi\"/><br /><sub><b>Matteo Bianchi</b></sub></a><br /><a href=\"#agents-mbianchidev\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://marknoble.com/\"><img src=\"https://avatars.githubusercontent.com/u/3819700?v=4?s=100\" width=\"100px;\" alt=\"Mark Noble\"/><br /><sub><b>Mark Noble</b></sub></a><br /><a href=\"#agents-marknoble\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ManishJayaswal\"><img src=\"https://avatars.githubusercontent.com/u/9527491?v=4?s=100\" width=\"100px;\" alt=\"Manish Jayaswal\"/><br /><sub><b>Manish Jayaswal</b></sub></a><br /><a href=\"#agents-ManishJayaswal\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://linktr.ee/lukemurray\"><img src=\"https://avatars.githubusercontent.com/u/24467442?v=4?s=100\" width=\"100px;\" alt=\"Luke Murray\"/><br /><sub><b>Luke Murray</b></sub></a><br /><a href=\"#agents-lukemurraynz\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/LouellaCreemers\"><img src=\"https://avatars.githubusercontent.com/u/46204894?v=4?s=100\" width=\"100px;\" alt=\"Louella Creemers\"/><br /><sub><b>Louella Creemers</b></sub></a><br /><a href=\"#instructions-LouellaCreemers\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/saikoumudi\"><img src=\"https://avatars.githubusercontent.com/u/22682497?v=4?s=100\" width=\"100px;\" alt=\"Sai Koumudi Kaluvakolanu\"/><br /><sub><b>Sai Koumudi Kaluvakolanu</b></sub></a><br /><a href=\"#agents-saikoumudi\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/whiteken\"><img src=\"https://avatars.githubusercontent.com/u/20211937?v=4?s=100\" width=\"100px;\" alt=\"Kenny White\"/><br /><sub><b>Kenny White</b></sub></a><br /><a href=\"#instructions-whiteken\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/KaloyanGenev\"><img src=\"https://avatars.githubusercontent.com/u/42644424?v=4?s=100\" width=\"100px;\" alt=\"KaloyanGenev\"/><br /><sub><b>KaloyanGenev</b></sub></a><br /><a href=\"#agents-KaloyanGenev\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ranrar\"><img src=\"https://avatars.githubusercontent.com/u/95967772?v=4?s=100\" width=\"100px;\" alt=\"Kim Skov Rasmussen\"/><br /><sub><b>Kim Skov Rasmussen</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=Ranrar\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.julien-dubois.com/\"><img src=\"https://avatars.githubusercontent.com/u/316835?v=4?s=100\" width=\"100px;\" alt=\"Julien Dubois\"/><br /><sub><b>Julien Dubois</b></sub></a><br /><a href=\"#prompts-jdubois\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://digio.es/\"><img src=\"https://avatars.githubusercontent.com/u/173672918?v=4?s=100\" width=\"100px;\" alt=\"JosÃ© Antonio Garrido\"/><br /><sub><b>JosÃ© Antonio Garrido</b></sub></a><br /><a href=\"#instructions-josegarridodigio\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.sugbo4j.co.nz/\"><img src=\"https://avatars.githubusercontent.com/u/15100839?v=4?s=100\" width=\"100px;\" alt=\"Joseph Gonzales\"/><br /><sub><b>Joseph Gonzales</b></sub></a><br /><a href=\"#instructions-josephgonzales01\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a> <a href=\"#prompts-josephgonzales01\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yortch\"><img src=\"https://avatars.githubusercontent.com/u/4576246?v=4?s=100\" width=\"100px;\" alt=\"Jorge Balderas\"/><br /><sub><b>Jorge Balderas</b></sub></a><br /><a href=\"#instructions-yortch\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://johnpapa.net/\"><img src=\"https://avatars.githubusercontent.com/u/1202528?v=4?s=100\" width=\"100px;\" alt=\"John Papa\"/><br /><sub><b>John Papa</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=johnpapa\" title=\"Code\">ğŸ’»</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.johnlokerse.dev/\"><img src=\"https://avatars.githubusercontent.com/u/3514513?v=4?s=100\" width=\"100px;\" alt=\"John\"/><br /><sub><b>John</b></sub></a><br /><a href=\"#agents-johnlokerse\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://joe-watkins.io/\"><img src=\"https://avatars.githubusercontent.com/u/3695795?v=4?s=100\" width=\"100px;\" alt=\"Joe Watkins\"/><br /><sub><b>Joe Watkins</b></sub></a><br /><a href=\"#instructions-joe-watkins\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jan-v.nl/\"><img src=\"https://avatars.githubusercontent.com/u/462356?v=4?s=100\" width=\"100px;\" alt=\"Jan de Vries\"/><br /><sub><b>Jan de Vries</b></sub></a><br /><a href=\"#agents-Jandev\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nohwnd\"><img src=\"https://avatars.githubusercontent.com/u/5735905?v=4?s=100\" width=\"100px;\" alt=\"Jakub JareÅ¡\"/><br /><sub><b>Jakub JareÅ¡</b></sub></a><br /><a href=\"#prompts-nohwnd\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jaxn\"><img src=\"https://avatars.githubusercontent.com/u/29095?v=4?s=100\" width=\"100px;\" alt=\"Jackson Miller\"/><br /><sub><b>Jackson Miller</b></sub></a><br /><a href=\"#instructions-jaxn\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Ioana37\"><img src=\"https://avatars.githubusercontent.com/u/69301842?v=4?s=100\" width=\"100px;\" alt=\"Ioana A\"/><br /><sub><b>Ioana A</b></sub></a><br /><a href=\"#instructions-Ioana37\" title=\"Custom instructions for GitHub Copilot\">ğŸ§­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hunterhogan\"><img src=\"https://avatars.githubusercontent.com/u/2958419?v=4?s=100\" width=\"100px;\" alt=\"Hunter Hogan\"/><br /><sub><b>Hunter Hogan</b></sub></a><br /><a href=\"#agents-hunterhogan\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/hashimwarren\"><img src=\"https://avatars.githubusercontent.com/u/6027587?v=4?s=100\" width=\"100px;\" alt=\"Hashim Warren\"/><br /><sub><b>Hashim Warren</b></sub></a><br /><a href=\"#agents-hashimwarren\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Arggon\"><img src=\"https://avatars.githubusercontent.com/u/20962238?v=4?s=100\" width=\"100px;\" alt=\"Gonzalo\"/><br /><sub><b>Gonzalo</b></sub></a><br /><a href=\"#prompts-Arggon\" title=\"Reusable prompts for GitHub Copilot\">âŒ¨ï¸</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://hachyderm.io/@0gis0\"><img src=\"https://avatars.githubusercontent.com/u/175379?v=4?s=100\" width=\"100px;\" alt=\"Gisela Torres\"/><br /><sub><b>Gisela Torres</b></sub></a><br /><a href=\"#agents-0GiS0\" title=\"Specialized agents for GitHub Copilot\">ğŸ­</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/shibicr93\"><img src=\"https://avatars.githubusercontent.com/u/6803434?v=4?s=100\" width=\"100px;\" alt=\"Shibi Ramachandran\"/><br /><sub><b>Shibi Ramachandran</b></sub></a><br /><a href=\"https://github.com/github/awesome-copilot/commits?author=shibicr93\" title=\"Code\">ğŸ’»</a></td>\n    </tr>\n  </tbody>\n  <tfoot>\n    <tr>\n      <td align=\"center\" size=\"13px\" colspan=\"7\">\n        <img src=\"https://raw.githubusercontent.com/all-contributors/all-contributors-cli/1b8533af435da9854653492b1327a23a4dbd0a10/assets/logo-small.svg\">\n          <a href=\"https://all-contributors.js.org/docs/en/bot/usage\">Add your contributions</a>\n        </img>\n      </td>\n    </tr>\n  </tfoot>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nThis project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!\n\n## ğŸ“š Additional Resources\n\n- [VS Code Copilot Customization Documentation](https://code.visualstudio.com/docs/copilot/copilot-customization) - Official Microsoft documentation\n- [GitHub Copilot Chat Documentation](https://code.visualstudio.com/docs/copilot/chat/copilot-chat) - Complete chat feature guide\n- [VS Code Settings](https://code.visualstudio.com/docs/getstarted/settings) - General VS Code configuration guide\n\n## â„¢ï¸ Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\ntrademarks or logos is subject to and must follow\n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n",
      "stars_today": 129
    },
    {
      "id": 936473202,
      "name": "FlashMLA",
      "full_name": "deepseek-ai/FlashMLA",
      "description": "FlashMLA: Efficient Multi-head Latent Attention Kernels",
      "html_url": "https://github.com/deepseek-ai/FlashMLA",
      "stars": 12369,
      "forks": 965,
      "language": "C++",
      "topics": [],
      "created_at": "2025-02-21T06:31:27Z",
      "updated_at": "2026-01-25T01:55:13Z",
      "pushed_at": "2026-01-20T16:05:02Z",
      "open_issues": 84,
      "owner": {
        "login": "deepseek-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/148330874?v=4"
      },
      "readme": "# FlashMLA\n\n## Introduction\n\nFlashMLA is DeepSeek's library of optimized attention kernels, powering the [DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3) and [DeepSeek-V3.2-Exp](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp) models. This repository contains the following implementations:\n\n**Sparse Attention Kernels**\n\n*These kernels power DeepSeek Sparse Attention (DSA), as introduced in [this paper](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp).*\n\n- Token-level sparse attention for the prefill stage\n- Token-level sparse attention for the decoding stage, with FP8 KV cache\n\n**Dense Attention Kernels**\n\n- Dense attention for the prefill stage\n- Dense attention for the decoding stage\n\n## News\n\n- **2025.09.29 Release of Sparse Attention Kernels**: With the launch of [DeepSeek-V3.2](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp), we are releasing the corresponding token-level sparse attention kernels. These kernels power the model's DeepSeek Sparse Attention (DSA) and achieve up to 640 TFlops during prefilling and 410 TFlops during decoding. We also release a deep-dive blog for our new FP8 sparse decoding kernel. Check it out [here](docs/20250929-hopper-fp8-sparse-deep-dive.md).\n- **2025.08.01 Kernels for MHA on SM100**: Thanks to [NVIDIA's PR](https://github.com/deepseek-ai/FlashMLA/pull/76) for MHA forward / backward kernels on SM100!\n- **2025.04.22 Deep-Dive Blog**: We'd love to share the technical details behind the new FlashMLA kernel! Check out our deep-dive write-up [here](docs/20250422-new-kernel-deep-dive.md).\n- **2025.04.22 Performance Update**: We're excited to announce the new release of Flash MLA, which delivers 5% ~ 15% performance improvement for compute-bound workloads, achieving up to 660 TFlops on NVIDIA H800 SXM5 GPUs. The interface of the new version is fully compatible with the old one. Simply upgrade to the new version for an immediate performance boost! ğŸš€ğŸš€ğŸš€\n\n## Performance\n\n#### Test & benchmark MLA decoding (Sparse & Dense):\n\n```bash\npython tests/test_flash_mla_dense_decoding.py\npython tests/test_flash_mla_sparse_decoding.py\n```\n\nThe dense MLA decoding kernel achieves up to 3000 GB/s in memory-bound configuration and 660 TFLOPS in computation-bound configuration on H800 SXM5 with CUDA 12.8. The token-level sparse MLA decoding kernel (which uses an FP8 KV cache while performing the matrix multiplication in bfloat16) achieves 410 TFLOPS in compute-bound configuration on H800 SXM5 with CUDA 12.8, and achieves up to 350 TFlops on B200 (which is not really optimized yet).\n\n#### Test & benchmark MHA prefill (Dense):\n\n```bash\npython tests/test_fmha_sm100.py\n```\n\nIt achieves up to 1460 TFlops in forward and 1000 TFlops in backward computation on B200, as reported by NVIDIA.\n\n#### Test & benchmark MLA prefill (Sparse):\n\n```bash\npython tests/test_flash_mla_sparse_prefill.py\n```\n\nIt achieves up to 640 TFlops in forward computation on H800 SXM5 with CUDA 12.8, and achieves up to 1450 TFlops on B200, CUDA 12.9.\n\n## Requirements\n\n- SM90 / SM100 (See the support matrix below)\n- CUDA 12.8 and above (CUDA 12.9+ is required for SM100 kernels)\n- PyTorch 2.0 and above\n\nSupport matrix:\n\n| Kernel | GPU Architecture | MLA Mode [2] | KVCache Format |\n| :---: | :---: | :---: | :---: |\n| Dense Decoding | SM90 | MQA | BF16 |\n| Sparse Decoding | SM90 & SM100 | MQA | FP8 [1] |\n| Dense Prefill | SM100 | MHA |  |\n| Sparse Prefill | SM90 & SM100 | MQA |  |\n\n[1]: For more details on using FP8 KV cache, see documents below.\n\n[2]: Here \"MLA Mode\" refers to the mode used for MLA calculation. MQA stands for Multi-Query Attention mode (i.e. `head_dim_k` =  576 with `head_dim_v` = 512), while MHA stands for Multi-Head Attention mode (i.e. `head_dim_k` = 192 / 128 with `head_dim_v` = 128). For a detailed explanation of these modes, please refer to the appendix of [DeepSeek V3.2's Paper](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp).\n\n## Installation\n\n```bash\ngit clone https://github.com/deepseek-ai/FlashMLA.git flash-mla\ncd flash-mla\ngit submodule update --init --recursive\npip install -v .\n```\n\n## Usage\n\n### MLA Decoding\n\nTo use the MLA decoding kernels, call get_mla_metadata once before the decoding loop to get the tile scheduler metadata. Then, call flash_mla_with_kvcache in each decoding step. For example:\n\n```python\nfrom flash_mla import get_mla_metadata, flash_mla_with_kvcache\n\ntile_scheduler_metadata, num_splits = get_mla_metadata(\n    cache_seqlens,\n    s_q * h_q // h_kv,\n    h_kv,\n    h_q,\n    is_fp8,\n    topk,\n)\n\nfor i in range(num_layers):\n    ...\n    o_i, lse_i = flash_mla_with_kvcache(\n        q_i, kvcache_i, block_table, cache_seqlens, dv,\n        tile_scheduler_metadata, num_splits,\n        is_causal, is_fp8_kvcache, indices,\n    )\n    ...\n```\n\nWhere\n\n- `s_q` is the number of q tokens per q sequence. If MTP (speculative decoding) is disabled, it should be 1.\n- `h_kv` is the number of key-value heads.\n- `h_q` is the number of query heads.\n\n**FP8 KV Cache:**\nIf `is_fp8_kvcache` is set to `True`, the kernel reads the KV cache in the \"FP8 with scale\" format (described below). It dequantizes the cache to bfloat16 and performs attention computation in bfloat16. The output is also in bfloat16.\n\nIn the \"FP8 with scale\" format, each token's KV cache is 656 Bytes, structured as:\n-   **First 512 bytes:** The \"quantized NoPE\" part, containing 512 `float8_e4m3` values.\n-   **Next 16 bytes:** Scale factors, containing 4 `float32` values. The first `float32` is the scale for the first 128 `float8_e4m3` values, the second for the next 128, and so on.\n-   **Last 128 bytes:** The \"RoPE\" part, containing 64 `bfloat16` values. This part is not quantized for accuracy.\n\nSee `tests/quant.py` for quantization and dequantization details.\n\n**Sparse Attention (`indices` tensor):**\nThe `indices` tensor (if provided) enables token-level sparse attention by instructing the kernel to compute attention only for specified tokens.\n\n-   **Shape:** `indices` should be a 3D tensor of shape `(batch_size, seq_len_q, topk)`.\n-   **Format:** `indices_in_kvcache[i][j][k] = (the index of the page block where token t resides) * page_block_size + (the offset of token t within the page block)`, where `t` is the k-th token for the j-th query sequence in the i-th batch. Since the index of the page block has already been encoded into `indices_in_kvcache`, the kernel does not require the `block_table` parameter.\n-   **Invalid entries:** Set invalid indices to `-1`.\n\n**Return Values:**\nThe kernel returns `(out, lse)`, where:\n-   `out` is the attention result.\n-   `lse` is the log-sum-exp value of the attention scores for each query head.\n\nSee `tests/test_flash_mla_decoding.py` for a complete example.\n\n### Sparse MLA Prefill\n\nFor the sparse MLA prefill kernel, call `flash_mla_sparse_fwd` directly with the following parameters:\n-   `q`: Query tensor of shape `[s_q, h_q, d_qk]`\n-   `kv`: Key-Value tensor of shape `[s_kv, h_kv, d_qk]`\n-   `indices`: Indices tensor of shape `[s_q, h_kv, topk]`\n-   `sm_scale`: A scalar value\n\n**Note on batching:** This kernel does not support a batch dimension. For multi-batch inference, reshape the input tensors and adjust the `indices` parameter to simulate batch processing.\n\n**Invalid indices:** Set invalid entries in `indices` to `-1` or any number `>= s_kv`.\n\n**Return Values and Equivalent PyTorch Code:**\nThe kernel returns `(out, max_logits, lse)`. This is equivalent to the following PyTorch operations:\n\n```python\nQ: [s_q, h_q, d_qk], bfloat16\nkv: [s_kv, h_kv, d_qk], bfloat16\nindices: [s_q, h_kv, topk], int32\n\nkv = kv.squeeze(1)  # [s_kv, d_qk], h_kv must be 1\nindices = indices.squeeze(1)    # [s_q, topk]\nfocused_kv = kv[indices]    # For the i-th sequence (s_q), the corresponding KV tokens are selected from the KV cache based on indices[i, :]. This operation results in a tensor of shape [s_q, topk, d_qk].\n\nP = (Q @ focused_kv.transpose(-1, -2)) * sm_scale * math.log2(math.e)    # [s_q, h_q, topk]\nmax_logits = P.max(dim=-1) # [s_q, h_q]\nlse = log2sumexp2(P, dim=-1, base=2)   # [s_q, h_q]ï¼Œ\"log2sumexp2\" means that the exponentiation and logarithm are base-2\nS = exp2(P - lse)      # [s_q, h_q, topk]\nout = S @ focused_kv  # [s_q, h_q, d_qk]\n\nreturn (out, max_logits, lse)\n```\n\nSee `tests/test_flash_mla_prefill.py` for a complete example.\n\n### Dense MHA Prefill\n\nThis kernel implements the standard dense Multi-Head Attention (MHA) forward and backward operations. It can be called using:\n-   `flash_attn_varlen_func`\n-   `flash_attn_varlen_qkvpacked_func`\n-   `flash_attn_varlen_kvpacked_func`\n\nThe usage is similar to the `flash_attn` package. See `tests/test_fmha_sm100.py` for a complete example.\n\n## Acknowledgement\n\nFlashMLA is inspired by [FlashAttention 2&3](https://github.com/dao-AILab/flash-attention/) and [cutlass](https://github.com/nvidia/cutlass) projects.\n\n## Community Support\n\n### MetaX\nFor MetaX GPUs, visit the official website: [MetaX](https://www.metax-tech.com).\n\nThe corresponding FlashMLA version can be found at: [MetaX-MACA/FlashMLA](https://github.com/MetaX-MACA/FlashMLA)\n\n\n### Moore Threads\nFor the Moore Threads GPU, visit the official website: [Moore Threads](https://www.mthreads.com/).\n\nThe corresponding FlashMLA version is available on GitHub: [MooreThreads/MT-flashMLA](https://github.com/MooreThreads/MT-flashMLA).\n\n\n### Hygon DCU\nFor the Hygon DCU, visit the official website: [Hygon Developer](https://developer.sourcefind.cn/).\n\nThe corresponding FlashMLA version is available here: [OpenDAS/MLAttention](https://developer.sourcefind.cn/codes/OpenDAS/MLAttention).\n\n\n### Intellifusion\nFor the Intellifusion NNP, visit the official website: [Intellifusion](https://www.intellif.com).\n\nThe corresponding FlashMLA version is available on Gitee: [Intellifusion/tyllm](https://gitee.com/Intellifusion_2025/tyllm/blob/master/python/tylang/flash_mla.py).\n\n\n### Iluvatar Corex\nFor Iluvatar Corex GPUs, visit the official website: [Iluvatar Corex](https://www.iluvatar.com).\n\nThe corresponding FlashMLA version is available on GitHub: [Deep-Spark/FlashMLA](https://github.com/Deep-Spark/FlashMLA/tree/iluvatar_flashmla)\n\n\n### AMD Instinct\nFor AMD Instinct GPUs, visit the official website: [AMD Instinct](https://www.amd.com/en/products/accelerators/instinct.html).\n\nThe corresponding FlashMLA version can be found at: [AITER/MLA](https://github.com/ROCm/aiter/blob/main/aiter/mla.py)\n\n## Citation\n\n```bibtex\n@misc{flashmla2025,\n      title={FlashMLA: Efficient Multi-head Latent Attention Kernels},\n      author={Jiashi Li, Shengyu Liu},\n      year={2025},\n      publisher = {GitHub},\n      howpublished = {\\url{https://github.com/deepseek-ai/FlashMLA}},\n}\n```\n",
      "stars_today": 98
    },
    {
      "id": 1014938055,
      "name": "pg_textsearch",
      "full_name": "timescale/pg_textsearch",
      "description": "PostgreSQL extension for BM25 relevance-ranked full-text search. Postgres OSS licensed.",
      "html_url": "https://github.com/timescale/pg_textsearch",
      "stars": 2698,
      "forks": 66,
      "language": "C",
      "topics": [
        "bm25",
        "c-extension",
        "full-text-search",
        "postgresql"
      ],
      "created_at": "2025-07-06T17:45:50Z",
      "updated_at": "2026-01-25T01:44:13Z",
      "pushed_at": "2026-01-25T02:26:24Z",
      "open_issues": 18,
      "owner": {
        "login": "timescale",
        "avatar_url": "https://avatars.githubusercontent.com/u/8986001?v=4"
      },
      "readme": "# pg_textsearch\n\n[![CI](https://github.com/timescale/pg_textsearch/actions/workflows/ci.yml/badge.svg)](https://github.com/timescale/pg_textsearch/actions/workflows/ci.yml)\n[![Benchmarks](https://github.com/timescale/pg_textsearch/actions/workflows/benchmark.yml/badge.svg)](https://timescale.github.io/pg_textsearch/benchmarks/)\n[![Coverity Scan](https://scan.coverity.com/projects/32822/badge.svg)](https://scan.coverity.com/projects/pg_textsearch)\n\nModern ranked text search for Postgres.\n\n- Simple syntax: `ORDER BY content <@> 'search terms'`\n- BM25 ranking with configurable parameters (k1, b)\n- Works with Postgres text search configurations (english, french, german, etc.)\n- Fast top-k queries via Block-Max WAND optimization\n- Parallel index builds for large tables\n- Supports partitioned tables\n- Best in class performance and scalability\n\nâš ï¸ **Pre-release**: v0.5.0-dev - GA expected Feb 2026. Query performance is competitive with other leading Postgres-based solutions; see [benchmarks](https://timescale.github.io/pg_textsearch/benchmarks/comparison.html). This release adds index compression; parallel builds coming soon. See [ROADMAP.md](ROADMAP.md) for details.\n\n![Tapir and Friends](images/tapir_and_friends_v0.5.0-dev.png)\n\n*The theme of v0.5.0 is parallel indexing.*\n\n## Historical note\n\nThe original name of the project was Tapir - **T**extual **A**nalysis for **P**ostgres **I**nformation **R**etrieval.  We still use the tapir as our\nmascot and the name occurs in various places in the source code.\n\n## PostgreSQL Version Compatibility\n\npg_textsearch supports PostgreSQL 17 and 18.\n\n## Installation\n\n### Pre-built Binaries\n\nDownload pre-built binaries from the\n[Releases page](https://github.com/timescale/pg_textsearch/releases).\nAvailable for Linux and macOS (amd64 and arm64), PostgreSQL 17 and 18.\n\n### Build from Source\n\n```sh\ncd /tmp\ngit clone https://github.com/timescale/pg_textsearch\ncd pg_textsearch\nmake\nmake install # may need sudo\n```\n\n## Getting Started\n\nEnable the extension (do this once in each database where you want to use it)\n\n```sql\nCREATE EXTENSION pg_textsearch;\n```\n\nCreate a table with text content\n\n```sql\nCREATE TABLE documents (id bigserial PRIMARY KEY, content text);\nINSERT INTO documents (content) VALUES\n    ('PostgreSQL is a powerful database system'),\n    ('BM25 is an effective ranking function'),\n    ('Full text search with custom scoring');\n```\n\nCreate a pg_textsearch index on the text column\n\n```sql\nCREATE INDEX docs_idx ON documents USING bm25(content) WITH (text_config='english');\n```\n\n## Querying\n\nGet the most relevant documents using the `<@>` operator\n\n```sql\nSELECT * FROM documents\nORDER BY content <@> 'database system'\nLIMIT 5;\n```\n\nNote: `<@>` returns the negative BM25 score since Postgres only supports `ASC` order index scans on operators. Lower scores indicate better matches.\n\nThe index is automatically detected from the column. For explicit index specification:\n```sql\nSELECT * FROM documents\nWHERE content <@> to_bm25query('database system', 'docs_idx') < -1.0;\n```\n\nSupported operations:\n- `text <@> 'query'` - Score text against a query (index auto-detected)\n- `text <@> bm25query` - Score text with explicit index specification\n\n### Verifying Index Usage\n\nCheck query plan with EXPLAIN:\n```sql\nEXPLAIN SELECT * FROM documents\nORDER BY content <@> 'database system'\nLIMIT 5;\n```\n\nFor small datasets, PostgreSQL may prefer sequential scans. Force index usage:\n```sql\nSET enable_seqscan = off;\n```\n\nNote: Even if EXPLAIN shows a sequential scan, `<@>` and `to_bm25query` always use the index for corpus statistics (document counts, average length) required for BM25 scoring.\n\n### Filtering with WHERE Clauses\n\nThere are two ways filtering interacts with BM25 index scans:\n\n**Pre-filtering** uses a separate index (B-tree, etc.) to reduce rows before scoring:\n```sql\n-- Create index on filter column\nCREATE INDEX ON documents (category_id);\n\n-- Query filters first, then scores matching rows\nSELECT * FROM documents\nWHERE category_id = 123\nORDER BY content <@> 'search terms'\nLIMIT 10;\n```\n\n**Post-filtering** applies the BM25 index scan first, then filters results:\n```sql\nSELECT * FROM documents\nWHERE content <@> to_bm25query('search terms', 'docs_idx') < -5.0\nORDER BY content <@> 'search terms'\nLIMIT 10;\n```\n\n**Performance considerations**:\n\n- **Pre-filtering tradeoff**: If the filter matches many rows (e.g., 100K+), scoring\n  all of them can be expensive. The BM25 index is most efficient when it can use\n  top-k optimization (ORDER BY + LIMIT) to avoid scoring every matching document.\n\n- **Post-filtering tradeoff**: The index returns top-k results *before* filtering.\n  If your WHERE clause eliminates most results, you may get fewer rows than\n  requested. Increase LIMIT to compensate, then re-limit in application code.\n\n- **Best case**: Pre-filter with a selective condition (matches <10% of rows), then\n  let BM25 score the reduced set with ORDER BY + LIMIT.\n\nThis is similar to the [filtering behavior in pgvector](https://github.com/pgvector/pgvector?tab=readme-ov-file#filtering),\nwhere approximate indexes also apply filtering after the index scan.\n\n## Indexing\n\nCreate a BM25 index on your text columns:\n\n```sql\nCREATE INDEX ON documents USING bm25(content) WITH (text_config='english');\n```\n\n### Index Options\n\n- `text_config` - PostgreSQL text search configuration to use (required)\n- `k1` - term frequency saturation parameter (1.2 by default)\n- `b` - length normalization parameter (0.75 by default)\n\n```sql\nCREATE INDEX ON documents USING bm25(content) WITH (text_config='english', k1=1.5, b=0.8);\n```\n\nAlso supports different text search configurations:\n\n```sql\n-- English documents with stemming\nCREATE INDEX docs_en_idx ON documents USING bm25(content) WITH (text_config='english');\n\n-- Simple text processing without stemming\nCREATE INDEX docs_simple_idx ON documents USING bm25(content) WITH (text_config='simple');\n\n-- Language-specific configurations\nCREATE INDEX docs_fr_idx ON french_docs USING bm25(content) WITH (text_config='french');\nCREATE INDEX docs_de_idx ON german_docs USING bm25(content) WITH (text_config='german');\n```\n\n## Data Types\n\n### bm25query\n\nThe `bm25query` type represents queries for BM25 scoring with optional index context:\n\n```sql\n-- Create a bm25query with index name (required for WHERE clause and standalone scoring)\nSELECT to_bm25query('search query text', 'docs_idx');\n-- Returns: docs_idx:search query text\n\n-- Embedded index name syntax (alternative form using cast)\nSELECT 'docs_idx:search query text'::bm25query;\n-- Returns: docs_idx:search query text\n\n-- Create a bm25query without index name (only works in ORDER BY with index scan)\nSELECT to_bm25query('search query text');\n-- Returns: search query text\n```\n\n**Note**: In PostgreSQL 18, the embedded index name syntax using single colon (`:`) allows the\nquery planner to determine the index name even when evaluating SELECT clause expressions early.\nThis ensures compatibility across different query evaluation strategies.\n\n#### bm25query Functions\n\nFunction | Description\n--- | ---\nto_bm25query(text) â†’ bm25query | Create bm25query without index name (for ORDER BY only)\nto_bm25query(text, text) â†’ bm25query | Create bm25query with query text and index name\ntext <@> bm25query â†’ double precision | BM25 scoring operator (returns negative scores)\nbm25query = bm25query â†’ boolean | Equality comparison\n\n## Performance\n\npg_textsearch indexes use a memtable architecture for efficient writes. Like other index types, it's faster to create an index after loading your data.\n\n```sql\n-- Load data first\nINSERT INTO documents (content) VALUES (...);\n\n-- Then create index\nCREATE INDEX docs_idx ON documents USING bm25(content) WITH (text_config='english');\n```\n\n### Parallel Index Builds\n\npg_textsearch supports parallel index builds for faster indexing of large tables.\nPostgres automatically uses parallel workers based on table size and configuration.\n\n```sql\n-- Configure parallel workers (optional, uses server defaults otherwise)\nSET max_parallel_maintenance_workers = 4;\n\n-- Create index (parallel workers used automatically for large tables)\nCREATE INDEX docs_idx ON documents USING bm25(content) WITH (text_config='english');\n```\n\nYou'll see a notice when parallel build is used:\n```\nNOTICE:  Using parallel index build with 4 workers (1000000 tuples)\n```\n\nFor partitioned tables, each partition builds its index independently with parallel\nworkers if the partition is large enough. This allows efficient indexing of very\nlarge partitioned datasets.\n\n## Monitoring\n\n```sql\n-- Check index usage\nSELECT schemaname, tablename, indexname, idx_scan, idx_tup_read, idx_tup_fetch\nFROM pg_stat_user_indexes\nWHERE indexrelid::regclass::text ~ 'pg_textsearch';\n```\n\n### Configuration\n\nOptional settings in `postgresql.conf`:\n\n```bash\n# Query limit when no LIMIT clause detected\npg_textsearch.default_limit = 1000           # default 1000\n\n# Auto-spill thresholds (set to 0 to disable)\npg_textsearch.bulk_load_threshold = 100000    # terms per transaction\npg_textsearch.memtable_spill_threshold = 32000000  # posting entries (~1M docs/segment)\n\n# Compression (v0.4.0+)\npg_textsearch.compress_segments = on          # default on\n\n# Query optimization\npg_textsearch.enable_bmw = on                 # Block-Max WAND for top-k queries\n```\n\nThe `memtable_spill_threshold` controls when the in-memory index spills to\ndisk segments. When the memtable reaches this many posting entries, it\nautomatically flushes to a segment at transaction commit. This keeps memory\nusage bounded while maintaining good query performance.\n\n**Crash recovery**: The memtable is rebuilt from the heap on startup, so no\ndata is lost if Postgres crashes before spilling to disk.\n\n## Examples\n\n### Basic Search\n\n```sql\nCREATE TABLE articles (id serial PRIMARY KEY, title text, content text);\nCREATE INDEX articles_idx ON articles USING bm25(content) WITH (text_config='english');\n\nINSERT INTO articles (title, content) VALUES\n    ('Database Systems', 'PostgreSQL is a powerful relational database system'),\n    ('Search Technology', 'Full text search enables finding relevant documents quickly'),\n    ('Information Retrieval', 'BM25 is a ranking function used in search engines');\n\n-- Find relevant documents\nSELECT title, content <@> 'database search' as score\nFROM articles\nORDER BY score;\n```\n\nAlso supports different languages and custom parameters:\n\n```sql\n-- Different languages\nCREATE INDEX fr_idx ON french_articles USING bm25(content) WITH (text_config='french');\nCREATE INDEX de_idx ON german_articles USING bm25(content) WITH (text_config='german');\n\n-- Custom parameters\nCREATE INDEX custom_idx ON documents USING bm25(content)\n    WITH (text_config='english', k1=2.0, b=0.9);\n```\n\n\n## Limitations\n\n### Partitioned Tables\n\nBM25 indexes on partitioned tables use **partition-local statistics**. Each\npartition maintains its own:\n- Document count (`total_docs`)\n- Average document length (`avg_doc_len`)\n- Per-term document frequencies for IDF calculation\n\nThis means:\n- Queries targeting a single partition compute accurate BM25 scores using that\n  partition's statistics\n- Queries spanning multiple partitions return scores computed independently per\n  partition, which may not be directly comparable across partitions\n\n**Example**: If partition A has 1000 documents and partition B has 10 documents,\nthe term \"database\" would have different IDF values in each partition. Results\nfrom both partitions would have scores on different scales.\n\n**Recommendations**:\n- For time-partitioned data, query individual partitions when score comparability\n  matters\n- Use partitioning schemes where queries naturally target single partitions\n- Consider this behavior when designing partition strategies for search workloads\n\n```sql\n-- Query single partition (scores are accurate within partition)\nSELECT * FROM docs\nWHERE created_at >= '2024-01-01' AND created_at < '2025-01-01'\nORDER BY content <@> 'search terms'\nLIMIT 10;\n\n-- Cross-partition query (scores computed per-partition)\nSELECT * FROM docs\nORDER BY content <@> 'search terms'\nLIMIT 10;\n```\n\n### Word Length Limit\n\npg_textsearch inherits PostgreSQL's tsvector word length limit of 2047 characters.\nWords exceeding this limit are ignored during tokenization (with an INFO message).\nThis is defined by `MAXSTRLEN` in PostgreSQL's text search implementation.\n\nFor typical natural language text, this limit is never encountered. It may affect\ndocuments containing very long tokens such as base64-encoded data, long URLs, or\nconcatenated identifiers.\n\nThis behavior is similar to other search engines:\n- Elasticsearch: Truncates tokens (configurable via `truncate` filter, default 10 chars)\n- Tantivy: Truncates to 255 bytes by default\n\n### PL/pgSQL and Stored Procedures\n\nThe implicit `text <@> 'query'` syntax relies on planner hooks to automatically\ndetect the BM25 index. These hooks don't run inside PL/pgSQL DO blocks, functions,\nor stored procedures.\n\n**Inside PL/pgSQL**, use explicit index names with `to_bm25query()`:\n\n```sql\n-- This won't work in PL/pgSQL:\n-- SELECT * FROM docs ORDER BY content <@> 'search terms' LIMIT 10;\n\n-- Use explicit index name instead:\nSELECT * FROM docs\nORDER BY content <@> to_bm25query('search terms', 'docs_idx')\nLIMIT 10;\n```\n\nRegular SQL queries (outside PL/pgSQL) support both forms.\n\n## Troubleshooting\n\n```sql\n-- List available text search configurations\nSELECT cfgname FROM pg_ts_config;\n\n-- List BM25 indexes\nSELECT indexname FROM pg_indexes WHERE indexdef LIKE '%USING bm25%';\n```\n\n\n## Installation Notes\n\nIf your machine has multiple Postgres installations, specify the path to `pg_config`:\n\n```sh\nexport PG_CONFIG=/Library/PostgreSQL/18/bin/pg_config  # or 17\nmake clean && make && make install\n```\n\nIf you get compilation errors, install Postgres development files:\n\n```sh\n# Ubuntu/Debian\nsudo apt install postgresql-server-dev-17  # for PostgreSQL 17\nsudo apt install postgresql-server-dev-18  # for PostgreSQL 18\n```\n\n## Reference\n\n### Index Options\n\nOption | Type | Default | Description\n--- | --- | --- | ---\ntext_config | string | required | PostgreSQL text search configuration to use\nk1 | real | 1.2 | Term frequency saturation parameter (0.1 to 10.0)\nb | real | 0.75 | Length normalization parameter (0.0 to 1.0)\n\n### Text Search Configurations\n\nAvailable configurations depend on your Postgres installation:\n```\n# SELECT cfgname FROM pg_ts_config;\n  cfgname\n------------\n simple\n arabic\n armenian\n basque\n catalan\n danish\n dutch\n english\n finnish\n french\n german\n greek\n hindi\n hungarian\n indonesian\n irish\n italian\n lithuanian\n nepali\n norwegian\n portuguese\n romanian\n russian\n serbian\n spanish\n swedish\n tamil\n turkish\n yiddish\n(29 rows)\n```\nFurther language support is available via extensions such as [zhparser](https://github.com/amutu/zhparser).\n\n### Development Functions\n\nThese functions are for debugging and development use only. Their interface may\nchange in future releases without notice.\n\nFunction | Description\n--- | ---\nbm25_dump_index(index_name) â†’ text | Dump internal index structure (truncated)\nbm25_dump_index(index_name, file_path) â†’ text | Dump full index structure to file\nbm25_summarize_index(index_name) â†’ text | Show index statistics without content\nbm25_spill_index(index_name) â†’ int4 | Force memtable spill to disk segment\n\n```sql\n-- Quick overview of index statistics\nSELECT bm25_summarize_index('docs_idx');\n\n-- Detailed dump for debugging (truncated output)\nSELECT bm25_dump_index('docs_idx');\n\n-- Full dump to file (includes hex data)\nSELECT bm25_dump_index('docs_idx', '/tmp/docs_idx_dump.txt');\n\n-- Force spill to disk (returns number of entries spilled)\nSELECT bm25_spill_index('docs_idx');\n```\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for development setup, code style, and\nhow to submit pull requests.\n\n- **Bug Reports**: [Create an issue](https://github.com/timescale/pg_textsearch/issues/new?labels=bug&template=bug_report.md)\n- **Feature Requests**: [Request a feature](https://github.com/timescale/pg_textsearch/issues/new?labels=enhancement&template=feature_request.md)\n- **General Discussion**: [Start a discussion](https://github.com/timescale/pg_textsearch/discussions)\n",
      "stars_today": 97
    },
    {
      "id": 942206898,
      "name": "dynamo",
      "full_name": "ai-dynamo/dynamo",
      "description": "A Datacenter Scale Distributed Inference Serving Framework",
      "html_url": "https://github.com/ai-dynamo/dynamo",
      "stars": 5957,
      "forks": 812,
      "language": "Rust",
      "topics": [],
      "created_at": "2025-03-03T18:40:07Z",
      "updated_at": "2026-01-25T00:28:35Z",
      "pushed_at": "2026-01-25T02:19:03Z",
      "open_issues": 455,
      "owner": {
        "login": "ai-dynamo",
        "avatar_url": "https://avatars.githubusercontent.com/u/201626793?v=4"
      },
      "readme": "<!--\nSPDX-FileCopyrightText: Copyright (c) 2024-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\nSPDX-License-Identifier: Apache-2.0\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n\n![Dynamo banner](./docs/images/frontpage-banner.png)\n\n[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/dynamo)](https://github.com/ai-dynamo/dynamo/releases/latest)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/ai-dynamo/dynamo)\n[![Discord](https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat)](https://discord.gg/D92uqZRjCZ) ![Community Contributors](https://img.shields.io/badge/community_contributors-70%2B-brightgreen) ![Community PRs](https://img.shields.io/badge/PRs_merged-130%2B-blue)\n\n| **[Roadmap](https://github.com/ai-dynamo/dynamo/issues/5506)** | **[Support Matrix](https://github.com/ai-dynamo/dynamo/blob/main/docs/reference/support-matrix.md)** | **[Docs](https://docs.nvidia.com/dynamo/latest/index.html)** | **[Recipes](https://github.com/ai-dynamo/dynamo/tree/main/recipes)** | **[Examples](https://github.com/ai-dynamo/dynamo/tree/main/examples)** | **[Prebuilt Containers](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo)** | **[Design Proposals](https://github.com/ai-dynamo/enhancements)** | **[Blogs](https://developer.nvidia.com/blog/tag/nvidia-dynamo)**\n\n# NVIDIA Dynamo\n\nHigh-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.\n\n## Why Dynamo\n\n<p align=\"center\">\n  <img src=\"./docs/images/frontpage-gpu-vertical.png\" alt=\"Multi Node Multi-GPU topology\" width=\"600\" />\n</p>\n\nLarge language models exceed single-GPU capacity. Tensor parallelism spreads layers across GPUs but creates coordination challenges. Dynamo closes this orchestration gap.\n\nDynamo is inference engine agnostic (supports TRT-LLM, vLLM, SGLang) and provides:\n\n- **Disaggregated Prefill & Decode** â€“ Maximizes GPU throughput with latency/throughput trade-offs\n- **Dynamic GPU Scheduling** â€“ Optimizes performance based on fluctuating demand\n- **LLM-Aware Request Routing** â€“ Eliminates unnecessary KV cache re-computation\n- **Accelerated Data Transfer** â€“ Reduces inference response time using NIXL\n- **KV Cache Offloading** â€“ Leverages multiple memory hierarchies for higher throughput\n\n<p align=\"center\">\n  <img src=\"./docs/images/frontpage-architecture.png\" alt=\"Dynamo architecture\" width=\"600\" />\n</p>\n\nBuilt in Rust for performance and Python for extensibility, Dynamo is fully open-source with an OSS-first development approach.\n\n## Framework Support Matrix\n\n| Feature                                                              | [vLLM](docs/backends/vllm/README.md) | [SGLang](docs/backends/sglang/README.md) | [TensorRT-LLM](docs/backends/trtllm/README.md) |\n| -------------------------------------------------------------------- | :--: | :----: | :----------: |\n| [**Disaggregated Serving**](docs/design_docs/disagg_serving.md)      | âœ…   | âœ…     | âœ…           |\n| [**KV-Aware Routing**](docs/router/kv_cache_routing.md)              | âœ…   | âœ…     | âœ…           |\n| [**SLA-Based Planner**](docs/planner/sla_planner.md)                 | âœ…   | âœ…     | âœ…           |\n| [**KVBM**](docs/kvbm/kvbm_architecture.md)                           | âœ…   | ğŸš§     | âœ…           |\n| [**Multimodal**](docs/multimodal/index.md)                           | âœ…   | âœ…     | âœ…           |\n| [**Tool Calling**](docs/agents/tool-calling.md)                      | âœ…   | âœ…     | âœ…           |\n\n> **[Full Feature Matrix â†’](feature-matrix.md)** â€” Detailed compatibility including LoRA, Request Migration, Speculative Decoding, and feature interactions.\n\n## Latest News\n\n- [12/05] [Moonshot AI's Kimi K2 achieves 10x inference speedup with Dynamo on GB200](https://quantumzeitgeist.com/kimi-k2-nvidia-ai-ai-breakthrough/)\n- [12/02] [Mistral AI runs Mistral Large 3 with 10x faster inference using Dynamo](https://www.marktechpost.com/2025/12/02/nvidia-and-mistral-ai-bring-10x-faster-inference-for-the-mistral-3-family-on-gb200-nvl72-gpu-systems/)\n- [12/01] [InfoQ: NVIDIA Dynamo simplifies Kubernetes deployment for LLM inference](https://www.infoq.com/news/2025/12/nvidia-dynamo-kubernetes/)\n- [11/20] [Dell integrates PowerScale with Dynamo's NIXL for 19x faster TTFT](https://www.dell.com/en-us/dt/corporate/newsroom/announcements/detailpage.press-releases~usa~2025~11~dell-technologies-and-nvidia-advance-enterprise-ai-innovation.htm)\n- [11/20] [WEKA partners with NVIDIA on KV cache storage for Dynamo](https://siliconangle.com/2025/11/20/nvidia-weka-kv-cache-solution-ai-inferencing-sc25/)\n- [11/13] [Dynamo Office Hours Playlist](https://www.youtube.com/playlist?list=PL5B692fm6--tgryKu94h2Zb7jTFM3Go4X)\n- [10/16] [How Baseten achieved 2x faster inference with NVIDIA Dynamo](https://www.baseten.co/blog/how-baseten-achieved-2x-faster-inference-with-nvidia-dynamo/)\n\n## Get Started\n\n| Path | Use Case | Time | Requirements |\n|------|----------|------|--------------|\n| [**Local Quick Start**](#local-quick-start) | Test on a single machine | ~5 min | 1 GPU, Ubuntu 24.04 |\n| [**Kubernetes Deployment**](#kubernetes-deployment) | Production multi-node clusters | ~30 min | K8s cluster with GPUs |\n\n## Contributing\n\nWant to help shape the future of distributed LLM inference? We welcome contributors at all levelsâ€”from doc fixes to new features.\n\n- **[Contributing Guide](CONTRIBUTING.md)** â€“ How to get started\n- **[Report a Bug](https://github.com/ai-dynamo/dynamo/issues/new?template=bug_report.yml)** â€“ Found an issue?\n- **[Feature Request](https://github.com/ai-dynamo/dynamo/issues/new?template=feature_request.yml)** â€“ Have an idea?\n\n# Local Quick Start\n\nThe following examples require a few system level packages.\nRecommended to use Ubuntu 24.04 with a x86_64 CPU. See [docs/reference/support-matrix.md](docs/reference/support-matrix.md)\n\n## 1. Initial Setup\n\nThe Dynamo team recommends the `uv` Python package manager, although any way works. Install uv:\n\n```\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n### Install Python Development Headers\n\nBackend engines require Python development headers for JIT compilation. Install them with:\n\n```bash\nsudo apt install python3-dev\n```\n\n## 2. Select an Engine\n\nWe publish Python wheels specialized for each of our supported engines: vllm, sglang, and trtllm. The examples that follow use SGLang; continue reading for other engines.\n\n```\nuv venv venv\nsource venv/bin/activate\nuv pip install pip\n\n# Choose one\nuv pip install \"ai-dynamo[sglang]\"  #replace with [vllm], [trtllm], etc.\n```\n\n## 3. Run Dynamo\n\n### Sanity Check (Optional)\n\nBefore trying out Dynamo, you can verify your system configuration and dependencies:\n\n```bash\npython3 deploy/sanity_check.py\n```\n\nThis is a quick check for system resources, development tools, LLM frameworks, and Dynamo components.\n\n### Running an LLM API Server\n\nDynamo provides a simple way to spin up a local set of inference components including:\n\n- **OpenAI Compatible Frontend** â€“ High performance OpenAI compatible http api server written in Rust.\n- **Basic and Kv Aware Router** â€“ Route and load balance traffic to a set of workers.\n- **Workers** â€“ Set of pre-configured LLM serving engines.\n\n```bash\n# Start an OpenAI compatible HTTP server with prompt templating, tokenization, and routing.\n# For local dev: --store-kv file avoids etcd (workers and frontend must share a disk)\npython3 -m dynamo.frontend --http-port 8000 --store-kv file\n\n# Start the SGLang engine. You can run several of these for the same or different models.\n# The frontend will discover them automatically.\npython3 -m dynamo.sglang --model-path deepseek-ai/DeepSeek-R1-Distill-Llama-8B --store-kv file\n```\n\n> **Note:** vLLM workers publish KV cache events by default, which requires NATS. For dependency-free local development with vLLM, add `--kv-events-config '{\"enable_kv_cache_events\": false}'`. This keeps local prefix caching enabled while disabling event publishing. See [Service Discovery and Messaging](#service-discovery-and-messaging) for details.\n\n#### Send a Request\n\n```bash\ncurl localhost:8000/v1/chat/completions   -H \"Content-Type: application/json\"   -d '{\n    \"model\": \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n    \"messages\": [\n    {\n        \"role\": \"user\",\n        \"content\": \"Hello, how are you?\"\n    }\n    ],\n    \"stream\":false,\n    \"max_tokens\": 300\n  }' | jq\n```\n\nRerun with `curl -N` and change `stream` in the request to `true` to get the responses as soon as the engine issues them.\n\n### What's Next?\n\n- **Scale up**: Deploy on Kubernetes with [Recipes](recipes/)\n- **Add features**: Enable [KV-aware routing](docs/router/kv_cache_routing.md), [disaggregated serving](docs/design_docs/disagg_serving.md)\n- **Benchmark**: Use [AIPerf](docs/benchmarks/benchmarking.md) to measure performance\n- **Try other engines**: [vLLM](docs/backends/vllm/), [SGLang](docs/backends/sglang/), [TensorRT-LLM](docs/backends/trtllm/)\n\n# Kubernetes Deployment\n\nFor production deployments on Kubernetes clusters with multiple GPUs.\n\n## Prerequisites\n\n- Kubernetes cluster with GPU nodes\n- [Dynamo Platform installed](docs/kubernetes/README.md)\n- HuggingFace token for model downloads\n\n## Production Recipes\n\nPre-built deployment configurations for common models and topologies:\n\n| Model | Framework | Mode | GPUs | Recipe |\n|-------|-----------|------|------|--------|\n| Llama-3.1-70B | vLLM | Aggregated | 4x H100 | [View](recipes/vllm/llama-3.1-70b/) |\n| DeepSeek-R1 | SGLang | Disaggregated | 8x H200 | [View](recipes/sglang/deepseek-r1/) |\n| Qwen3-32B | TensorRT-LLM | Disaggregated | 8x GPU | [View](recipes/trtllm/qwen3-32b/) |\n\nSee [recipes/README.md](recipes/README.md) for the full list and deployment instructions.\n\n## Cloud Deployment Guides\n\n- [Amazon EKS](examples/deployments/EKS/)\n- [Google GKE](examples/deployments/GKE/)\n\n# Concepts\n\n## Engines\n\nDynamo is inference engine agnostic. Install the wheel for your chosen engine and run with `python3 -m dynamo.<engine> --help`.\n\n| Engine | Install | Docs | Best For |\n|--------|---------|------|----------|\n| vLLM | `uv pip install ai-dynamo[vllm]` | [Guide](docs/backends/vllm/) | Broadest feature coverage |\n| SGLang | `uv pip install ai-dynamo[sglang]` | [Guide](docs/backends/sglang/) | High-throughput serving |\n| TensorRT-LLM | `pip install --pre --extra-index-url https://pypi.nvidia.com ai-dynamo[trtllm]` | [Guide](docs/backends/trtllm/) | Maximum performance |\n\n> **Note:** TensorRT-LLM requires `pip` (not `uv`) due to URL-based dependencies. See the [TRT-LLM guide](docs/backends/trtllm/) for container setup and prerequisites.\n\nUse `CUDA_VISIBLE_DEVICES` to specify which GPUs to use. Engine-specific options (context length, multi-GPU, etc.) are documented in each backend guide.\n\n## Service Discovery and Messaging\n\nDynamo uses TCP for inter-component communication. External services are optional for most deployments:\n\n| Deployment | etcd | NATS | Notes |\n|------------|------|------|-------|\n| **Kubernetes** | âŒ Not required | âŒ Not required | K8s-native discovery; TCP request plane |\n| **Local Development** | âŒ Not required | âŒ Not required | Pass `--store-kv file`; vLLM also needs `--kv-events-config '{\"enable_kv_cache_events\": false}'` |\n| **KV-Aware Routing** | â€” | âœ… Required | Prefix caching enabled by default requires NATS |\n\nFor local development without external dependencies, pass `--store-kv file` (avoids etcd) to both the frontend and workers. vLLM users should also pass `--kv-events-config '{\"enable_kv_cache_events\": false}'` to disable KV event publishing (avoids NATS) while keeping local prefix caching enabled; SGLang and TRT-LLM don't require this flag.\n\nFor distributed non-Kubernetes deployments or KV-aware routing:\n\n- [etcd](https://etcd.io/) can be run directly as `./etcd`.\n- [nats](https://nats.io/) needs JetStream enabled: `nats-server -js`.\n\nTo quickly setup both: `docker compose -f deploy/docker-compose.yml up -d`\n\n# Advanced Topics\n\n## Benchmarking\n\nDynamo provides comprehensive benchmarking tools:\n\n- **[Benchmarking Guide](docs/benchmarks/benchmarking.md)** â€“ Compare deployment topologies using AIPerf\n- **[SLA-Driven Deployments](docs/planner/sla_planner_quickstart.md)** â€“ Optimize deployments to meet SLA requirements\n\n## Frontend OpenAPI Specification\n\nThe OpenAI-compatible frontend exposes an OpenAPI 3 spec at `/openapi.json`. To generate without running the server:\n\n```bash\ncargo run -p dynamo-llm --bin generate-frontend-openapi\n```\n\nThis writes to `docs/frontends/openapi.json`.\n\n# Building from Source\n\nFor contributors who want to build Dynamo from source rather than installing from PyPI.\n\n## 1. Install Libraries\n\n**Ubuntu:**\n\n```\nsudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake\n```\n\n**macOS:**\n\n- [Homebrew](https://brew.sh/)\n\n```\n# if brew is not installed on your system, install it\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n```\n\n- [Xcode](https://developer.apple.com/xcode/)\n\n```\nbrew install cmake protobuf\n\n## Check that Metal is accessible\nxcrun -sdk macosx metal\n```\n\nIf Metal is accessible, you should see an error like `metal: error: no input files`, which confirms it is installed correctly.\n\n## 2. Install Rust\n\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsource $HOME/.cargo/env\n```\n\n## 3. Create a Python Virtual Environment\n\nFollow the instructions in [uv installation](https://docs.astral.sh/uv/#installation) guide to install uv if you don't have `uv` installed. Once uv is installed, create a virtual environment and activate it.\n\n- Install uv\n\n```bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n- Create a virtual environment\n\n```bash\nuv venv dynamo\nsource dynamo/bin/activate\n```\n\n## 4. Install Build Tools\n\n```\nuv pip install pip maturin\n```\n\n[Maturin](https://github.com/PyO3/maturin) is the Rust<->Python bindings build tool.\n\n## 5. Build the Rust Bindings\n\n```\ncd lib/bindings/python\nmaturin develop --uv\n```\n\n## 6. Install GPU Memory Service\n\nThe GPU Memory Service is a Python package with a C++ extension. It requires only Python development headers and a C++ compiler (g++).\n\n```bash\ncd $PROJECT_ROOT\nuv pip install -e lib/gpu_memory_service\n```\n\n## 7. Install the Wheel\n\n```\ncd $PROJECT_ROOT\nuv pip install -e .\n```\n\nYou should now be able to run `python3 -m dynamo.frontend`.\n\nFor local development, pass `--store-kv file` to avoid external dependencies (see Service Discovery and Messaging section).\n\nSet the environment variable `DYN_LOG` to adjust the logging level; for example, `export DYN_LOG=debug`. It has the same syntax as `RUST_LOG`.\n\nIf you use vscode or cursor, we have a .devcontainer folder built on [Microsofts Extension](https://code.visualstudio.com/docs/devcontainers/containers). For instructions see the [ReadMe](.devcontainer/README.md) for more details.\n\n<!-- Reference links for Feature Compatibility Matrix -->\n[disagg]: docs/design_docs/disagg_serving.md\n[kv-routing]: docs/router/kv_cache_routing.md\n[planner]: docs/planner/sla_planner.md\n[kvbm]: docs/kvbm/kvbm_architecture.md\n[mm]: examples/multimodal/\n[migration]: docs/fault_tolerance/request_migration.md\n[lora]: examples/backends/vllm/deploy/lora/README.md\n[tools]: docs/agents/tool-calling.md\n",
      "stars_today": 93
    },
    {
      "id": 1012625755,
      "name": "git-ai",
      "full_name": "git-ai-project/git-ai",
      "description": "A Git extension for tracking the AI-generated code in your repos",
      "html_url": "https://github.com/git-ai-project/git-ai",
      "stars": 485,
      "forks": 45,
      "language": "Rust",
      "topics": [
        "ai",
        "ai-blame",
        "coding-agents"
      ],
      "created_at": "2025-07-02T16:09:26Z",
      "updated_at": "2026-01-25T02:20:02Z",
      "pushed_at": "2026-01-25T02:19:57Z",
      "open_issues": 71,
      "owner": {
        "login": "git-ai-project",
        "avatar_url": "https://avatars.githubusercontent.com/u/238678734?v=4"
      },
      "readme": "<div>\n<img src=\"https://github.com/acunniffe/git-ai/raw/main/assets/docs/git-ai.png\" align=\"right\"\n     alt=\"Git AI by acunniffe/git-ai\" width=\"100\" height=\"100\" />\n\n</div>\n<div>\n<h1 align=\"left\"><b>git-ai</b></h1>\n</div>\n<p align=\"left\">Track the AI Code in your repositories</p>\n\n<video src=\"https://github.com/user-attachments/assets/68304ca6-b262-4638-9fb6-0a26f55c7986\" muted loop controls autoplay></video>\n\n## Quick Start\n\n#### Mac, Linux, Windows (WSL)\n\n```bash\ncurl -sSL https://usegitai.com/install.sh | bash\n```\n\n#### Windows (non-WSL)\n\n```powershell\npowershell -NoProfile -ExecutionPolicy Bypass -Command \"irm http://usegitai.com/install.ps1 | iex\"\n```\n\nğŸŠ That's it! **No per-repo setup.** Once installed Git AI will work OOTB with any of these **Supported Agents**:\n\n<img src=\"https://github.com/acunniffe/git-ai/raw/main/assets/docs/supported-agents.png\" width=\"320\" />\n\n### Documentation https://usegitai.com/docs\n- [AI Blame](https://usegitai.com/docs/cli/ai-blame)\n- [Cross-Agent Prompt Saving](https://usegitai.com/docs/cli/prompt-storage)\n- [CLI Reference](https://usegitai.com/docs/cli/reference)\n- [Configuring Git AI for the enterprise](https://usegitai.com/docs/cli/configuration)\n\n### Just Install and Commit\n\nBuild as usual. Just prompt, edit and commit. Git AI will track every line of AI-Code and record the Coding Agent, Model, and prompt that generated it. \n\n<img src=\"https://github.com/acunniffe/git-ai/raw/main/assets/docs/graph.jpg\" width=\"400\" />\n\n#### How Does it work? \n\nSupported Coding Agents call Git AI and mark the lines they insert as AI-generated. \n\nOn commit, Git AI saves the final AI-attributions into a Git Note. These notes power AI-Blame, AI contribution stats, and more. The CLI makes sure these notes are preserved through rebases, merges, squashes, cherry-picks, etc.\n\n![Git Tree](https://github.com/user-attachments/assets/edd20990-ec0b-4a53-afa4-89fa33de9541)\n\nThe format of the notes is outlined here in the [Git AI Standard v3.0.0](https://github.com/git-ai-project/git-ai/blob/main/specs/git_ai_standard_v3.0.0.md)\n\n## Goals of `git-ai` project\n\nğŸ¤– **Track AI code in a Multi-Agent** world. Because developers get to choose their tools, engineering teams need a **vendor agnostic** way to track AI impact in their repos.\n\nğŸ¯ **Accurate attribution** from Laptop â†’ Pull Request â†’ Merged. Claude Code, Cursor and Copilot cannot track code after generationâ€”Git AI follows it through the entire workflow.\n\nğŸ”„ **Support real-world git workflows** by making sure AI-Authorship annotations survive a `merge --squash`, `rebase`, `reset`, `cherry-pick` etc.\n\nğŸ”— **Maintain link between prompts and code** - there is valuable context and requirements in team promptsâ€”preserve them alongside code.\n\nğŸš€ **Git-native + Fast** - `git-ai` is built on git plumbing commands. Negligible impact even in large repos (&lt;100ms). Tested in [Chromium](https://github.com/chromium/chromium).\n\n## Agent Support\n\n`git-ai` automatically sets up all supported agent hooks using the `git-ai install-hooks` command\n\n| Agent/IDE                                                                                  | Authorship | Prompts |\n| ------------------------------------------------------------------------------------------ | ---------- | ------- |\n| Cursor &gt;1.7                                                                             | âœ…         | âœ…      |\n| Claude Code                                                                                | âœ…         | âœ…      |\n| GitHub Copilot in VSCode via Extension                                                     | âœ…         | âœ…      |\n| Google Gemini CLI                                                                          | âœ…         | âœ…      |\n| Continue CLI                                                                               | âœ…         | âœ…      |\n| OpenCode                                                                                   | âœ…         | âœ…      |\n| Atlassian RovoDev CLI                                                                      | âœ…         | âœ…      |\n| AWS Kiro (in-progress)                                                                     | ğŸ”„         | ğŸ”„      |\n| Continue VS Code/IntelliJ (in-progress)                                                    | ğŸ”„         | ğŸ”„      |\n| Windsurf                                                                                   | ğŸ”„         | ğŸ”„      |\n| Augment Code                                                                               | ğŸ”„         | ğŸ”„      |\n| OpenAI Codex (waiting on [openai/codex #2109](https://github.com/openai/codex/issues/2109)) |            |         |\n| Junie &amp; Jetbrains IDEs                                                                 |            |         |\n| Ona                                                                                        |            |         |\n| Sourcegraph Cody + Amp                                                                     |            |         |\n| Google Antigravity                                                                         |            |         |\n\n\n> **Building a Coding Agent?** [Add support for Git AI by following this guide](https://usegitai.com/docs/cli/add-your-agent)\n\n## Installing the Stats Bot (early access)\n\nAggregate `git-ai` data at the PR, developer, Repository and Organization levels:\n\n- AI authorship breakdown for every Pull Request\n- Measure % of code that is AI generated through the entire SDLC\n- Compare accepted-rate for code written by each Agent + Model. \n- AI-Code Halflife (how durable is the AI code)\n> [Get early access by chatting with the maintainers](https://calendly.com/acunniffe/meeting-with-git-ai-authors)\n\n![alt](https://github.com/acunniffe/git-ai/raw/main/assets/docs/dashboard.png)\n\n",
      "stars_today": 92
    },
    {
      "id": 863717537,
      "name": "librepods",
      "full_name": "kavishdevar/librepods",
      "description": "AirPods liberated from Apple's ecosystem.",
      "html_url": "https://github.com/kavishdevar/librepods",
      "stars": 24836,
      "forks": 1309,
      "language": "Kotlin",
      "topics": [
        "accessiblity",
        "airpods",
        "android",
        "battery-monitor",
        "conversational-awareness",
        "ear-detection",
        "hearing-aid",
        "hearing-aids",
        "linux",
        "reverse-engineering"
      ],
      "created_at": "2024-09-26T19:31:11Z",
      "updated_at": "2026-01-25T01:50:10Z",
      "pushed_at": "2025-12-29T12:51:41Z",
      "open_issues": 119,
      "owner": {
        "login": "kavishdevar",
        "avatar_url": "https://avatars.githubusercontent.com/u/46088622?v=4"
      },
      "readme": ">[!IMPORTANT]\nDevelopment paused due to lack of time until 17th May 2026 (JEE Advanced). PRs and issues might not be responded to until then.\n\n![LibrePods Banner](./imgs/banner.png)\n\n## What is LibrePods?\n\nLibrePods unlocks Apple's exclusive AirPods features on non-Apple devices. Get access to noise control modes, adaptive transparency, ear detection, hearing aid, customized transparency mode, battery status, and more - all the premium features you paid for but Apple locked to their ecosystem.\n\n## Device Compatibility\n\n| Status | Device                | Features                                                   |\n| ------ | --------------------- | ---------------------------------------------------------- |\n| âœ…      | AirPods Pro (2nd Gen) | Fully supported and tested                                 |\n| âœ…      | AirPods Pro (3rd Gen) | Fully supported (except heartrate monitoring)              |\n| âœ…      | AirPods Max           | Fully supported (client shows unsupported features)        |\n| âš ï¸      | Other AirPods models  | Basic features (battery status, ear detection) should work |\n\nMost features should work with any AirPods. Currently, I've only got AirPods Pro 2 to test with. But, I believe the protocol remains the same for all other AirPods (based on analysis of the bluetooth stack on macOS).\n\n## Key Features\n\n- **Noise Control Modes**: Easily switch between noise control modes without having to reach out to your AirPods to long press\n- **Ear Detection**: Controls your music automatically when you put your AirPods in or take them out, and switch to phone speaker when you take them out\n- **Battery Status**: Accurate battery levels\n- **Head Gestures**: Answer calls just by nodding your head\n- **Conversational Awareness**: Volume automatically lowers when you speak\n- **Hearing Aid\\***\n- **Customize Transparency Mode\\***\n- **Multi-device connectivity\\*** (upto 2 devices)\n- **Other customizations**:\n  - Rename your AirPods\n  - Customize long-press actions\n  - All accessibility settings\n  - And more!\n\n&ast; Features marked with an asterisk require the VendorID to be change to that of Apple.\n\n## Platform Support\n\n### Linux\nfor the old version see the [Linux README](./linux/README.md). (doesn't have many features, maintainer didn't have time to work on it)\n\nnew version in development ([#241](https://github.com/kavishdevar/librepods/pull/241))\n\n![new version](https://github.com/user-attachments/assets/86b3c871-89a8-4e49-861a-5119de1e1d28)\n\n### Android\n\n#### Screenshots\n\n|                                                                                         |                                                    |                                                                              |\n| --------------------------------------------------------------------------------------- | -------------------------------------------------- | ---------------------------------------------------------------------------- |\n| ![Settings 1](./android/imgs/settings-1.png)                                            | ![Settings 2](./android/imgs/settings-2.png)       | ![Debug Screen](./android/imgs/debug.png)                                    |\n| ![Battery Notification and QS Tile for NC Mode](./android/imgs/notification-and-qs.png) | ![Popup](./android/imgs/popup.png)                 | ![Head Tracking and Gestures](./android/imgs/head-tracking-and-gestures.png) |\n| ![Long Press Configuration](./android/imgs/long-press.png)                              | ![Widget](./android/imgs/widget.png)               | ![Customizations 1](./android/imgs/customizations-1.png)                     |\n| ![Customizations 2](./android/imgs/customizations-2.png)                                | ![accessibility](./android/imgs/accessibility.png) | ![transparency](./android/imgs/transparency.png)                             |\n| ![hearing-aid](./android/imgs/hearing-aid.png)                                          | ![hearing-test](./android/imgs/hearing-test.png)   | ![hearing-aid-adjustments](./android/imgs/hearing-aid-adjustments.png)       |\n\n\nhere's a very unprofessional demo video\n\nhttps://github.com/user-attachments/assets/43911243-0576-4093-8c55-89c1db5ea533\n\n#### Root Requirement\n\nIf you are using ColorOS/OxygenOS 16, you don't need root except for customizing transparency mode, setting up hearing aid, and use Bluetooth Multipoint. Changing ANC, conversational awareness, ear detection, and other customizations will work without root. For everyone else:\n\n> [!CAUTION]\n> **You must have a rooted device with Xposed to use LibrePods on Android.** This is due to a [bug in the Android Bluetooth stack](https://issuetracker.google.com/issues/371713238). Please upvote the issue by clicking the '+1' icon on the IssueTracker page. DO NOT leave a +1 comment - use the +1 button in the top right of the page next to the \"Hotlists\" field.  Leaving +1 comment spam makes it impossible for developers to engage in the necessary technical discussion to implement this fix, and will disincentivize the responsible Google developers from engaging.  I don't know a fix for Android versions <13 either. So, this needs a phone running A13+.\n> \n> There are **no exceptions** to the root requirement until Google/your OEM figures out a fix.\n\nUntil then, you must xposed. I used to provide a non-xposed method too, where the module used overlayfs to replace the bluetooth library with a locally patched one, but that was broken due to how various devices handled overlayfs and a patched library. With xposed, you can also enable the DID hook enabling a few extra features.\n\n## Changing VendorID in the DID profile to that of Apple\n\nTurns out, if you change the VendorID in DID Profile to that of Apple, you get access to several special features!\n\nYou can do this on Linux by editing the DeviceID in `/etc/bluetooth/main.conf`. Add this line to the config file `DeviceID = bluetooth:004C:0000:0000`. For android you can enable the `act as Apple device` setting in the app's settings.\n\n### Multi-device Connectivity\n\nUpto two devices can be simultaneously connected to AirPods, for audio and control both. Seamless connection switching. The same notification shows up on Apple device when Android takes over the AirPods as if it were an Apple device (\"Move to iPhone\"). Android also shows a popup when the other device takes over.\n\n### Accessibility Settings and Hearing Aid\n\nAccessibility settings like customizing transparency mode (amplification, balance, tone, conversation boost, and ambient noise reduction), and loud sound reduction can be configured.\n\nAll hearing aid customizations can be done from Android (linux soon), including setting the audiogram result. The app doesn't provide a way to take a hearing test because it requires much more precision. It is much better to use an already available audiogram result. \n\n#### A few notes\n\n- Due to recent AirPods' firmware upgrades, you must enable `Off listening mode` to switch to `Off`. This is because in this mode, loud sounds are not reduced.\n\n- If you have take both AirPods out, the app will automatically switch to the phone speaker. But, Android might keep on trying to connect to the AirPods because the phone is still connected to them, just the A2DP profile is not connected. The app tries to disconnect the A2DP profile as soon as it detects that Android has connected again if they're not in the ear.\n\n- When renaming your AirPods through the app, you'll need to re-pair them with your phone for the name change to take effect. This is a limitation of how Bluetooth device naming works on Android.\n\n- If you want the AirPods icon and battery status to show in Android Settings app, install the app as a system app by using the root module.\n\n## Supporters\n\nA huge thank you to everyone supporting the project!\n- @davdroman\n- @tedsalmon\n- @wiless\n- @SmartMsg\n- @lunaroyster\n- @ressiwage\n\n## Special thanks\n- @tyalie for making the first documentation on the protocol! ([tyalie/AAP-Protocol-Definition](https://github.com/tyalie/AAP-Protocol-Defintion))\n- @rithvikvibhu and folks over at lagrangepoint for helping with the hearing aid feature ([gist](https://gist.github.com/rithvikvibhu/45e24bbe5ade30125f152383daf07016))\n- @devnoname120 for helping with the first root patch\n- @timgromeyer for making the first version of the linux app\n- @hackclub for hosting [High Seas](https://highseas.hackclub.com) and [Low Skies](https://low-skies.hackclub.com)!\n\n## Star History\n\n<a href=\"https://www.star-history.com/#kavishdevar/librepods&type=date&legend=top-left\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=kavishdevar/librepods&type=date&theme=dark&legend=top-left\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=kavishdevar/librepods&type=date&legend=top-left\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=kavishdevar/librepods&type=date&legend=top-left\" />\n </picture>\n</a>\n\n# License\n\nLibrePods - AirPods liberated from Appleâ€™s ecosystem\nCopyright (C) 2025 LibrePods contributors\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\nany later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nAll trademarks, logos, and brand names are the property of their respective owners. Use of them does not imply any affiliation with or endorsement by them. All AirPods images, symbols, and the SF Pro font are the property of Apple Inc.\n",
      "stars_today": 75
    },
    {
      "id": 304836585,
      "name": "ezbookkeeping",
      "full_name": "mayswind/ezbookkeeping",
      "description": "A lightweight, self-hosted personal finance app with a user-friendly interface and powerful bookkeeping features.",
      "html_url": "https://github.com/mayswind/ezbookkeeping",
      "stars": 3994,
      "forks": 403,
      "language": "Go",
      "topics": [
        "accounting",
        "app",
        "bookkeeping",
        "docker",
        "expense-manager",
        "expense-tracker",
        "expenses",
        "finance",
        "finance-management",
        "finances",
        "financial",
        "golang",
        "homelab",
        "mobile",
        "money",
        "money-manager",
        "personal-finance",
        "self-hosted",
        "typescript",
        "vue"
      ],
      "created_at": "2020-10-17T08:54:02Z",
      "updated_at": "2026-01-25T02:13:32Z",
      "pushed_at": "2026-01-24T15:55:18Z",
      "open_issues": 10,
      "owner": {
        "login": "mayswind",
        "avatar_url": "https://avatars.githubusercontent.com/u/2211648?v=4"
      },
      "readme": "# ezBookkeeping\n[![License](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/mayswind/ezbookkeeping/blob/master/LICENSE)\n[![Go Report](https://goreportcard.com/badge/github.com/mayswind/ezbookkeeping)](https://goreportcard.com/report/github.com/mayswind/ezbookkeeping)\n[![Latest Release](https://img.shields.io/github/release/mayswind/ezbookkeeping.svg?style=flat)](https://github.com/mayswind/ezbookkeeping/releases)\n[![Latest Build](https://img.shields.io/github/actions/workflow/status/mayswind/ezbookkeeping/build-snapshot.yml?branch=main)](https://github.com/mayswind/ezbookkeeping/actions)\n[![Latest Docker Image Size](https://img.shields.io/docker/image-size/mayswind/ezbookkeeping.svg?style=flat)](https://hub.docker.com/r/mayswind/ezbookkeeping)\n[![Docker Pulls](https://img.shields.io/docker/pulls/mayswind/ezbookkeeping)](https://hub.docker.com/r/mayswind/ezbookkeeping)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/mayswind/ezbookkeeping)\n\n[![Recommend By HelloGitHub](https://api.hellogithub.com/v1/widgets/recommend.svg?rid=ded5af09da574ec1811ddb154f1b2093&claim_uid=LT7EZxeBukCnh0K)](https://hellogithub.com/en/repository/mayswind/ezbookkeeping)\n[![Trending](https://trendshift.io/api/badge/repositories/12917)](https://trendshift.io/repositories/12917)\n\n## Introduction\nezBookkeeping is a lightweight, self-hosted personal finance app with a user-friendly interface and powerful bookkeeping features. It's easy to deploy, and you can start it with just one single Docker command. Designed to be resource-efficient and highly scalable, it can run smoothly on devices as small as a Raspberry Pi, or scale up to NAS, MicroServers, and even large cluster environments.\n\nezBookkeeping offers tailored interfaces for both mobile and desktop devices. With support for PWA (Progressive Web Apps), you can even [add it to your mobile home screen](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/mobile/add_to_home_screen.gif) and use it like a native app.\n\nLive Demo: [https://ezbookkeeping-demo.mayswind.net](https://ezbookkeeping-demo.mayswind.net)\n\n## Features\n- **Open Source & Self-Hosted**\n    - Built for privacy and control\n- **Lightweight & Fast**\n    - Optimized for performance, runs smoothly even on low-resource environments\n- **Easy Installation**\n    - Docker-ready\n    - Supports SQLite, MySQL, PostgreSQL\n    - Cross-platform (Windows, macOS, Linux)\n    - Works on x86, amd64, ARM architectures\n- **User-Friendly Interface**\n    - UI optimized for both mobile and desktop\n    - PWA support for native-like mobile experience\n    - Dark mode\n- **AI-Powered Features**\n    - Receipt image recognition\n    - Supports MCP (Model Context Protocol) for AI integration\n- **Powerful Bookkeeping**\n    - Two-level accounts and categories\n    - Attach images to transactions\n    - Location tracking with maps\n    - Recurring transactions\n    - Advanced filtering, search, visualization, and analysis\n- **Localization & Globalization**\n    - Multi-language and multi-currency support\n    - Automatic exchange rates\n    - Multi-timezone awareness\n    - Custom formats for dates, numbers, and currencies\n- **Security**\n    - Two-factor authentication (2FA)\n    - Login rate limiting\n    - Application lock (PIN code / WebAuthn)\n- **Data Import/Export**\n    - Supports CSV, OFX, QFX, QIF, IIF, Camt.053, MT940, GnuCash, Firefly III, Beancount, and more\n\n## Screenshots\n### Desktop Version\n[![ezBookkeeping](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/desktop/en.png)](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/desktop/en.png)\n\n### Mobile Version\n[![ezBookkeeping](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/mobile/en.png)](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/mobile/en.png)\n\n## Installation\n### Run with Docker\nVisit [Docker Hub](https://hub.docker.com/r/mayswind/ezbookkeeping) to see all images and tags.\n\n**Latest Release:**\n\n    $ docker run -p8080:8080 mayswind/ezbookkeeping\n\n**Latest Daily Build:**\n\n    $ docker run -p8080:8080 mayswind/ezbookkeeping:latest-snapshot\n\n### Install from Binary\nDownload the latest release: [https://github.com/mayswind/ezbookkeeping/releases](https://github.com/mayswind/ezbookkeeping/releases)\n\n**Linux / macOS**\n\n    $ ./ezbookkeeping server run\n\n**Windows**\n\n    > .\\ezbookkeeping.exe server run\n\nBy default, ezBookkeeping listens on port 8080. You can then visit `http://{YOUR_HOST_ADDRESS}:8080/` .\n\n### Build from Source\nMake sure you have [Golang](https://golang.org/), [GCC](https://gcc.gnu.org/), [Node.js](https://nodejs.org/) and [NPM](https://www.npmjs.com/) installed. Then download the source code, and follow these steps:\n\n**Linux / macOS**\n\n    $ ./build.sh package -o ezbookkeeping.tar.gz\n\nAll the files will be packaged in `ezbookkeeping.tar.gz`.\n\n**Windows**\n\n    > .\\build.bat package -o ezbookkeeping.zip\n\nor\n\n    PS > .\\build.ps1 package -Output ezbookkeeping.zip\n\nAll the files will be packaged in `ezbookkeeping.zip`.\n\nYou can also build a Docker image. Make sure you have [Docker](https://www.docker.com/) installed, then follow these steps:\n\n**Linux**\n\n    $ ./build.sh docker\n\n## Contributing\nWe welcome contributions of all kinds.\n\nFound a bug? [Submit an issue](https://github.com/mayswind/ezbookkeeping/issues)\n\nWant to contribute code? Feel free to fork and send a pull request.\n\nContributions of all kinds â€” bug reports, feature suggestions, documentation improvements, or code â€” are highly appreciated.\n\nCheck out our [Contributor Graph](https://github.com/mayswind/ezbookkeeping/graphs/contributors) to see the amazing people who've already helped.\n\n## Translating\nHelp make ezBookkeeping accessible to users around the world. If you want to contribute a translation, please refer to our [translation guide](https://ezbookkeeping.mayswind.net/translating).\n\nCurrently available translations:\n\n| Tag | Language | Contributors |\n| --- | --- | --- |\n| de | Deutsch | [@chrgm](https://github.com/chrgm) |\n| en | English | / |\n| es | EspaÃ±ol | [@Miguelonlonlon](https://github.com/Miguelonlonlon), [@abrugues](https://github.com/abrugues), [@AndresTeller](https://github.com/AndresTeller), [@diegofercri](https://github.com/diegofercri) |\n| fr | FranÃ§ais | [@brieucdlf](https://github.com/brieucdlf) |\n| it | Italiano | [@waron97](https://github.com/waron97) |\n| ja | æ—¥æœ¬èª | [@tkymmm](https://github.com/tkymmm) |\n| kn | à²•à²¨à³à²¨à²¡ | [@Darshanbm05](https://github.com/Darshanbm05) |\n| ko | í•œêµ­ì–´ | [@overworks](https://github.com/overworks) |\n| nl | Nederlands | [@automagics](https://github.com/automagics) |\n| pt-BR | PortuguÃªs (Brasil) | [@thecodergus](https://github.com/thecodergus) |\n| ru | Ğ ÑƒÑÑĞºĞ¸Ğ¹ | [@artegoser](https://github.com/artegoser) |\n| sl | SlovenÅ¡Äina | [@thehijacker](https://github.com/thehijacker) |\n| ta | à®¤à®®à®¿à®´à¯ | [@hhharsha36](https://github.com/hhharsha36) |\n| th | à¹„à¸—à¸¢ | [@natthavat28](https://github.com/natthavat28) |\n| tr | TÃ¼rkÃ§e | [@aydnykn](https://github.com/aydnykn) |\n| uk | Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ° | [@nktlitvinenko](https://github.com/nktlitvinenko) |\n| vi | Tiáº¿ng Viá»‡t | [@f97](https://github.com/f97) |\n| zh-Hans | ä¸­æ–‡ (ç®€ä½“) | / |\n| zh-Hant | ä¸­æ–‡ (ç¹é«”) | / |\n\nDon't see your language? Help us add it.\n\n## Documentation\n1. [English](https://ezbookkeeping.mayswind.net)\n1. [ä¸­æ–‡ (ç®€ä½“)](https://ezbookkeeping.mayswind.net/zh_Hans)\n\n## License\n[MIT](https://github.com/mayswind/ezbookkeeping/blob/master/LICENSE)\n",
      "stars_today": 75
    },
    {
      "id": 1023959202,
      "name": "runanywhere-sdks",
      "full_name": "RunanywhereAI/runanywhere-sdks",
      "description": "Production ready toolkit to run AI locally",
      "html_url": "https://github.com/RunanywhereAI/runanywhere-sdks",
      "stars": 4133,
      "forks": 133,
      "language": "Kotlin",
      "topics": [
        "agent-framework",
        "android",
        "apple-intelligence",
        "edge",
        "edge-ai",
        "foundational-models",
        "inference",
        "ios",
        "kotlin",
        "llamacpp",
        "llm",
        "multimodal",
        "ollama",
        "on-device-ai",
        "privacy",
        "swift",
        "voice-ai",
        "voice-assistant"
      ],
      "created_at": "2025-07-22T01:23:34Z",
      "updated_at": "2026-01-25T00:34:05Z",
      "pushed_at": "2026-01-24T06:24:17Z",
      "open_issues": 22,
      "owner": {
        "login": "RunanywhereAI",
        "avatar_url": "https://avatars.githubusercontent.com/u/220821781?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"examples/logo.svg\" alt=\"RunAnywhere Logo\" width=\"140\"/>\n</p>\n\n<h1 align=\"center\">RunAnywhere</h1>\n\n<p align=\"center\">\n  <strong>On-device AI for mobile apps.</strong><br/>\n  Run LLMs, speech-to-text, and text-to-speech locallyâ€”private, offline, fast.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://apps.apple.com/us/app/runanywhere/id6756506307\">\n    <img src=\"https://img.shields.io/badge/App_Store-Download-0D96F6?style=for-the-badge&logo=apple&logoColor=white\" alt=\"Download on App Store\" />\n  </a>\n  &nbsp;\n  <a href=\"https://play.google.com/store/apps/details?id=com.runanywhere.runanywhereai\">\n    <img src=\"https://img.shields.io/badge/Google_Play-Download-34A853?style=for-the-badge&logo=google-play&logoColor=white\" alt=\"Get it on Google Play\" />\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/RunanywhereAI/runanywhere-sdks/stargazers\"><img src=\"https://img.shields.io/github/stars/RunanywhereAI/runanywhere-sdks?style=flat-square\" alt=\"GitHub Stars\" /></a>\n  <a href=\"LICENSE\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue?style=flat-square\" alt=\"License\" /></a>\n  <a href=\"https://discord.gg/N359FBbDVd\"><img src=\"https://img.shields.io/badge/Discord-Join-5865F2?style=flat-square&logo=discord&logoColor=white\" alt=\"Discord\" /></a>\n</p>\n\n<p align=\"center\">\n  <img src=\"docs/screenshots/main-screenshot.jpg\" alt=\"Chat\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/chat-interface.png\" alt=\"Analytics\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/quiz-flow.png\" alt=\"Structured Output\" width=\"180\"/>\n  &nbsp;&nbsp;\n  <img src=\"examples/ios/RunAnywhereAI/docs/screenshots/voice-ai.png\" alt=\"Voice AI\" width=\"180\"/>\n</p>\n\n---\n\n## What is RunAnywhere?\n\nRunAnywhere lets you add AI features to your mobile app that run entirely on-device:\n\n- **LLM Chat** â€” Llama, Mistral, Qwen, SmolLM, and more\n- **Speech-to-Text** â€” Whisper-powered transcription\n- **Text-to-Speech** â€” Neural voice synthesis\n- **Voice Assistant** â€” Full STT â†’ LLM â†’ TTS pipeline\n\nNo cloud. No latency. No data leaves the device.\n\n---\n\n## SDKs\n\n| Platform | Status | Installation | Documentation |\n|----------|--------|--------------|---------------|\n| **Swift** (iOS/macOS) | Stable | [Swift Package Manager](#swift-ios--macos) | [docs.runanywhere.ai/swift](https://docs.runanywhere.ai/swift/introduction) |\n| **Kotlin** (Android) | Stable | [Gradle](#kotlin-android) | [docs.runanywhere.ai/kotlin](https://docs.runanywhere.ai/kotlin/introduction) |\n| **React Native** | Beta | [npm](#react-native) | [docs.runanywhere.ai/react-native](https://docs.runanywhere.ai/react-native/introduction) |\n| **Flutter** | Beta | [pub.dev](#flutter) | [docs.runanywhere.ai/flutter](https://docs.runanywhere.ai/flutter/introduction) |\n\n---\n\n## Quick Start\n\n### Swift (iOS / macOS)\n\n```swift\nimport RunAnywhere\nimport LlamaCPPRuntime\n\n// 1. Initialize\nLlamaCPP.register()\ntry RunAnywhere.initialize()\n\n// 2. Load a model\ntry await RunAnywhere.downloadModel(\"smollm2-360m\")\ntry await RunAnywhere.loadModel(\"smollm2-360m\")\n\n// 3. Generate\nlet response = try await RunAnywhere.chat(\"What is the capital of France?\")\nprint(response) // \"Paris is the capital of France.\"\n```\n\n**Install via Swift Package Manager:**\n\n```\nhttps://github.com/RunanywhereAI/runanywhere-sdks\n```\n\n[Full documentation â†’](https://docs.runanywhere.ai/swift/introduction) Â· [Source code](sdk/runanywhere-swift/)\n\n---\n\n### Kotlin (Android)\n\n```kotlin\nimport com.runanywhere.sdk.public.RunAnywhere\nimport com.runanywhere.sdk.public.extensions.*\n\n// 1. Initialize\nLlamaCPP.register()\nRunAnywhere.initialize(environment = SDKEnvironment.DEVELOPMENT)\n\n// 2. Load a model\nRunAnywhere.downloadModel(\"smollm2-360m\").collect { println(\"${it.progress * 100}%\") }\nRunAnywhere.loadLLMModel(\"smollm2-360m\")\n\n// 3. Generate\nval response = RunAnywhere.chat(\"What is the capital of France?\")\nprintln(response) // \"Paris is the capital of France.\"\n```\n\n**Install via Gradle:**\n\n```kotlin\ndependencies {\n    implementation(\"com.runanywhere.sdk:runanywhere-kotlin:0.1.4\")\n    implementation(\"com.runanywhere.sdk:runanywhere-core-llamacpp:0.1.4\")\n}\n```\n\n[Full documentation â†’](https://docs.runanywhere.ai/kotlin/introduction) Â· [Source code](sdk/runanywhere-kotlin/)\n\n---\n\n### React Native\n\n```typescript\nimport { RunAnywhere, SDKEnvironment } from '@runanywhere/core';\nimport { LlamaCPP } from '@runanywhere/llamacpp';\n\n// 1. Initialize\nawait RunAnywhere.initialize({ environment: SDKEnvironment.Development });\nLlamaCPP.register();\n\n// 2. Load a model\nawait RunAnywhere.downloadModel('smollm2-360m');\nawait RunAnywhere.loadModel(modelPath);\n\n// 3. Generate\nconst response = await RunAnywhere.chat('What is the capital of France?');\nconsole.log(response); // \"Paris is the capital of France.\"\n```\n\n**Install via npm:**\n\n```bash\nnpm install @runanywhere/core @runanywhere/llamacpp\n```\n\n[Full documentation â†’](https://docs.runanywhere.ai/react-native/introduction) Â· [Source code](sdk/runanywhere-react-native/)\n\n---\n\n### Flutter\n\n```dart\nimport 'package:runanywhere/runanywhere.dart';\nimport 'package:runanywhere_llamacpp/runanywhere_llamacpp.dart';\n\n// 1. Initialize\nawait RunAnywhere.initialize();\nawait LlamaCpp.register();\n\n// 2. Load a model\nawait RunAnywhere.downloadModel('smollm2-360m');\nawait RunAnywhere.loadModel('smollm2-360m');\n\n// 3. Generate\nfinal response = await RunAnywhere.chat('What is the capital of France?');\nprint(response); // \"Paris is the capital of France.\"\n```\n\n**Install via pub.dev:**\n\n```yaml\ndependencies:\n  runanywhere: ^0.15.11\n  runanywhere_llamacpp: ^0.15.11\n```\n\n[Full documentation â†’](https://docs.runanywhere.ai/flutter/introduction) Â· [Source code](sdk/runanywhere-flutter/)\n\n---\n\n## Sample Apps\n\nFull-featured demo applications demonstrating SDK capabilities:\n\n| Platform | Source Code | Download |\n|----------|-------------|----------|\n| iOS | [examples/ios/RunAnywhereAI](examples/ios/RunAnywhereAI/) | [App Store](https://apps.apple.com/us/app/runanywhere/id6756506307) |\n| Android | [examples/android/RunAnywhereAI](examples/android/RunAnywhereAI/) | [Google Play](https://play.google.com/store/apps/details?id=com.runanywhere.runanywhereai) |\n| React Native | [examples/react-native/RunAnywhereAI](examples/react-native/RunAnywhereAI/) | Build from source |\n| Flutter | [examples/flutter/RunAnywhereAI](examples/flutter/RunAnywhereAI/) | Build from source |\n\n---\n\n## Features\n\n| Feature | iOS | Android | React Native | Flutter |\n|---------|-----|---------|--------------|---------|\n| LLM Text Generation | âœ… | âœ… | âœ… | âœ… |\n| Streaming | âœ… | âœ… | âœ… | âœ… |\n| Speech-to-Text | âœ… | âœ… | âœ… | âœ… |\n| Text-to-Speech | âœ… | âœ… | âœ… | âœ… |\n| Voice Assistant Pipeline | âœ… | âœ… | âœ… | âœ… |\n| Model Download + Progress | âœ… | âœ… | âœ… | âœ… |\n| Structured Output (JSON) | âœ… | âœ… | ğŸ”œ | ğŸ”œ |\n| Apple Foundation Models | âœ… | â€” | â€” | â€” |\n\n---\n\n## Supported Models\n\n### LLM (GGUF format via llama.cpp)\n\n| Model | Size | RAM Required | Use Case |\n|-------|------|--------------|----------|\n| SmolLM2 360M | ~400MB | 500MB | Fast, lightweight |\n| Qwen 2.5 0.5B | ~500MB | 600MB | Multilingual |\n| Llama 3.2 1B | ~1GB | 1.2GB | Balanced |\n| Mistral 7B Q4 | ~4GB | 5GB | High quality |\n\n### Speech-to-Text (Whisper via ONNX)\n\n| Model | Size | Languages |\n|-------|------|-----------|\n| Whisper Tiny | ~75MB | English |\n| Whisper Base | ~150MB | Multilingual |\n\n### Text-to-Speech (Piper via ONNX)\n\n| Voice | Size | Language |\n|-------|------|----------|\n| Piper US English | ~65MB | English (US) |\n| Piper British English | ~65MB | English (UK) |\n\n---\n\n## Repository Structure\n\n```\nrunanywhere-sdks/\nâ”œâ”€â”€ sdk/\nâ”‚   â”œâ”€â”€ runanywhere-swift/          # iOS/macOS SDK\nâ”‚   â”œâ”€â”€ runanywhere-kotlin/         # Android SDK\nâ”‚   â”œâ”€â”€ runanywhere-react-native/   # React Native SDK\nâ”‚   â”œâ”€â”€ runanywhere-flutter/        # Flutter SDK\nâ”‚   â””â”€â”€ runanywhere-commons/        # Shared C++ core\nâ”‚\nâ”œâ”€â”€ examples/\nâ”‚   â”œâ”€â”€ ios/RunAnywhereAI/          # iOS sample app\nâ”‚   â”œâ”€â”€ android/RunAnywhereAI/      # Android sample app\nâ”‚   â”œâ”€â”€ react-native/RunAnywhereAI/ # React Native sample app\nâ”‚   â””â”€â”€ flutter/RunAnywhereAI/      # Flutter sample app\nâ”‚\nâ””â”€â”€ docs/                           # Documentation\n```\n\n---\n\n## Requirements\n\n| Platform | Minimum | Recommended |\n|----------|---------|-------------|\n| iOS | 17.0+ | 17.0+ |\n| macOS | 14.0+ | 14.0+ |\n| Android | API 24 (7.0) | API 28+ |\n| React Native | 0.74+ | 0.76+ |\n| Flutter | 3.10+ | 3.24+ |\n\n**Memory:** 2GB minimum, 4GB+ recommended for larger models\n\n---\n\n## Contributing\n\nWe welcome contributions. See our [Contributing Guide](CONTRIBUTING.md) for details.\n\n```bash\n# Clone the repo\ngit clone https://github.com/RunanywhereAI/runanywhere-sdks.git\n\n# Set up a specific SDK (example: Swift)\ncd runanywhere-sdks/sdk/runanywhere-swift\n./scripts/build-swift.sh --setup\n\n# Run the sample app\ncd ../../examples/ios/RunAnywhereAI\nopen RunAnywhereAI.xcodeproj\n```\n\n---\n\n## Support\n\n- **Discord:** [Join our community](https://discord.gg/N359FBbDVd)\n- **GitHub Issues:** [Report bugs or request features](https://github.com/RunanywhereAI/runanywhere-sdks/issues)\n- **Email:** founders@runanywhere.ai\n- **Twitter:** [@RunanywhereAI](https://twitter.com/RunanywhereAI)\n\n---\n\n## License\n\nApache 2.0 â€” see [LICENSE](LICENSE) for details.\n",
      "stars_today": 69
    },
    {
      "id": 912559512,
      "name": "sim",
      "full_name": "simstudioai/sim",
      "description": "Open-source platform to build and deploy AI agent workflows.",
      "html_url": "https://github.com/simstudioai/sim",
      "stars": 26159,
      "forks": 3263,
      "language": "TypeScript",
      "topics": [
        "agent-workflow",
        "agentic-workflow",
        "agents",
        "ai",
        "aiagents",
        "anthropic",
        "artificial-intelligence",
        "automation",
        "chatbot",
        "deepseek",
        "gemini",
        "low-code",
        "nextjs",
        "no-code",
        "openai",
        "rag",
        "react",
        "typescript"
      ],
      "created_at": "2025-01-05T22:47:49Z",
      "updated_at": "2026-01-25T02:27:36Z",
      "pushed_at": "2026-01-24T22:31:02Z",
      "open_issues": 151,
      "owner": {
        "login": "simstudioai",
        "avatar_url": "https://avatars.githubusercontent.com/u/199344406?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://sim.ai\" target=\"_blank\" rel=\"noopener noreferrer\">\n    <img src=\"apps/sim/public/logo/reverse/text/large.png\" alt=\"Sim Logo\" width=\"500\"/>\n  </a>\n</p>\n\n<p align=\"center\">Build and deploy AI agent workflows in minutes.</p>\n\n<p align=\"center\">\n  <a href=\"https://sim.ai\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/sim.ai-6F3DFA\" alt=\"Sim.ai\"></a>\n  <a href=\"https://discord.gg/Hr4UWYEcTT\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&logoColor=white\" alt=\"Discord\"></a>\n  <a href=\"https://x.com/simdotai\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/twitter/follow/simdotai?style=social\" alt=\"Twitter\"></a>\n  <a href=\"https://docs.sim.ai\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/Docs-6F3DFA.svg\" alt=\"Documentation\"></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://deepwiki.com/simstudioai/sim\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://deepwiki.com/badge.svg\" alt=\"Ask DeepWiki\"></a>  <a href=\"https://cursor.com/link/prompt?text=Help%20me%20set%20up%20Sim%20locally.%20Follow%20these%20steps%3A%0A%0A1.%20First%2C%20verify%20Docker%20is%20installed%20and%20running%3A%0A%20%20%20docker%20--version%0A%20%20%20docker%20info%0A%0A2.%20Clone%20the%20repository%3A%0A%20%20%20git%20clone%20https%3A%2F%2Fgithub.com%2Fsimstudioai%2Fsim.git%0A%20%20%20cd%20sim%0A%0A3.%20Start%20the%20services%20with%20Docker%20Compose%3A%0A%20%20%20docker%20compose%20-f%20docker-compose.prod.yml%20up%20-d%0A%0A4.%20Wait%20for%20all%20containers%20to%20be%20healthy%20(this%20may%20take%201-2%20minutes)%3A%0A%20%20%20docker%20compose%20-f%20docker-compose.prod.yml%20ps%0A%0A5.%20Verify%20the%20app%20is%20accessible%20at%20http%3A%2F%2Flocalhost%3A3000%0A%0AIf%20there%20are%20any%20errors%2C%20help%20me%20troubleshoot%20them.%20Common%20issues%3A%0A-%20Port%203000%2C%203002%2C%20or%205432%20already%20in%20use%0A-%20Docker%20not%20running%0A-%20Insufficient%20memory%20(needs%2012GB%2B%20RAM)%0A%0AFor%20local%20AI%20models%20with%20Ollama%2C%20use%20this%20instead%20of%20step%203%3A%0A%20%20%20docker%20compose%20-f%20docker-compose.ollama.yml%20--profile%20setup%20up%20-d\"><img src=\"https://img.shields.io/badge/Set%20Up%20with-Cursor-000000?logo=cursor&logoColor=white\" alt=\"Set Up with Cursor\"></a>\n</p>\n\n### Build Workflows with Ease\nDesign agent workflows visually on a canvasâ€”connect agents, tools, and blocks, then run them instantly.\n\n<p align=\"center\">\n  <img src=\"apps/sim/public/static/workflow.gif\" alt=\"Workflow Builder Demo\" width=\"800\"/>\n</p>\n\n### Supercharge with Copilot\nLeverage Copilot to generate nodes, fix errors, and iterate on flows directly from natural language.\n\n<p align=\"center\">\n  <img src=\"apps/sim/public/static/copilot.gif\" alt=\"Copilot Demo\" width=\"800\"/>\n</p>\n\n### Integrate Vector Databases\nUpload documents to a vector store and let agents answer questions grounded in your specific content.\n\n<p align=\"center\">\n  <img src=\"apps/sim/public/static/knowledge.gif\" alt=\"Knowledge Uploads and Retrieval Demo\" width=\"800\"/>\n</p>\n\n## Quickstart\n\n### Cloud-hosted: [sim.ai](https://sim.ai)\n\n<a href=\"https://sim.ai\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://img.shields.io/badge/sim.ai-6F3DFA?logo=data:image/svg%2bxml;base64,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&logoColor=white\" alt=\"Sim.ai\"></a>\n\n### Self-hosted: NPM Package\n\n```bash\nnpx simstudio\n```\nâ†’ http://localhost:3000\n\n#### Note\nDocker must be installed and running on your machine.\n\n#### Options\n\n| Flag | Description |\n|------|-------------|\n| `-p, --port <port>` | Port to run Sim on (default `3000`) |\n| `--no-pull` | Skip pulling latest Docker images |\n\n### Self-hosted: Docker Compose\n\n```bash\ngit clone https://github.com/simstudioai/sim.git && cd sim\ndocker compose -f docker-compose.prod.yml up -d\n```\n\nOpen [http://localhost:3000](http://localhost:3000)\n\n#### Using Local Models with Ollama\n\nRun Sim with local AI models using [Ollama](https://ollama.ai) - no external APIs required:\n\n```bash\n# Start with GPU support (automatically downloads gemma3:4b model)\ndocker compose -f docker-compose.ollama.yml --profile setup up -d\n\n# For CPU-only systems:\ndocker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d\n```\n\nWait for the model to download, then visit [http://localhost:3000](http://localhost:3000). Add more models with:\n```bash\ndocker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b\n```\n\n#### Using an External Ollama Instance\n\nIf Ollama is running on your host machine, use `host.docker.internal` instead of `localhost`:\n\n```bash\nOLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d\n```\n\nOn Linux, use your host's IP address or add `extra_hosts: [\"host.docker.internal:host-gateway\"]` to the compose file.\n\n#### Using vLLM\n\nSim supports [vLLM](https://docs.vllm.ai/) for self-hosted models. Set `VLLM_BASE_URL` and optionally `VLLM_API_KEY` in your environment.\n\n### Self-hosted: Dev Containers\n\n1. Open VS Code with the [Remote - Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)\n2. Open the project and click \"Reopen in Container\" when prompted\n3. Run `bun run dev:full` in the terminal or use the `sim-start` alias\n   - This starts both the main application and the realtime socket server\n\n### Self-hosted: Manual Setup\n\n**Requirements:** [Bun](https://bun.sh/), [Node.js](https://nodejs.org/) v20+, PostgreSQL 12+ with [pgvector](https://github.com/pgvector/pgvector)\n\n1. Clone and install:\n\n```bash\ngit clone https://github.com/simstudioai/sim.git\ncd sim\nbun install\n```\n\n2. Set up PostgreSQL with pgvector:\n\n```bash\ndocker run --name simstudio-db -e POSTGRES_PASSWORD=your_password -e POSTGRES_DB=simstudio -p 5432:5432 -d pgvector/pgvector:pg17\n```\n\nOr install manually via the [pgvector guide](https://github.com/pgvector/pgvector#installation).\n\n3. Configure environment:\n\n```bash\ncp apps/sim/.env.example apps/sim/.env\ncp packages/db/.env.example packages/db/.env\n# Edit both .env files to set DATABASE_URL=\"postgresql://postgres:your_password@localhost:5432/simstudio\"\n```\n\n4. Run migrations:\n\n```bash\ncd packages/db && bunx drizzle-kit migrate --config=./drizzle.config.ts\n```\n\n5. Start development servers:\n\n```bash\nbun run dev:full  # Starts both Next.js app and realtime socket server\n```\n\nOr run separately: `bun run dev` (Next.js) and `cd apps/sim && bun run dev:sockets` (realtime).\n\n## Copilot API Keys\n\nCopilot is a Sim-managed service. To use Copilot on a self-hosted instance:\n\n- Go to https://sim.ai â†’ Settings â†’ Copilot and generate a Copilot API key\n- Set `COPILOT_API_KEY` environment variable in your self-hosted apps/sim/.env file to that value\n\n## Environment Variables\n\nKey environment variables for self-hosted deployments. See [`.env.example`](apps/sim/.env.example) for defaults or [`env.ts`](apps/sim/lib/core/config/env.ts) for the full list.\n\n| Variable | Required | Description |\n|----------|----------|-------------|\n| `DATABASE_URL` | Yes | PostgreSQL connection string with pgvector |\n| `BETTER_AUTH_SECRET` | Yes | Auth secret (`openssl rand -hex 32`) |\n| `BETTER_AUTH_URL` | Yes | Your app URL (e.g., `http://localhost:3000`) |\n| `NEXT_PUBLIC_APP_URL` | Yes | Public app URL (same as above) |\n| `ENCRYPTION_KEY` | Yes | Encrypts environment variables (`openssl rand -hex 32`) |\n| `INTERNAL_API_SECRET` | Yes | Encrypts internal API routes (`openssl rand -hex 32`) |\n| `API_ENCRYPTION_KEY` | Yes | Encrypts API keys (`openssl rand -hex 32`) |\n| `COPILOT_API_KEY` | No | API key from sim.ai for Copilot features |\n\n## Troubleshooting\n\n### Ollama models not showing in dropdown (Docker)\n\nIf you're running Ollama on your host machine and Sim in Docker, change `OLLAMA_URL` from `localhost` to `host.docker.internal`:\n\n```bash\nOLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d\n```\n\nSee [Using an External Ollama Instance](#using-an-external-ollama-instance) for details.\n\n### Database connection issues\n\nEnsure PostgreSQL has the pgvector extension installed. When using Docker, wait for the database to be healthy before running migrations.\n\n### Port conflicts\n\nIf ports 3000, 3002, or 5432 are in use, configure alternatives:\n\n```bash\n# Custom ports\nNEXT_PUBLIC_APP_URL=http://localhost:3100 POSTGRES_PORT=5433 docker compose up -d\n```\n\n## Tech Stack\n\n- **Framework**: [Next.js](https://nextjs.org/) (App Router)\n- **Runtime**: [Bun](https://bun.sh/)\n- **Database**: PostgreSQL with [Drizzle ORM](https://orm.drizzle.team)\n- **Authentication**: [Better Auth](https://better-auth.com)\n- **UI**: [Shadcn](https://ui.shadcn.com/), [Tailwind CSS](https://tailwindcss.com)\n- **State Management**: [Zustand](https://zustand-demo.pmnd.rs/)\n- **Flow Editor**: [ReactFlow](https://reactflow.dev/)\n- **Docs**: [Fumadocs](https://fumadocs.vercel.app/)\n- **Monorepo**: [Turborepo](https://turborepo.org/)\n- **Realtime**: [Socket.io](https://socket.io/)\n- **Background Jobs**: [Trigger.dev](https://trigger.dev/)\n- **Remote Code Execution**: [E2B](https://www.e2b.dev/)\n\n## Contributing\n\nWe welcome contributions! Please see our [Contributing Guide](.github/CONTRIBUTING.md) for details.\n\n## License\n\nThis project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.\n\n<p align=\"center\">Made with â¤ï¸ by the Sim Team</p>\n",
      "stars_today": 65
    },
    {
      "id": 186733095,
      "name": "v2rayNG",
      "full_name": "2dust/v2rayNG",
      "description": "A V2Ray client for Android, support Xray core and v2fly core",
      "html_url": "https://github.com/2dust/v2rayNG",
      "stars": 50014,
      "forks": 6837,
      "language": "Kotlin",
      "topics": [
        "android",
        "proxy",
        "shadowsocks",
        "socks5",
        "trojan",
        "v2fly",
        "v2ray",
        "vless",
        "vmess",
        "vpn",
        "xray",
        "xtls"
      ],
      "created_at": "2019-05-15T02:15:31Z",
      "updated_at": "2026-01-25T01:20:31Z",
      "pushed_at": "2026-01-24T06:16:44Z",
      "open_issues": 7,
      "owner": {
        "login": "2dust",
        "avatar_url": "https://avatars.githubusercontent.com/u/31833384?v=4"
      },
      "readme": "# v2rayNG\n\nA V2Ray client for Android, support [Xray core](https://github.com/XTLS/Xray-core) and [v2fly core](https://github.com/v2fly/v2ray-core)\n\n[![API](https://img.shields.io/badge/API-24%2B-yellow.svg?style=flat)](https://developer.android.com/about/versions/lollipop)\n[![Kotlin Version](https://img.shields.io/badge/Kotlin-2.3.0-blue.svg)](https://kotlinlang.org)\n[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/2dust/v2rayNG)](https://github.com/2dust/v2rayNG/commits/master)\n[![CodeFactor](https://www.codefactor.io/repository/github/2dust/v2rayng/badge)](https://www.codefactor.io/repository/github/2dust/v2rayng)\n[![GitHub Releases](https://img.shields.io/github/downloads/2dust/v2rayNG/latest/total?logo=github)](https://github.com/2dust/v2rayNG/releases)\n[![Chat on Telegram](https://img.shields.io/badge/Chat%20on-Telegram-brightgreen.svg)](https://t.me/v2rayn)\n\n### Telegram Channel\n[github_2dust](https://t.me/github_2dust)\n\n### Usage\n\n#### Geoip and Geosite\n- geoip.dat and geosite.dat files are in `Android/data/com.v2ray.ang/files/assets` (path may differ on some Android device)\n- download feature will get enhanced version in this [repo](https://github.com/Loyalsoldier/v2ray-rules-dat) (Note it need a working proxy)\n- latest official [domain list](https://github.com/Loyalsoldier/v2ray-rules-dat) and [ip list](https://github.com/Loyalsoldier/geoip) can be imported manually\n- possible to use third party dat file in the same folder, like [h2y](https://guide.v2fly.org/routing/sitedata.html#%E5%A4%96%E7%BD%AE%E7%9A%84%E5%9F%9F%E5%90%8D%E6%96%87%E4%BB%B6)\n\n### More in our [wiki](https://github.com/2dust/v2rayNG/wiki)\n\n### Development guide\n\nAndroid project under V2rayNG folder can be compiled directly in Android Studio, or using Gradle wrapper. But the v2ray core inside the aar is (probably) outdated.  \nThe aar can be compiled from the Golang project [AndroidLibV2rayLite](https://github.com/2dust/AndroidLibV2rayLite) or [AndroidLibXrayLite](https://github.com/2dust/AndroidLibXrayLite).\nFor a quick start, read guide for [Go Mobile](https://github.com/golang/go/wiki/Mobile) and [Makefiles for Go Developers](https://tutorialedge.net/golang/makefiles-for-go-developers/)\n\nv2rayNG can run on Android Emulators. For WSA, VPN permission need to be granted via\n`appops set [package name] ACTIVATE_VPN allow`\n",
      "stars_today": 58
    },
    {
      "id": 968905557,
      "name": "arcane",
      "full_name": "getarcaneapp/arcane",
      "description": "Modern Docker Management, Designed for Everyone",
      "html_url": "https://github.com/getarcaneapp/arcane",
      "stars": 4032,
      "forks": 122,
      "language": "Go",
      "topics": [
        "compose",
        "container-management",
        "containers",
        "docker",
        "docker-compose",
        "docker-management",
        "go",
        "self-hosted",
        "sveltekit",
        "typescript",
        "web-ui"
      ],
      "created_at": "2025-04-19T00:43:29Z",
      "updated_at": "2026-01-25T01:38:53Z",
      "pushed_at": "2026-01-24T22:49:32Z",
      "open_issues": 128,
      "owner": {
        "login": "getarcaneapp",
        "avatar_url": "https://avatars.githubusercontent.com/u/236685631?v=4"
      },
      "readme": "> [!IMPORTANT]\n> All Arcane repos have moved to the [@getarcaneapp](https://github.com/getarcaneapp) org on GitHub.\n>\n> This means the images used for Arcane for all future releases (past 1.7.2) will use the following repositories:\n>\n> Arcane: `ghcr.io/getarcaneapp/arcane`\n>\n> Arcane Agent: `ghcr.io/getarcaneapp/arcane-headless`\n\n<div align=\"center\">\n\n  <img src=\".github/assets/img/PNG-3.png\" alt=\"Arcane Logo\" width=\"500\" />\n  <p>Modern Docker Management, Designed for Everyone.</p>\n\n<a title=\"Crowdin\" target=\"_blank\" href=\"https://crowdin.com/project/arcane-docker-management\"><img src=\"https://badges.crowdin.net/arcane-docker-management/localized.svg\"></a>\n<a href=\"https://pkg.go.dev/github.com/getarcaneapp/arcane/backend\"><img src=\"https://pkg.go.dev/badge/github.com/getarcaneapp/arcane/backend.svg\" alt=\"Go Reference\"></a>\n<a href=\"https://goreportcard.com/report/github.com/getarcaneapp/arcane/backend\"><img src=\"https://goreportcard.com/badge/github.com/getarcaneapp/arcane/backend\" alt=\"Go Report Card\"></a>\n<a href=\"https://github.com/getarcaneapp/arcane/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/license-BSD--3--Clause-blue.svg\" alt=\"License\"></a>\n\n<br />\n\n<img width=\"1685\" alt=\"image\" align=\"center\" src=\".github/assets/arcane-dashboard.png\" />\n\n## Documentation\n\nFor setup instructions, configuration details, and development guides, visit the **[official documentation site](https://getarcane.app)**.\n\n## Sponsors\n\nThis project is supported by the following amazing people:\n\n<p align=\"center\">\n  <a href=\"https://github.com/sponsors/kmendell\">\n    <img src='https://github.com/kmendell/static/blob/main/sponsors.svg?raw=true' alt=\"Logos\" />\n  </a>\n</p>\n\n## Security & Transparency\n\nView the Software Bill of Materials (SBOM) for Arcane at **[getarcane.app/sbom](https://getarcane.app/sbom)**.\n\n## Translating\n\nHelp translate Arcane on Crowdin: https://crowdin.com/project/arcane-docker-management\n\nThank you for checking out Arcane! Your feedback and contributions are always welcome.\n\n</div>\n",
      "stars_today": 50
    },
    {
      "id": 845156346,
      "name": "IKEA-3D-Model-Download-Button",
      "full_name": "apinanaivot/IKEA-3D-Model-Download-Button",
      "description": "Adds ability to download models from IKEA website",
      "html_url": "https://github.com/apinanaivot/IKEA-3D-Model-Download-Button",
      "stars": 867,
      "forks": 25,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2024-08-20T17:33:04Z",
      "updated_at": "2026-01-25T02:17:50Z",
      "pushed_at": "2025-12-21T10:17:53Z",
      "open_issues": 7,
      "owner": {
        "login": "apinanaivot",
        "avatar_url": "https://avatars.githubusercontent.com/u/12139741?v=4"
      },
      "readme": "# IKEA 3D Model Downloader\r\n\r\nThis Tampermonkey script adds a download button for 3D models on IKEA product pages, allowing you to easily save .GLB files of IKEA furniture and decorations. It works across different language versions of IKEA websites and automatically names the downloaded files based on the product name and color. The files can be opened in 3D software like Blender. This allows you to try out the furniture in your own 3D home planning software before making a purchase decision.\r\n\r\nUPDATE: 28.11.2025 - Works on latest IKEA website\r\n\r\n<p align=\"left\">\r\n  <img src=\"https://raw.githubusercontent.com/apinanaivot/IKEA-3D-Model-Download-Button/main/sample.jpg\" width=\"550\" title=\"IKEA 3D Model Downloader\">\r\n</p>\r\n\r\n## Features\r\n\r\n- Adds a \"Download 3D\" button next to the \"View in 3D\" button on IKEA product pages\r\n- Works on all language versions of IKEA websites\r\n- Automatically names downloaded files using the product name and color\r\n\r\n## Installation\r\n\r\n1. Install the [Tampermonkey](https://www.tampermonkey.net/) browser extension for your browser.\r\n2. Click [this link](https://github.com/apinanaivot/IKEA-3D-Model-Download-Button/raw/refs/heads/main/ikea-3d-model-downloader.user.js) to install or update this script, or alternatively create a new script in Tampermonkey and paste the contents of `ikea-3d-model-downloader.user.js` into it.\r\n3. Save the script and ensure it's enabled in Tampermonkey.\r\n\r\n## Usage\r\n\r\n1. Navigate to any IKEA product page that has a \"View in 3D\" button.\r\n2. You'll see a new \"Download 3D\" button next to the \"View in 3D\" button.\r\n3. Click the \"Download 3D\" button to download the GLB file of the 3D model.\r\n4. The file will be saved with a name in the format: `[Product Name] - [Color].glb`\r\n\r\n## Troubleshooting\r\n\r\n- If the download button doesn't appear, ensure you're on a product page with a 3D model available and refresh the page.\r\n- If using Chrome, try turning on developer mode\r\n- If nothing works, create a [bug report here](https://github.com/apinanaivot/IKEA-3D-Model-Download-Button/issues) and I'll try to fix it as soon as possible\r\n\r\n## Disclaimer\r\n\r\nThis tool is designed for personal home planning and visualization. Always respect IKEA's terms of service and use the saved models only for personal home design projects. The authors are not responsible for any misuse or violation of terms.\r\n\r\n## \r\n\r\n\r\n<a href=\"https://www.star-history.com/#apinanaivot/IKEA-3D-Model-Download-Button&Date\">\r\n <picture>\r\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=apinanaivot/IKEA-3D-Model-Download-Button&type=Date&theme=dark\" />\r\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=apinanaivot/IKEA-3D-Model-Download-Button&type=Date\" />\r\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=apinanaivot/IKEA-3D-Model-Download-Button&type=Date\" />\r\n </picture>\r\n</a>\r\n",
      "stars_today": 50
    },
    {
      "id": 1082927074,
      "name": "Claude-Usage-Tracker",
      "full_name": "hamed-elfayome/Claude-Usage-Tracker",
      "description": "Native macOS menu bar app for tracking Claude AI usage limits in real-time. Built with Swift/SwiftUI.",
      "html_url": "https://github.com/hamed-elfayome/Claude-Usage-Tracker",
      "stars": 616,
      "forks": 35,
      "language": "Swift",
      "topics": [
        "claude",
        "claude-ai",
        "claude-code",
        "claudecode",
        "macos",
        "usage-application"
      ],
      "created_at": "2025-10-25T02:21:17Z",
      "updated_at": "2026-01-25T02:21:48Z",
      "pushed_at": "2026-01-23T04:24:34Z",
      "open_issues": 13,
      "owner": {
        "login": "hamed-elfayome",
        "avatar_url": "https://avatars.githubusercontent.com/u/72640424?v=4"
      },
      "readme": "# Claude Usage Tracker\n\n<div align=\"center\">\n  <img src=\".github/cover.jpg\" alt=\"Claude Usage Tracker\" width=\"100%\">\n\n  **A native macOS menu bar application for real-time monitoring of Claude AI usage limits**\n\n  ![macOS](https://img.shields.io/badge/macOS-14.0+-black?style=flat-square&logo=apple)\n  ![Swift](https://img.shields.io/badge/Swift-5.0+-orange?style=flat-square&logo=swift)\n  ![SwiftUI](https://img.shields.io/badge/SwiftUI-5.0+-blue?style=flat-square&logo=swift)\n  ![License](https://img.shields.io/badge/license-MIT-green?style=flat-square)\n  ![Version](https://img.shields.io/badge/version-2.3.0-blue?style=flat-square)\n  ![Languages](https://img.shields.io/badge/languages-8-purple?style=flat-square)\n\n  <sub>ğŸ‡¬ğŸ‡§ English â€¢ ğŸ‡ªğŸ‡¸ EspaÃ±ol â€¢ ğŸ‡«ğŸ‡· FranÃ§ais â€¢ ğŸ‡©ğŸ‡ª Deutsch â€¢ ğŸ‡®ğŸ‡¹ Italiano â€¢ ğŸ‡µğŸ‡¹ PortuguÃªs â€¢ ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª â€¢ ğŸ‡°ğŸ‡· í•œêµ­ì–´</sub>\n\n  ### [Download Latest Release (v2.3.0)](https://github.com/hamed-elfayome/Claude-Usage-Tracker/releases/latest/download/Claude-Usage.zip)\n\n  <sub>macOS 14.0+ (Sonoma) | ~4 MB | Native Swift/SwiftUI | Officially Signed</sub>\n\n  <a href=\"https://www.buymeacoffee.com/hamedelfayome\" target=\"_blank\"><img src=\"https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png\" alt=\"Buy Me A Coffee\" height=\"40\"></a>\n</div>\n\n---\n\n## Overview\n\nClaude Usage Tracker is a lightweight, native macOS menu bar application that provides real-time monitoring of your Claude AI usage limits. Built entirely with Swift and SwiftUI, it offers a clean, intuitive interface to track your 5-hour session window, weekly usage limits, and Opus-specific consumption.\n\n### Key Capabilities\n\n- **Multi-Profile Support**: Manage unlimited Claude accounts with isolated credentials and settings\n- **Multi-Profile Display**: Monitor all profiles simultaneously in the menu bar (NEW in v2.3.0)\n- **Claude Code Integration**: Sync CLI accounts and auto-switch credentials when changing profiles\n- **Real-Time Monitoring**: Track session, weekly, and API console usage per profile\n- **Customizable Interface**: 5 icon styles + monochrome mode + remaining/used percentage toggle\n- **Smart Automation**: Auto-start sessions (per-profile background service), threshold notifications\n- **Developer Tools**: Terminal statusline integration with automatic profile updates\n- **Privacy-First**: Local storage, no telemetry, no cloud sync\n- **Native Performance**: Lightweight Swift/SwiftUI design for macOS\n\n<div align=\"center\">\n  <img src=\".github/icon.jpg\" alt=\"Menu Bar Icon\" height=\"180\">\n  <img src=\".github/popover.png\" alt=\"Popover Interface\" width=\"200\">\n\n  <sub>Menu bar icon and detailed usage popover</sub>\n\n  <img src=\".github/statusline.png\" alt=\"Claude Code Statusline\">\n  <br>\n  <sub>Live terminal statusline showing directory, branch, and color-coded usage</sub>\n</div>\n\n---\n\n## What's New\n\n- **v2.3.0 - Multi-Profile Menu Bar Display (2026-01-23)**:\n  - **Multi-profile menu bar display**: Monitor all your Claude accounts simultaneously in the menu bar\n  - **Remaining vs. used percentage**: Choose to display remaining budget instead of used percentage\n  - **Unified usage calculations**: Centralized logic with intelligent color adaptation\n  - **Enhanced icon rendering**: Per-profile icons with independent styling and settings\n\n- **v2.2.3** â€“ Improved setup wizard with smart banners\n- **v2.2.2** â€“ CLI OAuth authentication fallback, simplified auto-start\n- **v2.2.0** â€“ Multi-profile management, CLI integration, Korean language\n- **v2.1.2** â€“ Statusline improvements, organization ID optimization\n- **v2.1.1** â€“ Session timer countdown in menu bar\n- **v2.1.0** â€“ 3-step setup wizard, smart organization preservation\n- **v2.0.0** â€“ Apple code signing, automatic updates, Keychain security\n\n**[View Full Release History](CHANGELOG.md)**\n\n---\n\n## Getting Started\n\n### Prerequisites\n\nBefore installing Claude Usage Tracker, ensure you have:\n\n- **macOS 14.0 (Sonoma) or later** - Check: Apple menu â†’ About This Mac\n- **Active Claude AI account** - Sign up at [claude.ai](https://claude.ai)\n\n**Authentication** (choose one method):\n- **Easiest**: [Claude Code](https://claude.com/claude-code) installed and logged in - App automatically uses CLI credentials (v2.2.2+)\n- **Manual**: Web browser access to extract session key from claude.ai (Chrome, Safari, Firefox, etc.)\n\n**Note**: For terminal statusline integration, you'll still need to manually configure a session key even if using Claude Code OAuth\n\n### Installation\n\n#### Option 1: Homebrew (Recommended)\n\n```bash\nbrew install --cask hamed-elfayome/claude-usage/claude-usage-tracker\n```\n\nOr tap first, then install:\n\n```bash\nbrew tap hamed-elfayome/claude-usage\nbrew install --cask claude-usage-tracker\n```\n\n**Note**: Starting with v2.0.0, the app is officially signed with an Apple Developer certificate. No security workarounds needed!\n\n**To update**:\n```bash\nbrew upgrade --cask claude-usage-tracker\n```\n\nOr use the built-in automatic update feature (Settings â†’ Updates).\n\n**To uninstall**:\n```bash\nbrew uninstall --cask claude-usage-tracker\n```\n\n#### Option 2: Direct Download\n\n**[Download Claude-Usage.zip](https://github.com/hamed-elfayome/Claude-Usage-Tracker/releases/latest/download/Claude-Usage.zip)**\n\n1. Download the `.zip` file from the link above\n2. Extract the zip file (double-click or use Archive Utility)\n3. Drag `Claude Usage.app` to your Applications folder\n4. Double-click to launch - that's it!\n\n**v2.0.0+ Note**: The app is now officially signed with an Apple Developer certificate. You can install and run it like any other Mac application - no security warnings or workarounds needed.\n\n**Automatic Updates**: Once installed, the app will automatically check for updates and notify you when new versions are available (Settings â†’ Updates).\n\n#### Option 3: Build from Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/alexbartok/Claude-Usage-Tracker.git\ncd Claude-Usage-Tracker\n\n# Open in Xcode\nopen \"Claude Usage.xcodeproj\"\n\n# Build and run (âŒ˜R)\n```\n\n### Quick Start Guide\n\n#### Option A: Automatic Setup with Claude Code (Easiest)\n\n**New in v2.2.2**: If you have Claude Code installed and logged in, the app works automatically!\n\n1. **Install Claude Code** (if not already installed)\n   - Download from [claude.com/claude-code](https://claude.com/claude-code)\n   - Log in using `claude login`\n\n2. **Launch Claude Usage Tracker**\n   - The app automatically detects your Claude Code Account\n   - No manual configuration needed!\n\n3. **Verify It's Working**\n   - Click the menu bar icon\n   - You should see your usage statistics immediately\n\n#### Option B: Manual Setup with Session Key\n\nIf you prefer manual configuration or don't use Claude Code:\n\n**Step 1: Extract Your Session Key**\n\n1. **Open Claude AI**\n   - Navigate to [claude.ai](https://claude.ai) in your browser\n   - Make sure you're logged in\n\n2. **Open Developer Tools**\n   - **Chrome/Edge**: Press `F12` or `Cmd+Option+I` (macOS) / `Ctrl+Shift+I` (Windows)\n   - **Safari**: Enable Developer menu in Preferences â†’ Advanced, then press `Cmd+Option+I`\n   - **Firefox**: Press `F12` or `Cmd+Option+I` (macOS) / `Ctrl+Shift+I` (Windows)\n\n3. **Navigate to Cookies**\n   - Go to: **Application** tab (Chrome/Edge) or **Storage** tab (Firefox)\n   - Expand: **Cookies** â†’ **https://claude.ai**\n   - Find: `sessionKey` cookie\n   - Copy: The value (starts with `sk-ant-sid01-...`)\n\n**Step 2: Configure Session Key**\n\n1. **Click the menu bar icon** and select \"Settings\"\n2. **Navigate to \"Personal Usage\"** tab\n3. **3-Step Wizard** guides you through setup:\n   - **Step 1**: Paste your session key and click \"Test Connection\"\n   - **Step 2**: Select your Claude organization from the list\n   - **Step 3**: Review and click \"Save Configuration\"\n4. **Wait for confirmation** (success message appears)\n\n**Step 3: Verify It's Working**\n\n1. **Check Menu Bar**: You should see the Claude Usage icon in your menu bar\n2. **Click the Icon**: Popover appears showing your usage statistics\n3. **View Data**: Session usage, weekly usage, and reset timers should display\n\n**Success!** The app is now monitoring your Claude usage.\n\n#### Next Steps\n\n- **Customize Icon**: Go to Settings â†’ Appearance to choose your preferred menu bar style\n- **Su**: Go to Settings â†’ Appearance to choose your preferred menu bar style\n- **Enable Notifications**: Settings â†’ Notifications to get threshold alerts\n- **Auto-Start Sessions**: Settings â†’ Session Management to enable automatic session initialization\n- **Terminal Integration**: Settings â†’ Claude Code to set up statusline (requires session key configuration)\n\n---\n\n## Advanced Configuration\n\n### Manual Session Key Setup\n\nIf you prefer to configure the session key manually instead of using the setup wizard:\n\n```bash\n# Create session key file\necho \"sk-ant-sid01-YOUR_SESSION_KEY_HERE\" > ~/.claude-session-key\n\n# Set secure permissions (important for security)\nchmod 600 ~/.claude-session-key\n```\n\nAfter creating the file, launch the app and it will automatically detect the session key.\n\n---\n\n## Multi-Profile Management\n\n**New in v2.2.0**: Claude Usage Tracker now supports unlimited profiles, allowing you to manage multiple Claude accounts seamlessly with automatic credential switching.\n\n**New in v2.3.0**: Multi-profile menu bar display lets you monitor all your profiles simultaneously!\n\n### Features\n\n#### Profile Management\n- **Unlimited Profiles**: Create as many profiles as needed for different Claude accounts\n- **Multi-Profile Display**: Show all profiles in the menu bar at once (v2.3.0)\n  - Toggle between Single mode (active profile only) and Multi mode (all profiles)\n  - Each profile displays with its own icon style and settings\n  - Click any profile icon to view its usage details\n  - Independent refresh rates per profile\n- **Fun Auto-Names**: Profiles auto-generate with names like \"Quantum Llama\", \"Sneaky Penguin\", \"Turbo Sloth\"\n- **Custom Names**: Rename profiles to whatever you prefer\n- **Quick Switching**: Switch profiles instantly via popover dropdown or settings sidebar\n- **Profile Badges**: Visual indicators show which profiles have Claude.ai credentials and CLI accounts\n\n#### Claude Code CLI Integration\n- **One-Click Sync**: Sync your currently logged-in Claude Code account to a profile\n- **Automatic Switching**: When you switch profiles, CLI credentials automatically update\n- **Credential Display**: View masked access tokens and subscription type\n- **Smart Re-Sync**: Credentials automatically refresh before profile switches to capture CLI changes\n- **Per-Profile CLI**: Each profile can have its own Claude Code account or share the system account\n\n#### Per-Profile Settings\nEach profile has isolated settings:\n- **Credentials**: Separate Claude.ai session keys, API keys, and organization IDs\n- **Appearance**: Independent icon styles and monochrome mode\n- **Refresh Interval**: Custom refresh rates (5-300 seconds)\n- **Auto-Start Sessions**: Enable/disable per profile\n- **Notifications**: Independent threshold alerts (75%, 90%, 95%)\n- **Usage Data**: Tracked separately per profile\n\n#### Profile Switcher\nAccess profile switcher in multiple places:\n- **Popover Header**: Dropdown menu with profile badges\n- **Settings Sidebar**: Active profile picker with visual indicators\n- **Manage Profiles Tab**: Full profile management interface\n\n#### How to Use\n\n1. **Create Profiles**:\n   - Go to Settings â†’ Manage Profiles\n   - Click \"Create New Profile\"\n   - Auto-generates a fun name or enter your own\n\n2. **Configure Credentials**:\n   - Switch to desired profile in sidebar\n   - Go to Claude.AI / API Console / CLI Account tabs\n   - Enter credentials (isolated per profile)\n\n3. **Sync Claude Code** (Optional):\n   - Log in to Claude Code in terminal\n   - Open Settings â†’ CLI Account\n   - Click \"Sync from Claude Code\"\n   - Now when you switch profiles, CLI credentials auto-update!\n\n4. **Switch Profiles**:\n   - Click popover dropdown\n   - Or use settings sidebar picker\n   - CLI credentials apply automatically\n\n\n---\n\n## Features\n\n### Installation & Updates\n- **Official Apple Code Signing**: Professionally signed application - installs like any Mac app\n- **Automatic Updates**: Built-in update system powered by Sparkle framework\n- **One-Click Installation**: No security workarounds or manual approvals needed\n- **Update Notifications**: Get notified when new versions are available\n\n### Usage Tracking & Monitoring\n- Real-time monitoring of 5-hour session, weekly limits, and Opus-specific usage\n- API console usage tracking for comprehensive visibility\n- Extra usage cost tracking for Claude Extra subscribers\n- Color-coded indicators (green/orange/red) based on consumption levels\n- Smart countdown timers for session and weekly resets\n\n### Menu Bar & Interface\n- **5 Customizable Icon Styles**: Battery, Progress Bar, Percentage Only, Icon with Bar, Compact\n- **Multi-Metric Icons**: Display separate icons for session, weekly, and api usage simultaneously\n- **Monochrome Mode**: Optional black & white aesthetic\n- **Interactive Popover**: One-click access with detachable floating window capability\n- **Live Status Indicator**: Real-time Claude system status from status.claude.com\n- **Multi-Language Support**: 6 languages (English, Spanish, French, German, Italian, Portuguese)\n- Adaptive colors for light/dark mode\n\n### Automation & Intelligence\n- **Auto-Start Sessions**: Automatically initialize new sessions when usage resets to 0%\n- **Smart Notifications**: Threshold alerts at 75%, 90%, and 95% usage\n- **Network Monitoring**: Auto-detect connectivity changes and handle offline scenarios\n- **Launch at Login**: System-level auto-start option\n- **Configurable Refresh**: Set intervals from 5 to 120 seconds\n- Session reset and auto-start confirmations\n\n### Developer Integration\n- **Claude Code Terminal Statusline**: Real-time usage in your terminal\n- Customizable components: directory, git branch, usage percentage, progress bar, reset timer\n- One-click automated installation\n- Live preview before applying changes\n\n### Security & Privacy\n- **macOS Keychain Storage**: Session keys stored in macOS Keychain (most secure option)\n- **Automatic Migration**: Seamless migration from old storage methods\n- **Apple Code Signed**: Verified by Apple for enhanced security and trust\n- **Advanced Error Handling**: Professional error system with user-friendly recovery\n- **Robust Validation**: Session key and API endpoint validation\n- Local storage with no cloud sync\n- Zero telemetry or tracking\n- HTTPS-only communication with Claude API\n\n### Advanced Capabilities\n- Multi-screen support\n- First-run guided setup wizard\n- Protocol-based modular architecture\n- Persistent settings with App Groups\n- Comprehensive test coverage\n\n---\n\n## Usage\n\n### Menu Bar Interface\n\nClick the menu bar icon to access:\n\n- **Session Usage**: 5-hour rolling window percentage and reset time\n- **Weekly Usage**: Overall weekly consumption across all models\n- **Opus Usage**: Weekly Opus-specific usage (if applicable)\n- **Quick Actions**: Refresh, Settings, and Quit\n\n### Settings\n\nAccess comprehensive settings through the menu bar popover â†’ Settings button. The app features a modern sidebar interface with profile switcher and organized tabs:\n\n### Profile-Specific Settings\n\n#### Profile Switcher (Sidebar)\n- **Quick Profile Selection**: Dropdown to switch between profiles instantly\n- **Profile Badges**: Visual indicators for Claude.ai ğŸ”µ and CLI âœ… credentials\n- **Active Profile Display**: Shows currently selected profile\n\n#### Claude.AI (Credentials)\nConfigure your Claude.ai personal account:\n- **3-Step Setup Wizard**: Guided session key configuration\n  - Non-destructive connection testing\n  - Visual organization selector\n  - Configuration summary with preview\n- **Smart Updates**: Organization preserved when re-entering same key\n- **Quick Access**: One-click link to claude.ai\n\n#### API Console (Credentials)\nConfigure API console usage tracking:\n- **API Session Key**: Set your API authentication key\n- **Organization ID**: Configure organization for API tracking\n- **Dual Tracking**: Monitor both web and API usage simultaneously\n- **API Billing**: View API console usage costs\n\n#### CLI Account (Credentials)\nSync Claude Code CLI credentials:\n- **One-Click Sync**: Copy currently logged-in Claude Code account to profile\n- **Credential Display**: View masked access token and subscription type\n- **Auto-Switch**: Credentials automatically update when changing profiles\n- **Remove Sync**: Unlink CLI account from profile\n\n#### Appearance\nCustomize menu bar icon per profile:\n- **Icon Style Selection**: Choose from 5 different display modes\n  - Battery Style (classic indicator with fill)\n  - Progress Bar (horizontal bar with percentage)\n  - Percentage Only (text-only minimalist)\n  - Icon with Bar (Claude icon + progress)\n  - Compact (space-efficient)\n- **Monochrome Mode**: Toggle black & white icon style\n- **Percentage Display Mode** (NEW in v2.3.0): Toggle between used/remaining percentage\n  - Show \"75% used\" or \"25% remaining\" - your choice\n  - Color coding automatically adapts (green for high remaining, red for low)\n  - Helps focus on budget left rather than budget spent\n- **Live Preview**: See changes in real-time before applying\n\n#### General (Profile Settings)\nPer-profile behavior configuration:\n- **Refresh Interval**: Configure auto-refresh rate (5-300 seconds)\n- **Auto-Start Sessions**: Enable/disable automatic session initialization on reset\n- **Model Selection**: Uses the most cost-effective model available\n- **Notifications**: Per-profile threshold alerts (75%, 90%, 95%)\n\n### App-Wide Settings\n\n#### Manage Profiles\nCreate and manage multiple profiles:\n- **Create Profiles**: Add new profiles with fun auto-generated names\n- **Rename Profiles**: Customize profile names\n- **Delete Profiles**: Remove unused profiles (minimum 1 required)\n- **Profile List**: View all profiles with credential status indicators\n- **Display Mode Toggle** (NEW in v2.3.0): Switch between Single and Multi mode\n  - Single Mode: Show only the active profile in menu bar\n  - Multi Mode: Show all profiles simultaneously in menu bar\n\n#### Language\nApplication language preferences:\n- **Language Selection**: Choose from 8 supported languages\n- **Live Updates**: Interface updates immediately when language changes\n- Supported: English, Spanish, French, German, Italian, Portuguese, Japanese, Korean\n\n#### Claude Code (Statusline)\nTerminal integration (app-wide):\n- **Component Selection**: Choose what to display (directory, branch, usage, progress bar, reset time)\n- **Live Preview**: See exact statusline format before installing\n- **One-Click Install**: Automated script installation to `~/.claude/`\n- **Automatic Updates**: Statusline updates when switching profiles\n- See [Claude Code Integration](#claude-code-integration) section for detailed setup\n\n#### Updates\nAutomatic update configuration:\n- **Automatic Update Checking**: Configure how often to check for updates\n- **Update Notifications**: Get notified when new versions are available\n- **One-Click Installation**: Download and install updates with a single click\n- **Release Notes**: View what's new in each update\n\n#### About\nApplication information:\n- **Version Information**: Current app version\n- **Credits**: Contributors and acknowledgments\n- **Links**: GitHub repository, issue tracker, documentation\n\n\n## Claude Code Integration\n\nBring real-time Claude usage monitoring directly into your terminal with Claude Code statusline integration! Display your current usage percentage, git branch, and working directory without leaving your development workflow.\n\n### What is Claude Code?\n\n[Claude Code](https://claude.com/claude-code) is Anthropic's official CLI tool for interacting with Claude AI directly from your terminal. The statusline feature allows you to display custom information at the bottom of your terminal window.\n\n<div align=\"center\">\n  <img src=\".github/statusline.png\" alt=\"Claude Code Statusline in Action\" width=\"90%\">\n  <br>\n  <sub>Example: Terminal statusline with all components enabled</sub>\n</div>\n\n### Setup Instructions\n\n#### Prerequisites\n\n1. **Claude Code installed**: Download from [claude.com/claude-code](https://claude.com/claude-code)\n2. **Session key configured**: Must be manually configured in the Personal Usage tab (Claude Code OAuth doesn't work for statusline - it requires direct session key)\n\n#### Installation Steps\n\n1. **Open Claude Usage Tracker Settings**\n   - Click the menu bar icon\n   - Click \"Settings\"\n   - Navigate to the \"Claude Code\" tab\n\n2. **Choose Your Components**\n   - Toggle on/off the components you want to see:\n     - **Directory name**: Shows current working directory\n     - **Git branch**: Displays current branch with â‡ icon\n     - **Usage statistics**: Shows session percentage with color coding\n     - **Progress bar**: Visual 10-segment indicator (optional when usage is enabled)\n\n3. **Preview Your Statusline**\n   - The live preview shows exactly how it will appear\n   - Example: `claude-usage â”‚ â‡ main â”‚ Usage: 25% â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘`\n\n4. **Apply Configuration**\n   - Click \"Apply\" button\n   - Scripts will be installed to `~/.claude/`\n   - Claude Code's `settings.json` will be updated automatically\n\n5. **Restart Claude Code**\n   - Close and reopen your Claude Code terminal\n   - The statusline will appear at the bottom of your terminal window\n\n### What Gets Installed\n\nThe setup automatically creates:\n\n- `~/.claude/fetch-claude-usage.swift`: Swift script that fetches usage data from Claude API\n- `~/.claude/statusline-command.sh`: Bash script that builds the statusline display\n- `~/.claude/statusline-config.txt`: Configuration file with your component preferences\n- `~/.claude/settings.json`: Updated with statusline command (or created if doesn't exist)\n\nAll scripts are set with secure permissions (755) and only read your existing session key file.\n\n### Customization\n\n#### Available Components\n\n| Component | Description | Example |\n|-----------|-------------|---------|\n| Directory | Current directory name | `claude-usage` |\n| Git Branch | Active git branch | `â‡ main` |\n| Usage | Session percentage | `Usage: 25%` |\n| Progress Bar | 10-segment visual indicator | `â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘` |\n| Reset Time | When session resets | `â†’ Reset: 3:45 PM` |\n\n#### Color Coding\n\nUsage percentage is color-coded with a 10-level gradient:\n- **0-10%**: Dark green\n- **11-30%**: Green shades\n- **31-50%**: Yellow-green transitioning to olive\n- **51-70%**: Yellow to orange\n- **71-90%**: Dark orange to red\n- **91-100%**: Deep red\n\n#### Disabling Statusline\n\nTo remove the statusline:\n1. Open Claude Usage Tracker Settings â†’ Claude Code tab\n2. Click \"Reset\" button\n3. Restart Claude Code\n\nThis removes the statusline configuration but keeps the scripts installed for easy re-enabling.\n\n### Troubleshooting\n\n#### Statusline Not Appearing\n\n1. Verify Claude Code is installed and working\n2. Check that you restarted Claude Code after applying\n3. Ensure session key is valid in General settings tab\n4. Check that `~/.claude/settings.json` exists and has the statusline configuration\n\n#### Shows \"Usage: ~\"\n\nThis indicates the Swift script couldn't fetch usage data:\n- Verify your session key is valid\n- Check that `~/.claude-session-key` exists\n- Ensure you're connected to the internet\n- Try refreshing your session key from claude.ai\n\n#### Permission Issues\n\nIf scripts can't be executed:\n```bash\nchmod 755 ~/.claude/fetch-claude-usage.swift\nchmod 755 ~/.claude/statusline-command.sh\n```\n\n### Example Statuslines\n\nWith all components enabled:\n```\nmy-project â”‚ â‡ feature/new-ui â”‚ Usage: 47% â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘ â†’ Reset: 4:15 PM\n```\n\nMinimal (usage only):\n```\nUsage: 12% â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\n```\n\nDirectory and branch only:\n```\nbackend-api â”‚ â‡ develop\n```\n\n## Architecture\n\n### Technology Stack\n\n- **Language**: Swift 5.0+\n- **UI Framework**: SwiftUI 5.0+\n- **Platform**: macOS 14.0+ (Sonoma)\n- **Architecture**: MVVM with Protocol-Oriented Design\n- **Storage**: UserDefaults with App Groups\n- **Networking**: URLSession with async/await\n- **Design Patterns**: Coordinator pattern, Protocol-based services, Modular components\n\n## API Integration\n\nThe application integrates with multiple Claude API endpoints for comprehensive usage tracking:\n\n### Web Usage Endpoint\n\n```\nGET https://claude.ai/api/organizations/{org_id}/usage\n```\n\n**Authentication**: Session cookie (`sessionKey`) from claude.ai\n\n**Response Structure**:\n- `five_hour`: 5-hour session usage data\n  - `utilization_pct`: Usage percentage (0-100)\n  - `reset_at`: ISO 8601 timestamp for next reset\n- `seven_day`: Weekly usage across all models\n  - `utilization_pct`: Weekly usage percentage\n- `seven_day_opus`: Opus-specific weekly usage\n  - `utilization_pct`: Opus weekly percentage\n- `extra_usage`: Claude Extra cost tracking (if applicable)\n  - `current_spending`: Amount spent\n  - `budget_limit`: Maximum allowed spending\n\n### API Console Endpoint\n\n```\nGET https://api.anthropic.com/v1/organization/{org_id}/usage\n```\n\n**Authentication**: API Key (`x-api-key` header)\n\n**Response Structure**:\n- API console usage statistics\n- Billing information\n- Rate limits and quotas\n\n### Dual Tracking\n\nThe app can simultaneously monitor both web (claude.ai) and API console usage, providing complete visibility into your Claude consumption across all access methods.\n\n## Security\n\n- **macOS Keychain**: Session keys stored securely in macOS Keychain (most secure storage available)\n- **Automatic Migration**: v2.0+ automatically migrates session keys from older storage methods to Keychain\n- **Apple Code Signed**: Officially signed with Apple Developer certificate for verified authenticity\n- **Secure Updates**: Automatic updates delivered over HTTPS with code signature verification\n- **No Cloud Sync**: All data remains local to your machine\n- **No Telemetry**: Zero tracking or analytics\n- **Advanced Error Handling**: Robust error system with user-friendly recovery\n- **Session Key Validation**: Comprehensive validation of API credentials\n- **Network**: HTTPS-only communication with claude.ai and Anthropic API\n\n## Troubleshooting\n\n### Application Not Connecting\n\n1. Verify your session key is valid\n2. Check that you're logged into claude.ai in your browser\n3. Try extracting a fresh session key\n4. Ensure you have an active internet connection\n\n### 403 Permission Errors\n\nIf you see \"Unauthorized\" or 403 errors:\n1. Open Settings â†’ Personal Usage\n2. Use the 3-step wizard to reconfigure:\n   - Test your session key\n   - Select the correct organization\n   - Save configuration\n3. The wizard will preserve your organization selection when updating keys\n\n### Menu Bar Icons Showing Zero\n\nIf icons briefly flash to zero during refresh:\n- This has been fixed in v2.1.0+\n- Update to the latest version for smooth refresh experience\n- Old data now stays visible until new data arrives\n\n### Menu Bar Icon Not Appearing\n\n1. Check System Settings â†’ Desktop & Dock â†’ Menu Bar\n2. Restart the application\n3. Check Console.app for error messages\n\n### Session Key Expired\n\nSession keys may expire after a period of time. Extract a new key from claude.ai and update it in Settings â†’ Personal Usage using the wizard.\n\n### Updates Not Working\n\nIf automatic updates aren't working:\n\n1. Check Settings â†’ Updates to ensure automatic checking is enabled\n2. Verify you're running v2.0.0 or later (earlier versions don't have auto-update)\n3. Check your internet connection\n4. Manually download the latest version from GitHub if needed\n\n## Contributors\n\n<img src=\"https://contrib.rocks/image?repo=hamed-elfayome/Claude-Usage-Tracker\" alt=\"Contributors\" height=\"30px\" />\n\nThis project is built for the community â€” everyone is welcome\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.\n\n### Development Setup\n\n1. Fork the repository\n2. Create your feature branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n### Code Style\n\n- Follow Swift API Design Guidelines\n- Use SwiftUI best practices\n- Maintain MVVM architecture\n- Add comments for complex logic\n- Write descriptive commit messages\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- Built with Swift and SwiftUI\n- Designed for macOS Sonoma and later\n- Uses Claude AI's usage API\n- Inspired by the need for better usage visibility\n\n## Disclaimer\n\nThis application is not affiliated with, endorsed by, or sponsored by Anthropic PBC. Claude is a trademark of Anthropic PBC. This is an independent third-party tool created for personal usage monitoring.\n\n## AI Transparency\n\nThis project is developed using AI-assisted workflows (primarily Claude Code via Happy). We believe in transparent collaboration between human developers and AI tools.\n\n---\n\n<div align=\"center\">\n  <sub>Built for the Claude AI community</sub>\n</div>\n",
      "stars_today": 50
    },
    {
      "id": 865675427,
      "name": "zhihu-plus-plus",
      "full_name": "zly2006/zhihu-plus-plus",
      "description": "å»å¹¿å‘Šã€å ç”¨ä½ã€AIå¤§æ¨¡å‹poweredçš„æ–°æ—¶ä»£çŸ¥ä¹å®‰å“ç«¯ä½“éªŒã€‚",
      "html_url": "https://github.com/zly2006/zhihu-plus-plus",
      "stars": 550,
      "forks": 17,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2024-09-30T23:44:47Z",
      "updated_at": "2026-01-25T01:37:56Z",
      "pushed_at": "2026-01-24T08:39:44Z",
      "open_issues": 7,
      "owner": {
        "login": "zly2006",
        "avatar_url": "https://avatars.githubusercontent.com/u/66198935?v=4"
      },
      "readme": "# Zhihu++ï¼šæ³¨é‡éšç§ã€äº’è”ç½‘ä¸ªäººæƒåˆ©å’Œæ— å¹¿å‘Šçš„çŸ¥ä¹å®¢æˆ·ç«¯\n\n[![GitHub release](https://img.shields.io/github/v/release/zly2006/zhihu-plus-plus) ![](https://img.shields.io/github/downloads/zly2006/zhihu-plus-plus/total)](https://github.com/zly2006/zhihu-plus-plus/releases)\n\n<img src=\"misc/zhihu_shit.png\" width=\"100\" height=\"100\" />\n\n**å…³äºå›¾æ ‡:** æˆ‘çš„æœ¬æ„æ˜¯æƒ³è¯´çŸ¥ä¹å®˜æ–¹å®¢æˆ·ç«¯å°±æ˜¯ä¸€å¨ï¼Œä½†æ˜¯ä¹Ÿæœ‰å¾ˆå¤šäººè¡¨ç¤ºå½±å“è§‚æ„Ÿï¼Œæ•…åœ¨æ­¤å¾é›†å›¾æ ‡è®¾è®¡ï¼Œæœ€å¥½ä¸è¦ä¾µçŠ¯çŸ¥ä¹çš„å•†æ ‡æƒã€‚æ¬¢è¿å‘Issueè®¨è®ºã€‚\n\næœ¬é¡¹ç›®è¿˜ä¸å¤Ÿå®Œå–„ï¼Œæ¬¢è¿PRï¼Œå¦‚æœå¯¹ç¬¬ä¸‰æ–¹çŸ¥ä¹å®¢æˆ·ç«¯æœ‰å…´è¶£ï¼Œä¹Ÿå¯ä»¥è¯•è¯•æ—¶é—´æ›´æ—©ã€åŠŸèƒ½æ›´å…¨é¢çš„[Hydrogen](https://github.com/zhihulite/Hydrogen)\n\nZhihu++ç‹¬åˆ›æœ¬åœ°æ¨èç®—æ³•ï¼ŒæŠŠå†…å®¹æ¨èå®Œå…¨æ”¾åœ¨æœ¬åœ°è¿›è¡Œï¼Œä¸ºæ‚¨æä¾›å’Œç­›é€‰é«˜è´¨é‡å†…å®¹ã€‚\næœ¬åœ°æ¨èç®—æ³•å®Œå…¨ç‹¬ç«‹äºçŸ¥ä¹ç®—æ³•ï¼Œä¾èµ–çˆ¬è™«è¿è¡Œï¼Œå¯ä»¥è‡ªç”±å®šåˆ¶å„ç§æ¨èæƒé‡ï¼Œä¿è¯çœ‹åˆ°è‡ªå·±æƒ³çœ‹çš„å†…å®¹ã€‚\næˆ‘ç›¸ä¿¡ï¼Œè¿™ç‚¹ç»µè–„ä¹‹åŠ›å¯ä»¥å¸®åŠ©å¹¿å¤§ç”¨æˆ·ä»å¤§å…¬å¸çš„æ‰‹ä¸­å¤ºå›æœ¬è¯¥å±äºæˆ‘ä»¬çš„æƒåˆ©â€”â€”é€‰æ‹©è‡ªå·±çš„ç”Ÿæ´»ï¼Œä¸è¢«ç®—æ³•å¥´å½¹çš„æƒåˆ©ã€‚\n\n[äº¤æµç¾¤](https://qm.qq.com/q/Rz6KFswFoK) ç¾¤å·ï¼š619307382\n\n[äº¤æµã€åé¦ˆ discord](https://discord.gg/YCPFZV5XSA) ï¼ˆè¯·åœ¨ my-other-apps/zhihu-plus-plus é¢‘é“è®¨è®ºï¼‰\n\nçŸ¥ä¹æ‰‹æœºå®¢æˆ·ç«¯ï¼Œè¹²å‘ç¥å™¨ã€‚å»å¹¿å‘Šï¼Œå»æ¨å¹¿è½¯æ–‡ï¼Œå»æ¨é”€å¸¦è´§ï¼Œå»ç›é€‰ä¸“æ ã€‚\n\næ”¯æŒæ‰‹æœºç«¯/ç½‘é¡µç«¯/æ··åˆç­‰å¤šç§æ¨èæ–¹æ¡ˆã€‚\n\nå¯ä»¥è®¾ç½®å±è”½è¯ã€AIå±è”½å›ç­”ã€å±è”½ç”¨æˆ·ã€å±è”½è¯é¢˜ç­‰ã€‚\n\næœ¬é¡¹ç›®ä¸æ˜¯ç»å…¸æ„ä¹‰ä¸Šçš„è‡ªç”±è½¯ä»¶ï¼Œè¯¦è§[æˆæƒåè®®](LICENSE.md)ã€‚\n\n## ä¸‹è½½\n\nå‘Šåˆ«çŸ¥ä¹ 110MB+ çš„å®¢æˆ·ç«¯ï¼Œåªè¦ 3 MBï¼\n\n[ç‚¹æˆ‘ä¸‹è½½](https://github.com/zly2006/zhihu-plus-plus/releases)\n\n[ä¸‹è½½æœ€æ–°å¼€å‘ç‰ˆæœ¬](https://github.com/zly2006/zhihu-plus-plus/releases/tag/nightly)\n\n## è·¯çº¿å›¾\n\n### å·²ç»å®ç°çš„åŠŸèƒ½\n\n- ç™»å½•\n  - æ”¯æŒæ‰‹æœºéªŒè¯ç ç™»å½•\n  - æ”¯æŒé€šè¿‡æ‰«ç åœ¨ç”µè„‘ç«¯ç™»å½•\n  - æ”¯æŒæ‰‹åŠ¨è®¾ç½®cookieç™»å½•\n- é¦–é¡µæ¨è\n  - æ”¯æŒ Web ç«¯æ¨èç®—æ³•\n  - æ”¯æŒå®‰å“ç«¯æ¨èç®—æ³•\n  - æ”¯æŒåˆ‡æ¢ **ç™»å½•çŠ¶æ€ / éç™»å½•çŠ¶æ€** ä¸‹çš„æ¨èï¼Œé˜²æ­¢ä¿¡æ¯èŒ§æˆ¿\n- é˜…è¯»å›ç­”\n- é˜…è¯»æ–‡ç« \n- æœ—è¯»å†…å®¹\n  - å¬æ–‡ç« \n  - å¬å›ç­”\n- å›ç­”é¡µé•¿æŒ‰ä¿å­˜å›¾ç‰‡ **æ— æ°´å°**\n- è¿‡æ»¤å¹¿å‘Šã€è½¯æ–‡å’Œä½è´¨é‡å†…å®¹\n- æµè§ˆå™¨å”¤èµ·\n- å†å²è®°å½•\n- æ”¶è—å¤¹\n- å±è”½è¯\n- å±è”½ç”¨æˆ·\n- è¯„è®ºåŒº\n- é€šçŸ¥\n- è¡¨æƒ…åŒ…\n  - ç»å…¸è¡¨æƒ…`[æƒŠå–œ]`å¼ºåŠ¿å›å½’ï¼\n- å…¶ä»–\n  - æ”¯æŒ zse96 v2 ç­¾åç®—æ³•ï¼ˆå¯ä»¥è°ƒç”¨99%çš„ç½‘é¡µç«¯APIï¼‰\n  - æ”¯æŒæ¨¡æ‹Ÿå®‰å“ç«¯ API è°ƒç”¨\n- å…¶ä»–ï¼ˆéçŸ¥ä¹ï¼‰\n  - æä¾›äº†äºŒç»´ç æ‰«ç ç»“æœå±•ç¤ºå’Œå¤åˆ¶åŠŸèƒ½ï¼Œå¯ç”¨äºæå–ç½‘å€ã€Wi-Fiå¯†ç ç­‰ä¿¡æ¯\n\n### è®¡åˆ’å®ç°çš„åŠŸèƒ½\n\n> [TODO](TODO.md)\n\n- å±è”½è¯é¢˜\n",
      "stars_today": 49
    },
    {
      "id": 933197458,
      "name": "helium",
      "full_name": "imputnet/helium",
      "description": "Private, fast, and honest web browser",
      "html_url": "https://github.com/imputnet/helium",
      "stars": 10592,
      "forks": 219,
      "language": "C++",
      "topics": [
        "browser",
        "chromium",
        "privacy",
        "web-browser"
      ],
      "created_at": "2025-02-15T11:43:15Z",
      "updated_at": "2026-01-25T01:56:10Z",
      "pushed_at": "2026-01-24T11:45:09Z",
      "open_issues": 211,
      "owner": {
        "login": "imputnet",
        "avatar_url": "https://avatars.githubusercontent.com/u/152056268?v=4"
      },
      "readme": "<div align=\"center\">\n    <br/>\n    <p>\n        <img src=\"resources/branding/app_icon/raw.png\"\n            title=\"Helium\" alt=\"Helium logo\" width=\"120\" />\n        <h1>Helium</h1>\n    </p>\n    <p width=\"120\">\n        The Chromium-based web browser made for people, with love.\n        <br>\n        Best privacy by default, unbiased ad-blocking, no bloat and no noise.\n    </p>\n    <a href=\"https://helium.computer/\">\n        helium.computer\n    </a>\n    <br/>\n</div>\n\n## Downloads\n> [!NOTE]\n> Helium is still in beta, so unexpected issues may occur. We are not responsible\nfor any damage caused by usage of beta software.\n\nBest way to download Helium is to open [helium.computer](https://helium.computer/) on your computer.\nIt'll pick the right build for your OS and architecture automatically.\n\nIf you wish to download builds \"straight from the tap\" with all options in one place,\nyou can do it on GitHub in the Releases section in each platform's repo:\n- [macOS](https://github.com/imputnet/helium-macos/releases/latest)\n- [Linux](https://github.com/imputnet/helium-linux/releases/latest) (AppImage)\n- [Windows](https://github.com/imputnet/helium-windows/releases/latest) (no auto-updates yet)\n\n## Platform packaging\nHelium is available on all major desktop platforms, with entirety of source code\nfor all of them published here:\n- [Helium for macOS](https://github.com/imputnet/helium-macos)\n- [Helium for Linux](https://github.com/imputnet/helium-linux)\n- [Helium for Windows](https://github.com/imputnet/helium-windows)\n\n## Other Helium repos\nAlong with the main repo and platform packaging, these projects are also a part of Helium:\n- [Helium services](https://github.com/imputnet/helium-services)\n- [Helium onboarding](https://github.com/imputnet/helium-onboarding) (the onboarding page seen in Helium at `helium://setup`)\n- [uBlock Origin packaging](https://github.com/imputnet/ublock-origin-crx)\n\n## Credits\n### ungoogled-chromium\nHelium is proudly based on [ungoogled-chromium](https://github.com/ungoogled-software/ungoogled-chromium).\nIt wouldn't be possible for us to get rid of Google's bloat and get a development+building pipeline this fast without it.\nHuge shout-out to everyone behind this amazing project!\n(and we intend to contribute even more stuff upstream in the future)\n\n### The Chromium project\n[The Chromium Project](https://www.chromium.org/) is obviously at the core of Helium,\nmaking it possible to exist in the first place.\n\n### ungoogled-chromium's dependencies\n- [Inox patchset](https://github.com/gcarq/inox-patchset)\n- [Debian](https://tracker.debian.org/pkg/chromium-browser)\n- [Bromite](https://github.com/bromite/bromite)\n- [Iridium Browser](https://iridiumbrowser.de/)\n\n## License\nAll code, patches, modified portions of imported code or patches, and\nany other content that is unique to Helium and not imported from other\nrepositories is licensed under GPL-3.0. See [LICENSE](LICENSE).\n\nAny content imported from other projects retains its original license (for\nexample, any original unmodified code imported from ungoogled-chromium remains\nlicensed under their [BSD 3-Clause license](LICENSE.ungoogled_chromium)).\n\n## More documentation (soon)\n> [!NOTE]\n> We will add more documentation along with design and motivation guidelines in the future.\nAll docs will be linked here along with other related content.\n",
      "stars_today": 48
    },
    {
      "id": 1061082009,
      "name": "Echo-Music",
      "full_name": "iad1tya/Echo-Music",
      "description": "A modern music streaming app with  adfree experience, synced lyrics, and offline playback.",
      "html_url": "https://github.com/iad1tya/Echo-Music",
      "stars": 290,
      "forks": 18,
      "language": "Kotlin",
      "topics": [
        "adfree",
        "free",
        "kotlin",
        "kotlin-android",
        "music",
        "musicstreaming",
        "streaming",
        "streaming-audio",
        "youtubemusic"
      ],
      "created_at": "2025-09-21T07:44:30Z",
      "updated_at": "2026-01-25T02:04:51Z",
      "pushed_at": "2026-01-23T17:51:47Z",
      "open_issues": 38,
      "owner": {
        "login": "iad1tya",
        "avatar_url": "https://avatars.githubusercontent.com/u/147871321?v=4"
      },
      "readme": "<div align=\"center\">\n  <img src=\"assets/Echo_github.png\" alt=\"Echo Music Logo\" width=\"140\"/>\n  <h1>Echo Music</h1>\n  <p><strong>A robust, open-source music streaming client offering an ad-free experience, offline capabilities, and advanced music discovery.</strong></p>\n\n  <a href=\"https://echomusic.fun/download\"><img src=\"assets/download.png\" alt=\"Download\" width=\"200\"/></a>\n  <br>\n  <a href=\"https://github.com/iad1tya/Echo-Music/releases\"><img src=\"assets/github.png\" alt=\"Releases\" width=\"160\"/></a>\n  <a href=\"https://echomusic.fun/obtainium\"><img src=\"assets/obtainium.png\" alt=\"Obtainium\" width=\"200\"/></a>\n</div>\n\n---\n\n## Overview\n\nEcho Music is designed to provide a seamless and premium music listening experience. It leverages the vast library of YouTube Music while eliminating advertisements and adding powerful features such as offline downloads, real-time lyrics, and environment-aware music recognition.\n\n## Screenshots\n\n<div align=\"center\">\n  <img src=\"assets/Screenshots/sc_1.png\" alt=\"Home Screen\" width=\"200\"/>\n  <img src=\"assets/Screenshots/sc_2.png\" alt=\"Music Player\" width=\"200\"/>\n  <img src=\"assets/Screenshots/sc_3.png\" alt=\"Playlist Management\" width=\"200\"/>\n</div>\n<div align=\"center\">\n  <img src=\"assets/Screenshots/sc_4.png\" alt=\"Settings\" width=\"200\"/>\n  <img src=\"assets/Screenshots/sc_5.png\" alt=\"Settings\" width=\"200\"/>\n</div>\n\n## Features\n\n### Streaming and Playback\n*   **Ad-Free Experience:** Stream music without interruptions from advertisements.\n*   **seamless Playback:** Switch effortlessly between audio-only and video modes.\n*   **Background Playback:** Continue listening while using other applications or when the screen is off.\n*   **Offline Mode:** Download tracks, albums, and playlists for offline listening with a dedicated download manager.\n\n### Discovery and Echo Find\n*   **Echo Find:** Identify songs playing in your surroundings instantly using advanced audio recognition.\n*   **Smart Recommendations:** Receive personalized song suggestions based on your listening history and preferences.\n*   **Comprehensive Browsing:** Explore Charts, Podcasts, Moods, and Genres to discover new music.\n\n### Advanced Capabilities\n*   **Synchronized Lyrics:** View real-time synced lyrics. Includes AI-powered translation for multilingual support.\n*   **Sleep Timer:** Configure automatic playback cessation after a specified duration.\n*   **Cross-Device Support:** Cast content to Chromecast-enabled devices or stream via DLNA/UPnP to compatible network speakers and TVs.\n*   **Data Import:** Import playlists and library data from other services.\n\n---\n\n## Installation\n\n### Option 1: Direct Download (APK)\nDownload the latest Android Package Kit (APK) from the [Releases Page](https://github.com/iad1tya/Echo-Music/releases/latest).\n\n### Option 2: Build from Source\nTo build the application locally, follow these steps:\n\n1.  **Clone the Repository**\n    ```bash\n    git clone https://github.com/iad1tya/Echo-Music.git\n    cd Echo-Music\n    ```\n\n2.  **Configure Android SDK**\n    Create a `local.properties` file and define your SDK path:\n    ```bash\n    echo \"sdk.dir=/path/to/your/android/sdk\" > local.properties\n    ```\n\n3.  **Firebase Configuration**\n    Firebase setup is required for analytics and reliable imports. Please refer to [FIREBASE_SETUP.md](FIREBASE_SETUP.md) for detailed instructions on adding your `google-services.json`.\n\n4.  **Build**\n    Execute the Gradle build command:\n    ```bash\n    ./gradlew assembleFossDebug\n    ```\n\n---\n\n## Community and Support\n\nJoin our community for updates, support, and discussions.\n\n<div align=\"center\">\n  <a href=\"https://discord.gg/EcfV3AxH5c\"><img src=\"assets/discord.png\" width=\"140\"/></a>\n  <a href=\"https://t.me/EchoMusicApp\"><img src=\"assets/telegram.png\" width=\"130\"/></a>\n</div>\n\n### Support the Project\n\nIf you find this project useful, consider supporting its development.\n\n<div align=\"center\">\n  <a href=\"https://buymeacoffee.com/iad1tya\"><img src=\"assets/bmac.png\" width=\"140\"/></a>\n  <a href=\"https://intradeus.github.io/http-protocol-redirector/?r=upi://pay?pa=iad1tya@upi&pn=Aditya%20Yadav&am=&tn=Thank%20You\"><img src=\"assets/upi.svg\" width=\"100\"/></a>\n  <a href=\"https://www.patreon.com/cw/iad1tya\"><img src=\"assets/patreon3.png\" width=\"100\"/></a>\n</div>\n\n### Cryptocurrency Addresses\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\"><strong>Bitcoin</strong><br><code>bc1qcvyr7eekha8uytmffcvgzf4h7xy7shqzke35fy</code></td>\n      <td align=\"center\"><strong>Ethereum</strong><br><code>0x51bc91022E2dCef9974D5db2A0e22d57B360e700</code></td>\n      <td align=\"center\"><strong>Solana</strong><br><code>9wjca3EQnEiqzqgy7N5iqS1JGXJiknMQv6zHgL96t94S</code></td>\n    </tr>\n  </table>\n</div>\n\n\n---\n\n<div align=\"center\">\n    Licensed under <a href=\"LICENSE\">GPL-3.0</a>\n</div>\n",
      "stars_today": 46
    },
    {
      "id": 94061307,
      "name": "ink",
      "full_name": "vadimdemedes/ink",
      "description": "ğŸŒˆ React for interactive command-line apps",
      "html_url": "https://github.com/vadimdemedes/ink",
      "stars": 34272,
      "forks": 818,
      "language": "TypeScript",
      "topics": [
        "cli",
        "command-line",
        "flexbox",
        "interactive",
        "javascript",
        "react"
      ],
      "created_at": "2017-06-12T06:12:28Z",
      "updated_at": "2026-01-25T02:26:04Z",
      "pushed_at": "2026-01-24T04:26:53Z",
      "open_issues": 97,
      "owner": {
        "login": "vadimdemedes",
        "avatar_url": "https://avatars.githubusercontent.com/u/697676?v=4"
      },
      "readme": "[![](https://raw.githubusercontent.com/vshymanskyy/StandWithUkraine/main/banner2-direct.svg)](https://github.com/vshymanskyy/StandWithUkraine/blob/main/docs/README.md)\n\n---\n\n<div align=\"center\">\n\t<br>\n\t<br>\n\t<img width=\"240\" alt=\"Ink\" src=\"media/logo.png\">\n\t<br>\n\t<br>\n\t<br>\n</div>\n\n> React for CLIs. Build and test your CLI output using components.\n\n[![Build Status](https://github.com/vadimdemedes/ink/workflows/test/badge.svg)](https://github.com/vadimdemedes/ink/actions)\n[![npm](https://img.shields.io/npm/dm/ink?logo=npm)](https://npmjs.com/package/ink)\n\nInk provides the same component-based UI building experience that React offers in the browser, but for command-line apps.\nIt uses [Yoga](https://github.com/facebook/yoga) to build Flexbox layouts in the terminal, so most CSS-like properties are available in Ink as well.\nIf you are already familiar with React, you already know Ink.\n\nSince Ink is a React renderer, all features of React are supported.\nHead over to the [React](https://reactjs.org) website for documentation on how to use it.\nOnly Ink's methods are documented in this readme.\n\n---\n\n<div align=\"center\">\n\t<p>\n\t\t<p>\n\t\t\t<sup>\n\t\t\t\t<a href=\"https://opencollective.com/vadimdemedes\">My open source work is supported by the community â¤ï¸</a>\n\t\t\t</sup>\n\t\t</p>\n\t</p>\n</div>\n\n## Install\n\n```sh\nnpm install ink react\n```\n\n## Usage\n\n```jsx\nimport React, {useState, useEffect} from 'react';\nimport {render, Text} from 'ink';\n\nconst Counter = () => {\n\tconst [counter, setCounter] = useState(0);\n\n\tuseEffect(() => {\n\t\tconst timer = setInterval(() => {\n\t\t\tsetCounter(previousCounter => previousCounter + 1);\n\t\t}, 100);\n\n\t\treturn () => {\n\t\t\tclearInterval(timer);\n\t\t};\n\t}, []);\n\n\treturn <Text color=\"green\">{counter} tests passed</Text>;\n};\n\nrender(<Counter />);\n```\n\n<img src=\"media/demo.svg\" width=\"600\">\n\nFeel free to play around with the code and fork this Repl at [https://repl.it/@vadimdemedes/ink-counter-demo](https://repl.it/@vadimdemedes/ink-counter-demo).\n\n## Who's Using Ink?\n\n- [Claude Code](https://github.com/anthropics/claude-code) - An agentic coding tool made by Anthropic.\n- [Gemini CLI](https://github.com/google-gemini/gemini-cli) - An agentic coding tool made by Google.\n- [GitHub Copilot CLI](https://github.com/features/copilot/cli) - Just say what you want the shell to do.\n- [Canva CLI](https://www.canva.dev/docs/apps/canva-cli/) - CLI for creating and managing Canva Apps.\n- [Cloudflare's Wrangler](https://github.com/cloudflare/wrangler2) - The CLI for Cloudflare Workers.\n- [Linear](https://linear.app) - Linear built an internal CLI for managing deployments, configs, and other housekeeping tasks.\n- [Gatsby](https://www.gatsbyjs.org) - Gatsby is a modern web framework for blazing-fast websites.\n- [tap](https://node-tap.org) - A Test-Anything-Protocol library for JavaScript.\n- [Terraform CDK](https://github.com/hashicorp/terraform-cdk) - Cloud Development Kit (CDK) for HashiCorp Terraform.\n- [Specify CLI](https://specifyapp.com) - Automate the distribution of your design tokens.\n- [Twilio's SIGNAL](https://github.com/twilio-labs/plugin-signal2020) - CLI for Twilio's SIGNAL conference. [Blog post](https://www.twilio.com/blog/building-conference-cli-in-react).\n- [Typewriter](https://github.com/segmentio/typewriter) - Generates strongly-typed [Segment](https://segment.com) analytics clients from arbitrary JSON Schema.\n- [Prisma](https://www.prisma.io) - The unified data layer for modern applications.\n- [Blitz](https://blitzjs.com) - The Fullstack React Framework.\n- [New York Times](https://github.com/nytimes/kyt) - NYT uses Ink's `kyt` - a toolkit that encapsulates and manages the configuration for web apps.\n- [tink](https://github.com/npm/tink) - A next-generation runtime and package manager.\n- [Inkle](https://github.com/jrr/inkle) - A Wordle game.\n- [loki](https://github.com/oblador/loki) - Visual regression testing tool for Storybook.\n- [Bit](https://github.com/teambit/bit) - Build, distribute, and collaborate on components.\n- [Remirror](https://github.com/remirror/remirror) - Your friendly, world-class editor toolkit.\n- [Prime](https://github.com/birkir/prime) - Open-source GraphQL CMS.\n- [emoj](https://github.com/sindresorhus/emoj) - Find relevant emojis.\n- [emma](https://github.com/maticzav/emma-cli) - Find and install npm packages easily.\n- [npm-check-extras](https://github.com/akgondber/npm-check-extras) - Check for outdated and unused dependencies, and run update/delete actions on selected ones.\n- [swiff](https://github.com/simple-integrated-marketing/swiff) - Multi-environment command-line tools for time-saving web developers.\n- [share](https://github.com/marionebl/share-cli) - Share files quickly.\n- [Kubelive](https://github.com/ameerthehacker/kubelive) - A CLI for Kubernetes that provides live data about the cluster and its resources.\n- [changelog-view](https://github.com/jdeniau/changelog-view) - View changelogs.\n- [cfpush](https://github.com/mamachanko/cfpush) - Interactive Cloud Foundry tutorial.\n- [startd](https://github.com/mgrip/startd) - Turn your React component into a web app.\n- [wiki-cli](https://github.com/hexrcs/wiki-cli) - Search Wikipedia and read article summaries.\n- [garson](https://github.com/goliney/garson) - Build interactive, config-based command-line interfaces.\n- [git-contrib-calendar](https://github.com/giannisp/git-contrib-calendar) - Display a contributions calendar for any Git repository.\n- [gitgud](https://github.com/GitGud-org/GitGud) - Interactive command-line GUI for Git.\n- [Autarky](https://github.com/pranshuchittora/autarky) - Find and delete old `node_modules` directories to free up disk space.\n- [fast-cli](https://github.com/sindresorhus/fast-cli) - Test your download and upload speeds.\n- [tasuku](https://github.com/privatenumber/tasuku) - Minimal task runner.\n- [mnswpr](https://github.com/mordv/mnswpr) - A Minesweeper game.\n- [lrn](https://github.com/krychu/lrn) - Learning by repetition.\n- [turdle](https://github.com/mynameisankit/turdle) - A Wordle game.\n- [Shopify CLI](https://github.com/Shopify/cli) - Build apps, themes, and storefronts for the Shopify platform.\n- [ToDesktop CLI](https://www.todesktop.com/electron) - All-in-one platform for building Electron apps.\n- [Walle](https://github.com/Pobepto/walle) - A full-featured crypto wallet for EVM networks.\n- [Sudoku](https://github.com/mrozio13pl/sudoku-in-terminal) - A Sudoku game.\n- [Sea Trader](https://github.com/zyishai/sea-trader) - A Taipan!-inspired trading simulator game.\n- [srtd](https://github.com/t1mmen/srtd) - Live-reloading SQL templates for Supabase projects.\n- [tweakcc](https://github.com/Piebald-AI/tweakcc) - Customize your Claude Code styling.\n- [argonaut](https://github.com/darksworm/argonaut) - Manage Argo CD resources.\n- [Qodo Command](https://github.com/qodo-ai/command) - Build, run, and manage AI agents.\n- [Nanocoder](https://github.com/nano-collective/nanocoder) - A community-built, local-first AI coding agent with multi-provider support.\n- [Neovate Code](https://github.com/neovateai/neovate-code) - An agentic coding tool made by AntGroup.\n- [instagram-cli](https://github.com/supreme-gg-gg/instagram-cli) - Instagram client.\n- [ElevenLabs CLI](https://github.com/elevenlabs/cli) - ElevenLabs agents client.\n\n*(PRs welcome. Append new entries at the end. Repos must have 100+ stars and showcase Ink beyond a basic list picker.)*\n\n## Contents\n\n- [Getting Started](#getting-started)\n- [Components](#components)\n  - [`<Text>`](#text)\n  - [`<Box>`](#box)\n  - [`<Newline>`](#newline)\n  - [`<Spacer>`](#spacer)\n  - [`<Static>`](#static)\n  - [`<Transform>`](#transform)\n- [Hooks](#hooks)\n  - [`useInput`](#useinputinputhandler-options)\n  - [`useApp`](#useapp)\n  - [`useStdin`](#usestdin)\n  - [`useStdout`](#usestdout)\n  - [`useStderr`](#usestderr)\n  - [`useFocus`](#usefocusoptions)\n  - [`useFocusManager`](#usefocusmanager)\n- [API](#api)\n- [Testing](#testing)\n- [Using React Devtools](#using-react-devtools)\n- [Screen Reader Support](#screen-reader-support)\n- [Useful Components](#useful-components)\n- [Useful Hooks](#useful-hooks)\n- [Examples](#examples)\n\n## Getting Started\n\nUse [create-ink-app](https://github.com/vadimdemedes/create-ink-app) to quickly scaffold a new Ink-based CLI.\n\n```sh\nnpx create-ink-app my-ink-cli\n```\n\nAlternatively, create a TypeScript project:\n\n```sh\nnpx create-ink-app --typescript my-ink-cli\n```\n\n<details><summary>Manual JavaScript setup</summary>\n<p>\nInk requires the same Babel setup as you would do for regular React-based apps in the browser.\n\nSet up Babel with a React preset to ensure all examples in this readme work as expected.\nAfter [installing Babel](https://babeljs.io/docs/en/usage), install `@babel/preset-react` and insert the following configuration in `babel.config.json`:\n\n```sh\nnpm install --save-dev @babel/preset-react\n```\n\n```json\n{\n\t\"presets\": [\"@babel/preset-react\"]\n}\n```\n\nNext, create a file `source.js`, where you'll type code that uses Ink:\n\n```jsx\nimport React from 'react';\nimport {render, Text} from 'ink';\n\nconst Demo = () => <Text>Hello World</Text>;\n\nrender(<Demo />);\n```\n\nThen, transpile this file with Babel:\n\n```sh\nnpx babel source.js -o cli.js\n```\n\nNow you can run `cli.js` with Node.js:\n\n```sh\nnode cli\n```\n\nIf you don't like transpiling files during development, you can use [import-jsx](https://github.com/vadimdemedes/import-jsx) or [@esbuild-kit/esm-loader](https://github.com/esbuild-kit/esm-loader) to `import` a JSX file and transpile it on the fly.\n\n</p>\n</details>\n\nInk uses [Yoga](https://github.com/facebook/yoga), a Flexbox layout engine, to build great user interfaces for your CLIs using familiar CSS-like properties you've used when building apps for the browser.\nIt's important to remember that each element is a Flexbox container.\nThink of it as if every `<div>` in the browser had `display: flex`.\nSee [`<Box>`](#box) built-in component below for documentation on how to use Flexbox layouts in Ink.\nNote that all text must be wrapped in a [`<Text>`](#text) component.\n\n## Components\n\n### `<Text>`\n\nThis component can display text and change its style to make it bold, underlined, italic, or strikethrough.\n\n```jsx\nimport {render, Text} from 'ink';\n\nconst Example = () => (\n\t<>\n\t\t<Text color=\"green\">I am green</Text>\n\t\t<Text color=\"black\" backgroundColor=\"white\">\n\t\t\tI am black on white\n\t\t</Text>\n\t\t<Text color=\"#ffffff\">I am white</Text>\n\t\t<Text bold>I am bold</Text>\n\t\t<Text italic>I am italic</Text>\n\t\t<Text underline>I am underline</Text>\n\t\t<Text strikethrough>I am strikethrough</Text>\n\t\t<Text inverse>I am inversed</Text>\n\t</>\n);\n\nrender(<Example />);\n```\n\n**Note:** `<Text>` allows only text nodes and nested `<Text>` components inside of it. For example, `<Box>` component can't be used inside `<Text>`.\n\n#### color\n\nType: `string`\n\nChange text color.\nInk uses [chalk](https://github.com/chalk/chalk) under the hood, so all its functionality is supported.\n\n```jsx\n<Text color=\"green\">Green</Text>\n<Text color=\"#005cc5\">Blue</Text>\n<Text color=\"rgb(232, 131, 136)\">Red</Text>\n```\n\n<img src=\"media/text-color.jpg\" width=\"247\">\n\n#### backgroundColor\n\nType: `string`\n\nSame as `color` above, but for background.\n\n```jsx\n<Text backgroundColor=\"green\" color=\"white\">Green</Text>\n<Text backgroundColor=\"#005cc5\" color=\"white\">Blue</Text>\n<Text backgroundColor=\"rgb(232, 131, 136)\" color=\"white\">Red</Text>\n```\n\n<img src=\"media/text-backgroundColor.jpg\" width=\"226\">\n\n#### dimColor\n\nType: `boolean`\\\nDefault: `false`\n\nDim the color (make it less bright).\n\n```jsx\n<Text color=\"red\" dimColor>\n\tDimmed Red\n</Text>\n```\n\n<img src=\"media/text-dimColor.jpg\" width=\"138\">\n\n#### bold\n\nType: `boolean`\\\nDefault: `false`\n\nMake the text bold.\n\n#### italic\n\nType: `boolean`\\\nDefault: `false`\n\nMake the text italic.\n\n#### underline\n\nType: `boolean`\\\nDefault: `false`\n\nMake the text underlined.\n\n#### strikethrough\n\nType: `boolean`\\\nDefault: `false`\n\nMake the text crossed with a line.\n\n#### inverse\n\nType: `boolean`\\\nDefault: `false`\n\nInvert background and foreground colors.\n\n```jsx\n<Text inverse color=\"yellow\">\n\tInversed Yellow\n</Text>\n```\n\n<img src=\"media/text-inverse.jpg\" width=\"138\">\n\n#### wrap\n\nType: `string`\\\nAllowed values: `wrap` `truncate` `truncate-start` `truncate-middle` `truncate-end`\\\nDefault: `wrap`\n\nThis property tells Ink to wrap or truncate text if its width is larger than the container.\nIf `wrap` is passed (the default), Ink will wrap text and split it into multiple lines.\nIf `truncate-*` is passed, Ink will truncate text instead, resulting in one line of text with the rest cut off.\n\n```jsx\n<Box width={7}>\n\t<Text>Hello World</Text>\n</Box>\n//=> 'Hello\\nWorld'\n\n// `truncate` is an alias to `truncate-end`\n<Box width={7}>\n\t<Text wrap=\"truncate\">Hello World</Text>\n</Box>\n//=> 'Helloâ€¦'\n\n<Box width={7}>\n\t<Text wrap=\"truncate-middle\">Hello World</Text>\n</Box>\n//=> 'Heâ€¦ld'\n\n<Box width={7}>\n\t<Text wrap=\"truncate-start\">Hello World</Text>\n</Box>\n//=> 'â€¦World'\n```\n\n### `<Box>`\n\n`<Box>` is an essential Ink component to build your layout.\nIt's like `<div style=\"display: flex\">` in the browser.\n\n```jsx\nimport {render, Box, Text} from 'ink';\n\nconst Example = () => (\n\t<Box margin={2}>\n\t\t<Text>This is a box with margin</Text>\n\t</Box>\n);\n\nrender(<Example />);\n```\n\n#### Dimensions\n\n##### width\n\nType: `number` `string`\n\nWidth of the element in spaces.\nYou can also set it as a percentage, which will calculate the width based on the width of the parent element.\n\n```jsx\n<Box width={4}>\n\t<Text>X</Text>\n</Box>\n//=> 'X   '\n```\n\n```jsx\n<Box width={10}>\n\t<Box width=\"50%\">\n\t\t<Text>X</Text>\n\t</Box>\n\t<Text>Y</Text>\n</Box>\n//=> 'X    Y'\n```\n\n##### height\n\nType: `number` `string`\n\nHeight of the element in lines (rows).\nYou can also set it as a percentage, which will calculate the height based on the height of the parent element.\n\n```jsx\n<Box height={4}>\n\t<Text>X</Text>\n</Box>\n//=> 'X\\n\\n\\n'\n```\n\n```jsx\n<Box height={6} flexDirection=\"column\">\n\t<Box height=\"50%\">\n\t\t<Text>X</Text>\n\t</Box>\n\t<Text>Y</Text>\n</Box>\n//=> 'X\\n\\n\\nY\\n\\n'\n```\n\n##### minWidth\n\nType: `number`\n\nSets a minimum width of the element.\nPercentages aren't supported yet; see https://github.com/facebook/yoga/issues/872.\n\n##### minHeight\n\nType: `number`\n\nSets a minimum height of the element.\nPercentages aren't supported yet; see https://github.com/facebook/yoga/issues/872.\n\n#### Padding\n\n##### paddingTop\n\nType: `number`\\\nDefault: `0`\n\nTop padding.\n\n##### paddingBottom\n\nType: `number`\\\nDefault: `0`\n\nBottom padding.\n\n##### paddingLeft\n\nType: `number`\\\nDefault: `0`\n\nLeft padding.\n\n##### paddingRight\n\nType: `number`\\\nDefault: `0`\n\nRight padding.\n\n##### paddingX\n\nType: `number`\\\nDefault: `0`\n\nHorizontal padding. Equivalent to setting `paddingLeft` and `paddingRight`.\n\n##### paddingY\n\nType: `number`\\\nDefault: `0`\n\nVertical padding. Equivalent to setting `paddingTop` and `paddingBottom`.\n\n##### padding\n\nType: `number`\\\nDefault: `0`\n\nPadding on all sides. Equivalent to setting `paddingTop`, `paddingBottom`, `paddingLeft` and `paddingRight`.\n\n```jsx\n<Box paddingTop={2}><Text>Top</Text></Box>\n<Box paddingBottom={2}><Text>Bottom</Text></Box>\n<Box paddingLeft={2}><Text>Left</Text></Box>\n<Box paddingRight={2}><Text>Right</Text></Box>\n<Box paddingX={2}><Text>Left and right</Text></Box>\n<Box paddingY={2}><Text>Top and bottom</Text></Box>\n<Box padding={2}><Text>Top, bottom, left and right</Text></Box>\n```\n\n#### Margin\n\n##### marginTop\n\nType: `number`\\\nDefault: `0`\n\nTop margin.\n\n##### marginBottom\n\nType: `number`\\\nDefault: `0`\n\nBottom margin.\n\n##### marginLeft\n\nType: `number`\\\nDefault: `0`\n\nLeft margin.\n\n##### marginRight\n\nType: `number`\\\nDefault: `0`\n\nRight margin.\n\n##### marginX\n\nType: `number`\\\nDefault: `0`\n\nHorizontal margin. Equivalent to setting `marginLeft` and `marginRight`.\n\n##### marginY\n\nType: `number`\\\nDefault: `0`\n\nVertical margin. Equivalent to setting `marginTop` and `marginBottom`.\n\n##### margin\n\nType: `number`\\\nDefault: `0`\n\nMargin on all sides. Equivalent to setting `marginTop`, `marginBottom`, `marginLeft` and `marginRight`.\n\n```jsx\n<Box marginTop={2}><Text>Top</Text></Box>\n<Box marginBottom={2}><Text>Bottom</Text></Box>\n<Box marginLeft={2}><Text>Left</Text></Box>\n<Box marginRight={2}><Text>Right</Text></Box>\n<Box marginX={2}><Text>Left and right</Text></Box>\n<Box marginY={2}><Text>Top and bottom</Text></Box>\n<Box margin={2}><Text>Top, bottom, left and right</Text></Box>\n```\n\n#### Gap\n\n#### gap\n\nType: `number`\\\nDefault: `0`\n\nSize of the gap between an element's columns and rows. A shorthand for `columnGap` and `rowGap`.\n\n```jsx\n<Box gap={1} width={3} flexWrap=\"wrap\">\n\t<Text>A</Text>\n\t<Text>B</Text>\n\t<Text>C</Text>\n</Box>\n// A B\n//\n// C\n```\n\n#### columnGap\n\nType: `number`\\\nDefault: `0`\n\nSize of the gap between an element's columns.\n\n```jsx\n<Box columnGap={1}>\n\t<Text>A</Text>\n\t<Text>B</Text>\n</Box>\n// A B\n```\n\n#### rowGap\n\nType: `number`\\\nDefault: `0`\n\nSize of the gap between an element's rows.\n\n```jsx\n<Box flexDirection=\"column\" rowGap={1}>\n\t<Text>A</Text>\n\t<Text>B</Text>\n</Box>\n// A\n//\n// B\n```\n\n#### Flex\n\n##### flexGrow\n\nType: `number`\\\nDefault: `0`\n\nSee [flex-grow](https://css-tricks.com/almanac/properties/f/flex-grow/).\n\n```jsx\n<Box>\n\t<Text>Label:</Text>\n\t<Box flexGrow={1}>\n\t\t<Text>Fills all remaining space</Text>\n\t</Box>\n</Box>\n```\n\n##### flexShrink\n\nType: `number`\\\nDefault: `1`\n\nSee [flex-shrink](https://css-tricks.com/almanac/properties/f/flex-shrink/).\n\n```jsx\n<Box width={20}>\n\t<Box flexShrink={2} width={10}>\n\t\t<Text>Will be 1/4</Text>\n\t</Box>\n\t<Box width={10}>\n\t\t<Text>Will be 3/4</Text>\n\t</Box>\n</Box>\n```\n\n##### flexBasis\n\nType: `number` `string`\n\nSee [flex-basis](https://css-tricks.com/almanac/properties/f/flex-basis/).\n\n```jsx\n<Box width={6}>\n\t<Box flexBasis={3}>\n\t\t<Text>X</Text>\n\t</Box>\n\t<Text>Y</Text>\n</Box>\n//=> 'X  Y'\n```\n\n```jsx\n<Box width={6}>\n\t<Box flexBasis=\"50%\">\n\t\t<Text>X</Text>\n\t</Box>\n\t<Text>Y</Text>\n</Box>\n//=> 'X  Y'\n```\n\n##### flexDirection\n\nType: `string`\\\nAllowed values: `row` `row-reverse` `column` `column-reverse`\n\nSee [flex-direction](https://css-tricks.com/almanac/properties/f/flex-direction/).\n\n```jsx\n<Box>\n\t<Box marginRight={1}>\n\t\t<Text>X</Text>\n\t</Box>\n\t<Text>Y</Text>\n</Box>\n// X Y\n\n<Box flexDirection=\"row-reverse\">\n\t<Text>X</Text>\n\t<Box marginRight={1}>\n\t\t<Text>Y</Text>\n\t</Box>\n</Box>\n// Y X\n\n<Box flexDirection=\"column\">\n\t<Text>X</Text>\n\t<Text>Y</Text>\n</Box>\n// X\n// Y\n\n<Box flexDirection=\"column-reverse\">\n\t<Text>X</Text>\n\t<Text>Y</Text>\n</Box>\n// Y\n// X\n```\n\n##### flexWrap\n\nType: `string`\\\nAllowed values: `nowrap` `wrap` `wrap-reverse`\n\nSee [flex-wrap](https://css-tricks.com/almanac/properties/f/flex-wrap/).\n\n```jsx\n<Box width={2} flexWrap=\"wrap\">\n\t<Text>A</Text>\n\t<Text>BC</Text>\n</Box>\n// A\n// B C\n```\n\n```jsx\n<Box flexDirection=\"column\" height={2} flexWrap=\"wrap\">\n\t<Text>A</Text>\n\t<Text>B</Text>\n\t<Text>C</Text>\n</Box>\n// A C\n// B\n```\n\n##### alignItems\n\nType: `string`\\\nAllowed values: `flex-start` `center` `flex-end`\n\nSee [align-items](https://css-tricks.com/almanac/properties/a/align-items/).\n\n```jsx\n<Box alignItems=\"flex-start\">\n\t<Box marginRight={1}>\n\t\t<Text>X</Text>\n\t</Box>\n\t<Text>\n\t\tA\n\t\t<Newline/>\n\t\tB\n\t\t<Newline/>\n\t\tC\n\t</Text>\n</Box>\n// X A\n//   B\n//   C\n\n<Box alignItems=\"center\">\n\t<Box marginRight={1}>\n\t\t<Text>X</Text>\n\t</Box>\n\t<Text>\n\t\tA\n\t\t<Newline/>\n\t\tB\n\t\t<Newline/>\n\t\tC\n\t</Text>\n</Box>\n//   A\n// X B\n//   C\n\n<Box alignItems=\"flex-end\">\n\t<Box marginRight={1}>\n\t\t<Text>X</Text>\n\t</Box>\n\t<Text>\n\t\tA\n\t\t<Newline/>\n\t\tB\n\t\t<Newline/>\n\t\tC\n\t</Text>\n</Box>\n//   A\n//   B\n// X C\n```\n\n##### alignSelf\n\nType: `string`\\\nDefault: `auto`\\\nAllowed values: `auto` `flex-start` `center` `flex-end`\n\nSee [align-self](https://css-tricks.com/almanac/properties/a/align-self/).\n\n```jsx\n<Box height={3}>\n\t<Box alignSelf=\"flex-start\">\n\t\t<Text>X</Text>\n\t</Box>\n</Box>\n// X\n//\n//\n\n<Box height={3}>\n\t<Box alignSelf=\"center\">\n\t\t<Text>X</Text>\n\t</Box>\n</Box>\n//\n// X\n//\n\n<Box height={3}>\n\t<Box alignSelf=\"flex-end\">\n\t\t<Text>X</Text>\n\t</Box>\n</Box>\n//\n//\n// X\n```\n\n##### justifyContent\n\nType: `string`\\\nAllowed values: `flex-start` `center` `flex-end` `space-between` `space-around` `space-evenly`\n\nSee [justify-content](https://css-tricks.com/almanac/properties/j/justify-content/).\n\n```jsx\n<Box justifyContent=\"flex-start\">\n\t<Text>X</Text>\n</Box>\n// [X      ]\n\n<Box justifyContent=\"center\">\n\t<Text>X</Text>\n</Box>\n// [   X   ]\n\n<Box justifyContent=\"flex-end\">\n\t<Text>X</Text>\n</Box>\n// [      X]\n\n<Box justifyContent=\"space-between\">\n\t<Text>X</Text>\n\t<Text>Y</Text>\n</Box>\n// [X      Y]\n\n<Box justifyContent=\"space-around\">\n\t<Text>X</Text>\n\t<Text>Y</Text>\n</Box>\n// [  X   Y  ]\n\n<Box justifyContent=\"space-evenly\">\n\t<Text>X</Text>\n\t<Text>Y</Text>\n</Box>\n// [   X   Y   ]\n```\n\n#### Visibility\n\n##### display\n\nType: `string`\\\nAllowed values: `flex` `none`\\\nDefault: `flex`\n\nSet this property to `none` to hide the element.\n\n##### overflowX\n\nType: `string`\\\nAllowed values: `visible` `hidden`\\\nDefault: `visible`\n\nBehavior for an element's overflow in the horizontal direction.\n\n##### overflowY\n\nType: `string`\\\nAllowed values: `visible` `hidden`\\\nDefault: `visible`\n\nBehavior for an element's overflow in the vertical direction.\n\n##### overflow\n\nType: `string`\\\nAllowed values: `visible` `hidden`\\\nDefault: `visible`\n\nA shortcut for setting `overflowX` and `overflowY` at the same time.\n\n#### Borders\n\n##### borderStyle\n\nType: `string`\\\nAllowed values: `single` `double` `round` `bold` `singleDouble` `doubleSingle` `classic` | `BoxStyle`\n\nAdd a border with a specified style.\nIf `borderStyle` is `undefined` (the default), no border will be added.\nInk uses border styles from the [`cli-boxes`](https://github.com/sindresorhus/cli-boxes) module.\n\n```jsx\n<Box flexDirection=\"column\">\n\t<Box>\n\t\t<Box borderStyle=\"single\" marginRight={2}>\n\t\t\t<Text>single</Text>\n\t\t</Box>\n\n\t\t<Box borderStyle=\"double\" marginRight={2}>\n\t\t\t<Text>double</Text>\n\t\t</Box>\n\n\t\t<Box borderStyle=\"round\" marginRight={2}>\n\t\t\t<Text>round</Text>\n\t\t</Box>\n\n\t\t<Box borderStyle=\"bold\">\n\t\t\t<Text>bold</Text>\n\t\t</Box>\n\t</Box>\n\n\t<Box marginTop={1}>\n\t\t<Box borderStyle=\"singleDouble\" marginRight={2}>\n\t\t\t<Text>singleDouble</Text>\n\t\t</Box>\n\n\t\t<Box borderStyle=\"doubleSingle\" marginRight={2}>\n\t\t\t<Text>doubleSingle</Text>\n\t\t</Box>\n\n\t\t<Box borderStyle=\"classic\">\n\t\t\t<Text>classic</Text>\n\t\t</Box>\n\t</Box>\n</Box>\n```\n\n<img src=\"media/box-borderStyle.jpg\" width=\"521\">\n\nAlternatively, pass a custom border style like so:\n\n```jsx\n<Box\n\tborderStyle={{\n\t\ttopLeft: 'â†˜',\n\t\ttop: 'â†“',\n\t\ttopRight: 'â†™',\n\t\tleft: 'â†’',\n\t\tbottomLeft: 'â†—',\n\t\tbottom: 'â†‘',\n\t\tbottomRight: 'â†–',\n\t\tright: 'â†'\n\t}}\n>\n\t<Text>Custom</Text>\n</Box>\n```\n\nSee example in [examples/borders](examples/borders/borders.tsx).\n\n##### borderColor\n\nType: `string`\n\nChange border color.\nA shorthand for setting `borderTopColor`, `borderRightColor`, `borderBottomColor`, and `borderLeftColor`.\n\n```jsx\n<Box borderStyle=\"round\" borderColor=\"green\">\n\t<Text>Green Rounded Box</Text>\n</Box>\n```\n\n<img src=\"media/box-borderColor.jpg\" width=\"228\">\n\n##### borderTopColor\n\nType: `string`\n\nChange top border color.\nAccepts the same values as [`color`](#color) in `<Text>` component.\n\n```jsx\n<Box borderStyle=\"round\" borderTopColor=\"green\">\n\t<Text>Hello world</Text>\n</Box>\n```\n\n##### borderRightColor\n\nType: `string`\n\nChange the right border color.\nAccepts the same values as [`color`](#color) in `<Text>` component.\n\n```jsx\n<Box borderStyle=\"round\" borderRightColor=\"green\">\n\t<Text>Hello world</Text>\n</Box>\n```\n\n##### borderBottomColor\n\nType: `string`\n\nChange the bottom border color.\nAccepts the same values as [`color`](#color) in `<Text>` component.\n\n```jsx\n<Box borderStyle=\"round\" borderBottomColor=\"green\">\n\t<Text>Hello world</Text>\n</Box>\n```\n\n##### borderLeftColor\n\nType: `string`\n\nChange the left border color.\nAccepts the same values as [`color`](#color) in `<Text>` component.\n\n```jsx\n<Box borderStyle=\"round\" borderLeftColor=\"green\">\n\t<Text>Hello world</Text>\n</Box>\n```\n\n##### borderDimColor\n\nType: `boolean`\\\nDefault: `false`\n\nDim the border color.\nA shorthand for setting `borderTopDimColor`, `borderBottomDimColor`, `borderLeftDimColor`, and `borderRightDimColor`.\n\n```jsx\n<Box borderStyle=\"round\" borderDimColor>\n\t<Text>Hello world</Text>\n</Box>\n```\n\n##### borderTopDimColor\n\nType: `boolean`\\\nDefault: `false`\n\nDim the top border color.\n\n```jsx\n<Box borderStyle=\"round\" borderTopDimColor>\n\t<Text>Hello world</Text>\n</Box>\n```\n\n##### borderBottomDimColor\n\nType: `boolean`\\\nDefault: `false`\n\nDim the bottom border color.\n\n```jsx\n<Box borderStyle=\"round\" borderBottomDimColor>\n\t<Text>Hello world</Text>\n</Box>\n```\n\n##### borderLeftDimColor\n\nType: `boolean`\\\nDefault: `false`\n\nDim the left border color.\n\n```jsx\n<Box borderStyle=\"round\" borderLeftDimColor>\n\t<Text>Hello world</Text>\n</Box>\n```\n\n##### borderRightDimColor\n\nType: `boolean`\\\nDefault: `false`\n\nDim the right border color.\n\n```jsx\n<Box borderStyle=\"round\" borderRightDimColor>\n\t<Text>Hello world</Text>\n</Box>\n```\n\n##### borderTop\n\nType: `boolean`\\\nDefault: `true`\n\nDetermines whether the top border is visible.\n\n##### borderRight\n\nType: `boolean`\\\nDefault: `true`\n\nDetermines whether the right border is visible.\n\n##### borderBottom\n\nType: `boolean`\\\nDefault: `true`\n\nDetermines whether the bottom border is visible.\n\n##### borderLeft\n\nType: `boolean`\\\nDefault: `true`\n\nDetermines whether the left border is visible.\n\n#### Background\n\n##### backgroundColor\n\nType: `string`\n\nBackground color for the element.\n\nAccepts the same values as [`color`](#color) in the `<Text>` component.\n\n```jsx\n<Box flexDirection=\"column\">\n\t<Box backgroundColor=\"red\" width={20} height={5} alignSelf=\"flex-start\">\n\t\t<Text>Red background</Text>\n\t</Box>\n\n\t<Box backgroundColor=\"#FF8800\" width={20} height={3} marginTop={1} alignSelf=\"flex-start\">\n\t\t<Text>Orange background</Text>\n\t</Box>\n\n\t<Box backgroundColor=\"rgb(0, 255, 0)\" width={20} height={3} marginTop={1} alignSelf=\"flex-start\">\n\t\t<Text>Green background</Text>\n\t</Box>\n</Box>\n```\n\nThe background color fills the entire `<Box>` area and is inherited by child `<Text>` components unless they specify their own `backgroundColor`.\n\n```jsx\n<Box backgroundColor=\"blue\" alignSelf=\"flex-start\">\n\t<Text>Blue inherited </Text>\n\t<Text backgroundColor=\"yellow\">Yellow override </Text>\n\t<Text>Blue inherited again</Text>\n</Box>\n```\n\nBackground colors work with borders and padding:\n\n```jsx\n<Box backgroundColor=\"cyan\" borderStyle=\"round\" padding={1} alignSelf=\"flex-start\">\n\t<Text>Background with border and padding</Text>\n</Box>\n```\n\nSee example in [examples/box-backgrounds](examples/box-backgrounds/box-backgrounds.tsx).\n\n### `<Newline>`\n\nAdds one or more newline (`\\n`) characters.\nMust be used within `<Text>` components.\n\n#### count\n\nType: `number`\\\nDefault: `1`\n\nNumber of newlines to insert.\n\n```jsx\nimport {render, Text, Newline} from 'ink';\n\nconst Example = () => (\n\t<Text>\n\t\t<Text color=\"green\">Hello</Text>\n\t\t<Newline />\n\t\t<Text color=\"red\">World</Text>\n\t</Text>\n);\n\nrender(<Example />);\n```\n\nOutput:\n\n```\nHello\nWorld\n```\n\n### `<Spacer>`\n\nA flexible space that expands along the major axis of its containing layout.\nIt's useful as a shortcut for filling all the available space between elements.\n\nFor example, using `<Spacer>` in a `<Box>` with default flex direction (`row`) will position \"Left\" on the left side and will push \"Right\" to the right side.\n\n```jsx\nimport {render, Box, Text, Spacer} from 'ink';\n\nconst Example = () => (\n\t<Box>\n\t\t<Text>Left</Text>\n\t\t<Spacer />\n\t\t<Text>Right</Text>\n\t</Box>\n);\n\nrender(<Example />);\n```\n\nIn a vertical flex direction (`column`), it will position \"Top\" at the top of the container and push \"Bottom\" to the bottom.\nNote that the container needs to be tall enough to see this in effect.\n\n```jsx\nimport {render, Box, Text, Spacer} from 'ink';\n\nconst Example = () => (\n\t<Box flexDirection=\"column\" height={10}>\n\t\t<Text>Top</Text>\n\t\t<Spacer />\n\t\t<Text>Bottom</Text>\n\t</Box>\n);\n\nrender(<Example />);\n```\n\n### `<Static>`\n\n`<Static>` component permanently renders its output above everything else.\nIt's useful for displaying activity like completed tasks or logs - things that\ndon't change after they're rendered (hence the name \"Static\").\n\nIt's preferred to use `<Static>` for use cases like these when you can't know\nor control the number of items that need to be rendered.\n\nFor example, [Tap](https://github.com/tapjs/node-tap) uses `<Static>` to display\na list of completed tests. [Gatsby](https://github.com/gatsbyjs/gatsby) uses it\nto display a list of generated pages while still displaying a live progress bar.\n\n```jsx\nimport React, {useState, useEffect} from 'react';\nimport {render, Static, Box, Text} from 'ink';\n\nconst Example = () => {\n\tconst [tests, setTests] = useState([]);\n\n\tuseEffect(() => {\n\t\tlet completedTests = 0;\n\t\tlet timer;\n\n\t\tconst run = () => {\n\t\t\t// Fake 10 completed tests\n\t\t\tif (completedTests++ < 10) {\n\t\t\t\tsetTests(previousTests => [\n\t\t\t\t\t...previousTests,\n\t\t\t\t\t{\n\t\t\t\t\t\tid: previousTests.length,\n\t\t\t\t\t\ttitle: `Test #${previousTests.length + 1}`\n\t\t\t\t\t}\n\t\t\t\t]);\n\n\t\t\t\ttimer = setTimeout(run, 100);\n\t\t\t}\n\t\t};\n\n\t\trun();\n\n\t\treturn () => {\n\t\t\tclearTimeout(timer);\n\t\t};\n\t}, []);\n\n\treturn (\n\t\t<>\n\t\t\t{/* This part will be rendered once to the terminal */}\n\t\t\t<Static items={tests}>\n\t\t\t\t{test => (\n\t\t\t\t\t<Box key={test.id}>\n\t\t\t\t\t\t<Text color=\"green\">âœ” {test.title}</Text>\n\t\t\t\t\t</Box>\n\t\t\t\t)}\n\t\t\t</Static>\n\n\t\t\t{/* This part keeps updating as state changes */}\n\t\t\t<Box marginTop={1}>\n\t\t\t\t<Text dimColor>Completed tests: {tests.length}</Text>\n\t\t\t</Box>\n\t\t</>\n\t);\n};\n\nrender(<Example />);\n```\n\n**Note:** `<Static>` only renders new items in the `items` prop and ignores items\nthat were previously rendered. This means that when you add new items to the `items`\narray, changes you make to previous items will not trigger a rerender.\n\nSee [examples/static](examples/static/static.tsx) for an example usage of `<Static>` component.\n\n#### items\n\nType: `Array`\n\nArray of items of any type to render using the function you pass as a component child.\n\n#### style\n\nType: `object`\n\nStyles to apply to a container of child elements.\nSee [`<Box>`](#box) for supported properties.\n\n```jsx\n<Static items={...} style={{padding: 1}}>\n\t{...}\n</Static>\n```\n\n#### children(item)\n\nType: `Function`\n\nFunction that is called to render every item in the `items` array.\nThe first argument is the item itself, and the second argument is the index of that item in the\n`items` array.\n\nNote that a `key` must be assigned to the root component.\n\n```jsx\n<Static items={['a', 'b', 'c']}>\n\t{(item, index) => {\n\t\t// This function is called for every item in ['a', 'b', 'c']\n\t\t// `item` is 'a', 'b', 'c'\n\t\t// `index` is 0, 1, 2\n\t\treturn (\n\t\t\t<Box key={index}>\n\t\t\t\t<Text>Item: {item}</Text>\n\t\t\t</Box>\n\t\t);\n\t}}\n</Static>\n```\n\n### `<Transform>`\n\nTransform a string representation of React components before they're written to output.\nFor example, you might want to apply a [gradient to text](https://github.com/sindresorhus/ink-gradient), [add a clickable link](https://github.com/sindresorhus/ink-link), or [create some text effects](https://github.com/sindresorhus/ink-big-text).\nThese use cases can't accept React nodes as input; they expect a string.\nThat's what the `<Transform>` component does: it gives you an output string of its child components and lets you transform it in any way.\n\n**Note:** `<Transform>` must be applied only to `<Text>` children components and shouldn't change the dimensions of the output; otherwise, the layout will be incorrect.\n\n```jsx\nimport {render, Transform} from 'ink';\n\nconst Example = () => (\n\t<Transform transform={output => output.toUpperCase()}>\n\t\t<Text>Hello World</Text>\n\t</Transform>\n);\n\nrender(<Example />);\n```\n\nSince the `transform` function converts all characters to uppercase, the final output rendered to the terminal will be \"HELLO WORLD\", not \"Hello World\".\n\nWhen the output wraps to multiple lines, it can be helpful to know which line is being processed.\n\nFor example, to implement a hanging indent component, you can indent all the lines except for the first.\n\n```jsx\nimport {render, Transform} from 'ink';\n\nconst HangingIndent = ({content, indent = 4, children, ...props}) => (\n\t<Transform\n\t\ttransform={(line, index) =>\n\t\t\tindex === 0 ? line : ' '.repeat(indent) + line\n\t\t}\n\t\t{...props}\n\t>\n\t\t{children}\n\t</Transform>\n);\n\nconst text =\n\t'WHEN I WROTE the following pages, or rather the bulk of them, ' +\n\t'I lived alone, in the woods, a mile from any neighbor, in a ' +\n\t'house which I had built myself, on the shore of Walden Pond, ' +\n\t'in Concord, Massachusetts, and earned my living by the labor ' +\n\t'of my hands only. I lived there two years and two months. At ' +\n\t'present I am a sojourner in civilized life again.';\n\n// Other text properties are allowed as well\nrender(\n\t<HangingIndent bold dimColor indent={4}>\n\t\t{text}\n\t</HangingIndent>\n);\n```\n\n#### transform(outputLine, index)\n\nType: `Function`\n\nFunction that transforms children output.\nIt accepts children and must return transformed children as well.\n\n##### children\n\nType: `string`\n\nOutput of child components.\n\n##### index\n\nType: `number`\n\nThe zero-indexed line number of the line that's currently being transformed.\n\n## Hooks\n\n### useInput(inputHandler, options?)\n\nThis hook is used for handling user input.\nIt's a more convenient alternative to using `useStdin` and listening for `data` events.\nThe callback you pass to `useInput` is called for each character when the user enters any input.\nHowever, if the user pastes text and it's more than one character, the callback will be called only once, and the whole string will be passed as `input`.\nYou can find a full example of using `useInput` at [examples/use-input](examples/use-input/use-input.tsx).\n\n```jsx\nimport {useInput} from 'ink';\n\nconst UserInput = () => {\n\tuseInput((input, key) => {\n\t\tif (input === 'q') {\n\t\t\t// Exit program\n\t\t}\n\n\t\tif (key.leftArrow) {\n\t\t\t// Left arrow key pressed\n\t\t}\n\t});\n\n\treturn â€¦\n};\n```\n\n#### inputHandler(input, key)\n\nType: `Function`\n\nThe handler function that you pass to `useInput` receives two arguments:\n\n##### input\n\nType: `string`\n\nThe input that the program received.\n\n##### key\n\nType: `object`\n\nHandy information about a key that was pressed.\n\n###### key.leftArrow\n\n###### key.rightArrow\n\n###### key.upArrow\n\n###### key.downArrow\n\nType: `boolean`\\\nDefault: `false`\n\nIf an arrow key was pressed, the corresponding property will be `true`.\nFor example, if the user presses the left arrow key, `key.leftArrow` equals `true`.\n\n###### key.return\n\nType: `boolean`\\\nDefault: `false`\n\nReturn (Enter) key was pressed.\n\n###### key.escape\n\nType: `boolean`\\\nDefault: `false`\n\nEscape key was pressed.\n\n###### key.ctrl\n\nType: `boolean`\\\nDefault: `false`\n\nCtrl key was pressed.\n\n###### key.shift\n\nType: `boolean`\\\nDefault: `false`\n\nShift key was pressed.\n\n###### key.tab\n\nType: `boolean`\\\nDefault: `false`\n\nTab key was pressed.\n\n###### key.backspace\n\nType: `boolean`\\\nDefault: `false`\n\nBackspace key was pressed.\n\n###### key.delete\n\nType: `boolean`\\\nDefault: `false`\n\nDelete key was pressed.\n\n###### key.pageDown\n\n###### key.pageUp\n\nType: `boolean`\\\nDefault: `false`\n\nIf the Page Up or Page Down key was pressed, the corresponding property will be `true`.\nFor example, if the user presses Page Down, `key.pageDown` equals `true`.\n\n###### key.meta\n\nType: `boolean`\\\nDefault: `false`\n\n[Meta key](https://en.wikipedia.org/wiki/Meta_key) was pressed.\n\n#### options\n\nType: `object`\n\n##### isActive\n\nType: `boolean`\\\nDefault: `true`\n\nEnable or disable capturing of user input.\nUseful when there are multiple `useInput` hooks used at once to avoid handling the same input several times.\n\n### useApp()\n\n`useApp` is a React hook that exposes a method to manually exit the app (unmount).\n\n#### exit(error?)\n\nType: `Function`\n\nExit (unmount) the whole Ink app.\n\n##### error\n\nType: `Error`\n\nOptional error. If passed, [`waitUntilExit`](waituntilexit) will reject with that error.\n\n```js\nimport {useApp} from 'ink';\n\nconst Example = () => {\n\tconst {exit} = useApp();\n\n\t// Exit the app after 5 seconds\n\tuseEffect(() => {\n\t\tsetTimeout(() => {\n\t\t\texit();\n\t\t}, 5000);\n\t}, []);\n\n\treturn â€¦\n};\n```\n\n### useStdin()\n\n`useStdin` is a React hook that exposes the stdin stream.\n\n#### stdin\n\nType: `stream.Readable`\\\nDefault: `process.stdin`\n\nThe stdin stream passed to `render()` in `options.stdin`, or `process.stdin` by default.\nUseful if your app needs to handle user input.\n\n```js\nimport {useStdin} from 'ink';\n\nconst Example = () => {\n\tconst {stdin} = useStdin();\n\n\treturn â€¦\n};\n```\n\n#### isRawModeSupported\n\nType: `boolean`\n\nA boolean flag determining if the current `stdin` supports `setRawMode`.\nA component using `setRawMode` might want to use `isRawModeSupported` to nicely fall back in environments where raw mode is not supported.\n\n```jsx\nimport {useStdin} from 'ink';\n\nconst Example = () => {\n\tconst {isRawModeSupported} = useStdin();\n\n\treturn isRawModeSupported ? (\n\t\t<MyInputComponent />\n\t) : (\n\t\t<MyComponentThatDoesntUseInput />\n\t);\n};\n```\n\n#### setRawMode(isRawModeEnabled)\n\nType: `function`\n\n##### isRawModeEnabled\n\nType: `boolean`\n\nSee [`setRawMode`](https://nodejs.org/api/tty.html#tty_readstream_setrawmode_mode).\nInk exposes this function to be able to handle <kbd>Ctrl</kbd>+<kbd>C</kbd>, that's why you should use Ink's `setRawMode` instead of `process.stdin.setRawMode`.\n\n**Warning:** This function will throw unless the current `stdin` supports `setRawMode`. Use [`isRawModeSupported`](#israwmodesupported) to detect `setRawMode` support.\n\n```js\nimport {useStdin} from 'ink';\n\nconst Example = () => {\n\tconst {setRawMode} = useStdin();\n\n\tuseEffect(() => {\n\t\tsetRawMode(true);\n\n\t\treturn () => {\n\t\t\tsetRawMode(false);\n\t\t};\n\t});\n\n\treturn â€¦\n};\n```\n\n### useStdout()\n\n`useStdout` is a React hook that exposes the stdout stream where Ink renders your app.\n\n#### stdout\n\nType: `stream.Writable`\\\nDefault: `process.stdout`\n\n```js\nimport {useStdout} from 'ink';\n\nconst Example = () => {\n\tconst {stdout} = useStdout();\n\n\treturn â€¦\n};\n```\n\n#### write(data)\n\nWrite any string to stdout while preserving Ink's output.\nIt's useful when you want to display external information outside of Ink's rendering and ensure there's no conflict between the two.\nIt's similar to `<Static>`, except it can't accept components; it only works with strings.\n\n##### data\n\nType: `string`\n\nData to write to stdout.\n\n```js\nimport {useStdout} from 'ink';\n\nconst Example = () => {\n\tconst {write} = useStdout();\n\n\tuseEffect(() => {\n\t\t// Write a single message to stdout, above Ink's output\n\t\twrite('Hello from Ink to stdout\\n');\n\t}, []);\n\n\treturn â€¦\n};\n```\n\nSee additional usage example in [examples/use-stdout](examples/use-stdout/use-stdout.tsx).\n\n### useStderr()\n\n`useStderr` is a React hook that exposes the stderr stream.\n\n#### stderr\n\nType: `stream.Writable`\\\nDefault: `process.stderr`\n\nStderr stream.\n\n```js\nimport {useStderr} from 'ink';\n\nconst Example = () => {\n\tconst {stderr} = useStderr();\n\n\treturn â€¦\n};\n```\n\n#### write(data)\n\nWrite any string to stderr while preserving Ink's output.\n\nIt's useful when you want to display external information outside of Ink's rendering and ensure there's no conflict between the two.\nIt's similar to `<Static>`, except it can't accept components; it only works with strings.\n\n##### data\n\nType: `string`\n\nData to write to stderr.\n\n```js\nimport {useStderr} from 'ink';\n\nconst Example = () => {\n\tconst {write} = useStderr();\n\n\tuseEffect(() => {\n\t\t// Write a single message to stderr, above Ink's output\n\t\twrite('Hello from Ink to stderr\\n');\n\t}, []);\n\n\treturn â€¦\n};\n```\n\n### useFocus(options?)\n\nA component that uses the `useFocus` hook becomes \"focusable\" to Ink, so when the user presses <kbd>Tab</kbd>, Ink will switch focus to this component.\nIf there are multiple components that execute the `useFocus` hook, focus will be given to them in the order in which these components are rendered.\nThis hook returns an object with an `isFocused` boolean property, which determines whether this component is focused.\n\n#### options\n\n##### autoFocus\n\nType: `boolean`\\\nDefault: `false`\n\nAuto-focus this component if there's no active (focused) component right now.\n\n##### isActive\n\nType: `boolean`\\\nDefault: `true`\n\nEnable or disable this component's focus, while still maintaining its position in the list of focusable components.\nThis is useful for inputs that are temporarily disabled.\n\n##### id\n\nType: `string`\\\nRequired: `false`\n\nSet a component's focus ID, which can be used to programmatically focus the component. This is useful for large interfaces with many focusable elements to avoid having to cycle through all of them.\n\n```jsx\nimport {render, useFocus, Text} from 'ink';\n\nconst Example = () => {\n\tconst {isFocused} = useFocus();\n\n\treturn <Text>{isFocused ? 'I am focused' : 'I am not focused'}</Text>;\n};\n\nrender(<Example />);\n```\n\nSee example in [examples/use-focus](examples/use-focus/use-focus.tsx) and [examples/use-focus-with-id](examples/use-focus-with-id/use-focus-with-id.tsx).\n\n### useFocusManager()\n\nThis hook exposes methods to enable or disable focus management for all components or manually switch focus to the next or previous components.\n\n#### enableFocus()\n\nEnable focus management for all components.\n\n**Note:** You don't need to call this method manually unless you've disabled focus management. Focus management is enabled by default.\n\n```js\nimport {useFocusManager} from 'ink';\n\nconst Example = () => {\n\tconst {enableFocus} = useFocusManager();\n\n\tuseEffect(() => {\n\t\tenableFocus();\n\t}, []);\n\n\treturn â€¦\n};\n```\n\n#### disableFocus()\n\nDisable focus management for all components.\nThe currently active component (if there's one) will lose its focus.\n\n```js\nimport {useFocusManager} from 'ink';\n\nconst Example = () => {\n\tconst {disableFocus} = useFocusManager();\n\n\tuseEffect(() => {\n\t\tdisableFocus();\n\t}, []);\n\n\treturn â€¦\n};\n```\n\n#### focusNext()\n\nSwitch focus to the next focusable component.\nIf there's no active component right now, focus will be given to the first focusable component.\nIf the active component is the last in the list of focusable components, focus will be switched to the first focusable component.\n\n**Note:** Ink calls this method when user presses <kbd>Tab</kbd>.\n\n```js\nimport {useFocusManager} from 'ink';\n\nconst Example = () => {\n\tconst {focusNext} = useFocusManager();\n\n\tuseEffect(() => {\n\t\tfocusNext();\n\t}, []);\n\n\treturn â€¦\n};\n```\n\n#### focusPrevious()\n\nSwitch focus to the previous focusable component.\nIf there's no active component right now, focus will be given to the first focusable component.\nIf the active component is the first in the list of focusable components, focus will be switched to the last focusable component.\n\n**Note:** Ink calls this method when user presses <kbd>Shift</kbd>+<kbd>Tab</kbd>.\n\n```js\nimport {useFocusManager} from 'ink';\n\nconst Example = () => {\n\tconst {focusPrevious} = useFocusManager();\n\n\tuseEffect(() => {\n\t\tfocusPrevious();\n\t}, []);\n\n\treturn â€¦\n};\n```\n\n#### focus(id)\n\n##### id\n\nType: `string`\n\nSwitch focus to the component with the given [`id`](#id).\nIf there's no component with that ID, focus will be given to the next focusable component.\n\n```js\nimport {useFocusManager, useInput} from 'ink';\n\nconst Example = () => {\n\tconst {focus} = useFocusManager();\n\n\tuseInput(input => {\n\t\tif (input === 's') {\n\t\t\t// Focus the component with focus ID 'someId'\n\t\t\tfocus('someId');\n\t\t}\n\t});\n\n\treturn â€¦\n};\n```\n\n### useIsScreenReaderEnabled()\n\nReturns whether a screen reader is enabled. This is useful when you want to render different output for screen readers.\n\n```jsx\nimport {useIsScreenReaderEnabled, Text} from 'ink';\n\nconst Example = () => {\n\tconst isScreenReaderEnabled = useIsScreenReaderEnabled();\n\n\treturn (\n\t\t<Text>\n\t\t\t{isScreenReaderEnabled\n\t\t\t\t? 'Screen reader is enabled'\n\t\t\t\t: 'Screen reader is disabled'}\n\t\t</Text>\n\t);\n};\n```\n\n## API\n\n#### render(tree, options?)\n\nReturns: [`Instance`](#instance)\n\nMount a component and render the output.\n\n##### tree\n\nType: `ReactElement`\n\n##### options\n\nType: `object`\n\n###### stdout\n\nType: `stream.Writable`\\\nDefault: `process.stdout`\n\nOutput stream where the app will be rendered.\n\n###### stdin\n\nType: `stream.Readable`\\\nDefault: `process.stdin`\n\nInput stream where app will listen for input.\n\n###### stderr\n\nType: `stream.Writable`\\\nDefault: `process.stderr`\n\nError stream.\n\n###### exitOnCtrlC\n\nType: `boolean`\\\nDefault: `true`\n\nConfigure whether Ink should listen for Ctrl+C keyboard input and exit the app.\nThis is needed in case `process.stdin` is in [raw mode](https://nodejs.org/api/tty.html#tty_readstream_setrawmode_mode), because then Ctrl+C is ignored by default and the process is expected to handle it manually.\n\n###### patchConsole\n\nType: `boolean`\\\nDefault: `true`\n\nPatch console methods to ensure console output doesn't mix with Ink's output.\nWhen any of the `console.*` methods are called (like `console.log()`), Ink intercepts their output, clears the main output, renders output from the console method, and then rerenders the main output again.\nThat way, both are visible and don't overlap each other.\n\nThis functionality is powered by [patch-console](https://github.com/vadimdemedes/patch-console), so if you need to disable Ink's interception of output but want to build something custom, you can use that.\n\n###### onRender\n\nType: `({renderTime: number}) => void`\\\nDefault: `undefined`\n\nRuns the given callback after each render and re-render with a metrics object.\n\n###### debug\n\nType: `boolean`\\\nDefault: `false`\n\nIf `true`, each update will be rendered as separate output, without replacing the previous one.\n\n###### maxFps\n\nType: `number`\\\nDefault: `30`\n\nMaximum frames per second for render updates.\nThis controls how frequently the UI can update to prevent excessive re-rendering.\nHigher values allow more frequent updates but may impact performance.\nSetting it to a lower value may be useful for components that update very frequently, to reduce CPU usage.\n\n###### incrementalRendering\n\nType: `boolean`\\\nDefault: `false`\n\nEnable incremental rendering mode which only updates changed lines instead of redrawing the entire output.\nThis can reduce flickering and improve performance for frequently updating UIs.\n\n#### Instance\n\nThis is the object that `render()` returns.\n\n##### rerender(tree)\n\nReplace the previous root node with a new one or update the props of the current root node.\n\n###### tree\n\nType: `ReactElement`\n\n```jsx\n// Update props of the root node\nconst {rerender} = render(<Counter count={1} />);\nrerender(<Counter count={2} />);\n\n// Replace root node\nconst {rerender} = render(<OldCounter />);\nrerender(<NewCounter />);\n```\n\n##### unmount()\n\nManually unmount the whole Ink app.\n\n```jsx\nconst {unmount} = render(<MyApp />);\nunmount();\n```\n\n##### waitUntilExit()\n\nReturns a promise that resolves when the app is unmounted.\n\n```jsx\nconst {unmount, waitUntilExit} = render(<MyApp />);\n\nsetTimeout(unmount, 1000);\n\nawait waitUntilExit(); // resolves after `unmount()` is called\n```\n\n##### clear()\n\nClear output.\n\n```jsx\nconst {clear} = render(<MyApp />);\nclear();\n```\n\n#### measureElement(ref)\n\nMeasure the dimensions of a particular `<Box>` element.\nReturns an object with `width` and `height` properties.\nThis function is useful when your component needs to know the amount of available space it has. You can use it when you need to change the layout based on the length of its content.\n\n**Note:** `measureElement()` returns correct results only after the initial render, when the layout has been calculated. Until then, `width` and `height` equal zero. It's recommended to call `measureElement()` in a `useEffect` hook, which fires after the component has rendered.\n\n##### ref\n\nType: `MutableRef`\n\nA reference to a `<Box>` element captured with the `ref` property.\nSee [Refs](https://reactjs.org/docs/refs-and-the-dom.html) for more information on how to capture references.\n\n```jsx\nimport {render, measureElement, Box, Text} from 'ink';\n\nconst Example = () => {\n\tconst ref = useRef();\n\n\tuseEffect(() => {\n\t\tconst {width, height} = measureElement(ref.current);\n\t\t// width = 100, height = 1\n\t}, []);\n\n\treturn (\n\t\t<Box width={100}>\n\t\t\t<Box ref={ref}>\n\t\t\t\t<Text>This box will stretch to 100 width</Text>\n\t\t\t</Box>\n\t\t</Box>\n\t);\n};\n\nrender(<Example />);\n```\n\n## Testing\n\nInk components are simple to test with [ink-testing-library](https://github.com/vadimdemedes/ink-testing-library).\nHere's a simple example that checks how the component is rendered:\n\n```jsx\nimport React from 'react';\nimport {Text} from 'ink';\nimport {render} from 'ink-testing-library';\n\nconst Test = () => <Text>Hello World</Text>;\nconst {lastFrame} = render(<Test />);\n\nlastFrame() === 'Hello World'; //=> true\n```\n\nCheck out [ink-testing-library](https://github.com/vadimdemedes/ink-testing-library) for more examples and full documentation.\n\n## Using React Devtools\n\n![](media/devtools.jpg)\n\nInk supports [React Devtools](https://github.com/facebook/react/tree/master/packages/react-devtools) out of the box. To enable integration with React Devtools in your Ink-based CLI, first ensure you have installed the optional `react-devtools-core` dependency, and then run your app with the `DEV=true` environment variable:\n\n```sh\nDEV=true my-cli\n```\n\nThen, start React Devtools itself:\n\n```sh\nnpx react-devtools\n```\n\nAfter it starts, you should see the component tree of your CLI.\nYou can even inspect and change the props of components, and see the results immediately in the CLI, without restarting it.\n\n**Note**: You must manually quit your CLI via <kbd>Ctrl</kbd>+<kbd>C</kbd> after you're done testing.\n\n## Screen Reader Support\n\nInk has basic support for screen readers.\n\nTo enable it, you can either pass the `isScreenReaderEnabled` option to the `render` function or set the `INK_SCREEN_READER` environment variable to `true`.\n\nInk implements a small subset of functionality from the [ARIA specification](https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA).\n\n```jsx\nrender(<MyApp />, {isScreenReaderEnabled: true});\n```\n\nWhen screen reader support is enabled, Ink will try its best to generate a screen-reader-friendly output.\n\nFor example, for this code:\n\n```jsx\n<Box aria-role=\"checkbox\" aria-state={{checked: true}}>\n\t<Text>Accept terms and conditions</Text>\n</Box>\n```\n\nInk will generate the following output for screen readers:\n\n```\n(checked) checkbox: Accept terms and conditions\n```\n\nYou can also provide a custom label for screen readers if you want to render something different for them.\n\nFor example, if you are building a progress bar, you can use `aria-label` to provide a more descriptive label for screen readers.\n\n```jsx\n<Box>\n\t<Box width=\"50%\" height={1} backgroundColor=\"green\" />\n\t<Text aria-label=\"Progress: 50%\">50%</Text>\n</Box>\n```\n\nIn the example above, the screen reader will read \"Progress: 50%\" instead of \"50%\".\n\n### `aria-label`\n\nType: `string`\n\nA label for the element for screen readers.\n\n### `aria-hidden`\n\nType: `boolean`\\\nDefault: `false`\n\nHide the element from screen readers.\n\n##### aria-role\n\nType: `string`\n\nThe role of the element.\n\nSupported values:\n- `button`\n- `checkbox`\n- `radio`\n- `radiogroup`\n- `list`\n- `listitem`\n- `menu`\n- `menuitem`\n- `progressbar`\n- `tab`\n- `tablist`\n- `timer`\n- `toolbar`\n- `table`\n\n##### aria-state\n\nType: `object`\n\nThe state of the element.\n\nSupported values:\n- `checked` (boolean)\n- `disabled` (boolean)\n- `expanded` (boolean)\n- `selected` (boolean)\n\n## Creating Components\n\nWhen building custom components, it's important to keep accessibility in mind. While Ink provides the building blocks, ensuring your components are accessible will make your CLIs usable by a wider audience.\n\n### General Principles\n\n- **Provide screen reader-friendly output:** Use the `useIsScreenReaderEnabled` hook to detect if a screen reader is active. You can then render more descriptive output for screen reader users.\n- **Leverage ARIA props:** For components that have a specific role (e.g., a checkbox or button), use the `aria-role`, `aria-state`, and `aria-label` props on `<Box>` and `<Text>` to provide semantic meaning to screen readers.\n\nFor a practical example of building an accessible component, see the [ARIA example](/examples/aria/aria.tsx).\n\n## Useful Components\n\n- [ink-text-input](https://github.com/vadimdemedes/ink-text-input) - Text input.\n- [ink-spinner](https://github.com/vadimdemedes/ink-spinner) - Spinner.\n- [ink-select-input](https://github.com/vadimdemedes/ink-select-input) - Select (dropdown) input.\n- [ink-link](https://github.com/sindresorhus/ink-link) - Link.\n- [ink-gradient](https://github.com/sindresorhus/ink-gradient) - Gradient color.\n- [ink-big-text](https://github.com/sindresorhus/ink-big-text) - Awesome text.\n- [ink-picture](https://github.com/endernoke/ink-picture) - Display images.\n- [ink-tab](https://github.com/jdeniau/ink-tab) - Tab.\n- [ink-color-pipe](https://github.com/LitoMore/ink-color-pipe) - Create color text with simpler style strings.\n- [ink-multi-select](https://github.com/karaggeorge/ink-multi-select) - Select one or more values from a list\n- [ink-divider](https://github.com/JureSotosek/ink-divider) - A divider.\n- [ink-progress-bar](https://github.com/brigand/ink-progress-bar) - Progress bar.\n- [ink-table](https://github.com/maticzav/ink-table) - Table.\n- [ink-ascii](https://github.com/hexrcs/ink-ascii) - Awesome text component with more font choices, based on Figlet.\n- [ink-markdown](https://github.com/cameronhunter/ink-markdown) - Render syntax highlighted Markdown.\n- [ink-quicksearch-input](https://github.com/Eximchain/ink-quicksearch-input) - Select component with fast, quicksearch-like navigation.\n- [ink-confirm-input](https://github.com/kevva/ink-confirm-input) - Yes/No confirmation input.\n- [ink-syntax-highlight](https://github.com/vsashyn/ink-syntax-highlight) - Code syntax highlighting.\n- [ink-form](https://github.com/lukasbach/ink-form) - Form.\n- [ink-task-list](https://github.com/privatenumber/ink-task-list) - Task list.\n- [ink-spawn](https://github.com/kraenhansen/ink-spawn) - Spawn child processes.\n- [ink-titled-box](https://github.com/mishieck/ink-titled-box) - Box with a title.\n- [ink-chart](https://github.com/pppp606/ink-chart) - Sparkline and bar chart.\n- [ink-scroll-view](https://github.com/ByteLandTechnology/ink-scroll-view) - Scroll container.\n- [ink-scroll-list](https://github.com/ByteLandTechnology/ink-scroll-list) - Scrollable list.\n- [ink-stepper](https://github.com/archcorsair/ink-stepper) - Step-by-step wizard.\n- [ink-virtual-list](https://github.com/archcorsair/ink-virtual-list) - Virtualized list that renders only visible items for performance.\n\n## Useful Hooks\n\n- [ink-use-stdout-dimensions](https://github.com/cameronhunter/ink-monorepo/tree/master/packages/ink-use-stdout-dimensions) - Subscribe to stdout dimensions.\n\n## Examples\n\nThe [`examples`](/examples) directory contains a set of real examples. You can run them with:\n\n```bash\nnpm run example examples/[example name]\n# e.g. npm run example examples/borders\n```\n\n- [Jest](examples/jest/jest.tsx) - Implementation of basic Jest UI.\n- [Counter](examples/counter/counter.tsx) - A simple counter that increments every 100ms.\n- [Form with validation](https://github.com/final-form/rff-cli-example) - Manage form state using [Final Form](https://github.com/final-form/final-form#-final-form).\n- [Borders](examples/borders/borders.tsx) - Add borders to the `<Box>` component.\n- [Suspense](examples/suspense/suspense.tsx) - Use React Suspense.\n- [Table](examples/table/table.tsx) - Renders a table with multiple columns and rows.\n- [Focus management](examples/use-focus/use-focus.tsx) - Use the `useFocus` hook to manage focus between components.\n- [User input](examples/use-input/use-input.tsx) - Listen for user input.\n- [Write to stdout](examples/use-stdout/use-stdout.tsx) - Write to stdout, bypassing main Ink output.\n- [Write to stderr](examples/use-stderr/use-stderr.tsx) - Write to stderr, bypassing main Ink output.\n- [Static](examples/static/static.tsx) - Use the `<Static>` component to render permanent output.\n- [Child process](examples/subprocess-output) - Renders output from a child process.\n\n## Maintainers\n\n- [Vadim Demedes](https://github.com/vadimdemedes)\n- [Sindre Sorhus](https://github.com/sindresorhus)\n",
      "stars_today": 44
    },
    {
      "id": 215654064,
      "name": "temporal",
      "full_name": "temporalio/temporal",
      "description": "Temporal service",
      "html_url": "https://github.com/temporalio/temporal",
      "stars": 17910,
      "forks": 1308,
      "language": "Go",
      "topics": [
        "cronjob-scheduler",
        "distributed-cron",
        "distributed-systems",
        "golang",
        "microservice-framework",
        "microservice-orchestration",
        "microservices-architecture",
        "orchestrator",
        "service-bus",
        "service-fabric",
        "workflow-automation",
        "workflow-engine",
        "workflow-management",
        "workflow-management-system",
        "workflows"
      ],
      "created_at": "2019-10-16T22:15:35Z",
      "updated_at": "2026-01-24T22:58:45Z",
      "pushed_at": "2026-01-24T16:11:54Z",
      "open_issues": 643,
      "owner": {
        "login": "temporalio",
        "avatar_url": "https://avatars.githubusercontent.com/u/56493103?v=4"
      },
      "readme": "<div class=\"title-block\" style=\"text-align: center;\" align=\"center\">\n\n# Temporalâ€”durable execution platform\n\n<p><img title=\"temporal logo\" src=\"https://avatars.githubusercontent.com/u/56493103?s=320\" width=\"320\" height=\"320\"></p>\n\n[![GitHub Release](https://img.shields.io/github/v/release/temporalio/temporal)](https://github.com/temporalio/temporal/releases/latest)\n[![GitHub License](https://img.shields.io/github/license/temporalio/temporal)](https://github.com/temporalio/temporal/blob/main/LICENSE)\n[![Code Coverage](https://img.shields.io/badge/codecov-report-blue)](https://app.codecov.io/gh/temporalio/temporal)\n[![Community](https://img.shields.io/static/v1?label=community&message=get%20help&color=informational)](https://community.temporal.io)\n[![Go Report Card](https://goreportcard.com/badge/github.com/temporalio/temporal)](https://goreportcard.com/report/github.com/temporalio/temporal)\n\n**[Introduction](#introduction) &nbsp;&nbsp;&bull;&nbsp;&nbsp;**\n**[Getting Started](#getting-started) &nbsp;&nbsp;&bull;&nbsp;&nbsp;**\n**[Contributing](#contributing) &nbsp;&nbsp;&bull;&nbsp;&nbsp;**\n**[Temporal Docs](https://docs.temporal.io/) &nbsp;&nbsp;&bull;&nbsp;&nbsp;**\n**[Temporal 101](https://learn.temporal.io/courses/temporal_101/)**\n\n</div>\n\n## Introduction\n\nTemporal is a durable execution platform that enables developers to build scalable applications without sacrificing productivity or reliability.\nThe Temporal server executes units of application logic called Workflows in a resilient manner that automatically handles intermittent failures, and retries failed operations.\n\nTemporal is a mature technology that originated as a fork of Uber's Cadence.\nIt is developed by [Temporal Technologies](https://temporal.io/), a startup by the creators of Cadence.\n\n[![image](https://github.com/temporalio/temporal/assets/251288/693d18b5-01de-4a3b-b47b-96347b84f610)](https://youtu.be/wIpz4ioK0gI 'Getting to know Temporal')\n\n## Getting Started\n\n### Download and Start Temporal Server Locally\n\nExecute the following commands to start a pre-built image along with all the dependencies.\n\n```bash\nbrew install temporal\ntemporal server start-dev\n```\n\nRefer to [Temporal CLI](https://docs.temporal.io/cli/#installation) documentation for more installation options.\n\n### Run the Samples\n\nClone or download samples for [Go](https://github.com/temporalio/samples-go) or [Java](https://github.com/temporalio/samples-java) and run them with the local Temporal server.\nWe have a number of [HelloWorld type scenarios](https://github.com/temporalio/samples-java#helloworld) available, as well as more advanced ones. Note that the sets of samples are currently different between Go and Java.\n\n### Use CLI\n\nUse [Temporal CLI](https://docs.temporal.io/cli/) to interact with the running Temporal server.\n\n```bash\ntemporal operator namespace list\ntemporal workflow list\n```\n\n### Use Temporal Web UI\n\nTry [Temporal Web UI](https://docs.temporal.io/web-ui) by opening [http://localhost:8233](http://localhost:8233) for viewing your sample workflows executing on Temporal.\n\n## Repository\n\nThis repository contains the source code of the Temporal server. To implement Workflows, Activities and Workers, use one of the [supported languages](https://docs.temporal.io/dev-guide/).\n\n## Contributing\n\nWe'd love your help in making Temporal great.\n\nHelpful links to get started:\n\n- [work on or propose a new feature](https://github.com/temporalio/proposals)\n- [learn about the Temporal Server architecture](./docs/architecture/README.md)\n- [learn how to build and run the Temporal Server locally](./CONTRIBUTING.md)\n- [learn about Temporal Server testing tools and best practices](./docs/development/testing.md)\n- join the Temporal community [forum](https://community.temporal.io) and [Slack](https://t.mp/slack)\n\n## License\n\n[MIT License](https://github.com/temporalio/temporal/blob/main/LICENSE)\n",
      "stars_today": 43
    },
    {
      "id": 942771284,
      "name": "github-mcp-server",
      "full_name": "github/github-mcp-server",
      "description": "GitHub's official MCP Server",
      "html_url": "https://github.com/github/github-mcp-server",
      "stars": 26262,
      "forks": 3441,
      "language": "Go",
      "topics": [
        "github",
        "mcp",
        "mcp-server"
      ],
      "created_at": "2025-03-04T16:42:04Z",
      "updated_at": "2026-01-25T01:11:52Z",
      "pushed_at": "2026-01-25T00:08:52Z",
      "open_issues": 259,
      "owner": {
        "login": "github",
        "avatar_url": "https://avatars.githubusercontent.com/u/9919?v=4"
      },
      "readme": "[![Go Report Card](https://goreportcard.com/badge/github.com/github/github-mcp-server)](https://goreportcard.com/report/github.com/github/github-mcp-server)\n\n# GitHub MCP Server\n\nThe GitHub MCP Server connects AI tools directly to GitHub's platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code files, manage issues and PRs, analyze code, and automate workflows. All through natural language interactions.\n\n### Use Cases\n\n- Repository Management: Browse and query code, search files, analyze commits, and understand project structure across any repository you have access to.\n- Issue & PR Automation: Create, update, and manage issues and pull requests. Let AI help triage bugs, review code changes, and maintain project boards.\n- CI/CD & Workflow Intelligence: Monitor GitHub Actions workflow runs, analyze build failures, manage releases, and get insights into your development pipeline.\n- Code Analysis: Examine security findings, review Dependabot alerts, understand code patterns, and get comprehensive insights into your codebase.\n- Team Collaboration: Access discussions, manage notifications, analyze team activity, and streamline processes for your team.\n\nBuilt for developers who want to connect their AI tools to GitHub context and capabilities, from simple natural language queries to complex multi-step agent workflows.\n\n---\n\n## Remote GitHub MCP Server\n\n[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D) [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D&quality=insiders)\n\nThe remote GitHub MCP Server is hosted by GitHub and provides the easiest method for getting up and running. If your MCP host does not support remote MCP servers, don't worry! You can use the [local version of the GitHub MCP Server](https://github.com/github/github-mcp-server?tab=readme-ov-file#local-github-mcp-server) instead.\n\n### Prerequisites\n\n1. A compatible MCP host with remote server support (VS Code 1.101+, Claude Desktop, Cursor, Windsurf, etc.)\n2. Any applicable [policies enabled](https://github.com/github/github-mcp-server/blob/main/docs/policies-and-governance.md)\n\n### Install in VS Code\n\nFor quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start. Make sure you're using [VS Code 1.101](https://code.visualstudio.com/updates/v1_101) or [later](https://code.visualstudio.com/updates) for remote MCP and OAuth support.\n\nAlternatively, to manually configure VS Code, choose the appropriate JSON block from the examples below and add it to your host configuration:\n\n<table>\n<tr><th>Using OAuth</th><th>Using a GitHub PAT</th></tr>\n<tr><th align=left colspan=2>VS Code (version 1.101 or greater)</th></tr>\n<tr valign=top>\n<td>\n\n```json\n{\n  \"servers\": {\n    \"github\": {\n      \"type\": \"http\",\n      \"url\": \"https://api.githubcopilot.com/mcp/\"\n    }\n  }\n}\n```\n\n</td>\n<td>\n\n```json\n{\n  \"servers\": {\n    \"github\": {\n      \"type\": \"http\",\n      \"url\": \"https://api.githubcopilot.com/mcp/\",\n      \"headers\": {\n        \"Authorization\": \"Bearer ${input:github_mcp_pat}\"\n      }\n    }\n  },\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"github_mcp_pat\",\n      \"description\": \"GitHub Personal Access Token\",\n      \"password\": true\n    }\n  ]\n}\n```\n\n</td>\n</tr>\n</table>\n\n### Install in other MCP hosts\n\n- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot\n- **[Claude Applications](/docs/installation-guides/install-claude.md)** - Installation guide for Claude Desktop and Claude Code CLI\n- **[Codex](/docs/installation-guides/install-codex.md)** - Installation guide for Open AI Codex\n- **[Cursor](/docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE\n- **[Windsurf](/docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE\n- **[Rovo Dev CLI](/docs/installation-guides/install-rovo-dev-cli.md)** - Installation guide for Rovo Dev CLI\n\n> **Note:** Each MCP host application needs to configure a GitHub App or OAuth App to support remote access via OAuth. Any host application that supports remote MCP servers should support the remote GitHub server with PAT authentication. Configuration details and support levels vary by host. Make sure to refer to the host application's documentation for more info.\n\n### Configuration\n\n#### Toolset configuration\n\nSee [Remote Server Documentation](docs/remote-server.md) for full details on remote server configuration, toolsets, headers, and advanced usage. This file provides comprehensive instructions and examples for connecting, customizing, and installing the remote GitHub MCP Server in VS Code and other MCP hosts.\n\nWhen no toolsets are specified, [default toolsets](#default-toolset) are used.\n\n#### Insiders Mode\n\n> **Try new features early!** The remote server offers an insiders version with early access to new features and experimental tools.\n\n<table>\n<tr><th>Using URL Path</th><th>Using Header</th></tr>\n<tr valign=top>\n<td>\n\n```json\n{\n  \"servers\": {\n    \"github\": {\n      \"type\": \"http\",\n      \"url\": \"https://api.githubcopilot.com/mcp/insiders\"\n    }\n  }\n}\n```\n\n</td>\n<td>\n\n```json\n{\n  \"servers\": {\n    \"github\": {\n      \"type\": \"http\",\n      \"url\": \"https://api.githubcopilot.com/mcp/\",\n      \"headers\": {\n        \"X-MCP-Insiders\": \"true\"\n      }\n    }\n  }\n}\n```\n\n</td>\n</tr>\n</table>\n\nSee [Remote Server Documentation](docs/remote-server.md#insiders-mode) for more details and examples.\n\n#### GitHub Enterprise\n\n##### GitHub Enterprise Cloud with data residency (ghe.com)\n\nGitHub Enterprise Cloud can also make use of the remote server.\n\nExample for `https://octocorp.ghe.com` with GitHub PAT token:\n\n```\n{\n    ...\n    \"proxima-github\": {\n      \"type\": \"http\",\n      \"url\": \"https://copilot-api.octocorp.ghe.com/mcp\",\n      \"headers\": {\n        \"Authorization\": \"Bearer ${input:github_mcp_pat}\"\n      }\n    },\n    ...\n}\n```\n\n> **Note:** When using OAuth with GitHub Enterprise with VS Code and GitHub Copilot, you also need to configure your VS Code settings to point to your GitHub Enterprise instance - see [Authenticate from VS Code](https://docs.github.com/en/enterprise-cloud@latest/copilot/how-tos/configure-personal-settings/authenticate-to-ghecom)\n\n##### GitHub Enterprise Server\n\nGitHub Enterprise Server does not support remote server hosting. Please refer to [GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)](#github-enterprise-server-and-enterprise-cloud-with-data-residency-ghecom) from the local server configuration.\n\n---\n\n## Local GitHub MCP Server\n\n[![Install with Docker in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D) [![Install with Docker in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D&quality=insiders)\n\n### Prerequisites\n\n1. To run the server in a container, you will need to have [Docker](https://www.docker.com/) installed.\n2. Once Docker is installed, you will also need to ensure Docker is running. The Docker image is available at `ghcr.io/github/github-mcp-server`. The image is public; if you get errors on pull, you may have an expired token and need to `docker logout ghcr.io`.\n3. Lastly you will need to [Create a GitHub Personal Access Token](https://github.com/settings/personal-access-tokens/new).\nThe MCP server can use many of the GitHub APIs, so enable the permissions that you feel comfortable granting your AI tools (to learn more about access tokens, please check out the [documentation](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens)).\n\n<details><summary><b>Handling PATs Securely</b></summary>\n\n### Environment Variables (Recommended)\n\nTo keep your GitHub PAT secure and reusable across different MCP hosts:\n\n1. **Store your PAT in environment variables**\n\n   ```bash\n   export GITHUB_PAT=your_token_here\n   ```\n\n   Or create a `.env` file:\n\n   ```env\n   GITHUB_PAT=your_token_here\n   ```\n\n2. **Protect your `.env` file**\n\n   ```bash\n   # Add to .gitignore to prevent accidental commits\n   echo \".env\" >> .gitignore\n   ```\n\n3. **Reference the token in configurations**\n\n   ```bash\n   # CLI usage\n   claude mcp update github -e GITHUB_PERSONAL_ACCESS_TOKEN=$GITHUB_PAT\n\n   # In config files (where supported)\n   \"env\": {\n     \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"$GITHUB_PAT\"\n   }\n   ```\n\n> **Note**: Environment variable support varies by host app and IDE. Some applications (like Windsurf) require hardcoded tokens in config files.\n\n### Token Security Best Practices\n\n- **Minimum scopes**: Only grant necessary permissions\n  - `repo` - Repository operations\n  - `read:packages` - Docker image access\n  - `read:org` - Organization team access\n- **Separate tokens**: Use different PATs for different projects/environments\n- **Regular rotation**: Update tokens periodically\n- **Never commit**: Keep tokens out of version control\n- **File permissions**: Restrict access to config files containing tokens\n\n  ```bash\n  chmod 600 ~/.your-app/config.json\n  ```\n\n</details>\n\n### GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)\n\nThe flag `--gh-host` and the environment variable `GITHUB_HOST` can be used to set\nthe hostname for GitHub Enterprise Server or GitHub Enterprise Cloud with data residency.\n\n- For GitHub Enterprise Server, prefix the hostname with the `https://` URI scheme, as it otherwise defaults to `http://`, which GitHub Enterprise Server does not support.\n- For GitHub Enterprise Cloud with data residency, use `https://YOURSUBDOMAIN.ghe.com` as the hostname.\n\n``` json\n\"github\": {\n    \"command\": \"docker\",\n    \"args\": [\n    \"run\",\n    \"-i\",\n    \"--rm\",\n    \"-e\",\n    \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n    \"-e\",\n    \"GITHUB_HOST\",\n    \"ghcr.io/github/github-mcp-server\"\n    ],\n    \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"${input:github_token}\",\n        \"GITHUB_HOST\": \"https://<your GHES or ghe.com domain name>\"\n    }\n}\n```\n\n## Installation\n\n### Install in GitHub Copilot on VS Code\n\nFor quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start.\n\nMore about using MCP server tools in VS Code's [agent mode documentation](https://code.visualstudio.com/docs/copilot/chat/mcp-servers).\n\nInstall in GitHub Copilot on other IDEs (JetBrains, Visual Studio, Eclipse, etc.)\n\nAdd the following JSON block to your IDE's MCP settings.\n\n```json\n{\n  \"mcp\": {\n    \"inputs\": [\n      {\n        \"type\": \"promptString\",\n        \"id\": \"github_token\",\n        \"description\": \"GitHub Personal Access Token\",\n        \"password\": true\n      }\n    ],\n    \"servers\": {\n      \"github\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"-i\",\n          \"--rm\",\n          \"-e\",\n          \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n          \"ghcr.io/github/github-mcp-server\"\n        ],\n        \"env\": {\n          \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"${input:github_token}\"\n        }\n      }\n    }\n  }\n}\n```\n\nOptionally, you can add a similar example (i.e. without the mcp key) to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with other host applications that accept the same format.\n\n<details>\n<summary><b>Example JSON block without the MCP key included</b></summary>\n<br>\n\n```json\n{\n  \"inputs\": [\n    {\n      \"type\": \"promptString\",\n      \"id\": \"github_token\",\n      \"description\": \"GitHub Personal Access Token\",\n      \"password\": true\n    }\n  ],\n  \"servers\": {\n    \"github\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\",\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n        \"ghcr.io/github/github-mcp-server\"\n      ],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"${input:github_token}\"\n      }\n    }\n  }\n}\n```\n\n</details>\n\n### Install in Other MCP Hosts\n\nFor other MCP host applications, please refer to our installation guides:\n\n- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot\n- **[Claude Code & Claude Desktop](docs/installation-guides/install-claude.md)** - Installation guide for Claude Code and Claude Desktop\n- **[Cursor](docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE\n- **[Google Gemini CLI](docs/installation-guides/install-gemini-cli.md)** - Installation guide for Google Gemini CLI\n- **[Windsurf](docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE\n\nFor a complete overview of all installation options, see our **[Installation Guides Index](docs/installation-guides)**.\n\n> **Note:** Any host application that supports local MCP servers should be able to access the local GitHub MCP server. However, the specific configuration process, syntax and stability of the integration will vary by host application. While many may follow a similar format to the examples above, this is not guaranteed. Please refer to your host application's documentation for the correct MCP configuration syntax and setup process.\n\n### Build from source\n\nIf you don't have Docker, you can use `go build` to build the binary in the\n`cmd/github-mcp-server` directory, and use the `github-mcp-server stdio` command with the `GITHUB_PERSONAL_ACCESS_TOKEN` environment variable set to your token. To specify the output location of the build, use the `-o` flag. You should configure your server to use the built executable as its `command`. For example:\n\n```JSON\n{\n  \"mcp\": {\n    \"servers\": {\n      \"github\": {\n        \"command\": \"/path/to/github-mcp-server\",\n        \"args\": [\"stdio\"],\n        \"env\": {\n          \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<YOUR_TOKEN>\"\n        }\n      }\n    }\n  }\n}\n```\n\n### CLI utilities\n\nThe `github-mcp-server` binary includes a few CLI subcommands that are helpful for debugging and exploring the server.\n\n- `github-mcp-server tool-search \"<query>\"` searches tools by name, description, and input parameter names. Use `--max-results` to return more matches.\nExample (color output requires a TTY; use `docker run -t` (or `-it`) when running in Docker):\n```bash\ndocker run -it --rm ghcr.io/github/github-mcp-server tool-search \"issue\" --max-results 5\ngithub-mcp-server tool-search \"issue\" --max-results 5\n```\n\n## Tool Configuration\n\nThe GitHub MCP Server supports enabling or disabling specific groups of functionalities via the `--toolsets` flag. This allows you to control which GitHub API capabilities are available to your AI tools. Enabling only the toolsets that you need can help the LLM with tool choice and reduce the context size.\n\n_Toolsets are not limited to Tools. Relevant MCP Resources and Prompts are also included where applicable._\n\nWhen no toolsets are specified, [default toolsets](#default-toolset) are used.\n\n> **Looking for examples?** See the [Server Configuration Guide](./docs/server-configuration.md) for common recipes like minimal setups, read-only mode, and combining tools with toolsets.\n\n#### Specifying Toolsets\n\nTo specify toolsets you want available to the LLM, you can pass an allow-list in two ways:\n\n1. **Using Command Line Argument**:\n\n   ```bash\n   github-mcp-server --toolsets repos,issues,pull_requests,actions,code_security\n   ```\n\n2. **Using Environment Variable**:\n\n   ```bash\n   GITHUB_TOOLSETS=\"repos,issues,pull_requests,actions,code_security\" ./github-mcp-server\n   ```\n\nThe environment variable `GITHUB_TOOLSETS` takes precedence over the command line argument if both are provided.\n\n#### Specifying Individual Tools\n\nYou can also configure specific tools using the `--tools` flag. Tools can be used independently or combined with toolsets and dynamic toolsets discovery for fine-grained control.\n\n1. **Using Command Line Argument**:\n\n   ```bash\n   github-mcp-server --tools get_file_contents,issue_read,create_pull_request\n   ```\n\n2. **Using Environment Variable**:\n\n   ```bash\n   GITHUB_TOOLS=\"get_file_contents,issue_read,create_pull_request\" ./github-mcp-server\n   ```\n\n3. **Combining with Toolsets** (additive):\n\n   ```bash\n   github-mcp-server --toolsets repos,issues --tools get_gist\n   ```\n\n   This registers all tools from `repos` and `issues` toolsets, plus `get_gist`.\n\n4. **Combining with Dynamic Toolsets** (additive):\n\n   ```bash\n   github-mcp-server --tools get_file_contents --dynamic-toolsets\n   ```\n\n   This registers `get_file_contents` plus the dynamic toolset tools (`enable_toolset`, `list_available_toolsets`, `get_toolset_tools`).\n\n**Important Notes:**\n\n- Tools, toolsets, and dynamic toolsets can all be used together\n- Read-only mode takes priority: write tools are skipped if `--read-only` is set, even if explicitly requested via `--tools`\n- Tool names must match exactly (e.g., `get_file_contents`, not `getFileContents`). Invalid tool names will cause the server to fail at startup with an error message\n- When tools are renamed, old names are preserved as aliases for backward compatibility. See [Deprecated Tool Aliases](docs/deprecated-tool-aliases.md) for details.\n\n### Using Toolsets With Docker\n\nWhen using Docker, you can pass the toolsets as environment variables:\n\n```bash\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_TOOLSETS=\"repos,issues,pull_requests,actions,code_security\" \\\n  ghcr.io/github/github-mcp-server\n```\n\n### Using Tools With Docker\n\nWhen using Docker, you can pass specific tools as environment variables. You can also combine tools with toolsets:\n\n```bash\n# Tools only\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_TOOLS=\"get_file_contents,issue_read,create_pull_request\" \\\n  ghcr.io/github/github-mcp-server\n\n# Tools combined with toolsets (additive)\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_TOOLSETS=\"repos,issues\" \\\n  -e GITHUB_TOOLS=\"get_gist\" \\\n  ghcr.io/github/github-mcp-server\n```\n\n### Special toolsets\n\n#### \"all\" toolset\n\nThe special toolset `all` can be provided to enable all available toolsets regardless of any other configuration:\n\n```bash\n./github-mcp-server --toolsets all\n```\n\nOr using the environment variable:\n\n```bash\nGITHUB_TOOLSETS=\"all\" ./github-mcp-server\n```\n\n#### \"default\" toolset\n\nThe default toolset `default` is the configuration that gets passed to the server if no toolsets are specified.\n\nThe default configuration is:\n\n- context\n- repos\n- issues\n- pull_requests\n- users\n\nTo keep the default configuration and add additional toolsets:\n\n```bash\nGITHUB_TOOLSETS=\"default,stargazers\" ./github-mcp-server\n```\n\n### Insiders Mode\n\nThe local GitHub MCP Server offers an insiders version with early access to new features and experimental tools.\n\n1. **Using Command Line Argument**:\n\n   ```bash\n   ./github-mcp-server --insider-mode\n   ```\n\n2. **Using Environment Variable**:\n\n   ```bash\n   GITHUB_INSIDER_MODE=true ./github-mcp-server\n   ```\n\nWhen using Docker:\n\n```bash\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_INSIDER_MODE=true \\\n  ghcr.io/github/github-mcp-server\n```\n\n### Available Toolsets\n\nThe following sets of tools are available:\n\n<!-- START AUTOMATED TOOLSETS -->\n|     | Toolset                 | Description                                                   |\n| --- | ----------------------- | ------------------------------------------------------------- |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/person-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/person-light.png\"><img src=\"pkg/octicons/icons/person-light.png\" width=\"20\" height=\"20\" alt=\"person\"></picture> | `context`               | **Strongly recommended**: Tools that provide context about the current user and GitHub context you are operating in |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/workflow-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/workflow-light.png\"><img src=\"pkg/octicons/icons/workflow-light.png\" width=\"20\" height=\"20\" alt=\"workflow\"></picture> | `actions` | GitHub Actions workflows and CI/CD operations |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/codescan-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/codescan-light.png\"><img src=\"pkg/octicons/icons/codescan-light.png\" width=\"20\" height=\"20\" alt=\"codescan\"></picture> | `code_security` | Code security related tools, such as GitHub Code Scanning |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/dependabot-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/dependabot-light.png\"><img src=\"pkg/octicons/icons/dependabot-light.png\" width=\"20\" height=\"20\" alt=\"dependabot\"></picture> | `dependabot` | Dependabot tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/comment-discussion-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/comment-discussion-light.png\"><img src=\"pkg/octicons/icons/comment-discussion-light.png\" width=\"20\" height=\"20\" alt=\"comment-discussion\"></picture> | `discussions` | GitHub Discussions related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/logo-gist-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/logo-gist-light.png\"><img src=\"pkg/octicons/icons/logo-gist-light.png\" width=\"20\" height=\"20\" alt=\"logo-gist\"></picture> | `gists` | GitHub Gist related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/git-branch-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/git-branch-light.png\"><img src=\"pkg/octicons/icons/git-branch-light.png\" width=\"20\" height=\"20\" alt=\"git-branch\"></picture> | `git` | GitHub Git API related tools for low-level Git operations |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/issue-opened-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/issue-opened-light.png\"><img src=\"pkg/octicons/icons/issue-opened-light.png\" width=\"20\" height=\"20\" alt=\"issue-opened\"></picture> | `issues` | GitHub Issues related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/tag-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/tag-light.png\"><img src=\"pkg/octicons/icons/tag-light.png\" width=\"20\" height=\"20\" alt=\"tag\"></picture> | `labels` | GitHub Labels related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/bell-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/bell-light.png\"><img src=\"pkg/octicons/icons/bell-light.png\" width=\"20\" height=\"20\" alt=\"bell\"></picture> | `notifications` | GitHub Notifications related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/organization-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/organization-light.png\"><img src=\"pkg/octicons/icons/organization-light.png\" width=\"20\" height=\"20\" alt=\"organization\"></picture> | `orgs` | GitHub Organization related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/project-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/project-light.png\"><img src=\"pkg/octicons/icons/project-light.png\" width=\"20\" height=\"20\" alt=\"project\"></picture> | `projects` | GitHub Projects related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/git-pull-request-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/git-pull-request-light.png\"><img src=\"pkg/octicons/icons/git-pull-request-light.png\" width=\"20\" height=\"20\" alt=\"git-pull-request\"></picture> | `pull_requests` | GitHub Pull Request related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/repo-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/repo-light.png\"><img src=\"pkg/octicons/icons/repo-light.png\" width=\"20\" height=\"20\" alt=\"repo\"></picture> | `repos` | GitHub Repository related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/shield-lock-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/shield-lock-light.png\"><img src=\"pkg/octicons/icons/shield-lock-light.png\" width=\"20\" height=\"20\" alt=\"shield-lock\"></picture> | `secret_protection` | Secret protection related tools, such as GitHub Secret Scanning |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/shield-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/shield-light.png\"><img src=\"pkg/octicons/icons/shield-light.png\" width=\"20\" height=\"20\" alt=\"shield\"></picture> | `security_advisories` | Security advisories related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/star-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/star-light.png\"><img src=\"pkg/octicons/icons/star-light.png\" width=\"20\" height=\"20\" alt=\"star\"></picture> | `stargazers` | GitHub Stargazers related tools |\n| <picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/people-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/people-light.png\"><img src=\"pkg/octicons/icons/people-light.png\" width=\"20\" height=\"20\" alt=\"people\"></picture> | `users` | GitHub User related tools |\n<!-- END AUTOMATED TOOLSETS -->\n\n### Additional Toolsets in Remote GitHub MCP Server\n\n| Toolset                 | Description                                                   |\n| ----------------------- | ------------------------------------------------------------- |\n| `copilot` | Copilot related tools (e.g. Copilot Coding Agent) |\n| `copilot_spaces` | Copilot Spaces related tools |\n| `github_support_docs_search` | Search docs to answer GitHub product and support questions |\n\n## Tools\n\n<!-- START AUTOMATED TOOLS -->\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/workflow-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/workflow-light.png\"><img src=\"pkg/octicons/icons/workflow-light.png\" width=\"20\" height=\"20\" alt=\"workflow\"></picture> Actions</summary>\n\n- **cancel_workflow_run** - Cancel workflow run\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **delete_workflow_run_logs** - Delete workflow logs\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **download_workflow_run_artifact** - Download workflow artifact\n  - **Required OAuth Scopes**: `repo`\n  - `artifact_id`: The unique identifier of the artifact (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_job_logs** - Get job logs\n  - **Required OAuth Scopes**: `repo`\n  - `failed_only`: When true, gets logs for all failed jobs in run_id (boolean, optional)\n  - `job_id`: The unique identifier of the workflow job (required for single job logs) (number, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `return_content`: Returns actual log content instead of URLs (boolean, optional)\n  - `run_id`: Workflow run ID (required when using failed_only) (number, optional)\n  - `tail_lines`: Number of lines to return from the end of the log (number, optional)\n\n- **get_workflow_run** - Get workflow run\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **get_workflow_run_logs** - Get workflow run logs\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **get_workflow_run_usage** - Get workflow usage\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **list_workflow_jobs** - List workflow jobs\n  - **Required OAuth Scopes**: `repo`\n  - `filter`: Filters jobs by their completed_at timestamp (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **list_workflow_run_artifacts** - List workflow artifacts\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **list_workflow_runs** - List workflow runs\n  - **Required OAuth Scopes**: `repo`\n  - `actor`: Returns someone's workflow runs. Use the login for the user who created the workflow run. (string, optional)\n  - `branch`: Returns workflow runs associated with a branch. Use the name of the branch. (string, optional)\n  - `event`: Returns workflow runs for a specific event type (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `status`: Returns workflow runs with the check run status (string, optional)\n  - `workflow_id`: The workflow ID or workflow file name (string, required)\n\n- **list_workflows** - List workflows\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **rerun_failed_jobs** - Rerun failed jobs\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **rerun_workflow_run** - Rerun workflow run\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `run_id`: The unique identifier of the workflow run (number, required)\n\n- **run_workflow** - Run workflow\n  - **Required OAuth Scopes**: `repo`\n  - `inputs`: Inputs the workflow accepts (object, optional)\n  - `owner`: Repository owner (string, required)\n  - `ref`: The git reference for the workflow. The reference can be a branch or tag name. (string, required)\n  - `repo`: Repository name (string, required)\n  - `workflow_id`: The workflow ID (numeric) or workflow file name (e.g., main.yml, ci.yaml) (string, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/codescan-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/codescan-light.png\"><img src=\"pkg/octicons/icons/codescan-light.png\" width=\"20\" height=\"20\" alt=\"codescan\"></picture> Code Security</summary>\n\n- **get_code_scanning_alert** - Get code scanning alert\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `alertNumber`: The number of the alert. (number, required)\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n\n- **list_code_scanning_alerts** - List code scanning alerts\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `owner`: The owner of the repository. (string, required)\n  - `ref`: The Git reference for the results you want to list. (string, optional)\n  - `repo`: The name of the repository. (string, required)\n  - `severity`: Filter code scanning alerts by severity (string, optional)\n  - `state`: Filter code scanning alerts by state. Defaults to open (string, optional)\n  - `tool_name`: The name of the tool used for code scanning. (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/person-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/person-light.png\"><img src=\"pkg/octicons/icons/person-light.png\" width=\"20\" height=\"20\" alt=\"person\"></picture> Context</summary>\n\n- **get_me** - Get my user profile\n  - No parameters required\n\n- **get_team_members** - Get team members\n  - **Required OAuth Scopes**: `read:org`\n  - **Accepted OAuth Scopes**: `admin:org`, `read:org`, `write:org`\n  - `org`: Organization login (owner) that contains the team. (string, required)\n  - `team_slug`: Team slug (string, required)\n\n- **get_teams** - Get teams\n  - **Required OAuth Scopes**: `read:org`\n  - **Accepted OAuth Scopes**: `admin:org`, `read:org`, `write:org`\n  - `user`: Username to get teams for. If not provided, uses the authenticated user. (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/dependabot-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/dependabot-light.png\"><img src=\"pkg/octicons/icons/dependabot-light.png\" width=\"20\" height=\"20\" alt=\"dependabot\"></picture> Dependabot</summary>\n\n- **get_dependabot_alert** - Get dependabot alert\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `alertNumber`: The number of the alert. (number, required)\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n\n- **list_dependabot_alerts** - List dependabot alerts\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n  - `severity`: Filter dependabot alerts by severity (string, optional)\n  - `state`: Filter dependabot alerts by state. Defaults to open (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/comment-discussion-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/comment-discussion-light.png\"><img src=\"pkg/octicons/icons/comment-discussion-light.png\" width=\"20\" height=\"20\" alt=\"comment-discussion\"></picture> Discussions</summary>\n\n- **get_discussion** - Get discussion\n  - **Required OAuth Scopes**: `repo`\n  - `discussionNumber`: Discussion Number (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_discussion_comments** - Get discussion comments\n  - **Required OAuth Scopes**: `repo`\n  - `after`: Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs. (string, optional)\n  - `discussionNumber`: Discussion Number (number, required)\n  - `owner`: Repository owner (string, required)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **list_discussion_categories** - List discussion categories\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name. If not provided, discussion categories will be queried at the organisation level. (string, optional)\n\n- **list_discussions** - List discussions\n  - **Required OAuth Scopes**: `repo`\n  - `after`: Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs. (string, optional)\n  - `category`: Optional filter by discussion category ID. If provided, only discussions with this category are listed. (string, optional)\n  - `direction`: Order direction. (string, optional)\n  - `orderBy`: Order discussions by field. If provided, the 'direction' also needs to be provided. (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name. If not provided, discussions will be queried at the organisation level. (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/logo-gist-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/logo-gist-light.png\"><img src=\"pkg/octicons/icons/logo-gist-light.png\" width=\"20\" height=\"20\" alt=\"logo-gist\"></picture> Gists</summary>\n\n- **create_gist** - Create Gist\n  - **Required OAuth Scopes**: `gist`\n  - `content`: Content for simple single-file gist creation (string, required)\n  - `description`: Description of the gist (string, optional)\n  - `filename`: Filename for simple single-file gist creation (string, required)\n  - `public`: Whether the gist is public (boolean, optional)\n\n- **get_gist** - Get Gist Content\n  - `gist_id`: The ID of the gist (string, required)\n\n- **list_gists** - List Gists\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `since`: Only gists updated after this time (ISO 8601 timestamp) (string, optional)\n  - `username`: GitHub username (omit for authenticated user's gists) (string, optional)\n\n- **update_gist** - Update Gist\n  - **Required OAuth Scopes**: `gist`\n  - `content`: Content for the file (string, required)\n  - `description`: Updated description of the gist (string, optional)\n  - `filename`: Filename to update or create (string, required)\n  - `gist_id`: ID of the gist to update (string, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/git-branch-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/git-branch-light.png\"><img src=\"pkg/octicons/icons/git-branch-light.png\" width=\"20\" height=\"20\" alt=\"git-branch\"></picture> Git</summary>\n\n- **get_repository_tree** - Get repository tree\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (username or organization) (string, required)\n  - `path_filter`: Optional path prefix to filter the tree results (e.g., 'src/' to only show files in the src directory) (string, optional)\n  - `recursive`: Setting this parameter to true returns the objects or subtrees referenced by the tree. Default is false (boolean, optional)\n  - `repo`: Repository name (string, required)\n  - `tree_sha`: The SHA1 value or ref (branch or tag) name of the tree. Defaults to the repository's default branch (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/issue-opened-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/issue-opened-light.png\"><img src=\"pkg/octicons/icons/issue-opened-light.png\" width=\"20\" height=\"20\" alt=\"issue-opened\"></picture> Issues</summary>\n\n- **add_issue_comment** - Add comment to issue\n  - **Required OAuth Scopes**: `repo`\n  - `body`: Comment content (string, required)\n  - `issue_number`: Issue number to comment on (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **assign_copilot_to_issue** - Assign Copilot to issue\n  - **Required OAuth Scopes**: `repo`\n  - `base_ref`: Git reference (e.g., branch) that the agent will start its work from. If not specified, defaults to the repository's default branch (string, optional)\n  - `custom_instructions`: Optional custom instructions to guide the agent beyond the issue body. Use this to provide additional context, constraints, or guidance that is not captured in the issue description (string, optional)\n  - `issue_number`: Issue number (number, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_label** - Get a specific label from a repository.\n  - **Required OAuth Scopes**: `repo`\n  - `name`: Label name. (string, required)\n  - `owner`: Repository owner (username or organization name) (string, required)\n  - `repo`: Repository name (string, required)\n\n- **issue_read** - Get issue details\n  - **Required OAuth Scopes**: `repo`\n  - `issue_number`: The number of the issue (number, required)\n  - `method`: The read operation to perform on a single issue.\n    Options are:\n    1. get - Get details of a specific issue.\n    2. get_comments - Get issue comments.\n    3. get_sub_issues - Get sub-issues of the issue.\n    4. get_labels - Get labels assigned to the issue.\n     (string, required)\n  - `owner`: The owner of the repository (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: The name of the repository (string, required)\n\n- **issue_write** - Create or update issue.\n  - **Required OAuth Scopes**: `repo`\n  - `assignees`: Usernames to assign to this issue (string[], optional)\n  - `body`: Issue body content (string, optional)\n  - `duplicate_of`: Issue number that this issue is a duplicate of. Only used when state_reason is 'duplicate'. (number, optional)\n  - `issue_number`: Issue number to update (number, optional)\n  - `labels`: Labels to apply to this issue (string[], optional)\n  - `method`: Write operation to perform on a single issue.\n    Options are:\n    - 'create' - creates a new issue.\n    - 'update' - updates an existing issue.\n     (string, required)\n  - `milestone`: Milestone number (number, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `state`: New state (string, optional)\n  - `state_reason`: Reason for the state change. Ignored unless state is changed. (string, optional)\n  - `title`: Issue title (string, optional)\n  - `type`: Type of this issue. Only use if the repository has issue types configured. Use list_issue_types tool to get valid type values for the organization. If the repository doesn't support issue types, omit this parameter. (string, optional)\n\n- **list_issue_types** - List available issue types\n  - **Required OAuth Scopes**: `read:org`\n  - **Accepted OAuth Scopes**: `admin:org`, `read:org`, `write:org`\n  - `owner`: The organization owner of the repository (string, required)\n\n- **list_issues** - List issues\n  - **Required OAuth Scopes**: `repo`\n  - `after`: Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs. (string, optional)\n  - `direction`: Order direction. If provided, the 'orderBy' also needs to be provided. (string, optional)\n  - `labels`: Filter by labels (string[], optional)\n  - `orderBy`: Order issues by field. If provided, the 'direction' also needs to be provided. (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `since`: Filter by date (ISO 8601 timestamp) (string, optional)\n  - `state`: Filter by state, by default both open and closed issues are returned when not provided (string, optional)\n\n- **search_issues** - Search issues\n  - **Required OAuth Scopes**: `repo`\n  - `order`: Sort order (string, optional)\n  - `owner`: Optional repository owner. If provided with repo, only issues for this repository are listed. (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Search query using GitHub issues search syntax (string, required)\n  - `repo`: Optional repository name. If provided with owner, only issues for this repository are listed. (string, optional)\n  - `sort`: Sort field by number of matches of categories, defaults to best match (string, optional)\n\n- **sub_issue_write** - Change sub-issue\n  - **Required OAuth Scopes**: `repo`\n  - `after_id`: The ID of the sub-issue to be prioritized after (either after_id OR before_id should be specified) (number, optional)\n  - `before_id`: The ID of the sub-issue to be prioritized before (either after_id OR before_id should be specified) (number, optional)\n  - `issue_number`: The number of the parent issue (number, required)\n  - `method`: The action to perform on a single sub-issue\n    Options are:\n    - 'add' - add a sub-issue to a parent issue in a GitHub repository.\n    - 'remove' - remove a sub-issue from a parent issue in a GitHub repository.\n    - 'reprioritize' - change the order of sub-issues within a parent issue in a GitHub repository. Use either 'after_id' or 'before_id' to specify the new position.\n    \t\t\t\t (string, required)\n  - `owner`: Repository owner (string, required)\n  - `replace_parent`: When true, replaces the sub-issue's current parent issue. Use with 'add' method only. (boolean, optional)\n  - `repo`: Repository name (string, required)\n  - `sub_issue_id`: The ID of the sub-issue to add. ID is not the same as issue number (number, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/tag-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/tag-light.png\"><img src=\"pkg/octicons/icons/tag-light.png\" width=\"20\" height=\"20\" alt=\"tag\"></picture> Labels</summary>\n\n- **get_label** - Get a specific label from a repository.\n  - **Required OAuth Scopes**: `repo`\n  - `name`: Label name. (string, required)\n  - `owner`: Repository owner (username or organization name) (string, required)\n  - `repo`: Repository name (string, required)\n\n- **label_write** - Write operations on repository labels.\n  - **Required OAuth Scopes**: `repo`\n  - `color`: Label color as 6-character hex code without '#' prefix (e.g., 'f29513'). Required for 'create', optional for 'update'. (string, optional)\n  - `description`: Label description text. Optional for 'create' and 'update'. (string, optional)\n  - `method`: Operation to perform: 'create', 'update', or 'delete' (string, required)\n  - `name`: Label name - required for all operations (string, required)\n  - `new_name`: New name for the label (used only with 'update' method to rename) (string, optional)\n  - `owner`: Repository owner (username or organization name) (string, required)\n  - `repo`: Repository name (string, required)\n\n- **list_label** - List labels from a repository\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (username or organization name) - required for all operations (string, required)\n  - `repo`: Repository name - required for all operations (string, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/bell-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/bell-light.png\"><img src=\"pkg/octicons/icons/bell-light.png\" width=\"20\" height=\"20\" alt=\"bell\"></picture> Notifications</summary>\n\n- **dismiss_notification** - Dismiss notification\n  - **Required OAuth Scopes**: `notifications`\n  - `state`: The new state of the notification (read/done) (string, required)\n  - `threadID`: The ID of the notification thread (string, required)\n\n- **get_notification_details** - Get notification details\n  - **Required OAuth Scopes**: `notifications`\n  - `notificationID`: The ID of the notification (string, required)\n\n- **list_notifications** - List notifications\n  - **Required OAuth Scopes**: `notifications`\n  - `before`: Only show notifications updated before the given time (ISO 8601 format) (string, optional)\n  - `filter`: Filter notifications to, use default unless specified. Read notifications are ones that have already been acknowledged by the user. Participating notifications are those that the user is directly involved in, such as issues or pull requests they have commented on or created. (string, optional)\n  - `owner`: Optional repository owner. If provided with repo, only notifications for this repository are listed. (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Optional repository name. If provided with owner, only notifications for this repository are listed. (string, optional)\n  - `since`: Only show notifications updated after the given time (ISO 8601 format) (string, optional)\n\n- **manage_notification_subscription** - Manage notification subscription\n  - **Required OAuth Scopes**: `notifications`\n  - `action`: Action to perform: ignore, watch, or delete the notification subscription. (string, required)\n  - `notificationID`: The ID of the notification thread. (string, required)\n\n- **manage_repository_notification_subscription** - Manage repository notification subscription\n  - **Required OAuth Scopes**: `notifications`\n  - `action`: Action to perform: ignore, watch, or delete the repository notification subscription. (string, required)\n  - `owner`: The account owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n\n- **mark_all_notifications_read** - Mark all notifications as read\n  - **Required OAuth Scopes**: `notifications`\n  - `lastReadAt`: Describes the last point that notifications were checked (optional). Default: Now (string, optional)\n  - `owner`: Optional repository owner. If provided with repo, only notifications for this repository are marked as read. (string, optional)\n  - `repo`: Optional repository name. If provided with owner, only notifications for this repository are marked as read. (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/organization-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/organization-light.png\"><img src=\"pkg/octicons/icons/organization-light.png\" width=\"20\" height=\"20\" alt=\"organization\"></picture> Organizations</summary>\n\n- **search_orgs** - Search organizations\n  - **Required OAuth Scopes**: `read:org`\n  - **Accepted OAuth Scopes**: `admin:org`, `read:org`, `write:org`\n  - `order`: Sort order (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Organization search query. Examples: 'microsoft', 'location:california', 'created:>=2025-01-01'. Search is automatically scoped to type:org. (string, required)\n  - `sort`: Sort field by category (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/project-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/project-light.png\"><img src=\"pkg/octicons/icons/project-light.png\" width=\"20\" height=\"20\" alt=\"project\"></picture> Projects</summary>\n\n- **add_project_item** - Add project item\n  - **Required OAuth Scopes**: `project`\n  - `item_id`: The numeric ID of the issue or pull request to add to the project. (number, required)\n  - `item_type`: The item's type, either issue or pull_request. (string, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n\n- **delete_project_item** - Delete project item\n  - **Required OAuth Scopes**: `project`\n  - `item_id`: The internal project item ID to delete from the project (not the issue or pull request ID). (number, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n\n- **get_project** - Get project\n  - **Required OAuth Scopes**: `read:project`\n  - **Accepted OAuth Scopes**: `project`, `read:project`\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number (number, required)\n\n- **get_project_field** - Get project field\n  - **Required OAuth Scopes**: `read:project`\n  - **Accepted OAuth Scopes**: `project`, `read:project`\n  - `field_id`: The field's id. (number, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n\n- **get_project_item** - Get project item\n  - **Required OAuth Scopes**: `read:project`\n  - **Accepted OAuth Scopes**: `project`, `read:project`\n  - `fields`: Specific list of field IDs to include in the response (e.g. [\"102589\", \"985201\", \"169875\"]). If not provided, only the title field is included. (string[], optional)\n  - `item_id`: The item's ID. (number, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n\n- **list_project_fields** - List project fields\n  - **Required OAuth Scopes**: `read:project`\n  - **Accepted OAuth Scopes**: `project`, `read:project`\n  - `after`: Forward pagination cursor from previous pageInfo.nextCursor. (string, optional)\n  - `before`: Backward pagination cursor from previous pageInfo.prevCursor (rare). (string, optional)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `per_page`: Results per page (max 50) (number, optional)\n  - `project_number`: The project's number. (number, required)\n\n- **list_project_items** - List project items\n  - **Required OAuth Scopes**: `read:project`\n  - **Accepted OAuth Scopes**: `project`, `read:project`\n  - `after`: Forward pagination cursor from previous pageInfo.nextCursor. (string, optional)\n  - `before`: Backward pagination cursor from previous pageInfo.prevCursor (rare). (string, optional)\n  - `fields`: Field IDs to include (e.g. [\"102589\", \"985201\"]). CRITICAL: Always provide to get field values. Without this, only titles returned. (string[], optional)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `per_page`: Results per page (max 50) (number, optional)\n  - `project_number`: The project's number. (number, required)\n  - `query`: Query string for advanced filtering of project items using GitHub's project filtering syntax. (string, optional)\n\n- **list_projects** - List projects\n  - **Required OAuth Scopes**: `read:project`\n  - **Accepted OAuth Scopes**: `project`, `read:project`\n  - `after`: Forward pagination cursor from previous pageInfo.nextCursor. (string, optional)\n  - `before`: Backward pagination cursor from previous pageInfo.prevCursor (rare). (string, optional)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `per_page`: Results per page (max 50) (number, optional)\n  - `query`: Filter projects by title text and open/closed state; permitted qualifiers: is:open, is:closed; examples: \"roadmap is:open\", \"is:open feature planning\". (string, optional)\n\n- **update_project_item** - Update project item\n  - **Required OAuth Scopes**: `project`\n  - `item_id`: The unique identifier of the project item. This is not the issue or pull request ID. (number, required)\n  - `owner`: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)\n  - `owner_type`: Owner type (string, required)\n  - `project_number`: The project's number. (number, required)\n  - `updated_field`: Object consisting of the ID of the project field to update and the new value for the field. To clear the field, set value to null. Example: {\"id\": 123456, \"value\": \"New Value\"} (object, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/git-pull-request-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/git-pull-request-light.png\"><img src=\"pkg/octicons/icons/git-pull-request-light.png\" width=\"20\" height=\"20\" alt=\"git-pull-request\"></picture> Pull Requests</summary>\n\n- **add_comment_to_pending_review** - Add review comment to the requester's latest pending pull request review\n  - **Required OAuth Scopes**: `repo`\n  - `body`: The text of the review comment (string, required)\n  - `line`: The line of the blob in the pull request diff that the comment applies to. For multi-line comments, the last line of the range (number, optional)\n  - `owner`: Repository owner (string, required)\n  - `path`: The relative path to the file that necessitates a comment (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n  - `side`: The side of the diff to comment on. LEFT indicates the previous state, RIGHT indicates the new state (string, optional)\n  - `startLine`: For multi-line comments, the first line of the range that the comment applies to (number, optional)\n  - `startSide`: For multi-line comments, the starting side of the diff that the comment applies to. LEFT indicates the previous state, RIGHT indicates the new state (string, optional)\n  - `subjectType`: The level at which the comment is targeted (string, required)\n\n- **create_pull_request** - Open new pull request\n  - **Required OAuth Scopes**: `repo`\n  - `base`: Branch to merge into (string, required)\n  - `body`: PR description (string, optional)\n  - `draft`: Create as draft PR (boolean, optional)\n  - `head`: Branch containing changes (string, required)\n  - `maintainer_can_modify`: Allow maintainer edits (boolean, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `title`: PR title (string, required)\n\n- **list_pull_requests** - List pull requests\n  - **Required OAuth Scopes**: `repo`\n  - `base`: Filter by base branch (string, optional)\n  - `direction`: Sort direction (string, optional)\n  - `head`: Filter by head user/org and branch (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `sort`: Sort by (string, optional)\n  - `state`: Filter by state (string, optional)\n\n- **merge_pull_request** - Merge pull request\n  - **Required OAuth Scopes**: `repo`\n  - `commit_message`: Extra detail for merge commit (string, optional)\n  - `commit_title`: Title for merge commit (string, optional)\n  - `merge_method`: Merge method (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **pull_request_read** - Get details for a single pull request\n  - **Required OAuth Scopes**: `repo`\n  - `method`: Action to specify what pull request data needs to be retrieved from GitHub. \n    Possible options: \n     1. get - Get details of a specific pull request.\n     2. get_diff - Get the diff of a pull request.\n     3. get_status - Get status of a head commit in a pull request. This reflects status of builds and checks.\n     4. get_files - Get the list of files changed in a pull request. Use with pagination parameters to control the number of results returned.\n     5. get_review_comments - Get review threads on a pull request. Each thread contains logically grouped review comments made on the same code location during pull request reviews. Returns threads with metadata (isResolved, isOutdated, isCollapsed) and their associated comments. Use cursor-based pagination (perPage, after) to control results.\n     6. get_reviews - Get the reviews on a pull request. When asked for review comments, use get_review_comments method.\n     7. get_comments - Get comments on a pull request. Use this if user doesn't specifically want review comments. Use with pagination parameters to control the number of results returned.\n     (string, required)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **pull_request_review_write** - Write operations (create, submit, delete) on pull request reviews.\n  - **Required OAuth Scopes**: `repo`\n  - `body`: Review comment text (string, optional)\n  - `commitID`: SHA of commit to review (string, optional)\n  - `event`: Review action to perform. (string, optional)\n  - `method`: The write operation to perform on pull request review. (string, required)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **request_copilot_review** - Request Copilot review\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n- **search_pull_requests** - Search pull requests\n  - **Required OAuth Scopes**: `repo`\n  - `order`: Sort order (string, optional)\n  - `owner`: Optional repository owner. If provided with repo, only pull requests for this repository are listed. (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Search query using GitHub pull request search syntax (string, required)\n  - `repo`: Optional repository name. If provided with owner, only pull requests for this repository are listed. (string, optional)\n  - `sort`: Sort field by number of matches of categories, defaults to best match (string, optional)\n\n- **update_pull_request** - Edit pull request\n  - **Required OAuth Scopes**: `repo`\n  - `base`: New base branch name (string, optional)\n  - `body`: New description (string, optional)\n  - `draft`: Mark pull request as draft (true) or ready for review (false) (boolean, optional)\n  - `maintainer_can_modify`: Allow maintainer edits (boolean, optional)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number to update (number, required)\n  - `repo`: Repository name (string, required)\n  - `reviewers`: GitHub usernames to request reviews from (string[], optional)\n  - `state`: New state (string, optional)\n  - `title`: New title (string, optional)\n\n- **update_pull_request_branch** - Update pull request branch\n  - **Required OAuth Scopes**: `repo`\n  - `expectedHeadSha`: The expected SHA of the pull request's HEAD ref (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `pullNumber`: Pull request number (number, required)\n  - `repo`: Repository name (string, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/repo-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/repo-light.png\"><img src=\"pkg/octicons/icons/repo-light.png\" width=\"20\" height=\"20\" alt=\"repo\"></picture> Repositories</summary>\n\n- **create_branch** - Create branch\n  - **Required OAuth Scopes**: `repo`\n  - `branch`: Name for new branch (string, required)\n  - `from_branch`: Source branch (defaults to repo default) (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **create_or_update_file** - Create or update file\n  - **Required OAuth Scopes**: `repo`\n  - `branch`: Branch to create/update the file in (string, required)\n  - `content`: Content of the file (string, required)\n  - `message`: Commit message (string, required)\n  - `owner`: Repository owner (username or organization) (string, required)\n  - `path`: Path where to create/update the file (string, required)\n  - `repo`: Repository name (string, required)\n  - `sha`: The blob SHA of the file being replaced. (string, optional)\n\n- **create_repository** - Create repository\n  - **Required OAuth Scopes**: `repo`\n  - `autoInit`: Initialize with README (boolean, optional)\n  - `description`: Repository description (string, optional)\n  - `name`: Repository name (string, required)\n  - `organization`: Organization to create the repository in (omit to create in your personal account) (string, optional)\n  - `private`: Whether repo should be private (boolean, optional)\n\n- **delete_file** - Delete file\n  - **Required OAuth Scopes**: `repo`\n  - `branch`: Branch to delete the file from (string, required)\n  - `message`: Commit message (string, required)\n  - `owner`: Repository owner (username or organization) (string, required)\n  - `path`: Path to the file to delete (string, required)\n  - `repo`: Repository name (string, required)\n\n- **fork_repository** - Fork repository\n  - **Required OAuth Scopes**: `repo`\n  - `organization`: Organization to fork to (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_commit** - Get commit details\n  - **Required OAuth Scopes**: `repo`\n  - `include_diff`: Whether to include file diffs and stats in the response. Default is true. (boolean, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `sha`: Commit SHA, branch name, or tag name (string, required)\n\n- **get_file_contents** - Get file or directory contents\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (username or organization) (string, required)\n  - `path`: Path to file/directory (string, optional)\n  - `ref`: Accepts optional git refs such as `refs/tags/{tag}`, `refs/heads/{branch}` or `refs/pull/{pr_number}/head` (string, optional)\n  - `repo`: Repository name (string, required)\n  - `sha`: Accepts optional commit SHA. If specified, it will be used instead of ref (string, optional)\n\n- **get_latest_release** - Get latest release\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **get_release_by_tag** - Get a release by tag name\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `tag`: Tag name (e.g., 'v1.0.0') (string, required)\n\n- **get_tag** - Get tag details\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n  - `tag`: Tag name (string, required)\n\n- **list_branches** - List branches\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **list_commits** - List commits\n  - **Required OAuth Scopes**: `repo`\n  - `author`: Author username or email address to filter commits by (string, optional)\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n  - `sha`: Commit SHA, branch or tag name to list commits of. If not provided, uses the default branch of the repository. If a commit SHA is provided, will list commits up to that SHA. (string, optional)\n\n- **list_releases** - List releases\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **list_tags** - List tags\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `repo`: Repository name (string, required)\n\n- **push_files** - Push files to repository\n  - **Required OAuth Scopes**: `repo`\n  - `branch`: Branch to push to (string, required)\n  - `files`: Array of file objects to push, each object with path (string) and content (string) (object[], required)\n  - `message`: Commit message (string, required)\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **search_code** - Search code\n  - **Required OAuth Scopes**: `repo`\n  - `order`: Sort order for results (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Search query using GitHub's powerful code search syntax. Examples: 'content:Skill language:Java org:github', 'NOT is:archived language:Python OR language:go', 'repo:github/github-mcp-server'. Supports exact matching, language filters, path filters, and more. (string, required)\n  - `sort`: Sort field ('indexed' only) (string, optional)\n\n- **search_repositories** - Search repositories\n  - **Required OAuth Scopes**: `repo`\n  - `minimal_output`: Return minimal repository information (default: true). When false, returns full GitHub API repository objects. (boolean, optional)\n  - `order`: Sort order (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: Repository search query. Examples: 'machine learning in:name stars:>1000 language:python', 'topic:react', 'user:facebook'. Supports advanced search syntax for precise filtering. (string, required)\n  - `sort`: Sort repositories by field, defaults to best match (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/shield-lock-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/shield-lock-light.png\"><img src=\"pkg/octicons/icons/shield-lock-light.png\" width=\"20\" height=\"20\" alt=\"shield-lock\"></picture> Secret Protection</summary>\n\n- **get_secret_scanning_alert** - Get secret scanning alert\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `alertNumber`: The number of the alert. (number, required)\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n\n- **list_secret_scanning_alerts** - List secret scanning alerts\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n  - `resolution`: Filter by resolution (string, optional)\n  - `secret_type`: A comma-separated list of secret types to return. All default secret patterns are returned. To return generic patterns, pass the token name(s) in the parameter. (string, optional)\n  - `state`: Filter by state (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/shield-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/shield-light.png\"><img src=\"pkg/octicons/icons/shield-light.png\" width=\"20\" height=\"20\" alt=\"shield\"></picture> Security Advisories</summary>\n\n- **get_global_security_advisory** - Get a global security advisory\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `ghsaId`: GitHub Security Advisory ID (format: GHSA-xxxx-xxxx-xxxx). (string, required)\n\n- **list_global_security_advisories** - List global security advisories\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `affects`: Filter advisories by affected package or version (e.g. \"package1,package2@1.0.0\"). (string, optional)\n  - `cveId`: Filter by CVE ID. (string, optional)\n  - `cwes`: Filter by Common Weakness Enumeration IDs (e.g. [\"79\", \"284\", \"22\"]). (string[], optional)\n  - `ecosystem`: Filter by package ecosystem. (string, optional)\n  - `ghsaId`: Filter by GitHub Security Advisory ID (format: GHSA-xxxx-xxxx-xxxx). (string, optional)\n  - `isWithdrawn`: Whether to only return withdrawn advisories. (boolean, optional)\n  - `modified`: Filter by publish or update date or date range (ISO 8601 date or range). (string, optional)\n  - `published`: Filter by publish date or date range (ISO 8601 date or range). (string, optional)\n  - `severity`: Filter by severity. (string, optional)\n  - `type`: Advisory type. (string, optional)\n  - `updated`: Filter by update date or date range (ISO 8601 date or range). (string, optional)\n\n- **list_org_repository_security_advisories** - List org repository security advisories\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `direction`: Sort direction. (string, optional)\n  - `org`: The organization login. (string, required)\n  - `sort`: Sort field. (string, optional)\n  - `state`: Filter by advisory state. (string, optional)\n\n- **list_repository_security_advisories** - List repository security advisories\n  - **Required OAuth Scopes**: `security_events`\n  - **Accepted OAuth Scopes**: `repo`, `security_events`\n  - `direction`: Sort direction. (string, optional)\n  - `owner`: The owner of the repository. (string, required)\n  - `repo`: The name of the repository. (string, required)\n  - `sort`: Sort field. (string, optional)\n  - `state`: Filter by advisory state. (string, optional)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/star-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/star-light.png\"><img src=\"pkg/octicons/icons/star-light.png\" width=\"20\" height=\"20\" alt=\"star\"></picture> Stargazers</summary>\n\n- **list_starred_repositories** - List starred repositories\n  - **Required OAuth Scopes**: `repo`\n  - `direction`: The direction to sort the results by. (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `sort`: How to sort the results. Can be either 'created' (when the repository was starred) or 'updated' (when the repository was last pushed to). (string, optional)\n  - `username`: Username to list starred repositories for. Defaults to the authenticated user. (string, optional)\n\n- **star_repository** - Star repository\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n- **unstar_repository** - Unstar repository\n  - **Required OAuth Scopes**: `repo`\n  - `owner`: Repository owner (string, required)\n  - `repo`: Repository name (string, required)\n\n</details>\n\n<details>\n\n<summary><picture><source media=\"(prefers-color-scheme: dark)\" srcset=\"pkg/octicons/icons/people-dark.png\"><source media=\"(prefers-color-scheme: light)\" srcset=\"pkg/octicons/icons/people-light.png\"><img src=\"pkg/octicons/icons/people-light.png\" width=\"20\" height=\"20\" alt=\"people\"></picture> Users</summary>\n\n- **search_users** - Search users\n  - **Required OAuth Scopes**: `repo`\n  - `order`: Sort order (string, optional)\n  - `page`: Page number for pagination (min 1) (number, optional)\n  - `perPage`: Results per page for pagination (min 1, max 100) (number, optional)\n  - `query`: User search query. Examples: 'john smith', 'location:seattle', 'followers:>100'. Search is automatically scoped to type:user. (string, required)\n  - `sort`: Sort users by number of followers or repositories, or when the person joined GitHub. (string, optional)\n\n</details>\n<!-- END AUTOMATED TOOLS -->\n\n### Additional Tools in Remote GitHub MCP Server\n\n<details>\n\n<summary>Copilot</summary>\n\n- **create_pull_request_with_copilot** - Perform task with GitHub Copilot coding agent\n  - `owner`: Repository owner. You can guess the owner, but confirm it with the user before proceeding. (string, required)\n  - `repo`: Repository name. You can guess the repository name, but confirm it with the user before proceeding. (string, required)\n  - `problem_statement`: Detailed description of the task to be performed (e.g., 'Implement a feature that does X', 'Fix bug Y', etc.) (string, required)\n  - `title`: Title for the pull request that will be created (string, required)\n  - `base_ref`: Git reference (e.g., branch) that the agent will start its work from. If not specified, defaults to the repository's default branch (string, optional)\n\n</details>\n\n<details>\n\n<summary>Copilot Spaces</summary>\n\n- **get_copilot_space** - Get Copilot Space\n  - `owner`: The owner of the space. (string, required)\n  - `name`: The name of the space. (string, required)\n\n- **list_copilot_spaces** - List Copilot Spaces\n\n</details>\n\n<details>\n\n<summary>GitHub Support Docs Search</summary>\n\n- **github_support_docs_search** - Retrieve documentation relevant to answer GitHub product and support questions. Support topics include: GitHub Actions Workflows, Authentication, GitHub Support Inquiries, Pull Request Practices, Repository Maintenance, GitHub Pages, GitHub Packages, GitHub Discussions, Copilot Spaces\n  - `query`: Input from the user about the question they need answered. This is the latest raw unedited user message. You should ALWAYS leave the user message as it is, you should never modify it. (string, required)\n\n</details>\n\n## Dynamic Tool Discovery\n\n**Note**: This feature is currently in beta and is not available in the Remote GitHub MCP Server. Please test it out and let us know if you encounter any issues.\n\nInstead of starting with all tools enabled, you can turn on dynamic toolset discovery. Dynamic toolsets allow the MCP host to list and enable toolsets in response to a user prompt. This should help to avoid situations where the model gets confused by the sheer number of tools available.\n\n### Using Dynamic Tool Discovery\n\nWhen using the binary, you can pass the `--dynamic-toolsets` flag.\n\n```bash\n./github-mcp-server --dynamic-toolsets\n```\n\nWhen using Docker, you can pass the toolsets as environment variables:\n\n```bash\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_DYNAMIC_TOOLSETS=1 \\\n  ghcr.io/github/github-mcp-server\n```\n\n## Read-Only Mode\n\nTo run the server in read-only mode, you can use the `--read-only` flag. This will only offer read-only tools, preventing any modifications to repositories, issues, pull requests, etc.\n\n```bash\n./github-mcp-server --read-only\n```\n\nWhen using Docker, you can pass the read-only mode as an environment variable:\n\n```bash\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_READ_ONLY=1 \\\n  ghcr.io/github/github-mcp-server\n```\n\n## Lockdown Mode\n\nLockdown mode limits the content that the server will surface from public repositories. When enabled, the server checks whether the author of each item has push access to the repository. Private repositories are unaffected, and collaborators keep full access to their own content.\n\n```bash\n./github-mcp-server --lockdown-mode\n```\n\nWhen running with Docker, set the corresponding environment variable:\n\n```bash\ndocker run -i --rm \\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\n  -e GITHUB_LOCKDOWN_MODE=1 \\\n  ghcr.io/github/github-mcp-server\n```\n\nThe behavior of lockdown mode depends on the tool invoked.\n\nFollowing tools will return an error when the author lacks the push access:\n\n- `issue_read:get`\n- `pull_request_read:get`\n\nFollowing tools will filter out content from users lacking the push access:\n\n- `issue_read:get_comments`\n- `issue_read:get_sub_issues`\n- `pull_request_read:get_comments`\n- `pull_request_read:get_review_comments`\n- `pull_request_read:get_reviews`\n\n## i18n / Overriding Descriptions\n\nThe descriptions of the tools can be overridden by creating a\n`github-mcp-server-config.json` file in the same directory as the binary.\n\nThe file should contain a JSON object with the tool names as keys and the new\ndescriptions as values. For example:\n\n```json\n{\n  \"TOOL_ADD_ISSUE_COMMENT_DESCRIPTION\": \"an alternative description\",\n  \"TOOL_CREATE_BRANCH_DESCRIPTION\": \"Create a new branch in a GitHub repository\"\n}\n```\n\nYou can create an export of the current translations by running the binary with\nthe `--export-translations` flag.\n\nThis flag will preserve any translations/overrides you have made, while adding\nany new translations that have been added to the binary since the last time you\nexported.\n\n```sh\n./github-mcp-server --export-translations\ncat github-mcp-server-config.json\n```\n\nYou can also use ENV vars to override the descriptions. The environment\nvariable names are the same as the keys in the JSON file, prefixed with\n`GITHUB_MCP_` and all uppercase.\n\nFor example, to override the `TOOL_ADD_ISSUE_COMMENT_DESCRIPTION` tool, you can\nset the following environment variable:\n\n```sh\nexport GITHUB_MCP_TOOL_ADD_ISSUE_COMMENT_DESCRIPTION=\"an alternative description\"\n```\n\n## Library Usage\n\nThe exported Go API of this module should currently be considered unstable, and subject to breaking changes. In the future, we may offer stability; please file an issue if there is a use case where this would be valuable.\n\n## License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to [MIT](./LICENSE) for the full terms.\n",
      "stars_today": 38
    },
    {
      "id": 613010835,
      "name": "documenso",
      "full_name": "documenso/documenso",
      "description": "The Open Source DocuSign Alternative.",
      "html_url": "https://github.com/documenso/documenso",
      "stars": 12280,
      "forks": 2287,
      "language": "TypeScript",
      "topics": [
        "digital-signature",
        "document-signing",
        "docusign-alternative",
        "e-signature",
        "esign",
        "esignature",
        "next-auth",
        "nextjs",
        "open-source",
        "pades-standard",
        "pdf",
        "pdf-sign",
        "pdf-signature",
        "postgresql",
        "prisma",
        "self-hosted",
        "signing",
        "typescript"
      ],
      "created_at": "2023-03-12T16:28:56Z",
      "updated_at": "2026-01-25T02:27:09Z",
      "pushed_at": "2026-01-25T02:11:09Z",
      "open_issues": 223,
      "owner": {
        "login": "documenso",
        "avatar_url": "https://avatars.githubusercontent.com/u/127681099?v=4"
      },
      "readme": "<img src=\"https://github.com/documenso/documenso/assets/13398220/a643571f-0239-46a6-a73e-6bef38d1228b\" alt=\"Documenso Logo\">\n\n<p align=\"center\" style=\"margin-top: 20px\">\n  <p align=\"center\">\n  The Open Source DocuSign Alternative.\n  <br>\n    <a href=\"https://documenso.com\"><strong>Learn more Â»</strong></a>\n    <br />\n    <br />\n    <a href=\"https://documen.so/discord\">Discord</a>\n    Â·\n    <a href=\"https://documenso.com\">Website</a>\n    Â·\n    <a href=\"https://github.com/documenso/documenso/issues\">Issues</a>\n    Â·\n    <a href=\"https://documen.so/live\">Upcoming Releases</a>\n    Â·\n    <a href=\"https://documen.so/roadmap\">Roadmap</a>\n  </p>\n</p>\n\n<p align=\"center\">\n   <a href=\"https://documen.so/discord\"><img src=\"https://img.shields.io/badge/Discord-documen.so/discord-%235865F2\" alt=\"Join Documenso on Discord\"></a>\n   <a href=\"https://github.com/documenso/documenso/stargazers\"><img src=\"https://img.shields.io/github/stars/documenso/documenso\" alt=\"Github Stars\"></a>\n   <a href=\"https://github.com/documenso/documenso/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/license-AGPLv3-purple\" alt=\"License\"></a>\n   <a href=\"https://github.com/documenso/documenso/pulse\"><img src=\"https://img.shields.io/github/commit-activity/m/documenso/documenso\" alt=\"Commits-per-month\"></a>\n   <a href=\"https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/documenso/documenso\">\n   <img alt=\"open in devcontainer\" src=\"https://img.shields.io/static/v1?label=Dev%20Containers&message=Enabled&color=blue&logo=visualstudiocode\" />\n   </a>\n   <a href=\"CODE_OF_CONDUCT.md\"><img src=\"https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg\" alt=\"Contributor Covenant\"></a>\n</p>\n\n<div align=\"center\">\n  <img src=\"https://github.com/documenso/documenso/assets/13398220/d96ed533-6f34-4a97-be9b-442bdb189c69\" style=\"width: 80%;\" />\n</div>\n\n## About Documenso\n\nSigning documents digitally should be fast and easy and should be the best practice for every document signed worldwide. This is technically quite easy today, but it also introduces a new party to every signature: The signing tool providers. While this is not a problem in itself, it should make us think about how we want these providers of trust to work. Documenso aims to be the world's most trusted document-signing tool. This trust is built by empowering you to self-host Documenso and review how it works under the hood.\n\nJoin us in creating the next generation of open trust infrastructure.\n\n## Recognition\n\n<p align=\"center\">\n  <a href=\"https://www.producthunt.com/posts/documenso?utm_source=badge-top-post-badge&utm_medium=badge&utm_souce=badge-documenso\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=395047&theme=light&period=daily\" alt=\"Documenso - The&#0032;open&#0032;source&#0032;DocuSign&#0032;alternative | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a>\n  <a href=\"https://www.producthunt.com/posts/documenso?utm_source=badge-featured&utm_medium=badge&utm_souce=badge-documenso\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=395047&theme=light\" alt=\"Documenso - The&#0032;Open&#0032;Source&#0032;DocuSign&#0032;Alternative&#0046; | Product Hunt\" style=\"width: 250px; height: 54px;\" width=\"250\" height=\"54\" /></a>\n</p>\n\n## Community and Next Steps ğŸ¯\n\n- Check out the first source code release in this repository and test it.\n- Tell us what you think in the [Discussions](https://github.com/documenso/documenso/discussions).\n- Join the [Discord server](https://documen.so/discord) for any questions and getting to know to other community members.\n- â­ the repository to help us raise awareness.\n- Spread the word on Twitter that Documenso is working towards a more open signing tool.\n- Fix or create [issues](https://github.com/documenso/documenso/issues), that are needed for the first production release.\n\n## Contributing\n\n- To contribute, please see our [contribution guide](https://github.com/documenso/documenso/blob/main/CONTRIBUTING.md).\n\n## Contact us\n\nContact us if you are interested in our Enterprise plan for large organizations that need extra flexibility and control.\n\n<a href=\"https://cal.com/timurercan/enterprise-customers?utm_source=banner&utm_campaign=oss\"><img alt=\"Book us with Cal.com\" src=\"https://cal.com/book-with-cal-dark.svg\" /></a>\n\n## Tech Stack\n\n<p align=\"left\">\n  <a href=\"https://www.typescriptlang.org\"><img src=\"https://shields.io/badge/TypeScript-3178C6?logo=TypeScript&logoColor=FFF&style=flat-square\" alt=\"TypeScript\"></a>\n  <a href=\"https://prisma.io\"><img width=\"122\" height=\"20\" src=\"http://made-with.prisma.io/indigo.svg\" alt=\"Made with Prisma\" /></a>\n  <a href=\"https://tailwindcss.com/\"><img src=\"https://img.shields.io/badge/tailwindcss-0F172A?&logo=tailwindcss\" alt=\"Tailwind CSS\"></a>\n  <a href=\"\"><img src=\"\" alt=\"\"></a>\n  <a href=\"\"><img src=\"\" alt=\"\"></a>\n  <a href=\"\"><img src=\"\" alt=\"\"></a>\n  <a href=\"\"><img src=\"\" alt=\"\"></a>\n  <a href=\"\"><img src=\"\" alt=\"\"></a>\n</p>\n\n- [Typescript](https://www.typescriptlang.org/) - Language\n- [ReactRouter](https://reactrouter.com/) - Framework\n- [Prisma](https://www.prisma.io/) - ORM\n- [Tailwind](https://tailwindcss.com/) - CSS\n- [shadcn/ui](https://ui.shadcn.com/) - Component Library\n- [react-email](https://react.email/) - Email Templates\n- [tRPC](https://trpc.io/) - API\n- [@documenso/pdf-sign](https://www.npmjs.com/package/@documenso/pdf-sign) - PDF Signatures (launching soon)\n- [React-PDF](https://github.com/wojtekmaj/react-pdf) - Viewing PDFs\n- [PDF-Lib](https://github.com/Hopding/pdf-lib) - PDF manipulation\n- [Stripe](https://stripe.com/) - Payments\n\n<!-- - Support for [opensignpdf (requires Java on server)](https://github.com/open-pdf-sign) is currently planned. -->\n\n## Local Development\n\n### Requirements\n\nTo run Documenso locally, you will need\n\n- Node.js (v22 or above)\n- Postgres SQL Database\n- Docker (optional)\n\n### Developer Quickstart\n\n> **Note**: This is a quickstart for developers. It assumes that you have both [docker](https://docs.docker.com/get-docker/) and [docker-compose](https://docs.docker.com/compose/) installed on your machine.\n\nWant to get up and running quickly? Follow these steps:\n\n1. [Fork this repository](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/about-forks) to your GitHub account.\n\nAfter forking the repository, clone it to your local device by using the following command:\n\n```sh\ngit clone https://github.com/<your-username>/documenso\n```\n\n2. Set up your `.env` file using the recommendations in the `.env.example` file. Alternatively, just run `cp .env.example .env` to get started with our handpicked defaults.\n\n3. Run `npm run dx` in the root directory\n\n   - This will spin up a postgres database and inbucket mailserver in a docker container.\n\n4. Run `npm run dev` in the root directory\n\n5. Want it even faster? Just use\n\n```sh\nnpm run d\n```\n\n#### Access Points for Your Application\n\n1. **App** - http://localhost:3000\n2. **Incoming Mail Access** - http://localhost:9000\n3. **Database Connection Details**\n\n   - **Port**: 54320\n   - **Connection**: Use your favorite database client to connect using the provided port.\n\n4. **S3 Storage Dashboard** - http://localhost:9001\n\n## Developer Setup\n\n### Manual Setup\n\nFollow these steps to setup Documenso on your local machine:\n\n1. [Fork this repository](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/about-forks) to your GitHub account.\n\nAfter forking the repository, clone it to your local device by using the following command:\n\n```sh\ngit clone https://github.com/<your-username>/documenso\n```\n\n2. Run `npm i` in the root directory\n\n3. Create your `.env` from the `.env.example`. You can use `cp .env.example .env` to get started with our handpicked defaults.\n\n4. Set the following environment variables:\n\n   - NEXTAUTH_SECRET\n   - NEXT_PUBLIC_WEBAPP_URL\n   - NEXT_PRIVATE_DATABASE_URL\n   - NEXT_PRIVATE_DIRECT_DATABASE_URL\n   - NEXT_PRIVATE_SMTP_FROM_NAME\n   - NEXT_PRIVATE_SMTP_FROM_ADDRESS\n\n5. Create the database schema by running `npm run prisma:migrate-dev`\n\n6. Run `npm run translate:compile` in the root directory to compile lingui\n\n7. Run `npm run dev` in the root directory to start\n\n8. Register a new user at http://localhost:3000/signup\n\n---\n\n- Optional: Seed the database using `npm run prisma:seed -w @documenso/prisma` to create a test user and document.\n- Optional: Create your own signing certificate.\n  - To generate your own using these steps and a Linux Terminal or Windows Subsystem for Linux (WSL), see **[Create your own signing certificate](./SIGNING.md)**.\n\n### Run in Gitpod\n\n- Click below to launch a ready-to-use Gitpod workspace in your browser.\n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/documenso/documenso)\n\n### Run in DevContainer\n\nWe support DevContainers for VSCode. [Click here to get started.](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/documenso/documenso)\n\n### Video walkthrough\n\nIf you're a visual learner and prefer to watch a video walkthrough of setting up Documenso locally, check out this video:\n\n[![Watch the video](https://img.youtube.com/vi/Y0ppIQrEnZs/hqdefault.jpg)](https://youtu.be/Y0ppIQrEnZs)\n\n## Docker\n\nWe provide a Docker container for Documenso, which is published on both DockerHub and GitHub Container Registry.\n\n- DockerHub: [https://hub.docker.com/r/documenso/documenso](https://hub.docker.com/r/documenso/documenso)\n- GitHub Container Registry: [https://ghcr.io/documenso/documenso](https://ghcr.io/documenso/documenso)\n\nYou can pull the Docker image from either of these registries and run it with your preferred container hosting provider.\n\nPlease note that you will need to provide environment variables for connecting to the database, mailserver, and so forth.\n\nFor detailed instructions on how to configure and run the Docker container, please refer to the [Docker README](./docker/README.md) in the `docker` directory.\n\n## Self Hosting\n\nWe support a variety of deployment methods, and are actively working on adding more. Stay tuned for updates!\n\n### Fetch, configure, and build\n\nFirst, clone the code from Github:\n\n```\ngit clone https://github.com/documenso/documenso.git\n```\n\nThen, inside the `documenso` folder, copy the example env file:\n\n```\ncp .env.example .env\n```\n\nThe following environment variables must be set:\n\n- `NEXTAUTH_SECRET`\n- `NEXT_PUBLIC_WEBAPP_URL`\n- `NEXT_PRIVATE_DATABASE_URL`\n- `NEXT_PRIVATE_DIRECT_DATABASE_URL`\n- `NEXT_PRIVATE_SMTP_FROM_NAME`\n- `NEXT_PRIVATE_SMTP_FROM_ADDRESS`\n\n> If you are using a reverse proxy in front of Documenso, don't forget to provide the public URL for the `NEXT_PUBLIC_WEBAPP_URL` variable!\n\nNow you can install the dependencies and build it:\n\n```\nnpm i\nnpm run build\nnpm run prisma:migrate-deploy\n```\n\nFinally, you can start it with:\n\n```\ncd apps/remix\nnpm run start\n```\n\nThis will start the server on `localhost:3000`. For now, any reverse proxy can then do the frontend and SSL termination.\n\n> If you want to run with another port than 3000, you can start the application with `next -p <ANY PORT>` from the `apps/remix` folder.\n\n### Run as a service\n\nYou can use a systemd service file to run the app. Here is a simple example of the service running on port 3500 (using 3000 by default):\n\n```bash\n[Unit]\nDescription=documenso\nAfter=network.target\n\n[Service]\nEnvironment=PATH=/path/to/your/node/binaries\nType=simple\nUser=www-data\nWorkingDirectory=/var/www/documenso/apps/remix\nExecStart=/usr/bin/next start -p 3500\nTimeoutSec=15\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n```\n\n### Railway\n\n[![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/template/bG6D4p)\n\n### Render\n\n[![Deploy to Render](https://render.com/images/deploy-to-render-button.svg)](https://render.com/deploy?repo=https://github.com/documenso/documenso)\n\n### Koyeb\n\n[![Deploy to Koyeb](https://www.koyeb.com/static/images/deploy/button.svg)](https://app.koyeb.com/deploy?type=git&repository=github.com/documenso/documenso&branch=main&name=documenso-app&builder=dockerfile&dockerfile=/docker/Dockerfile)\n\n## Elestio\n\n[![Deploy on Elestio](https://elest.io/images/logos/deploy-to-elestio-btn.png)](https://elest.io/open-source/documenso)\n\n## Troubleshooting\n\n### I'm not receiving any emails when using the developer quickstart.\n\nWhen using the developer quickstart, an [Inbucket](https://inbucket.org/) server will be spun up in a docker container that will store all outgoing emails locally for you to view.\n\nThe Web UI can be found at http://localhost:9000, while the SMTP port will be on localhost:2500.\n\n### Support IPv6\n\nIf you are deploying to a cluster that uses only IPv6, You can use a custom command to pass a parameter to the Remix start command\n\nFor local docker run\n\n```bash\ndocker run -it documenso:latest npm run start -- -H ::\n```\n\nFor k8s or docker-compose\n\n```yaml\ncontainers:\n  - name: documenso\n    image: documenso:latest\n    imagePullPolicy: IfNotPresent\n    command:\n      - npm\n    args:\n      - run\n      - start\n      - --\n      - -H\n      - '::'\n```\n\n### I can't see environment variables in my package scripts.\n\nWrap your package script with the `with:env` script like such:\n\n```\nnpm run with:env -- npm run myscript\n```\n\nThe same can be done when using `npx` for one of the bin scripts:\n\n```\nnpm run with:env -- npx myscript\n```\n\nThis will load environment variables from your `.env` and `.env.local` files.\n\n## Repo Activity\n\n![Repository Activity](https://repobeats.axiom.co/api/embed/622a2e9aa709696f7226304b5b7178a5741b3868.svg)\n",
      "stars_today": 37
    },
    {
      "id": 41889031,
      "name": "NewPipe",
      "full_name": "TeamNewPipe/NewPipe",
      "description": "A libre lightweight streaming front-end for Android.",
      "html_url": "https://github.com/TeamNewPipe/NewPipe",
      "stars": 36451,
      "forks": 3394,
      "language": "Java",
      "topics": [
        "4k",
        "android",
        "bandcamp",
        "download-videos",
        "newpipe",
        "peertube",
        "soundcloud",
        "translation",
        "video",
        "watch",
        "youtube-video"
      ],
      "created_at": "2015-09-03T23:39:26Z",
      "updated_at": "2026-01-25T01:53:44Z",
      "pushed_at": "2026-01-23T16:41:22Z",
      "open_issues": 1361,
      "owner": {
        "login": "TeamNewPipe",
        "avatar_url": "https://avatars.githubusercontent.com/u/22159318?v=4"
      },
      "readme": "<h3 align=\"center\">We are <i>rewriting</i> large chunks of the codebase, to bring about <a href=\"https://newpipe.net/blog/pinned/announcement/newpipe-0.27.6-rewrite-team-states/#the-refactor\">a modern and stable NewPipe</a>! You can download nightly builds <a href=\"https://github.com/TeamNewPipe/NewPipe-refactor-nightly/releases\">here</a>.</h3>\n<h4 align=\"center\">Please work on the <code>refactor</code> branch if you want to contribute <i>new features</i>. The current codebase is in maintenance mode and will only receive <i>bugfixes</i>.</h4>\n\n<p align=\"center\"><a href=\"https://newpipe.net\"><img src=\"assets/new_pipe_icon_5.png\" width=\"150\"></a></p> \n<h2 align=\"center\"><b>NewPipe</b></h2>\n<h4 align=\"center\">A libre lightweight streaming front-end for Android.</h4>\n\n<p align=\"center\"><a href=\"https://f-droid.org/packages/org.schabi.newpipe/\"><img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on-en.svg\" alt=\"Get it on F-Droid\" width=206/></a></p>\n\n<p align=\"center\">\n<a href=\"https://github.com/TeamNewPipe/NewPipe/releases\" alt=\"GitHub NewPipe releases\"><img src=\"https://img.shields.io/github/release/TeamNewPipe/NewPipe.svg\" ></a>\n<a href=\"https://github.com/TeamNewPipe/NewPipe-nightly/releases\" alt=\"GitHub NewPipe nightly releases\"><img src=\"https://img.shields.io/github/release/TeamNewPipe/NewPipe-nightly.svg?labelColor=purple&label=dev%20nightly\"></a>\n<a href=\"https://github.com/TeamNewPipe/NewPipe-refactor-nightly/releases\" alt=\"GitHub NewPipe refactor nightly releases\"><img src=\"https://img.shields.io/github/release/TeamNewPipe/NewPipe-refactor-nightly.svg?labelColor=purple&label=refactor%20nightly\"></a>\n<a href=\"https://www.gnu.org/licenses/gpl-3.0\" alt=\"License: GPLv3\"><img src=\"https://img.shields.io/badge/License-GPL%20v3-blue.svg\"></a>\n<a href=\"https://github.com/TeamNewPipe/NewPipe/actions\" alt=\"Build Status\"><img src=\"https://github.com/TeamNewPipe/NewPipe/actions/workflows/ci.yml/badge.svg?branch=dev&event=push\"></a>\n<a href=\"https://hosted.weblate.org/engage/newpipe/\" alt=\"Translation Status\"><img src=\"https://hosted.weblate.org/widgets/newpipe/-/svg-badge.svg\"></a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://web.libera.chat/#newpipe\" alt=\"IRC channel: #newpipe\"><img src=\"https://img.shields.io/badge/IRC%20chat-%23newpipe-brightgreen.svg\"></a>\n<a href=\"https://matrix.to/#/#newpipe:matrix.newpipe-ev.de\" alt=\"Matrix channel: #newpipe\"><img src=\"https://img.shields.io/badge/Matrix%20chat-%23newpipe-blue\"></a>\n</p>\n\n<hr>\n<p align=\"center\"><a href=\"#screenshots\">Screenshots</a> &bull; <a href=\"#supported-services\">Supported Services</a> &bull; <a href=\"#description\">Description</a> &bull; <a href=\"#features\">Features</a> &bull; <a href=\"#installation-and-updates\">Installation and updates</a> &bull; <a href=\"#contribution\">Contribution</a> &bull; <a href=\"#donate\">Donate</a> &bull; <a href=\"#license\">License</a></p>\n<p align=\"center\"><a href=\"https://newpipe.net\">Website</a> &bull; <a href=\"https://newpipe.net/blog/\">Blog</a> &bull; <a href=\"https://newpipe.net/FAQ/\">FAQ</a> &bull; <a href=\"https://newpipe.net/press/\">Press</a></p>\n<hr>\n\n*Read this document in other languages: [Deutsch](doc/README.de.md), [English](README.md), [EspaÃ±ol](doc/README.es.md), [FranÃ§ais](doc/README.fr.md), [à¤¹à¤¿à¤¨à¥à¤¦à¥€](doc/README.hi.md), [Italiano](doc/README.it.md), [í•œêµ­ì–´](doc/README.ko.md), [PortuguÃªs Brasil](doc/README.pt_BR.md), [Polski](doc/README.pl.md), [à¨ªà©°à¨œà¨¾à¨¬à©€ ](doc/README.pa.md), [æ—¥æœ¬èª](doc/README.ja.md), [RomÃ¢nÄƒ](doc/README.ro.md), [Soomaali](doc/README.so.md), [TÃ¼rkÃ§e](doc/README.tr.md), [æ­£é«”ä¸­æ–‡](doc/README.zh_TW.md), [à¦…à¦¸à¦®à§€à¦¯à¦¼à¦¾](doc/README.asm.md), [Ğ¡Ñ€Ğ¿ÑĞºĞ¸](doc/README.sr.md), [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README.ar.md)* \n\n> [!warning]\n> <b>THIS APP IS IN BETA, SO YOU MAY ENCOUNTER BUGS. IF YOU DO, OPEN AN ISSUE IN OUR GITHUB REPOSITORY BY FILLING OUT THE ISSUE TEMPLATE.</b>\n> \n> <b>PUTTING NEWPIPE, OR ANY FORK OF IT, INTO THE GOOGLE PLAY STORE VIOLATES THEIR TERMS AND CONDITIONS.</b>\n\n## Screenshots\n\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/00.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/00.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/01.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/01.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/02.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/02.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/03.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/03.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/04.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/04.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/05.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/05.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/06.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/06.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/07.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/07.png)\n[<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/08.png\" width=160>](fastlane/metadata/android/en-US/images/phoneScreenshots/08.png)\n<br/><br/>\n[<img src=\"fastlane/metadata/android/en-US/images/tenInchScreenshots/09.png\" width=405>](fastlane/metadata/android/en-US/images/tenInchScreenshots/09.png)\n[<img src=\"fastlane/metadata/android/en-US/images/tenInchScreenshots/10.png\" width=405>](fastlane/metadata/android/en-US/images/tenInchScreenshots/10.png)\n\n### Supported Services\n\nNewPipe currently supports these services:\n\n<!-- We link to the service websites separately to avoid people accidentally opening a website they didn't want to. -->\n* YouTube ([website](https://www.youtube.com/)) and YouTube Music ([website](https://music.youtube.com/)) ([wiki](https://en.wikipedia.org/wiki/YouTube))\n* PeerTube ([website](https://joinpeertube.org/)) and all its instances (open the website to know what that means!) ([wiki](https://en.wikipedia.org/wiki/PeerTube))\n* Bandcamp ([website](https://bandcamp.com/)) ([wiki](https://en.wikipedia.org/wiki/Bandcamp))\n* SoundCloud ([website](https://soundcloud.com/)) ([wiki](https://en.wikipedia.org/wiki/SoundCloud))\n* media.ccc.de ([website](https://media.ccc.de/)) ([wiki](https://en.wikipedia.org/wiki/Chaos_Computer_Club))\n\nAs you can see, NewPipe supports multiple video and audio services. Though it started off with YouTube, other people have added more services over the years, making NewPipe more and more versatile!\n\nPartially due to circumstance, and partially due to its popularity, YouTube is the best supported out of these services. If you use or are familiar with any of these other services, please help us improve support for them! We're looking for maintainers for SoundCloud and PeerTube.\n\nIf you intend to add a new service, please get in touch with us first! Our [docs](https://teamnewpipe.github.io/documentation/) provide more information on how a new service can be added to the app and to the [NewPipe Extractor](https://github.com/TeamNewPipe/NewPipeExtractor).\n\n## Description\n\nNewPipe works by fetching the required data from the official API (e.g. PeerTube) of the service you're using. If the official API is restricted (e.g. YouTube) for our purposes, or is proprietary, the app parses the website or uses an internal API instead. This means that you don't need an account on any service to use NewPipe.\n\nAlso, since they are free and open source software, neither the app nor the Extractor use any proprietary libraries or frameworks, such as Google Play Services. This means you can use NewPipe on devices or custom ROMs that do not have Google apps installed.\n\n### Features\n\n* Watch videos at resolutions up to 4K\n* Listen to audio in the background, only loading the audio stream to save data\n* Popup mode (floating player, aka Picture-in-Picture)\n* Watch live streams\n* Show/hide subtitles/closed captions\n* Search videos and audios (on YouTube, you can specify the content language as well)\n* Enqueue videos (and optionally save them as local playlists)\n* Show/hide general information about videos (such as description and tags)\n* Show/hide next/related videos\n* Show/hide comments\n* Search videos, audios, channels, playlists and albums\n* Browse videos and audios within a channel\n* Subscribe to channels (yes, without logging into any account!)\n* Get notifications about new videos from channels you're subscribed to\n* Create and edit channel groups (for easier browsing and management)\n* Browse video feeds generated from your channel groups\n* View and search your watch history\n* Search and watch playlists (these are remote playlists, which means they're fetched from the service you're browsing)\n* Create and edit local playlists (these are created and saved within the app, and have nothing to do with any service)\n* Download videos/audios/subtitles (closed captions)\n* Open in Kodi\n* Watch/Block age-restricted material\n\n<!-- Hidden span to keep old links compatible. You should remove this span if you're translating the README into another language.-->\n<span id=\"updates\"></span>\n\n## Installation and updates\nYou can install NewPipe using one of the following methods:\n 1. Add our custom repo to F-Droid and install it from there. The instructions are here: https://newpipe.net/FAQ/tutorials/install-add-fdroid-repo/\n 2. Download the APK from [GitHub Releases](https://github.com/TeamNewPipe/NewPipe/releases), [compare the signing key](#apk-info) and install it.\n 3. Update via F-Droid. This is the slowest method of getting updates, as F-Droid must recognize changes, build the APK itself, sign it, and then push the update to users.\n 4. Build a debug APK yourself. This is the fastest way to get new features on your device, but is much more complicated, so we recommend using one of the other methods.\n 5. If you're interested in a specific feature or bugfix provided in a Pull Request in this repo, you can also download its APK from within the PR. Read the PR description for instructions. The great thing about PR-specific APKs is that they're installed side-by-side the official app, so you don't have to worry about losing your data or messing anything up.\n\nWe recommend method 1 for most users. APKs installed using method 1 or 2 are compatible with each other (meaning that if you installed NewPipe using either method 1 or 2, you can also update NewPipe using the other), but not with those installed using method 3. This is due to the same signing key (ours) being used for 1 and 2, but a different signing key (F-Droid's) being used for 3. Building a debug APK using method 4 excludes a key entirely. Signing keys help ensure that a user isn't tricked into installing a malicious update to an app. When using method 5, each APK is signed with a different random key supplied by GitHub Actions, so you cannot even update it. You will have to backup and restore the app data each time you wish to use a new APK.\n\nIn the meanwhile, if you want to switch sources for some reason (e.g. NewPipe's core functionality breaks and F-Droid doesn't have the latest update yet), we recommend following this procedure:\n1. Back up your data via Settings > Backup and Restore > Export Database so you keep your history, subscriptions, and playlists\n2. Uninstall NewPipe\n3. Download the APK from the new source and install it\n4. Import the data from step 1 via Settings > Backup and Restore > Import Database\n\n> [!Note]\n> When you're importing a database into the official app, always make sure that it is the one you exported _from_ the official app. If you import a database exported from an APK other than the official app, it may break things. Such an action is unsupported, and you should only do so when you're absolutely certain you know what you're doing.\n\n### APK Info\n\nThis is the SHA fingerprint of NewPipe's signing key to verify downloaded APKs which are signed by us. The fingerprint is also available on [NewPipe's website](https://newpipe.net#download). This is relevant for method 2.\n```\nCB:84:06:9B:D6:81:16:BA:FA:E5:EE:4E:E5:B0:8A:56:7A:A6:D8:98:40:4E:7C:B1:2F:9E:75:6D:F5:CF:5C:AB\n```\n\n## Contribution\nWhether you have ideas, translations, design changes, code cleaning, or even major code changes, help is always welcome. The app gets better and better with each contribution, no matter how big or small! If you'd like to get involved, check our [contribution notes](.github/CONTRIBUTING.md).\n\n<a href=\"https://hosted.weblate.org/engage/newpipe/\">\n<img src=\"https://hosted.weblate.org/widgets/newpipe/-/287x66-grey.png\" alt=\"Translation status\" />\n</a>\n\n## Donate\nIf you like NewPipe, you're welcome to send a donation. We prefer Liberapay, as it is both open-source and non-profit. For further info on donating to NewPipe, please visit our [website](https://newpipe.net/donate).\n\n<table>\n  <tr>\n    <td><a href=\"https://liberapay.com/TeamNewPipe/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/Liberapay_logo_v2_white-on-yellow.svg\" alt=\"Liberapay\" width=\"80px\" ></a></td>\n    <td><a href=\"https://liberapay.com/TeamNewPipe/\"><img src=\"assets/liberapay_qr_code.png\" alt=\"Visit NewPipe at liberapay.com\" width=\"100px\"></a></td>\n    <td><a href=\"https://liberapay.com/TeamNewPipe/donate\"><img src=\"assets/liberapay_donate_button.svg\" alt=\"Donate via Liberapay\" height=\"35px\"></a></td>\n  </tr>\n</table>\n\n## Privacy Policy\n\nThe NewPipe project aims to provide a private, anonymous experience for using web-based media services. Therefore, the app does not collect any data without your consent. NewPipe's privacy policy explains in detail what data is sent and stored when you send a crash report, or leave a comment in our blog. You can find the document [here](https://newpipe.net/legal/privacy/).\n\n## License\n[![GNU GPLv3 Image](https://www.gnu.org/graphics/gplv3-127x51.png)](https://www.gnu.org/licenses/gpl-3.0.en.html)  \n\nNewPipe is Free Software: You can use, study, share, and improve it at will. Specifically you can redistribute and/or modify it under the terms of the [GNU General Public License](https://www.gnu.org/licenses/gpl.html) as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n",
      "stars_today": 36
    },
    {
      "id": 1060001762,
      "name": "astron-agent",
      "full_name": "iflytek/astron-agent",
      "description": "Enterprise-grade, commercial-friendly agentic workflow platform for building next-generation SuperAgents.",
      "html_url": "https://github.com/iflytek/astron-agent",
      "stars": 8874,
      "forks": 1113,
      "language": "Java",
      "topics": [
        "agent",
        "agentic-workflow",
        "ai",
        "enterprise",
        "llm",
        "low-code",
        "mcp",
        "multi-agent",
        "next-gen",
        "orchestration",
        "python",
        "superagent",
        "workflow"
      ],
      "created_at": "2025-09-19T08:46:01Z",
      "updated_at": "2026-01-25T01:42:41Z",
      "pushed_at": "2026-01-24T07:19:15Z",
      "open_issues": 69,
      "owner": {
        "login": "iflytek",
        "avatar_url": "https://avatars.githubusercontent.com/u/26786495?v=4"
      },
      "readme": "[![Astron_Readme](./docs/imgs/Astron_Readme.png)](https://agent.xfyun.cn)\n\n<div align=\"center\">\n\n[![License](https://img.shields.io/badge/license-apache2.0-blue.svg)](LICENSE)\n[![GitHub Stars](https://img.shields.io/github/stars/iflytek/astron-agent?style=social)](https://github.com/iflytek/astron-agent/stargazers)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/iflytek/astron-agent)\n\nEnglish | [ç®€ä½“ä¸­æ–‡](docs/README-zh.md)\n\n</div>\n\n## ğŸ”­ What is Astron Agent\nAstron Agent is an **enterprise-grade, commercial-friendly** Agentic Workflow development platform that integrates AI workflow orchestration, model management, AI and MCP tool integration, RPA automation, and team collaboration features.\nThe platform supports **high-availability** deployment, enabling organizations to rapidly build **scalable, production-ready** intelligent agent applications and establish their AI foundation for the future.\n\n### Why Choose Astron Agent?\n- **Stable and Reliable**: Built on the same core technology as the iFLYTEK Astron Agent Platform, providing enterprise-grade reliability with a fully available high-availability version open source.\n- **Cross-System Integration**: Natively integrates intelligent RPA, efficiently connecting internal and external enterprise systems, enabling seamless interaction between Agents and enterprise systems.\n- **Enterprise-Grade Open Ecosystem**: Deeply compatible with various industry models and tools, supporting custom extensions and flexibly adapting to diverse enterprise scenarios.\n- **Business-Friendly**: Released under the Apache 2.0 License, with no commercial restrictions, allowing free commercial use.\n\n### Key Features\n- **Enterprise-Grade High Availability:** Full-stack capabilities for development, building, optimization, and management. Supports one-click deployment with strong reliability.  \n- **Intelligent RPA Integration:** Enables cross-system process automation, empowering Agents with controllable execution to achieve a complete loop â€œfrom decision to action.â€  \n- **Ready-to-Use Tool Ecosystem:** Integrates massive AI capabilities and tools from the [iFLYTEK Open Platform](https://www.xfyun.cn), validated by millions of developers, supporting plug-and-play integration without extra development.  \n- **Flexible Large Model Support:** Offers diverse access methods, from rapid API-based model access and validation to one-click deployment of enterprise-level MaaS (Model as a Service) on-premises clusters, meeting needs of all scales.  \n\n## ğŸ“° News\n\n- **[Astron Hackathon @ 2025 iFLYTEK Global 1024 Developer Festival](https://luma.com/9zmbc6xb)**  ğŸ¤ <a href=\"https://github.com/mklong\"><img src=\"https://github.com/mklong.png\" width=\"20\" align=\"center\" /> @mklong</a>\n- **[Astron Agent Zhengzhou Meetup](https://github.com/iflytek/astron-agent/discussions/672)**  ğŸ¤ <a href=\"https://github.com/lyj715824\"><img src=\"https://github.com/lyj715824.png\" width=\"20\" align=\"center\" /> @lyj715824</a> <a href=\"https://github.com/wowo-zZ\"><img src=\"https://github.com/wowo-zZ.png\" width=\"20\" align=\"center\" /> @wowo-zZ</a>\n- **[Astron on Campus @ Zhejiang University of Finance and Economics](https://mp.weixin.qq.com/s/oim_Z0ckgpFwf5jOskoJuA)**  ğŸ¤ <a href=\"https://github.com/lyj715824\"><img src=\"https://github.com/lyj715824.png\" width=\"20\" align=\"center\" /> @lyj715824</a>\n- **[Astron Agent & RPA Â· Qingdao Meetup Brings Agentic AI!](https://github.com/iflytek/astron-agent/discussions/740)**  ğŸ¤ <a href=\"https://github.com/vsxd\"><img src=\"https://github.com/vsxd.png\" width=\"20\" align=\"center\" /> @vsxd</a> <a href=\"https://github.com/doctorbruce\"><img src=\"https://github.com/doctorbruce.png\" width=\"20\" align=\"center\" /> @doctorbruce</a> <a href=\"https://github.com/MaxwellJean\"><img src=\"https://github.com/MaxwellJean.png\" width=\"20\" align=\"center\" /> @MaxwellJean</a>\n- **[Astron Training Camp Â· Cohort #1](https://www.aidaxue.com/astronCamp)**  ğŸ¤ <a href=\"https://github.com/lyj715824\"><img src=\"https://github.com/lyj715824.png\" width=\"20\" align=\"center\" /> @lyj715824</a>\n- **[Astron Talk @ Chongqing Mini Tech Fest](https://mp.weixin.qq.com/s/HROf1zZpkPVDSsCQrv2jRg)**  ğŸ¤ <a href=\"https://github.com/lyj715824\"><img src=\"https://github.com/lyj715824.png\" width=\"20\" align=\"center\" /> @lyj715824</a>\n\n## ğŸš€ Quick Start\n\nWe offer two deployment methods to meet different scenarios:\n\n### Option 1: Docker Compose (Recommended for Quick Start)\n\n```bash\n# Clone the repository\ngit clone https://github.com/iflytek/astron-agent.git\n\n# Navigate to astronAgent directory\ncd docker/astronAgent\n\n# Copy environment configuration\ncp .env.example .env\n\n# Configure environment variables\nvim .env\n```\n\nFor environment variable configuration, please refer to the documentation:[DEPLOYMENT_GUIDE_WITH_AUTH.md](https://github.com/iflytek/astron-agent/blob/main/docs/DEPLOYMENT_GUIDE_WITH_AUTH.md#step-2-configure-astronagent-environment-variables)\n\n```bash\n# Start all services (including Casdoor)\ndocker compose -f docker-compose-with-auth.yaml up -d\n```\n\n#### ğŸ“Š Service Access Addresses\n\nAfter startup, you can access the services at the following addresses:\n\n**Authentication Service**\n- **Casdoor Admin Interface**: http://localhost:8000\n\n**AstronAgent**\n- **Application Frontend (nginx proxy)**: http://localhost/\n\n**Note**\n- Default Casdoor login credentials: username: `admin`, password: `123`\n\n### Option 2: Helm (For Kubernetes Environments)\n\n> ğŸš§ **Note**: Helm charts are currently under development. Stay tuned for updates!\n\n```bash\n# Coming soon\n# helm repo add astron-agent https://iflytek.github.io/astron-agent\n# helm install astron-agent astron-agent/astron-agent\n```\n\n---\n\n> ğŸ“– For complete deployment instructions and configuration details, see [Deployment Guide](docs/DEPLOYMENT_GUIDE_WITH_AUTH.md)\n\n## ğŸ“– Using Astron Cloud\n\n**Try Astron**ï¼šAstron Cloud provides a ready-to-use environment for creating and managing Agents.Free quick access [https://agent.xfyun.cn](https://agent.xfyun.cn).\n\n**Using Guide**ï¼šFor detailed usage instructions, please refer to [Quick Start Guide](https://www.xfyun.cn/doc/spark/Agent03-%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.html).\n\n## ğŸ“š Documentation\n\n- [ğŸš€ Deployment Guide](docs/DEPLOYMENT_GUIDE.md)\n- [ğŸ”§ Configuration](docs/CONFIGURATION.md)\n- [ğŸš€ Quick Start](https://www.xfyun.cn/doc/spark/Agent02-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B.html)\n- [ğŸ“˜ Development Guide](https://www.xfyun.cn/doc/spark/Agent03-%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.html#_1-%E6%8C%87%E4%BB%A4%E5%9E%8B%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%80%E5%8F%91)\n- [ğŸ’¡ Best Practices](https://www.xfyun.cn/doc/spark/AgentNew-%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5%E6%A1%88%E4%BE%8B.html)\n- [ğŸ“± Use Cases](https://www.xfyun.cn/doc/spark/Agent05-%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B.html)\n- [â“ FAQ](https://www.xfyun.cn/doc/spark/Agent06-FAQ.html)\n\n## ğŸ¤ Contributing\n\nWe welcome contributions of all kinds! Please see our [Contributing Guide](CONTRIBUTING.md)\n\n## ğŸŒŸ Star History\n\n<div align=\"center\">\n  <img src=\"https://api.star-history.com/svg?repos=iflytek/astron-agent&type=Date\" alt=\"Star History Chart\" width=\"600\">\n</div>\n\n## ğŸ“ Support\n\n- ğŸ’¬ Community Discussion: [GitHub Discussions](https://github.com/iflytek/astron-agent/discussions)\n- ğŸ› Bug Reports: [Issues](https://github.com/iflytek/astron-agent/issues)\n- ğŸ‘¥ WeChat Work Group:\n\n<div align=\"center\">\n  <img src=\"./docs/imgs/WeCom_Group.png\" alt=\"WeChat Work Group\" width=\"300\">\n</div>\n\n## ğŸ“„ Open Source License\n\nThis project is licensed under the [Apache 2.0 License](LICENSE), allowing free use, modification, distribution, and commercial use without any restrictions.\n\n",
      "stars_today": 36
    },
    {
      "id": 481797111,
      "name": "Seal",
      "full_name": "JunkFood02/Seal",
      "description": "ğŸ¦­ Video/Audio Downloader for Android, based on yt-dlp",
      "html_url": "https://github.com/JunkFood02/Seal",
      "stars": 24205,
      "forks": 1035,
      "language": "Kotlin",
      "topics": [
        "android",
        "f-droid",
        "jetpack-compose",
        "kotlin",
        "material-design",
        "youtube-dl",
        "youtube-downloader",
        "yt-dlp"
      ],
      "created_at": "2022-04-15T01:15:25Z",
      "updated_at": "2026-01-24T23:44:47Z",
      "pushed_at": "2025-12-25T15:35:29Z",
      "open_issues": 574,
      "owner": {
        "login": "JunkFood02",
        "avatar_url": "https://avatars.githubusercontent.com/u/69683722?v=4"
      },
      "readme": "<div align=\"center\">\n\n<img width=\"\" src=\"fastlane/metadata/android/en-US/images/icon.png\"  width=160 height=160  align=\"center\">\n\n# Seal\n\n### Video/Audio Downloader for Android\n\n\nEnglish\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-zh_Hans.md\">ç®€ä½“ä¸­æ–‡</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-zh_Hant.md\">ç¹é«”ä¸­æ–‡</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-ar.md\">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-pt.md\">Portuguese</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-ua.md\">Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-th.md\">à¸ à¸²à¸©à¸²à¹„à¸—à¸¢</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-fa.md\">ÙØ§Ø±Ø³ÛŒ</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-it.md\">Italiano</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-az.md\">AzÉ™rbaycanca</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-ru.md\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-sr.md\">Ğ¡Ñ€Ğ¿ÑĞºĞ¸</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-ja.md\">æ—¥æœ¬èª</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-id.md\">Indonesia</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-hi.md\">à¤¹à¤¿à¤‚à¤¦à¥€</a>\n&nbsp;&nbsp;| &nbsp;&nbsp;\n<a href=\"https://github.com/JunkFood02/Seal/blob/main/translations/README-bn.md\">à¦¬à¦¾à¦‚à¦²à¦¾</a>\n\n\n\n[![F-Droid](https://img.shields.io/f-droid/v/com.junkfood.seal?color=b4eb12&label=F-Droid&logo=fdroid&logoColor=1f78d2)](https://f-droid.org/en/packages/com.junkfood.seal)\n[![GitHub release (latest by date)](https://img.shields.io/github/v/release/JunkFood02/Seal?color=black&label=Stable&logo=github)](https://github.com/JunkFood02/Seal/releases/latest/)\n[![GitHub release (latest by date including pre-releases)](https://img.shields.io/github/v/release/JunkFood02/Seal?include_prereleases&label=Preview&logo=Github)](https://github.com/JunkFood02/Seal/releases/)\n[![Keep a Changelog](https://img.shields.io/badge/Changelog-lightgray?style=flat&color=gray&logo=keep-a-changelog)](https://github.com/JunkFood02/Seal/blob/main/CHANGELOG.md)\n[![GitHub all releases](https://img.shields.io/github/downloads/JunkFood02/Seal/total?label=Downloads&logo=github)](https://github.com/JunkFood02/Seal/releases/)\n[![GitHub Repo stars](https://img.shields.io/github/stars/JunkFood02/Seal?style=flat&logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIC05NjAgOTYwIDk2MCIgd2lkdGg9IjI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogIDxwYXRoIGQ9Im0zNTQtMjQ3IDEyNi03NiAxMjYgNzctMzMtMTQ0IDExMS05Ni0xNDYtMTMtNTgtMTM2LTU4IDEzNS0xNDYgMTMgMTExIDk3LTMzIDE0M1pNMjMzLTgwbDY1LTI4MUw4MC01NTBsMjg4LTI1IDExMi0yNjUgMTEyIDI2NSAyODggMjUtMjE4IDE4OSA2NSAyODEtMjQ3LTE0OUwyMzMtODBabTI0Ny0zNTBaIiBzdHlsZT0iZmlsbDogcmdiKDI0NSwgMjI3LCA2Nik7Ii8%2BCjwvc3ZnPg%3D%3D&color=%23f8e444)](https://github.com/JunkFood02/Seal/stargazers)\n[![Supported-Sites](https://img.shields.io/badge/Sites-9cf?style=flat&logo=data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPHN2ZyBoZWlnaHQ9IjI0cHgiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0cHgiIGZpbGw9IiNGRkZGRkYiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+CiAgPHBhdGggZD0iTTExLjk5IDJDNi40NyAyIDIgNi40OCAyIDEyczQuNDcgMTAgOS45OSAxMEMxNy41MiAyMiAyMiAxNy41MiAyMiAxMlMxNy41MiAyIDExLjk5IDJ6bTYuOTMgNmgtMi45NWMtLjMyLTEuMjUtLjc4LTIuNDUtMS4zOC0zLjU2IDEuODQuNjMgMy4zNyAxLjkxIDQuMzMgMy41NnpNMTIgNC4wNGMuODMgMS4yIDEuNDggMi41MyAxLjkxIDMuOTZoLTMuODJjLjQzLTEuNDMgMS4wOC0yLjc2IDEuOTEtMy45NnpNNC4yNiAxNEM0LjEgMTMuMzYgNCAxMi42OSA0IDEycy4xLTEuMzYuMjYtMmgzLjM4Yy0uMDguNjYtLjE0IDEuMzItLjE0IDJzLjA2IDEuMzQuMTQgMkg0LjI2em0uODIgMmgyLjk1Yy4zMiAxLjI1Ljc4IDIuNDUgMS4zOCAzLjU2LTEuODQtLjYzLTMuMzctMS45LTQuMzMtMy41NnptMi45NS04SDUuMDhjLjk2LTEuNjYgMi40OS0yLjkzIDQuMzMtMy41NkM4LjgxIDUuNTUgOC4zNSA2Ljc1IDguMDMgOHpNMTIgMTkuOTZjLS44My0xLjItMS40OC0yLjUzLTEuOTEtMy45NmgzLjgyYy0uNDMgMS40My0xLjA4IDIuNzYtMS45MSAzLjk2ek0xNC4zNCAxNEg5LjY2Yy0uMDktLjY2LS4xNi0xLjMyLS4xNi0ycy4wNy0xLjM1LjE2LTJoNC42OGMuMDkuNjUuMTYgMS4zMi4xNiAycy0uMDcgMS4zNC0uMTYgMnptLjI1IDUuNTZjLjYtMS4xMSAxLjA2LTIuMzEgMS4zOC0zLjU2aDIuOTVjLS45NiAxLjY1LTIuNDkgMi45My00LjMzIDMuNTZ6TTE2LjM2IDE0Yy4wOC0uNjYuMTQtMS4zMi4xNC0ycy0uMDYtMS4zNC0uMTQtMmgzLjM4Yy4xNi42NC4yNiAxLjMxLjI2IDJzLS4xIDEuMzYtLjI2IDJoLTMuMzh6IiBzdHlsZT0iZmlsbDogcmdiKDE2MiwgMTk4LCAyMzQpOyIvPgo8L3N2Zz4=&label=Supported)](https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md)\n[![Telegram Channel](https://img.shields.io/badge/Telegram-Seal-blue?style=flat&logo=telegram)](https://t.me/seal_app)\n[![Matrix](https://img.shields.io/matrix/seal-space%3Amatrix.org?server_fqdn=matrix.org&style=flat&logo=element&label=Matrix&color=%230DBD8B)\n](https://matrix.to/#/#seal-space:matrix.org)\n\n\n</div>\n\n\n## ğŸ“± Screenshots\n\n<div align=\"center\">\n<div>\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/1.jpg\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/2.jpg\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/3.jpg\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/4.jpg\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/5.jpg\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/6.jpg\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/7.jpg\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/8.jpg\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/9.jpg\" width=\"30%\" />\n</div>\n</div>\n\n<br>\n\n## ğŸ“– Features\n\n- Download videos and audio files from video platforms supported by [yt-dlp](https://github.com/yt-dlp/yt-dlp) (formerly youtube-dl).\n\n- Embed metadata and video thumbnail into extracted audio files supported by [mutagen](https://github.com/quodlibet/mutagen).\n\n- Download all videos in the playlist with one click.\n\n- Use embedded [aria2c](https://github.com/aria2/aria2) as external downloader for all your downloads.\n\n- Embed subtitles into the downloaded videos.\n\n- Execute custom yt-dlp commands with templates.\n\n- Manage in-app downloads and custom command templates.\n\n- Easy to use and user-friendly.\n\n- [Material Design 3](https://m3.material.io/) style UI, with dynamic color theme.\n\n- MAD: UI and logic written with pure Kotlin. Single activity, no fragments, only composable destinations.\n\n\n\n## â¬‡ï¸ Download\n\nFor most devices, it is recommended to install the **arm64-v8a** version of the apks\n\n- Download the latest stable version from [GitHub releases](https://github.com/JunkFood02/Seal/releases/latest)\n  - Install the [pre-release](https://github.com/JunkFood02/Seal/releases/) versions to help us test out new features & changes\n\n- Stable releases are also available on [F-Droid](https://f-droid.org/packages/com.junkfood.seal/)\n\n<!-- [<img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\"\n     alt=\"Get it on F-Droid\"\n     height=\"70\">](https://f-droid.org/packages/com.junkfood.seal/) -->\n\n## ğŸ’¬ Contact\n\nJoin our [Telegram Channel](https://t.me/seal_app) or [Matrix Space](https://matrix.to/#/#seal-space:matrix.org) for discussion, announcements, and releases!\n\n## ğŸ’– Sponsors\n\n<p><!-- sponsors --><a href=\"https://github.com/4kaimar\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;4kaimar.png\" width=\"60px\" alt=\"User avatar: \" /></a><a href=\"https://github.com/Cook-I-T\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;Cook-I-T.png\" width=\"60px\" alt=\"User avatar: Cook I.T!\" /></a><a href=\"https://github.com/reallyrealcolby\"><img src=\"https:&#x2F;&#x2F;github.com&#x2F;reallyrealcolby.png\" width=\"60px\" alt=\"User avatar: \" /></a><!-- sponsors --></p>\n\n\nSeal will be always free and open source for everyone. If you like it, please consider [sponsoring me](https://github.com/sponsors/JunkFood02)!\n\n## ğŸ¤ Contributing\n\nContributions are welcome!\n\nYou can help translate Seal on [Hosted Weblate](https://hosted.weblate.org/projects/seal/).\n\t\n[![Translate status](https://hosted.weblate.org/widgets/seal/-/strings/multi-auto.svg)](https://hosted.weblate.org/engage/seal/)\n\t\n>[!Note]\n>\n>For submitting bug reports, feature requests, questions, or any other ideas to improve, please read [CONTRIBUTING.md](https://github.com/JunkFood02/Seal/blob/main/CONTRIBUTING.md) for instructions and guidelines first.\n\n## â­ï¸ Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=JunkFood02/Seal&type=Timeline)](https://star-history.com/#JunkFood02/Seal&Timeline)\n\n\n## ğŸ§± Credits\n\nSeal is a simple GUI of [yt-dlp](https://github.com/yt-dlp/yt-dlp), based on [youtubedl-android](https://github.com/yausername/youtubedl-android)\n\nSome of the UI designs and codes are borrowed from [Read You](https://github.com/Ashinch/ReadYou) and [Music You](https://github.com/Kyant0/MusicYou)\n\n[dvd](https://github.com/yausername/dvd)\n\n[Material color utilities](https://github.com/material-foundation/material-color-utilities)\n\n[Monet](https://github.com/Kyant0/Monet)\n\n## ğŸ“ƒ License\n\n[![GitHub](https://img.shields.io/github/license/JunkFood02/Seal?style=for-the-badge)](https://github.com/JunkFood02/Seal/blob/main/LICENSE)\n\n>[!Warning]\n>\n>Except for the source code licensed under the GPLv3 license,\n>all other parties are prohibited from using Seal's name as a downloader app,\n>and the same is true for Seal's derivatives.\n>Derivatives include but are not limited to forks and unofficial builds.\n\n<div align=\"right\">\n<table><td>\n<a href=\"#start-of-content\">ğŸ‘† Scroll to top</a>\n</td></table>\n</div>\n",
      "stars_today": 35
    },
    {
      "id": 606220217,
      "name": "skip",
      "full_name": "skiptools/skip",
      "description": "Skip enables the creation of native SwiftUI apps for iOS and Android",
      "html_url": "https://github.com/skiptools/skip",
      "stars": 2444,
      "forks": 73,
      "language": "Swift",
      "topics": [
        "android",
        "ios",
        "swift"
      ],
      "created_at": "2023-02-24T21:55:33Z",
      "updated_at": "2026-01-25T02:21:58Z",
      "pushed_at": "2026-01-23T22:35:36Z",
      "open_issues": 94,
      "owner": {
        "login": "skiptools",
        "avatar_url": "https://avatars.githubusercontent.com/u/126294127?v=4"
      },
      "readme": "# Skip\n\n[![CI](https://github.com/skiptools/skip/actions/workflows/ci.yml/badge.svg)](https://github.com/skiptools/skip/actions/workflows/ci.yml)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](https://www.skip.dev/slack)\n\nSkip is a technology for creating dual-platform apps in Swift that run on iOS and Android.\nRead the [documentation](https://skip.dev/docs/) to learn more about Skip.\n\nThis repository hosts the Skip Xcode and SwiftPM build plugin[^plugins]. It works works hand-in-hand with the [skipstone](https://github.com/skiptools/skipstone) tool, which is the binary distribution that powers both the `skip` CLI and the plugin commands. Most of the interesting code is in `skipstone`, but this is the package which Skip projects will directly depend on. For more information on how Skip packages are architected, see the [Framework Structure docs](https://skip.dev/docs/project-types/#framework_structure), or see one of the sample projects like [Hello Skip](https://github.com/skiptools/skipapp-hello).\n\n[^plugins]: Extend package manager functionality with build or command plugins. â€” [https://docs.swift.org/swiftpm/documentation/packagemanagerdocs/plugins/](https://docs.swift.org/swiftpm/documentation/packagemanagerdocs/plugins/)\n\nFor those who want to dive _right_ in without delay, the [Getting Started Guide](https://skip.dev/docs/gettingstarted/) can be summarized like so:\n\n```console\nbrew install skiptools/skip/skip\nskip checkup\nskip create\n```\n\nâ€¦and your Skip project will be created and opened in Xcode.\n\nThis repository also hosts the Skip forums for [support and discussions](http://community.skip.dev) as well as specific [issues and bug reports](https://github.com/skiptools/skip/issues).\n\n\n",
      "stars_today": 35
    },
    {
      "id": 53631945,
      "name": "ripgrep",
      "full_name": "BurntSushi/ripgrep",
      "description": "ripgrep recursively searches directories for a regex pattern while respecting your gitignore",
      "html_url": "https://github.com/BurntSushi/ripgrep",
      "stars": 59223,
      "forks": 2376,
      "language": "Rust",
      "topics": [
        "cli",
        "command-line",
        "command-line-tool",
        "gitignore",
        "grep",
        "recursively-search",
        "regex",
        "ripgrep",
        "rust",
        "search"
      ],
      "created_at": "2016-03-11T02:02:33Z",
      "updated_at": "2026-01-25T01:51:56Z",
      "pushed_at": "2025-12-17T16:38:12Z",
      "open_issues": 111,
      "owner": {
        "login": "BurntSushi",
        "avatar_url": "https://avatars.githubusercontent.com/u/456674?v=4"
      },
      "readme": "ripgrep (rg)\n------------\nripgrep is a line-oriented search tool that recursively searches the current\ndirectory for a regex pattern. By default, ripgrep will respect gitignore rules\nand automatically skip hidden files/directories and binary files. (To disable\nall automatic filtering by default, use `rg -uuu`.) ripgrep has first class\nsupport on Windows, macOS and Linux, with binary downloads available for [every\nrelease](https://github.com/BurntSushi/ripgrep/releases). ripgrep is similar to\nother popular search tools like The Silver Searcher, ack and grep.\n\n[![Build status](https://github.com/BurntSushi/ripgrep/workflows/ci/badge.svg)](https://github.com/BurntSushi/ripgrep/actions)\n[![Crates.io](https://img.shields.io/crates/v/ripgrep.svg)](https://crates.io/crates/ripgrep)\n[![Packaging status](https://repology.org/badge/tiny-repos/ripgrep.svg)](https://repology.org/project/ripgrep/badges)\n\nDual-licensed under MIT or the [UNLICENSE](https://unlicense.org).\n\n\n### CHANGELOG\n\nPlease see the [CHANGELOG](CHANGELOG.md) for a release history.\n\n### Documentation quick links\n\n* [Installation](#installation)\n* [User Guide](GUIDE.md)\n* [Frequently Asked Questions](FAQ.md)\n* [Regex syntax](https://docs.rs/regex/1/regex/#syntax)\n* [Configuration files](GUIDE.md#configuration-file)\n* [Shell completions](FAQ.md#complete)\n* [Building](#building)\n* [Translations](#translations)\n\n\n### Screenshot of search results\n\n[![A screenshot of a sample search with ripgrep](https://burntsushi.net/stuff/ripgrep1.png)](https://burntsushi.net/stuff/ripgrep1.png)\n\n\n### Quick examples comparing tools\n\nThis example searches the entire\n[Linux kernel source tree](https://github.com/BurntSushi/linux)\n(after running `make defconfig && make -j8`) for `[A-Z]+_SUSPEND`, where\nall matches must be words. Timings were collected on a system with an Intel\ni9-12900K 5.2 GHz.\n\nPlease remember that a single benchmark is never enough! See my\n[blog post on ripgrep](https://blog.burntsushi.net/ripgrep/)\nfor a very detailed comparison with more benchmarks and analysis.\n\n| Tool | Command | Line count | Time |\n| ---- | ------- | ---------- | ---- |\n| ripgrep (Unicode) | `rg -n -w '[A-Z]+_SUSPEND'` | 536 | **0.082s** (1.00x) |\n| [hypergrep](https://github.com/p-ranav/hypergrep) | `hgrep -n -w '[A-Z]+_SUSPEND'` | 536 | 0.167s (2.04x) |\n| [git grep](https://www.kernel.org/pub/software/scm/git/docs/git-grep.html) | `git grep -P -n -w '[A-Z]+_SUSPEND'` | 536 | 0.273s (3.34x) |\n| [The Silver Searcher](https://github.com/ggreer/the_silver_searcher) | `ag -w '[A-Z]+_SUSPEND'` | 534 | 0.443s (5.43x) |\n| [ugrep](https://github.com/Genivia/ugrep) | `ugrep -r --ignore-files --no-hidden -I -w '[A-Z]+_SUSPEND'` | 536 | 0.639s (7.82x) |\n| [git grep](https://www.kernel.org/pub/software/scm/git/docs/git-grep.html) | `LC_ALL=C git grep -E -n -w '[A-Z]+_SUSPEND'` | 536 | 0.727s (8.91x) |\n| [git grep (Unicode)](https://www.kernel.org/pub/software/scm/git/docs/git-grep.html) | `LC_ALL=en_US.UTF-8 git grep -E -n -w '[A-Z]+_SUSPEND'` | 536 | 2.670s (32.70x) |\n| [ack](https://github.com/beyondgrep/ack3) | `ack -w '[A-Z]+_SUSPEND'` | 2677 | 2.935s (35.94x) |\n\nHere's another benchmark on the same corpus as above that disregards gitignore\nfiles and searches with a whitelist instead. The corpus is the same as in the\nprevious benchmark, and the flags passed to each command ensure that they are\ndoing equivalent work:\n\n| Tool | Command | Line count | Time |\n| ---- | ------- | ---------- | ---- |\n| ripgrep | `rg -uuu -tc -n -w '[A-Z]+_SUSPEND'` | 447 | **0.063s** (1.00x) |\n| [ugrep](https://github.com/Genivia/ugrep) | `ugrep -r -n --include='*.c' --include='*.h' -w '[A-Z]+_SUSPEND'` | 447 | 0.607s (9.62x) |\n| [GNU grep](https://www.gnu.org/software/grep/) | `grep -E -r -n --include='*.c' --include='*.h' -w '[A-Z]+_SUSPEND'` | 447 | 0.674s (10.69x) |\n\nNow we'll move to searching on single large file. Here is a straight-up\ncomparison between ripgrep, ugrep and GNU grep on a file cached in memory\n(~13GB, [`OpenSubtitles.raw.en.gz`](http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2018/mono/OpenSubtitles.raw.en.gz), decompressed):\n\n| Tool | Command | Line count | Time |\n| ---- | ------- | ---------- | ---- |\n| ripgrep (Unicode) | `rg -w 'Sherlock [A-Z]\\w+'` | 7882 | **1.042s** (1.00x) |\n| [ugrep](https://github.com/Genivia/ugrep) | `ugrep -w 'Sherlock [A-Z]\\w+'` | 7882 | 1.339s (1.28x) |\n| [GNU grep (Unicode)](https://www.gnu.org/software/grep/) | `LC_ALL=en_US.UTF-8 egrep -w 'Sherlock [A-Z]\\w+'` | 7882 | 6.577s (6.31x) |\n\nIn the above benchmark, passing the `-n` flag (for showing line numbers)\nincreases the times to `1.664s` for ripgrep and `9.484s` for GNU grep. ugrep\ntimes are unaffected by the presence or absence of `-n`.\n\nBeware of performance cliffs though:\n\n| Tool | Command | Line count | Time |\n| ---- | ------- | ---------- | ---- |\n| ripgrep (Unicode) | `rg -w '[A-Z]\\w+ Sherlock [A-Z]\\w+'` | 485 | **1.053s** (1.00x) |\n| [GNU grep (Unicode)](https://www.gnu.org/software/grep/) | `LC_ALL=en_US.UTF-8 grep -E -w '[A-Z]\\w+ Sherlock [A-Z]\\w+'` | 485 | 6.234s (5.92x) |\n| [ugrep](https://github.com/Genivia/ugrep) | `ugrep -w '[A-Z]\\w+ Sherlock [A-Z]\\w+'` | 485 | 28.973s (27.51x) |\n\nAnd performance can drop precipitously across the board when searching big\nfiles for patterns without any opportunities for literal optimizations:\n\n| Tool | Command | Line count | Time |\n| ---- | ------- | ---------- | ---- |\n| ripgrep | `rg '[A-Za-z]{30}'` | 6749 | **15.569s** (1.00x) |\n| [ugrep](https://github.com/Genivia/ugrep) | `ugrep -E '[A-Za-z]{30}'` | 6749 | 21.857s (1.40x) |\n| [GNU grep](https://www.gnu.org/software/grep/) | `LC_ALL=C grep -E '[A-Za-z]{30}'` | 6749 | 32.409s (2.08x) |\n| [GNU grep (Unicode)](https://www.gnu.org/software/grep/) | `LC_ALL=en_US.UTF-8 grep -E '[A-Za-z]{30}'` | 6795 | 8m30s (32.74x) |\n\nFinally, high match counts also tend to both tank performance and smooth\nout the differences between tools (because performance is dominated by how\nquickly one can handle a match and not the algorithm used to detect the match,\ngenerally speaking):\n\n| Tool | Command | Line count | Time |\n| ---- | ------- | ---------- | ---- |\n| ripgrep | `rg the` | 83499915 | **6.948s** (1.00x) |\n| [ugrep](https://github.com/Genivia/ugrep) | `ugrep the` | 83499915 | 11.721s (1.69x) |\n| [GNU grep](https://www.gnu.org/software/grep/) | `LC_ALL=C grep the` | 83499915 | 15.217s (2.19x) |\n\n### Why should I use ripgrep?\n\n* It can replace many use cases served by other search tools\n  because it contains most of their features and is generally faster. (See\n  [the FAQ](FAQ.md#posix4ever) for more details on whether ripgrep can truly\n  replace grep.)\n* Like other tools specialized to code search, ripgrep defaults to\n  [recursive search](GUIDE.md#recursive-search) and does [automatic\n  filtering](GUIDE.md#automatic-filtering). Namely, ripgrep won't search files\n  ignored by your `.gitignore`/`.ignore`/`.rgignore` files, it won't search\n  hidden files and it won't search binary files. Automatic filtering can be\n  disabled with `rg -uuu`.\n* ripgrep can [search specific types of files](GUIDE.md#manual-filtering-file-types).\n  For example, `rg -tpy foo` limits your search to Python files and `rg -Tjs\n  foo` excludes JavaScript files from your search. ripgrep can be taught about\n  new file types with custom matching rules.\n* ripgrep supports many features found in `grep`, such as showing the context\n  of search results, searching multiple patterns, highlighting matches with\n  color and full Unicode support. Unlike GNU grep, ripgrep stays fast while\n  supporting Unicode (which is always on).\n* ripgrep has optional support for switching its regex engine to use PCRE2.\n  Among other things, this makes it possible to use look-around and\n  backreferences in your patterns, which are not supported in ripgrep's default\n  regex engine. PCRE2 support can be enabled with `-P/--pcre2` (use PCRE2\n  always) or `--auto-hybrid-regex` (use PCRE2 only if needed). An alternative\n  syntax is provided via the `--engine (default|pcre2|auto)` option.\n* ripgrep has [rudimentary support for replacements](GUIDE.md#replacements),\n  which permit rewriting output based on what was matched.\n* ripgrep supports [searching files in text encodings](GUIDE.md#file-encoding)\n  other than UTF-8, such as UTF-16, latin-1, GBK, EUC-JP, Shift_JIS and more.\n  (Some support for automatically detecting UTF-16 is provided. Other text\n  encodings must be specifically specified with the `-E/--encoding` flag.)\n* ripgrep supports searching files compressed in a common format (brotli,\n  bzip2, gzip, lz4, lzma, xz, or zstandard) with the `-z/--search-zip` flag.\n* ripgrep supports\n  [arbitrary input preprocessing filters](GUIDE.md#preprocessor)\n  which could be PDF text extraction, less supported decompression, decrypting,\n  automatic encoding detection and so on.\n* ripgrep can be configured via a\n  [configuration file](GUIDE.md#configuration-file).\n\nIn other words, use ripgrep if you like speed, filtering by default, fewer\nbugs and Unicode support.\n\n\n### Why shouldn't I use ripgrep?\n\nDespite initially not wanting to add every feature under the sun to ripgrep,\nover time, ripgrep has grown support for most features found in other file\nsearching tools. This includes searching for results spanning across multiple\nlines, and opt-in support for PCRE2, which provides look-around and\nbackreference support.\n\nAt this point, the primary reasons not to use ripgrep probably consist of one\nor more of the following:\n\n* You need a portable and ubiquitous tool. While ripgrep works on Windows,\n  macOS and Linux, it is not ubiquitous and it does not conform to any\n  standard such as POSIX. The best tool for this job is good old grep.\n* There still exists some other feature (or bug) not listed in this README that\n  you rely on that's in another tool that isn't in ripgrep.\n* There is a performance edge case where ripgrep doesn't do well where another\n  tool does do well. (Please file a bug report!)\n* ripgrep isn't possible to install on your machine or isn't available for your\n  platform. (Please file a bug report!)\n\n\n### Is it really faster than everything else?\n\nGenerally, yes. A large number of benchmarks with detailed analysis for each is\n[available on my blog](https://blog.burntsushi.net/ripgrep/).\n\nSummarizing, ripgrep is fast because:\n\n* It is built on top of\n  [Rust's regex engine](https://github.com/rust-lang/regex).\n  Rust's regex engine uses finite automata, SIMD and aggressive literal\n  optimizations to make searching very fast. (PCRE2 support can be opted into\n  with the `-P/--pcre2` flag.)\n* Rust's regex library maintains performance with full Unicode support by\n  building UTF-8 decoding directly into its deterministic finite automaton\n  engine.\n* It supports searching with either memory maps or by searching incrementally\n  with an intermediate buffer. The former is better for single files and the\n  latter is better for large directories. ripgrep chooses the best searching\n  strategy for you automatically.\n* Applies your ignore patterns in `.gitignore` files using a\n  [`RegexSet`](https://docs.rs/regex/1/regex/struct.RegexSet.html).\n  That means a single file path can be matched against multiple glob patterns\n  simultaneously.\n* It uses a lock-free parallel recursive directory iterator, courtesy of\n  [`crossbeam`](https://docs.rs/crossbeam) and\n  [`ignore`](https://docs.rs/ignore).\n\n\n### Feature comparison\n\nAndy Lester, author of [ack](https://beyondgrep.com/), has published an\nexcellent table comparing the features of ack, ag, git-grep, GNU grep and\nripgrep: https://beyondgrep.com/feature-comparison/\n\nNote that ripgrep has grown a few significant new features recently that\nare not yet present in Andy's table. This includes, but is not limited to,\nconfiguration files, passthru, support for searching compressed files,\nmultiline search and opt-in fancy regex support via PCRE2.\n\n\n### Playground\n\nIf you'd like to try ripgrep before installing, there's an unofficial\n[playground](https://codapi.org/ripgrep/) and an [interactive\ntutorial](https://codapi.org/try/ripgrep/).\n\nIf you have any questions about these, please open an issue in the [tutorial\nrepo](https://github.com/nalgeon/tryxinyminutes).\n\n\n### Installation\n\nThe binary name for ripgrep is `rg`.\n\n**[Archives of precompiled binaries for ripgrep are available for Windows,\nmacOS and Linux.](https://github.com/BurntSushi/ripgrep/releases)** Linux and\nWindows binaries are static executables. Users of platforms not explicitly\nmentioned below are advised to download one of these archives.\n\nIf you're a **macOS Homebrew** or a **Linuxbrew** user, then you can install\nripgrep from homebrew-core:\n\n```\n$ brew install ripgrep\n```\n\nIf you're a **MacPorts** user, then you can install ripgrep from the\n[official ports](https://www.macports.org/ports.php?by=name&substr=ripgrep):\n\n```\n$ sudo port install ripgrep\n```\n\nIf you're a **Windows Chocolatey** user, then you can install ripgrep from the\n[official repo](https://chocolatey.org/packages/ripgrep):\n\n```\n$ choco install ripgrep\n```\n\nIf you're a **Windows Scoop** user, then you can install ripgrep from the\n[official bucket](https://github.com/ScoopInstaller/Main/blob/master/bucket/ripgrep.json):\n\n```\n$ scoop install ripgrep\n```\n\nIf you're a **Windows Winget** user, then you can install ripgrep from the\n[winget-pkgs](https://github.com/microsoft/winget-pkgs/tree/master/manifests/b/BurntSushi/ripgrep)\nrepository:\n\n```\n$ winget install BurntSushi.ripgrep.MSVC\n```\n\nIf you're an **Arch Linux** user, then you can install ripgrep from the official repos:\n\n```\n$ sudo pacman -S ripgrep\n```\n\nIf you're a **Gentoo** user, you can install ripgrep from the\n[official repo](https://packages.gentoo.org/packages/sys-apps/ripgrep):\n\n```\n$ sudo emerge sys-apps/ripgrep\n```\n\nIf you're a **Fedora** user, you can install ripgrep from official\nrepositories.\n\n```\n$ sudo dnf install ripgrep\n```\n\nIf you're an **openSUSE** user, ripgrep is included in **openSUSE Tumbleweed**\nand **openSUSE Leap** since 15.1.\n\n```\n$ sudo zypper install ripgrep\n```\n\nIf you're a **CentOS Stream 10** user, you can install ripgrep from the\n[EPEL](https://docs.fedoraproject.org/en-US/epel/getting-started/) repository:\n\n```\n$ sudo dnf config-manager --set-enabled crb\n$ sudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-10.noarch.rpm\n$ sudo dnf install ripgrep\n```\n\nIf you're a **Red Hat 10** user, you can install ripgrep from the\n[EPEL](https://docs.fedoraproject.org/en-US/epel/getting-started/) repository:\n\n```\n$ sudo subscription-manager repos --enable codeready-builder-for-rhel-10-$(arch)-rpms\n$ sudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-10.noarch.rpm\n$ sudo dnf install ripgrep\n```\n\nIf you're a **Rocky Linux 10** user, you can install ripgrep from the\n[EPEL](https://docs.fedoraproject.org/en-US/epel/getting-started/) repository:\n\n```\n$ sudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-10.noarch.rpm\n$ sudo dnf install ripgrep\n```\n\nIf you're a **Nix** user, you can install ripgrep from\n[nixpkgs](https://github.com/NixOS/nixpkgs/blob/master/pkgs/by-name/ri/ripgrep/package.nix):\n\n```\n$ nix-env --install ripgrep\n```\n\nIf you're a **Flox** user, you can install ripgrep as follows:\n\n```\n$ flox install ripgrep\n```\n\nIf you're a **Guix** user, you can install ripgrep from the official\npackage collection:\n\n```\n$ guix install ripgrep\n```\n\nIf you're a **Debian** user (or a user of a Debian derivative like **Ubuntu**),\nthen ripgrep can be installed using a binary `.deb` file provided in each\n[ripgrep release](https://github.com/BurntSushi/ripgrep/releases).\n\n```\n$ curl -LO https://github.com/BurntSushi/ripgrep/releases/download/14.1.1/ripgrep_14.1.1-1_amd64.deb\n$ sudo dpkg -i ripgrep_14.1.1-1_amd64.deb\n```\n\nIf you run Debian stable, ripgrep is [officially maintained by\nDebian](https://tracker.debian.org/pkg/rust-ripgrep), although its version may\nbe older than the `deb` package available in the previous step.\n\n```\n$ sudo apt-get install ripgrep\n```\n\nIf you're an **Ubuntu Cosmic (18.10)** (or newer) user, ripgrep is\n[available](https://launchpad.net/ubuntu/+source/rust-ripgrep) using the same\npackaging as Debian:\n\n```\n$ sudo apt-get install ripgrep\n```\n\n(N.B. Various snaps for ripgrep on Ubuntu are also available, but none of them\nseem to work right and generate a number of very strange bug reports that I\ndon't know how to fix and don't have the time to fix. Therefore, it is no\nlonger a recommended installation option.)\n\nIf you're an **ALT** user, you can install ripgrep from the\n[official repo](https://packages.altlinux.org/en/search?name=ripgrep):\n\n```\n$ sudo apt-get install ripgrep\n```\n\nIf you're a **FreeBSD** user, then you can install ripgrep from the\n[official ports](https://www.freshports.org/textproc/ripgrep/):\n\n```\n$ sudo pkg install ripgrep\n```\n\nIf you're an **OpenBSD** user, then you can install ripgrep from the\n[official ports](https://openports.se/textproc/ripgrep):\n\n```\n$ doas pkg_add ripgrep\n```\n\nIf you're a **NetBSD** user, then you can install ripgrep from\n[pkgsrc](https://pkgsrc.se/textproc/ripgrep):\n\n```\n$ sudo pkgin install ripgrep\n```\n\nIf you're a **Haiku x86_64** user, then you can install ripgrep from the\n[official ports](https://github.com/haikuports/haikuports/tree/master/sys-apps/ripgrep):\n\n```\n$ sudo pkgman install ripgrep\n```\n\nIf you're a **Haiku x86_gcc2** user, then you can install ripgrep from the\nsame port as Haiku x86_64 using the x86 secondary architecture build:\n\n```\n$ sudo pkgman install ripgrep_x86\n```\n\nIf you're a **Void Linux** user, then you can install ripgrep from the\n[official repository](https://voidlinux.org/packages/?arch=x86_64&q=ripgrep):\n\n```\n$ sudo xbps-install -Syv ripgrep\n```\n\nIf you're a **Rust programmer**, ripgrep can be installed with `cargo`.\n\n* Note that the minimum supported version of Rust for ripgrep is **1.85.0**,\n  although ripgrep may work with older versions.\n* Note that the binary may be bigger than expected because it contains debug\n  symbols. This is intentional. To remove debug symbols and therefore reduce\n  the file size, run `strip` on the binary.\n\n```\n$ cargo install ripgrep\n```\n\nAlternatively, one can use [`cargo\nbinstall`](https://github.com/cargo-bins/cargo-binstall) to install a ripgrep\nbinary directly from GitHub:\n\n```\n$ cargo binstall ripgrep\n```\n\n\n### Building\n\nripgrep is written in Rust, so you'll need to grab a\n[Rust installation](https://www.rust-lang.org/) in order to compile it.\nripgrep compiles with Rust 1.85.0 (stable) or newer. In general, ripgrep tracks\nthe latest stable release of the Rust compiler.\n\nTo build ripgrep:\n\n```\n$ git clone https://github.com/BurntSushi/ripgrep\n$ cd ripgrep\n$ cargo build --release\n$ ./target/release/rg --version\n0.1.3\n```\n\n**NOTE:** In the past, ripgrep supported a `simd-accel` Cargo feature when\nusing a Rust nightly compiler. This only benefited UTF-16 transcoding.\nSince it required unstable features, this build mode was prone to breakage.\nBecause of that, support for it has been removed. If you want SIMD\noptimizations for UTF-16 transcoding, then you'll have to petition the\n[`encoding_rs`](https://github.com/hsivonen/encoding_rs) project to use stable\nAPIs.\n\nFinally, optional PCRE2 support can be built with ripgrep by enabling the\n`pcre2` feature:\n\n```\n$ cargo build --release --features 'pcre2'\n```\n\nEnabling the PCRE2 feature works with a stable Rust compiler and will\nattempt to automatically find and link with your system's PCRE2 library via\n`pkg-config`. If one doesn't exist, then ripgrep will build PCRE2 from source\nusing your system's C compiler and then statically link it into the final\nexecutable. Static linking can be forced even when there is an available PCRE2\nsystem library by either building ripgrep with the MUSL target or by setting\n`PCRE2_SYS_STATIC=1`.\n\nripgrep can be built with the MUSL target on Linux by first installing the MUSL\nlibrary on your system (consult your friendly neighborhood package manager).\nThen you just need to add MUSL support to your Rust toolchain and rebuild\nripgrep, which yields a fully static executable:\n\n```\n$ rustup target add x86_64-unknown-linux-musl\n$ cargo build --release --target x86_64-unknown-linux-musl\n```\n\nApplying the `--features` flag from above works as expected. If you want to\nbuild a static executable with MUSL and with PCRE2, then you will need to have\n`musl-gcc` installed, which might be in a separate package from the actual\nMUSL library, depending on your Linux distribution.\n\n\n### Running tests\n\nripgrep is relatively well-tested, including both unit tests and integration\ntests. To run the full test suite, use:\n\n```\n$ cargo test --all\n```\n\nfrom the repository root.\n\n\n### Related tools\n\n* [delta](https://github.com/dandavison/delta) is a syntax highlighting\npager that supports the `rg --json` output format. So all you need to do to\nmake it work is `rg --json pattern | delta`. See [delta's manual section on\ngrep](https://dandavison.github.io/delta/grep.html) for more details.\n\n\n### Vulnerability reporting\n\nFor reporting a security vulnerability, please\n[contact Andrew Gallant](https://blog.burntsushi.net/about/).\nThe contact page has my email address and PGP public key if you wish to send an\nencrypted message.\n\n\n### Translations\n\nThe following is a list of known translations of ripgrep's documentation. These\nare unofficially maintained and may not be up to date.\n\n* [Chinese](https://github.com/chinanf-boy/ripgrep-zh#%E6%9B%B4%E6%96%B0-)\n* [Spanish](https://github.com/UltiRequiem/traducciones/tree/master/ripgrep)\n",
      "stars_today": 33
    },
    {
      "id": 709589487,
      "name": "awesome-system-design-resources",
      "full_name": "ashishps1/awesome-system-design-resources",
      "description": "Learn System Design concepts and prepare for interviews using free resources.",
      "html_url": "https://github.com/ashishps1/awesome-system-design-resources",
      "stars": 29281,
      "forks": 6718,
      "language": "Java",
      "topics": [
        "awesome",
        "backend",
        "computer-science",
        "distributed-systems",
        "high-level-design",
        "hld",
        "interview",
        "interview-questions",
        "scalability",
        "system-design"
      ],
      "created_at": "2023-10-25T01:50:42Z",
      "updated_at": "2026-01-25T00:52:58Z",
      "pushed_at": "2026-01-11T14:54:34Z",
      "open_issues": 7,
      "owner": {
        "login": "ashishps1",
        "avatar_url": "https://avatars.githubusercontent.com/u/8646889?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"diagrams/system-design-github-logo.png\" width=\"350\" height=\"200\">\n</p>\n\nThis repository contains free resources to learn System Design concepts and prepare for interviews.\n\nğŸ‘‰ Subscribe to my [AlgoMaster Newsletter](https://bit.ly/amghsd) and get a **FREE System Design Interview Handbook** in your inbox.\n\nâœ… If you are new to System Design, start here: [System Design was HARD until I Learned these 30 Concepts](https://blog.algomaster.io/p/30-system-design-concepts)\n\n## âš™ï¸ Core Concepts\n- [Scalability](https://algomaster.io/learn/system-design/scalability)\n- [Availability](https://algomaster.io/learn/system-design/availability)\n- [Reliability](https://algomaster.io/learn/system-design/reliability)\n- [CAP Theorem](https://blog.algomaster.io/p/cap-theorem-explained)\n- [Consistent Hashing](https://blog.algomaster.io/p/consistent-hashing-explained)\n- [SPOF](https://blog.algomaster.io/p/system-design-how-to-avoid-single-point-of-failures)\n- [Failover](https://www.druva.com/glossary/what-is-a-failover-definition-and-related-faqs)\n- [Fault Tolerance](https://www.cockroachlabs.com/blog/what-is-fault-tolerance/)\n\n## ğŸŒ Networking Fundamentals\n- [OSI Model](https://algomaster.io/learn/system-design/osi)\n- [IP Addresses](https://algomaster.io/learn/system-design/ip-address)\n- [Domain Name System (DNS)](https://blog.algomaster.io/p/how-dns-actually-works)\n- [Proxy vs Reverse Proxy](https://blog.algomaster.io/p/proxy-vs-reverse-proxy-explained)\n- [HTTP/HTTPS](https://algomaster.io/learn/system-design/http-https)\n- [TCP vs UDP](https://algomaster.io/learn/system-design/tcp-vs-udp)\n- [Load Balancing](https://blog.algomaster.io/p/load-balancing-algorithms-explained-with-code)\n- [Checksums](https://algomaster.io/learn/system-design/checksums)\n\n## ğŸ”Œ API Fundamentals\n- [APIs](https://algomaster.io/learn/system-design/what-is-an-api)\n- [API Gateway](https://blog.algomaster.io/p/what-is-an-api-gateway)\n- [REST vs GraphQL](https://blog.algomaster.io/p/rest-vs-graphql)\n- [WebSockets](https://blog.algomaster.io/p/websockets)\n- [Webhooks](https://algomaster.io/learn/system-design/webhooks)\n- [Idempotency](https://algomaster.io/learn/system-design/idempotency)\n- [Rate limiting](https://blog.algomaster.io/p/rate-limiting-algorithms-explained-with-code)\n- [API Design](https://abdulrwahab.medium.com/api-architecture-best-practices-for-designing-rest-apis-bf907025f5f)\n\n## ğŸ—„ï¸ Database Fundamentals\n- [ACID Transactions](https://algomaster.io/learn/system-design/acid-transactions)\n- [SQL vs NoSQL](https://algomaster.io/learn/system-design/sql-vs-nosql)\n- [Database Indexes](https://algomaster.io/learn/system-design/indexing)\n- [Database Sharding](https://algomaster.io/learn/system-design/sharding)\n- [Data Replication](https://redis.com/blog/what-is-data-replication/)\n- [Database Scaling](https://blog.algomaster.io/p/system-design-how-to-scale-a-database)\n- [Databases Types](https://blog.algomaster.io/p/15-types-of-databases)\n- [Bloom Filters](https://algomaster.io/learn/system-design/bloom-filters)\n- [Database Architectures](https://www.mongodb.com/developer/products/mongodb/active-active-application-architectures/)\n\n## âš¡ Caching Fundamentals\n- [Caching 101](https://algomaster.io/learn/system-design/what-is-caching)\n- [Caching Strategies](https://algomaster.io/learn/system-design/caching-strategies)\n- [Cache Eviction Policies](https://blog.algomaster.io/p/7-cache-eviction-strategies)\n- [Distributed Caching](https://blog.algomaster.io/p/distributed-caching)\n- [Content Delivery Network (CDN)](https://algomaster.io/learn/system-design/content-delivery-network-cdn)\n\n## ğŸ”„ Asynchronous Communication\n- [Pub/Sub](https://algomaster.io/learn/system-design/pub-sub)\n- [Message Queues](https://algomaster.io/learn/system-design/message-queues)\n- [Change Data Capture (CDC)](https://algomaster.io/learn/system-design/change-data-capture-cdc)\n\n## ğŸ§© Distributed System and Microservices\n- [HeartBeats](https://blog.algomaster.io/p/heartbeats-in-distributed-systems)\n- [Service Discovery](https://blog.algomaster.io/p/service-discovery-in-distributed-systems)\n- [Consensus Algorithms](https://medium.com/@sourabhatta1819/consensus-in-distributed-system-ac79f8ba2b8c)\n- [Distributed Locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)\n- [Microservices Guidelines](https://newsletter.systemdesign.one/p/netflix-microservices) \n- [Gossip Protocol](http://highscalability.com/blog/2023/7/16/gossip-protocol-explained.html)\n- [Circuit Breaker](https://medium.com/geekculture/design-patterns-for-microservices-circuit-breaker-pattern-276249ffab33)\n- [Disaster Recovery](https://cloud.google.com/learn/what-is-disaster-recovery)\n- [Distributed Tracing](https://www.dynatrace.com/news/blog/what-is-distributed-tracing/)\n\n## ğŸ–‡ï¸ Architectural Patterns\n- [Client-Server Architecture](https://algomaster.io/learn/system-design/client-server-architecture)\n- [Microservices Architecture](https://medium.com/hashmapinc/the-what-why-and-how-of-a-microservices-architecture-4179579423a9)\n- [Serverless Architecture](https://blog.algomaster.io/p/2edeb23b-cfa5-4b24-845e-3f6f7a39d162)\n- [Event-Driven Architecture](https://www.confluent.io/learn/event-driven-architecture/)\n- [Peer-to-Peer (P2P) Architecture](https://www.spiceworks.com/tech/networking/articles/what-is-peer-to-peer/)\n\n## âš–ï¸ System Design Tradeoffs\n- [Top 15 Tradeoffs](https://blog.algomaster.io/p/system-design-top-15-trade-offs)\n- [Vertical vs Horizontal Scaling](https://algomaster.io/learn/system-design/vertical-vs-horizontal-scaling)\n- [Concurrency vs Parallelism](https://blog.algomaster.io/p/concurrency-vs-parallelism)\n- [Long Polling vs WebSockets](https://blog.algomaster.io/p/long-polling-vs-websockets)\n- [Batch vs Stream Processing](https://blog.algomaster.io/p/batch-processing-vs-stream-processing)\n- [Stateful vs Stateless Design](https://blog.algomaster.io/p/stateful-vs-stateless-architecture)\n- [Strong vs Eventual Consistency](https://blog.algomaster.io/p/strong-vs-eventual-consistency)\n- [Read-Through vs Write-Through Cache](https://blog.algomaster.io/p/59cae60d-9717-4e20-a59e-759e370db4e5)\n- [Push vs Pull Architecture](https://blog.algomaster.io/p/af5fe2fe-9a4f-4708-af43-184945a243af)\n- [REST vs RPC](https://blog.algomaster.io/p/106604fb-b746-41de-88fb-60e932b2ff68)\n- [Synchronous vs. asynchronous communications](https://blog.algomaster.io/p/aec1cebf-6060-45a7-8e00-47364ca70761)\n- [Latency vs Throughput](https://aws.amazon.com/compare/the-difference-between-throughput-and-latency/)\n\n## âœ… [How to Answer a System Design Interview Problem](https://algomaster.io/learn/system-design-interviews/answering-framework)\n\n## ğŸ’» System Design Interview Problems\n### Easy\n- [Design URL Shortener like TinyURL](https://algomaster.io/learn/system-design-interviews/design-url-shortener)\n- [Design Autocomplete for Search Engines](https://algomaster.io/learn/system-design-interviews/design-instagram)\n- [Design Load Balancer](https://algomaster.io/learn/system-design-interviews/design-load-balancer)\n- [Design Content Delivery Network (CDN)](https://www.youtube.com/watch?v=8zX0rue2Hic)\n- [Design Parking Garage](https://www.youtube.com/watch?v=NtMvNh0WFVM)\n- [Design Vending Machine](https://www.youtube.com/watch?v=D0kDMUgo27c)\n- [Design Distributed Key-Value Store](https://www.youtube.com/watch?v=rnZmdmlR-2M)\n- [Design Distributed Cache](https://www.youtube.com/watch?v=iuqZvajTOyA)\n- [Design Authentication System](https://www.youtube.com/watch?v=uj_4vxm9u90)\n- [Design Unified Payments Interface (UPI)](https://www.youtube.com/watch?v=QpLy0_c_RXk)\n### Medium\n- [Design WhatsApp](https://algomaster.io/learn/system-design-interviews/design-whatsapp)\n- [Design Spotify](https://algomaster.io/learn/system-design-interviews/design-spotify)\n- [Design Instagram](https://algomaster.io/learn/system-design-interviews/design-instagram)\n- [Design Notification Service](https://algomaster.io/learn/system-design-interviews/design-notification-service)\n- [Design Distributed Job Scheduler](https://blog.algomaster.io/p/design-a-distributed-job-scheduler)\n- [Design Tinder](https://www.youtube.com/watch?v=tndzLznxq40)\n- [Design Facebook](https://www.youtube.com/watch?v=9-hjBGxuiEs)\n- [Design Twitter](https://www.youtube.com/watch?v=wYk0xPP_P_8)\n- [Design Reddit](https://www.youtube.com/watch?v=KYExYE_9nIY)\n- [Design Netflix](https://www.youtube.com/watch?v=psQzyFfsUGU)\n- [Design Youtube](https://www.youtube.com/watch?v=jPKTo1iGQiE)\n- [Design Google Search](https://www.youtube.com/watch?v=CeGtqouT8eA)\n- [Design E-commerce Store like Amazon](https://www.youtube.com/watch?v=EpASu_1dUdE)\n- [Design TikTok](https://www.youtube.com/watch?v=Z-0g_aJL5Fw)\n- [Design Shopify](https://www.youtube.com/watch?v=lEL4F_0J3l8)\n- [Design Airbnb](https://www.youtube.com/watch?v=YyOXt2MEkv4)\n- [Design Rate Limiter](https://www.youtube.com/watch?v=mhUQe4BKZXs)\n- [Design Distributed Message Queue like Kafka](https://www.youtube.com/watch?v=iJLL-KPqBpM)\n- [Design Flight Booking System](https://www.youtube.com/watch?v=qsGcfVGvFSs)\n- [Design Online Code Editor](https://www.youtube.com/watch?v=07jkn4jUtso)\n- [Design an Analytics Platform (Metrics & Logging)](https://www.youtube.com/watch?v=kIcq1_pBQSY)\n- [Design Payment System](https://www.youtube.com/watch?v=olfaBgJrUBI)\n- [Design a Digital Wallet](https://www.youtube.com/watch?v=4ijjIUeq6hE)\n### Hard\n- [Design Location Based Service like Yelp](https://www.youtube.com/watch?v=M4lR_Va97cQ)\n- [Design Uber](https://www.youtube.com/watch?v=umWABit-wbk)\n- [Design Food Delivery App like Doordash](https://www.youtube.com/watch?v=iRhSAR3ldTw)\n- [Design Google Docs](https://www.youtube.com/watch?v=2auwirNBvGg)\n- [Design Google Maps](https://www.youtube.com/watch?v=jk3yvVfNvds)\n- [Design Zoom](https://www.youtube.com/watch?v=G32ThJakeHk)\n- [Design Distributed Counter](https://systemdesign.one/distributed-counter-system-design/)\n- [Design File Sharing System like Dropbox](https://www.youtube.com/watch?v=U0xTu6E2CT8)\n- [Design Ticket Booking System like BookMyShow](https://www.youtube.com/watch?v=lBAwJgoO3Ek)\n- [Design Distributed Web Crawler](https://www.youtube.com/watch?v=BKZxZwUgL3Y)\n- [Design Code Deployment System](https://www.youtube.com/watch?v=q0KGYwNbf-0)\n- [Design Distributed Cloud Storage like S3](https://www.youtube.com/watch?v=UmWtcgC96X8)\n- [Design Distributed Locking Service](https://www.youtube.com/watch?v=v7x75aN9liM)\n- [Design Slack](https://systemdesign.one/slack-architecture/)\n- [Design Live Comments](https://systemdesign.one/live-comment-system-design/)\n\n## ğŸ“‡ Courses\n- [System Design Fundamentals](https://algomaster.io/learn/system-design/course-introduction)\n- [System Design Interviews](https://algomaster.io/learn/system-design-interviews/introduction)\n\n## ğŸ“© Newsletters\n- [AlgoMaster Newsletter](https://blog.algomaster.io/)\n\n## ğŸ“š Books\n- [Designing Data-Intensive Applications](https://www.amazon.in/dp/9352135245)\n\n## ğŸ“º YouTube Channels\n- [Tech Dummies Narendra L](https://www.youtube.com/@TechDummiesNarendraL)\n- [Gaurav Sen](https://www.youtube.com/@gkcs)\n- [codeKarle](https://www.youtube.com/@codeKarle)\n- [ByteByteGo](https://www.youtube.com/@ByteByteGo)\n- [System Design Interview](https://www.youtube.com/@SystemDesignInterview)\n- [sudoCODE](https://www.youtube.com/@sudocode)\n- [Success in Tech](https://www.youtube.com/@SuccessinTech/videos)\n\n## ğŸ“œ Must-Read Engineering Articles\n- [How Discord stores trillions of messages](https://discord.com/blog/how-discord-stores-trillions-of-messages)\n- [Building In-Video Search at Netflix](https://netflixtechblog.com/building-in-video-search-936766f0017c)\n- [How Canva scaled Media uploads from Zero to 50 Million per Day](https://www.canva.dev/blog/engineering/from-zero-to-50-million-uploads-per-day-scaling-media-at-canva/)\n- [How Airbnb avoids double payments in a Distributed Payments System](https://medium.com/airbnb-engineering/avoiding-double-payments-in-a-distributed-payments-system-2981f6b070bb)\n- [Stripeâ€™s payments APIs - The first 10 years](https://stripe.com/blog/payment-api-design)\n- [Real time messaging at Slack](https://slack.engineering/real-time-messaging/)\n\n## ğŸ—ï¸ Must-Read Distributed Systems Papers\n- [Paxos: The Part-Time Parliament](https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf)\n- [MapReduce: Simplified Data Processing on Large Clusters](https://research.google.com/archive/mapreduce-osdi04.pdf)\n- [The Google File System](https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf)\n- [Dynamo: Amazonâ€™s Highly Available Key-value Store](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)\n- [Kafka: a Distributed Messaging System for Log Processing](https://notes.stephenholiday.com/Kafka.pdf)\n- [Spanner: Googleâ€™s Globally-Distributed Database](https://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf)\n- [Bigtable: A Distributed Storage System for Structured Data](https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf)\n- [ZooKeeper: Wait-free coordination for Internet-scale systems](https://www.usenix.org/legacy/event/usenix10/tech/full_papers/Hunt.pdf)\n- [The Log-Structured Merge-Tree (LSM-Tree)](https://www.cs.umb.edu/~poneil/lsmtree.pdf)\n- [The Chubby lock service for loosely-coupled distributed systems](https://static.googleusercontent.com/media/research.google.com/en//archive/chubby-osdi06.pdf)\n\n---\n\n<p align=\"center\">\n  <i>If you find this resource helpful, please give it a star â­ï¸ and share it with others!</i>\n</p>\n",
      "stars_today": 33
    },
    {
      "id": 709588939,
      "name": "awesome-leetcode-resources",
      "full_name": "ashishps1/awesome-leetcode-resources",
      "description": "Awesome LeetCode resources to learn Data Structures and Algorithms and prepare for Coding Interviews.",
      "html_url": "https://github.com/ashishps1/awesome-leetcode-resources",
      "stars": 15435,
      "forks": 3350,
      "language": "Java",
      "topics": [
        "algorithms",
        "coding",
        "data-structures",
        "dsa",
        "leetcode",
        "leetcode-patterns"
      ],
      "created_at": "2023-10-25T01:48:19Z",
      "updated_at": "2026-01-25T00:46:34Z",
      "pushed_at": "2025-11-25T13:00:27Z",
      "open_issues": 12,
      "owner": {
        "login": "ashishps1",
        "avatar_url": "https://avatars.githubusercontent.com/u/8646889?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"images/leetcode-repo-logo.png\" width=\"350\" height=\"200\">\n</p>\n<p align=\"center\">\n  <a href=\"https://blog.algomaster.io/\">Join Free Newsletter</a>\n</p>\n\nThis repository contains awesome LeetCode resources to learn Data Structures and Algorithms (DSA) and prepare for Coding interviews.\n\nğŸ‘‰ If you want to master DSA patterns, checkout [AlgoMaster.io](https://algomaster.io)\n\n## ğŸ’¡ Tips\n- [How I Mastered DSA](https://blog.algomaster.io/p/how-i-mastered-data-structures-and-algorithms)\n- [How to Start LeetCode](https://blog.algomaster.io/p/how-to-start-leetcode-in-2025)\n- [15 Leetcode Patterns](https://blog.algomaster.io/p/15-leetcode-patterns)\n\n## ğŸ“Œ Fundamental Concepts\n- [Algorithmic Complexity](https://blog.algomaster.io/p/57bd4963-462f-4294-a972-4012691fc729)\n- [Big-O Cheat Sheet](https://www.bigocheatsheet.com/)\n- [Arrays](https://www.youtube.com/watch?v=SlNq09scdWE&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Bit Manipulation Techniques](https://blog.algomaster.io/p/c650df76-f978-46ee-a572-eb13c354905d)\n- [Sorting Algorithms](https://medium.com/jl-codes/understanding-sorting-algorithms-af6222995c8)\n- [Linked List](https://www.youtube.com/watch?v=FbHf0ii0WDg&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Queues](https://medium.com/basecs/to-queue-or-not-to-queue-2653bcde5b04)\n- [Stacks](https://medium.com/basecs/stacks-and-overflows-dbcf7854dc67)\n- [Hash Tables](https://medium.com/basecs/taking-hash-tables-off-the-shelf-139cbf4752f0)\n- [Heaps](https://medium.com/basecs/learning-to-love-heaps-cef2b273a238)\n- [Recursion](https://leetcode.com/discuss/study-guide/1733447/become-master-in-recursion)\n- [Backtracking](https://medium.com/algorithms-and-leetcode/backtracking-e001561b9f28)\n- [Trees](https://leetcode.com/discuss/study-guide/1820334/Become-Master-in-Tree)\n- [Tries](https://medium.com/basecs/trying-to-understand-tries-3ec6bede0014)\n- [Binary Search](https://leetcode.com/discuss/study-guide/786126/Python-Powerful-Ultimate-Binary-Search-Template.-Solved-many-problems)\n- [Greedy Algorithm](https://www.freecodecamp.org/news/greedy-algorithms/)\n- [Dynamic Programming](https://medium.com/basecs/less-repetition-more-dynamic-programming-43d29830a630)\n- [Graph Theory](https://www.youtube.com/watch?v=xN5VGzK9_FQ&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Master Graph Algorithms](https://blog.algomaster.io/p/master-graph-algorithms-for-coding)\n- [DFS Traversal](https://medium.com/basecs/deep-dive-through-a-graph-dfs-traversal-8177df5d0f13)\n- [BFS Traversal](https://medium.com/basecs/going-broad-in-a-graph-bfs-traversal-959bd1a09255)\n- [Union-Find](https://leetcode.com/discuss/general-discussion/1072418/Disjoint-Set-Union-(DSU)Union-Find-A-Complete-Guide)\n- [Dijkstra Algorithm](https://leetcode.com/discuss/study-guide/1059477/A-guide-to-Dijkstra's-Algorithm)\n- [Minimum Spanning Tree](https://www.hackerearth.com/practice/algorithms/graphs/minimum-spanning-tree/tutorial/)\n\n## ğŸš€ Patterns\n- [15 Leetcode Patterns](https://blog.algomaster.io/p/15-leetcode-patterns)\n- [20 DP Patterns](https://blog.algomaster.io/p/20-patterns-to-master-dynamic-programming)\n- [Two Pointers Pattern](https://www.youtube.com/watch?v=QzZ7nmouLTI&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Sliding Window Pattern](https://www.youtube.com/watch?v=y2d0VHdvfdc&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Prefix Sum Pattern](https://www.youtube.com/watch?v=yuws7YK0Yng&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Fast and Slow Pointers Pattern](https://www.youtube.com/watch?v=b139yf7Ik-E&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Top 'K' Elements Pattern](https://www.youtube.com/watch?v=6_v6OoxvMOE&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Kadane's Algorithm](https://www.youtube.com/watch?v=NUWAXbSlsws&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Linked List In-place Reversal Pattern](https://www.youtube.com/watch?v=auoTGovuo9A&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Monotonic Stack Pattern](https://www.youtube.com/watch?v=DtJVwbbicjQ&list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2)\n- [Overlapping Intervals Pattern](https://blog.algomaster.io/p/812e72f7-eced-4256-a4c1-00606ae50679)\n- [Backtracking Pattern](https://blog.algomaster.io/p/81d42ca2-600c-4252-aa33-a56462090048)\n- [Modified Binary Search Pattern](https://blog.algomaster.io/p/d0d81b04-4c2a-4b45-a101-5137c3146686)\n- [Tree Patterns](https://leetcode.com/discuss/study-guide/937307/Iterative-or-Recursive-or-DFS-and-BFS-Tree-Traversal-or-In-Pre-Post-and-LevelOrder-or-Views)\n  - [Tree Iterative Traversal](https://medium.com/leetcode-patterns/leetcode-pattern-0-iterative-traversals-on-trees-d373568eb0ec)\n  - [Tree Question Pattern](https://leetcode.com/discuss/study-guide/2879240/TREE-QUESTION-PATTERN-2023-oror-TREE-STUDY-GUIDE) \n- [Graph Patterns](https://leetcode.com/discuss/study-guide/655708/Graph-For-Beginners-Problems-or-Pattern-or-Sample-Solutions)\n- [DFS + BFS Patterns (1)](https://medium.com/leetcode-patterns/leetcode-pattern-1-bfs-dfs-25-of-the-problems-part-1-519450a84353)\n- [DFS + BFS Patterns (2)](https://medium.com/leetcode-patterns/leetcode-pattern-2-dfs-bfs-25-of-the-problems-part-2-a5b269597f52)\n\n## ğŸ“ Must-Read Leetcode Articles\n- [Sliding Window Template](https://leetcode.com/problems/frequency-of-the-most-frequent-element/solutions/1175088/C++-Maximum-Sliding-Window-Cheatsheet-Template/)\n- [Two Pointers Patterns](https://leetcode.com/discuss/study-guide/1688903/Solved-all-two-pointers-problems-in-100-days)\n- [Collections of Important String Questions](https://leetcode.com/discuss/study-guide/2001789/Collections-of-Important-String-questions-Pattern)\n- [Substring Problem Template](https://leetcode.com/problems/minimum-window-substring/solutions/26808/Here-is-a-10-line-template-that-can-solve-most-'substring'-problems/)\n- [Binary Search Template](https://leetcode.com/discuss/study-guide/786126/Python-Powerful-Ultimate-Binary-Search-Template.-Solved-many-problems)\n- [A General Approach to Backtracking Questions](https://leetcode.com/problems/permutations/solutions/18239/A-general-approach-to-backtracking-questions-in-Java-(Subsets-Permutations-Combination-Sum-Palindrome-Partioning)/)\n- [Monotonic Stack Template](https://leetcode.com/discuss/study-guide/2347639/A-comprehensive-guide-and-template-for-monotonic-stack-based-problems)\n- [Heap Patterns](https://leetcode.com/discuss/general-discussion/1127238/master-heap-by-solving-23-questions-in-4-patterns-category)\n- [Bit Manipulation Patterns](https://leetcode.com/discuss/study-guide/4282051/all-types-of-patterns-for-bits-manipulations-and-how-to-use-it)\n- [Dynamic Programming Patterns](https://leetcode.com/discuss/study-guide/458695/Dynamic-Programming-Patterns)\n- [Stock Series Patterns](https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee/solutions/108870/most-consistent-ways-of-dealing-with-the-series-of-stock-problems/)\n\n## âœ… Curated Problems\n- [AlgoMaster 300](https://algomaster.io/practice/dsa-patterns)\n- [Blind 75](https://leetcode.com/discuss/general-discussion/460599/blind-75-leetcode-questions)\n- [Leetcode Top 100 Liked](https://leetcode.com/studyplan/top-100-liked/)\n- [Leetcode Top Interview 150](https://leetcode.com/studyplan/top-interview-150/)\n\n## ğŸ“º YouTube Playlist\n- [AlgoMaster DSA Playlist](https://www.youtube.com/playlist?list=PLK63NuByH5o9odyBT7nfYkHZyvGQ5oVp2&pp=gAQB)\n- [AlgoMaster LeetCode Pattern Playlist](https://www.youtube.com/playlist?list=PLK63NuByH5o-tqaMUHRA4r8ObRW7PWz45)\n- [Abdul Bari's Algorithms Playlist](https://www.youtube.com/playlist?list=PLDN4rrl48XKpZkf03iYFl-O29szjTrs_O)\n- [William Fiset's Data Structure Playlist](https://www.youtube.com/playlist?list=PLDV1Zeh2NRsB6SWUrDFW2RmDotAfPbeHu)\n- [William Fiset's Graphs Playlist](https://www.youtube.com/playlist?list=PLDV1Zeh2NRsDGO4--qE8yH72HFL1Km93P)\n- [Tushar Roy's Dynamic Programming Playlist](https://www.youtube.com/playlist?list=PLrmLmBdmIlpsHaNTPP_jHHDx_os9ItYXr)\n\n## ğŸ“‡ Courses\n- [Coursera - Algorithms, Part I](https://www.coursera.org/learn/algorithms-part1)\n- [Coursera - Algorithms, Part 2](https://www.coursera.org/learn/algorithms-part2)\n\n## ğŸ“š Books\n- [Data Structures And Algorithms Made Easy](https://www.amazon.in/dp/B08CMLS7LZ)\n- [Cracking the Coding Interview](https://www.amazon.in/dp/0984782850)\n\n## ğŸ“© Newsletter\n- [AlgoMaster Newsletter](https://blog.algomaster.io/)\n\n## ğŸ” Visualization\n- [AlgoMaster DSA Animations](https://algomaster.io/animations/dsa)\n- [VisuAlgo](https://visualgo.net/en)\n\n## ğŸ“ LeetCode Extensions\n- [LeetCode Timer](https://chromewebstore.google.com/detail/leetcode-timer/gfkgelnlcnomnahkfmhemgpahgmibofd): Easily time your leetcode practise sessions with automatic time setting based on difficulty.\n- [LeetCode Video Solutions](https://chromewebstore.google.com/detail/leetcode-video-solutions/ilnmgkahgjdpkoliooildngldmilhelm): Watch free LeetCode video â–¶ solutions on the problem page itself.\n- [LeetCode Format](https://chromewebstore.google.com/detail/leetcode-format/imogghebhifnnlgogigikjecilkicfpp): Adds Format code button on leetcode to format the code using Prettier code formatter.\n- [LeetHub v2](https://chromewebstore.google.com/detail/leethub-v2/mhanfgfagplhgemhjfeolkkdidbakocm?hl=en): Automatically integrate your Leetcode & GeeksforGeeks submissions to GitHub.\n- [LeetCode VS Code Extension](https://marketplace.visualstudio.com/items?itemName=LeetCode.vscode-leetcode): Solve LeetCode problems in VS Code.\n\nYour contributions are most welcome!\n\n---\n\n<p align=\"center\">\n  <i>If you find this resource helpful, please give it a star â­ï¸ and share it with others!</i>\n</p>\n",
      "stars_today": 33
    },
    {
      "id": 268424739,
      "name": "helix",
      "full_name": "helix-editor/helix",
      "description": "A post-modern modal text editor.",
      "html_url": "https://github.com/helix-editor/helix",
      "stars": 42587,
      "forks": 3279,
      "language": "Rust",
      "topics": [
        "kakoune",
        "rust",
        "text-editor",
        "vim"
      ],
      "created_at": "2020-06-01T04:26:56Z",
      "updated_at": "2026-01-25T02:03:33Z",
      "pushed_at": "2026-01-23T03:34:23Z",
      "open_issues": 1408,
      "owner": {
        "login": "helix-editor",
        "avatar_url": "https://avatars.githubusercontent.com/u/66235900?v=4"
      },
      "readme": "<div align=\"center\">\n\n<h1>\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"logo_dark.svg\">\n  <source media=\"(prefers-color-scheme: light)\" srcset=\"logo_light.svg\">\n  <img alt=\"Helix\" height=\"128\" src=\"logo_light.svg\">\n</picture>\n</h1>\n\n[![Build status](https://github.com/helix-editor/helix/actions/workflows/build.yml/badge.svg)](https://github.com/helix-editor/helix/actions)\n[![GitHub Release](https://img.shields.io/github/v/release/helix-editor/helix)](https://github.com/helix-editor/helix/releases/latest)\n[![Documentation](https://shields.io/badge/-documentation-452859)](https://docs.helix-editor.com/)\n[![GitHub contributors](https://img.shields.io/github/contributors/helix-editor/helix)](https://github.com/helix-editor/helix/graphs/contributors)\n[![Matrix Space](https://img.shields.io/matrix/helix-community:matrix.org)](https://matrix.to/#/#helix-community:matrix.org)\n\n</div>\n\n![Screenshot](./screenshot.png)\n\nA [Kakoune](https://github.com/mawww/kakoune) / [Neovim](https://github.com/neovim/neovim) inspired editor, written in Rust.\n\nThe editing model is very heavily based on Kakoune; during development I found\nmyself agreeing with most of Kakoune's design decisions.\n\nFor more information, see the [website](https://helix-editor.com) or\n[documentation](https://docs.helix-editor.com/).\n\nAll shortcuts/keymaps can be found [in the documentation on the website](https://docs.helix-editor.com/keymap.html).\n\n[Troubleshooting](https://github.com/helix-editor/helix/wiki/Troubleshooting)\n\n# Features\n\n- Vim-like modal editing\n- Multiple selections\n- Built-in language server support\n- Smart, incremental syntax highlighting and code editing via tree-sitter\n\nAlthough it's primarily a terminal-based editor, I am interested in exploring\na custom renderer (similar to Emacs) using wgpu.\n\nNote: Only certain languages have indentation definitions at the moment. Check\n`runtime/queries/<lang>/` for `indents.scm`.\n\n# Installation\n\n[Installation documentation](https://docs.helix-editor.com/install.html).\n\n[![Packaging status](https://repology.org/badge/vertical-allrepos/helix-editor.svg?exclude_unsupported=1)](https://repology.org/project/helix-editor/versions)\n\n# Contributing\n\nContributing guidelines can be found [here](./docs/CONTRIBUTING.md).\n\n# Getting help\n\nYour question might already be answered on the [FAQ](https://github.com/helix-editor/helix/wiki/FAQ).\n\nDiscuss the project on the community [Matrix Space](https://matrix.to/#/#helix-community:matrix.org) (make sure to join `#helix-editor:matrix.org` if you're on a client that doesn't support Matrix Spaces yet).\n\n# Credits\n\nThanks to [@jakenvac](https://github.com/jakenvac) for designing the logo!\n",
      "stars_today": 31
    },
    {
      "id": 497133950,
      "name": "ytdlnis",
      "full_name": "deniscerri/ytdlnis",
      "description": "Full-featured audio/video downloader for Android using yt-dlp",
      "html_url": "https://github.com/deniscerri/ytdlnis",
      "stars": 7455,
      "forks": 305,
      "language": "Kotlin",
      "topics": [
        "android",
        "audio",
        "downloader",
        "kotlin",
        "material-design",
        "mp3",
        "video",
        "youtube",
        "youtube-dl",
        "youtube-downloader",
        "yt-dlp",
        "yt-dlp-gui"
      ],
      "created_at": "2022-05-27T20:46:51Z",
      "updated_at": "2026-01-24T22:53:00Z",
      "pushed_at": "2026-01-24T22:52:56Z",
      "open_issues": 33,
      "owner": {
        "login": "deniscerri",
        "avatar_url": "https://avatars.githubusercontent.com/u/64997243?v=4"
      },
      "readme": "<h1 align=\"center\">\n\t<img src=\"fastlane/metadata/android/en-US/images/icon.png\" width=\"25%\" /> <br>\n\tYTDLnis\n</h1>\n\n<div align=\"center\">\n\tEnglish\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-sq.md\">Shqip</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-az.md\">AzÉ™rbaycanca</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-tr.md\">TÃ¼rkÃ§e</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-id.md\">Indonesia</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-pt.md\">PortuguÃªs</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-es.md\">EspaÃ±ol</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-ja.md\">Japanese</a>\n\t&nbsp;&nbsp;| &nbsp;&nbsp;\n\t<a href=\"https://github.com/deniscerri/ytdlnis/blob/main/README-ro.md\">RomÃ¢nÄƒ</a>\n</div>\n\n<h3 align=\"center\">\n\tYTDLnis is a free and open source video/audio downloader using yt-dlp for Android 7.0 and above.\n</h3>\n<h4 align=\"center\">\n\tCreated by Denis Ã‡erri\n</h4>\n\n<div align=\"center\">\n\n[![GitHub Releases](https://custom-icon-badges.herokuapp.com/badge/Download-blue?style=for-the-badge&logo=download&logoColor=white)](https://github.com/deniscerri/ytdlnis/releases/latest)\n[![F-Droid](https://custom-icon-badges.herokuapp.com/badge/FDroid-violet?style=for-the-badge&logo=download&logoColor=white)](https://f-droid.org/en/packages/com.deniscerri.ytdl)\n[![IzzyOnDroid repository](https://custom-icon-badges.herokuapp.com/badge/IzzyOnDroid%20Repo-red?style=for-the-badge&logo=download&logoColor=white)](https://android.izzysoft.de/repo/apk/com.deniscerri.ytdl)\n[![Uptodown](https://custom-icon-badges.herokuapp.com/badge/UpToDown-green?style=for-the-badge&logo=download&logoColor=white)](https://ytdlnis.en.uptodown.com/android/download)\n\n![CI](https://github.com/deniscerri/ytdlnis/actions/workflows/android.yml/badge.svg?branch=main&event=pull)\n[![Preview release](https://img.shields.io/github/release/deniscerri/ytdlnis.svg?maxAge=3600&include_prereleases&label=preview)](https://github.com/deniscerri/ytdlnis/releases) \n[![Downloads](https://img.shields.io/github/downloads/deniscerri/ytdlnis/total?style=flat-square)](https://github.com/deniscerri/ytdlnis/releases) \n[![Translation status](https://hosted.weblate.org/widgets/ytdlnis/-/svg-badge.svg)](https://hosted.weblate.org/engage/ytdlnis/?utm_source=widget) \n[![community](https://img.shields.io/badge/Discord-YTDLnis-blueviolet?style=flat-square&logo=discord)](https://discord.gg/WW3KYWxAPm) \n[![community](https://img.shields.io/badge/Telegram-YTDLnis-blue?style=flat-square&logo=telegram)](https://t.me/ytdlnis)\n[![community](https://img.shields.io/badge/Telegram-Updates-red?style=flat-square&logo=telegram)](https://t.me/ytdlnisupdates)\n[![website](https://img.shields.io/badge/Website-orange?style=flat-square&logo=youtube)](https://ytdlnis.org)\n![GitHub Sponsor](https://img.shields.io/github/sponsors/deniscerri?label=Sponsor&logo=GitHub)\n\n### Only the links above are the only trusted sources of YTDLnis. Everything else is not related to me.\n\n</div>\n\n## ğŸ’¡ Features:\n\n- Download audio/video files from more than <a href=\"https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md\">1000 websites</a>\n- Process playlists\n\t- Edit every playlist item separately just like in a normal download item\n\t- Select a common format for all items and/or select multiple audio formats in case you are downloading them as a video\n\t- Select a download path for all items\n\t- Select a filename template for all items\n\t- Batch update download type to audio/video/custom command in one click\n- Queue downloads and schedule them by date and time\n\t- You can also schedule multiple items at the same time\n- Download multiple items at the same time\n- Use custom commands and templates or use yt-dlp with the built-in terminal\n\t- You can backup and restore templates so you can share them with your buddies\n- Supports cookies. Log in with your accounts and download private/unavailable videos, unlock premium formats etc.\n- Cut videos based on timestamps and video chapters (experimental yt-dlp feature)\n\t- You can make unlimited cuts\n- Remove SponsorBlock elements from downloaded items\n\t- Embed them as a chapters in your video \n- Embed subtitles/metadata/chapters etc\n- Modify metadata such as title and author\n- Split item into separate files depending on its chapters\n- Select different download formats\n- Bottom card right from the share menu, no need to open the app \n\t- You can create a txt file and fill it with links/playlists/search queries separate by a new line and the app will process them\n- Search or insert a link from the app\n\t- You can stack searches so you can process them at the same time\n- Log downloads in case of problems\n- Re-download cancelled or failed downloads\n\t- You can use gestures to swipe left to redownload and right to delete\n\t- You can long click the redownload button in the details sheet to show the download card for more functionality\n- Incognito mode when you don't want to save a download history or logs\n- Quick download mode\n\t- Download immediately without having to wait for data to process. Turn off the bottom card and it will instantly start\n- Open / share downloaded files right from the finished notification\n- Most yt-dlp features are implemented, suggestions are welcome\n- Material You interface\n- Theming options\n- Backup and restore features\n- MVVM architecture with WorkManager\n\n## ğŸ“² Screenshots\n\n<div>\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/01.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/02.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/03.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/04.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/05.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/06.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/07.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/08.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/09.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/10.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/11.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/12.png\" width=\"30%\" />\n<img src=\"fastlane/metadata/android/en-US/images/phoneScreenshots/13.png\" width=\"90%\" />\n</div>\n\n## ğŸ’¬ Contact\n\nJoin our [Discord](https://discord.gg/WW3KYWxAPm) or [Telegram channel](https://t.me/ytdlnis) for announcements, discussion and releases.\n\n## ğŸ˜‡ Contributing\n\nPlease read the [contributing](CONTRIBUTING.MD) section if you would like to contribute.\n\n## ğŸ“ Help translate on Weblate\n<a href=\"https://hosted.weblate.org/engage/ytdlnis/\">\n<img src=\"https://hosted.weblate.org/widgets/ytdlnis/-/strings/open-graph.png\" alt=\"Translation status\" />\n</a>\n\n\n<a href=\"https://hosted.weblate.org/engage/ytdlnis/\">\n<img src=\"https://hosted.weblate.org/widgets/ytdlnis/-/multi-auto.svg\" alt=\"Translation status\" />\n</a>\n\n## ğŸ”‘ Connect with third-party apps using the package name\n\nThe app's package name is \"com.deniscerri.ytdl\".\n\n\n## ğŸ¤– Connect with third-party apps using intents\n\nYou can use intents to push commands to the app to run downloads without user interaction.\nAccepted variables:\n\n<b>TYPE</b> -> it can be: audio,video,command <br/>\n<b>BACKGROUND</b> -> it can be: true,false. If its true the app won't show the download card no matter what and run the download in the background <br/>\n\n### An example of downloading an audio item in the background with Tasker\n1. Create Send Intent task\n2. Action: android.intent.action.SEND\n3. Cat: Default\n4. Mime Type: text/*\n5. Extra: android.intent.extra.TEXT:url (instead of \"url\" write the URL of the video you want to download)\n6. Extra: TYPE:audio\n7. Extra: BACKGROUND:true\n\n## ğŸ“„ License\n\n[GNU GPL v3.0](https://github.com/deniscerri/ytdlnis/blob/main/LICENSE)\n\nExcept for the source code licensed under the GPLv3 license, all other parties are prohibited from using the \"YTDLnis\" name as a downloader app, and the same is true for its derivatives. Derivatives include but are not limited to forks and unofficial builds.\n\n## ğŸ˜ Donate\n\n\n[<img src=\"https://raw.githubusercontent.com/WSTxda/WSTxda/main/images/BMC.svg\"\nalt='Donate with BMC'\nheight=\"80\">](https://www.buymeacoffee.com/deniscerri)\n\n## ğŸ™ Thanks\n\n- [decipher3114](https://github.com/decipher3114) for the app's icon\n- [dvd](https://github.com/yausername/dvd) for being an example youtubedl-android implementation\n- [seal](https://github.com/JunkFood02/Seal) for certain design elements and features I wanted to have in this app when I started developing it\n- [youtubedl-android](https://github.com/yausername/youtubedl-android) for porting yt-dlp to Android\n- [yt-dlp](https://github.com/yt-dlp/yt-dlp) and its contributors for making this tool possible. Without it this app wouldn't exist\n\n\nand to a lot of other people, such as contributors.\n",
      "stars_today": 30
    },
    {
      "id": 677376114,
      "name": "Metrolist",
      "full_name": "mostafaalagamy/Metrolist",
      "description": "YouTube Music client for Android",
      "html_url": "https://github.com/mostafaalagamy/Metrolist",
      "stars": 6035,
      "forks": 303,
      "language": "Kotlin",
      "topics": [
        "android",
        "innertube",
        "material-design",
        "material-ui",
        "material3",
        "music",
        "music-player",
        "musicplayer",
        "newpipe",
        "newpipe-extractor",
        "youtube",
        "youtube-music",
        "ytmusic"
      ],
      "created_at": "2023-08-11T12:19:23Z",
      "updated_at": "2026-01-25T01:12:21Z",
      "pushed_at": "2026-01-25T00:35:24Z",
      "open_issues": 577,
      "owner": {
        "login": "mostafaalagamy",
        "avatar_url": "https://avatars.githubusercontent.com/u/80542861?v=4"
      },
      "readme": "<div align=\"center\">\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/icon.png\" width=\"160\" height=\"160\" style=\"display: block; margin: 0 auto\"/>\n<h1>Metrolist</h1>\n<p>YouTube Music client for Android</p>\n\n<div style=\"padding: 16px; margin: 16px 0; background-color: #FFFBE5; border-left: 6px solid #FFC107; border-radius: 4px;\">\n<h2 style=\"margin: 0;\"><strong>âš Warning</strong></h2>\nIf you're in a region where YouTube Music is not supported, you won't be able to use this app <strong>unless</strong> you have a proxy or VPN to connect to a YTM-supported region.\n</div>\n\n<h1>Screenshots</h1>\n\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/screenshots/screenshot_1.png\" width=\"30%\" />\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/screenshots/screenshot_2.png\" width=\"30%\" />\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/screenshots/screenshot_3.png\" width=\"30%\" />\n\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/screenshots/screenshot_4.png\" width=\"30%\" />\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/screenshots/screenshot_5.png\" width=\"30%\" />\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/screenshots/screenshot_6.png\" width=\"30%\" />\n\n<div align=\"center\">\n<h1>Release numbers</h1>\n</div>\n\n[![Latest release](https://img.shields.io/github/v/release/mostafaalagamy/Metrolist?style=for-the-badge)](https://github.com/mostafaalagamy/Metrolist/releases)\n[![GitHub license](https://img.shields.io/github/license/mostafaalagamy/metrolist?style=for-the-badge)](https://github.com/mostafaalagamy/Metrolist/blob/main/LICENSE)\n[![Downloads](https://img.shields.io/github/downloads/mostafaalagamy/Metrolist/total?style=for-the-badge)](https://github.com/mostafaalagamy/Metrolist/releases)\n</div>\n\n<div align=\"center\">\n<h1>Table of Contents</h1>\n</div>\n\n- [Features](#features)\n- [Download Now](#download-now)\n- [FAQ](#faq)\n- [Development Setup](#development-setup)\n- [Translations](#translations)\n- [Support Me](#support-me)\n- [Join our community](#join-our-community)\n- [Contributors](#thanks-to-all-contributors) \n\n<div align=\"center\">\n<h1>Features</h1>\n</div>\n\n- Play any song or video from YT Music\n- Background playback \n- Personalized quick picks \n- Library management \n- Download and cache songs for offline playback\n- Search for songs, albums, artists, videos and playlists\n- Live lyrics \n- YouTube Music account login support\n- Syncing of songs, artists, albums and playlists, from and to your account\n- Skip silence \n- Import playlists \n- Audio normalization \n- Adjust tempo/pitch \n- Local playlist management\n- Reorder songs in playlist or queue \n- Light - Dark - black - Dynamic theme\n- Sleep timer\n- Material 3 \n- etc.\n\n<div align=\"center\">\n<h1>Download Now</h1>\n\n<table>\n<tr>\n<td align=\"center\">\n<a href=\"https://github.com/mostafaalagamy/Metrolist/releases/latest/download/Metrolist.apk\"><img src=\"https://github.com/machiav3lli/oandbackupx/blob/034b226cea5c1b30eb4f6a6f313e4dadcbb0ece4/badge_github.png\" alt=\"Get it on GitHub\" height=\"82\"></a><br/>\n<a href=\"https://www.openapk.net/metrolist/com.metrolist.music/\"><img src=\"https://www.openapk.net/images/openapk-badge.png\" alt=\"Get it on OpenAPK\" height=\"80\"></a>\n</td>\n<td align=\"center\">\n<a href=\"https://apps.obtainium.imranr.dev/redirect?r=obtainium://add/https://github.com/mostafaalagamy/Metrolist/\"><img src=\"https://github.com/ImranR98/Obtainium/blob/main/assets/graphics/badge_obtainium.png\" alt=\"Get it on Obtainium\" height=\"50\"></a>\n</td>\n<td align=\"center\">\n<a href=\"https://apt.izzysoft.de/fdroid/index/apk/com.metrolist.music\"><img src=\"https://gitlab.com/IzzyOnDroid/repo/-/raw/master/assets/IzzyOnDroid.png\" alt=\"Get it on IzzyOnDroid\" height=\"80\"></a><br/>\n<a href=\"https://belberi.com/metrolist/?fbclid=PAY2xjawJP5dlleHRuA2FlbQIxMAABpjSk1oBp4e8aSV4nfX2dfunQObTlMWIkN-aVA9CSq36pnmkHsvfoYTjhHg_aem_9o9OGbQuZ2PjJTArq21UDA\"><img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/fastlane/metadata/android/en-US/images/belberi_github.png\" alt=\"Get it on Belberi\" height=\"82\"></a>\n</td>\n</tr>\n</table>\n\n</div>\n\n<div align=\"center\">\n<h1>Translations</h1>\n\n[![Translation status](https://img.shields.io/weblate/progress/metrolist?style=for-the-badge)](https://hosted.weblate.org/engage/metrolist/)\n\nWe use Weblate to translate Metrolist. For more details or to get started, visit our [Weblate page](https://hosted.weblate.org/projects/Metrolist/).\n\n<a href=\"https://hosted.weblate.org/projects/Metrolist/\">\n<img src=\"https://hosted.weblate.org/widget/Metrolist/horizontal-auto.svg\" alt=\"Translation status\" />\n</a>\n\nThank you very much for helping to make Metrolist accessible to many people worldwide.\n</div>\n\n<div align=\"center\">\n<h1>FAQ</h1>\n</div>\n\n### Q: Why Metrolist isn't showing in Android Auto?\n\n1. Go to Android Auto's settings and tap multiple times on the version in the bottom to enable\n   developer settings\n2. In the three dots menu at the top-right of the screen, click \"Developer settings\"\n3. Enable \"Unknown sources\"\n\n<div align=\"center\">\n<h1>Development Setup</h1>\n</div>\n\n### GitHub Secrets Configuration\n\nThis project uses GitHub Secrets to securely store API keys for building releases. To set up the secrets:\n\n1. Go to your GitHub repository settings\n2. Navigate to **Settings** â†’ **Secrets and variables** â†’ **Actions**\n3. Add the following repository secrets:\n   - `LASTFM_API_KEY`: Your LastFM API key\n   - `LASTFM_SECRET`: Your LastFM secret key\n\n4. Get your LastFM API credentials from: https://www.last.fm/api/account/create\n\n**Note:** These secrets are automatically injected into the build process via GitHub Actions and are not visible in the source code.\n\n<div align=\"center\">\n<h1>Support Me</h1>\n\nIf you'd like to support my work, send a Monero (XMR) donation to this address:\n\n44XjSELSWcgJTZiCKzjpCQWyXhokrH9RqH3rpp35FkSKi57T25hniHWHQNhLeXyFn3DDYqufmfRB1iEtENerZpJc7xJCcqt\n\nOr scan this QR code:\n\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/assets/XMR.png\" alt=\"QR Code\" width=\"200\" height=\"200\" />\n\nOr other\n\n<a href=\"https://www.buymeacoffee.com/mostafaalagamy\">\n<img src=\"https://github.com/mostafaalagamy/Metrolist/blob/main/assets/buymeacoffee.png?raw=true\" alt=\"Buy Me a Coffee\" width=\"150\" height=\"150\" />\n</a>\n\n<div align=\"center\">\n<h1>Join our community</h1>\n\n[![Discord](https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&logo=discord&logoColor=white&labelColor=1c1917)](https://dsc.gg/metrolist)\n[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white&labelColor=1c1917)](https://t.me/metrolistapp)\n</div>\n\n<div align=\"center\">\n<h1>Special thanks</h1>\n\n**InnerTune**\n[Zion Huang](https://github.com/z-huang) â€¢ [Malopieds](https://github.com/Malopieds)\n\n**OuterTune**\n[Davide Garberi](https://github.com/DD3Boh) â€¢ [Michael Zh](https://github.com/mikooomich)\n\nCredits:\n\n[**Kizzy**](https://github.com/dead8309/Kizzy) â€“ for the Discord Rich Presence implementation and inspiration.\n\n[**Better Lyrics**](https://better-lyrics.boidu.dev) â€“ for beautiful time-synced lyrics with word-by-word highlighting, and seamless YouTube Music integration.\n\n[**SimpMusic Lyrics**](https://github.com/maxrave-dev/SimpMusic) â€“ for providing lyrics data through the SimpMusic Lyrics API.\n\nThe open-source community for tools, libraries, and APIs that make this project possible.\n\n<sub>Thank you to all the amazing developers who made this project possible!</sub>\n\n</div>\n\n<div align=\"center\">\n<h1>Thanks to all contributors</h1>\n\n<a href = \"https://github.com/mostafaalagamy/Metrolist/graphs/contributors\">\n<img src = \"https://contrib.rocks/image?repo=mostafaalagamy/Metrolist\" width=\"600\"/>\n</a>\n\n</div>\n\n<div align=\"center\">\n<h1>Disclaimer</h1>\n</div>\n\nThis project and its contents are not affiliated with, funded, authorized, endorsed by, or in any way associated with YouTube, Google LLC, Metrolist Group LLC or any of its affiliates and subsidiaries.\n\nAny trademark, service mark, trade name, or other intellectual property rights used in this project are owned by the respective owners.\n\n**Made with â¤ï¸ by [Mo Agamy](https://github.com/mostafaalagamy)**\n",
      "stars_today": 30
    },
    {
      "id": 120156076,
      "name": "cloudreve",
      "full_name": "cloudreve/cloudreve",
      "description": "ğŸŒ© Self-hosted file management and sharing system, supports multiple storage providers",
      "html_url": "https://github.com/cloudreve/cloudreve",
      "stars": 26744,
      "forks": 3791,
      "language": "Go",
      "topics": [
        "cloud",
        "cloud-storage",
        "cloudreve",
        "file",
        "file-manager",
        "file-sharing",
        "golang"
      ],
      "created_at": "2018-02-04T04:56:38Z",
      "updated_at": "2026-01-25T01:42:41Z",
      "pushed_at": "2026-01-23T07:32:10Z",
      "open_issues": 242,
      "owner": {
        "login": "cloudreve",
        "avatar_url": "https://avatars.githubusercontent.com/u/48898462?v=4"
      },
      "readme": "[ä¸­æ–‡ç‰ˆæœ¬](https://github.com/cloudreve/cloudreve/blob/master/README_zh-CN.md)\n\n<h1 align=\"center\">\n  <br>\n  <a href=\"https://cloudreve.org/\" alt=\"logo\" ><img src=\"https://raw.githubusercontent.com/cloudreve/frontend/master/public/static/img/logo192.png\" width=\"150\"/></a>\n  <br>\n  Cloudreve\n  <br>\n</h1>\n<h4 align=\"center\">Self-hosted file management system with multi-cloud support.</h4>\n\n<p align=\"center\">\n  <a href=\"https://dev.azure.com/abslantliu/cloudreve/_build?definitionId=6\">\n    <img src=\"https://img.shields.io/github/check-runs/cloudreve/cloudreve/master\"\n         alt=\"Azure pipelines\">\n  </a>\n  <a href=\"https://github.com/cloudreve/cloudreve/releases\">\n    <img src=\"https://img.shields.io/github/v/release/cloudreve/cloudreve?include_prereleases\" />\n  </a>\n  <a href=\"https://github.com/cloudreve/cloudreve/releases\">\n     <img src=\"https://badgen.net/static/release%20size/34%20MB/blue\"/>\n  </a>\n  <a href=\"https://hub.docker.com/r/cloudreve/cloudreve\">\n  <img alt=\"Docker Pulls\" src=\"https://img.shields.io/docker/pulls/cloudreve/cloudreve\" />\n  </a>\n</p>\n<p align=\"center\">\n  <a href=\"https://cloudreve.org\">Homepage</a> â€¢\n  <a href=\"https://demo.cloudreve.org\">Try it</a> â€¢\n  <a href=\"https://github.com/cloudreve/cloudreve/discussions\">Discussion</a> â€¢\n  <a href=\"https://docs.cloudreve.org\">Documents</a> â€¢\n  <a href=\"https://github.com/cloudreve/cloudreve/releases\">Download</a> â€¢\n  <a href=\"https://t.me/cloudreve_official\">Telegram</a> â€¢\n  <a href=\"https://discord.com/invite/WTpMFpZT76\">Discord</a>\n</p>\n\n![Screenshot](https://raw.githubusercontent.com/cloudreve/docs/master/images/homepage.png)\n\n## :sparkles: Features\n\n- :cloud: Support storing files into Local, Remote node, OneDrive, S3 compatible API, Qiniu Kodo, Aliyun OSS, Tencent COS, Huawei Cloud OBS, Kingsoft Cloud KS3, Upyun.\n- :outbox_tray: Upload/Download in directly transmission from client to storage providers.\n- ğŸ’¾ Integrate with Aria2/qBittorrent to download files in background, use multiple download nodes to share the load.\n- ğŸ“š Compress/Extract/Preview archived files, download files in batch.\n- ğŸ’» WebDAV support covering all storage providers.\n- :zap:Drag&Drop to upload files or folders, with parallel resumable upload support.\n- :card_file_box: Extract media metadata from files, search files by metadata or tags.\n- :family_woman_girl_boy: Multi-users with multi-groups.\n- :link: Create share links for files and folders with expiration date.\n- :eye_speech_bubble: Preview videos, images, audios, ePub files online; edit texts, diagrams, Markdown, images, Office documents online.\n- :art: Customize theme colors, dark mode, PWA application, SPA, i18n.\n- :rocket: All-in-one packaging, with all features out of the box.\n- ğŸŒˆ ... ...\n\n## :hammer_and_wrench: Deploy\n\nTo deploy Cloudreve, you can refer to [Getting started](https://docs.cloudreve.org/overview/quickstart) for a quick local deployment to test.\n\nWhen you're ready to deploy Cloudreve to a production environment, you can refer to [Deploy](https://docs.cloudreve.org/overview/deploy/) for a complete deployment.\n\n## :gear: Build\n\nPlease refer to [Build](https://docs.cloudreve.org/overview/build/) for how to build Cloudreve from source code.\n\n## :rocket: Contributing\n\nIf you're interested in contributing to Cloudreve, please refer to [Contributing](https://docs.cloudreve.org/api/contributing/) for how to contribute to Cloudreve.\n\n## :alembic: Stacks\n\n- [Go](https://golang.org/) + [Gin](https://github.com/gin-gonic/gin) + [ent](https://github.com/ent/ent)\n- [React](https://github.com/facebook/react) + [Redux](https://github.com/reduxjs/redux) + [Material-UI](https://github.com/mui-org/material-ui)\n\n## :scroll: License\n\nGPL V3\n",
      "stars_today": 29
    },
    {
      "id": 993475914,
      "name": "container",
      "full_name": "apple/container",
      "description": "A tool for creating and running Linux containers using lightweight virtual machines on a Mac. It is written in Swift, and optimized for Apple silicon. ",
      "html_url": "https://github.com/apple/container",
      "stars": 23555,
      "forks": 600,
      "language": "Swift",
      "topics": [],
      "created_at": "2025-05-30T21:26:05Z",
      "updated_at": "2026-01-25T01:18:56Z",
      "pushed_at": "2026-01-24T01:59:29Z",
      "open_issues": 233,
      "owner": {
        "login": "apple",
        "avatar_url": "https://avatars.githubusercontent.com/u/10639145?v=4"
      },
      "readme": "# `container`\n\n`container` is a tool that you can use to create and run Linux containers as lightweight virtual machines on your Mac. It's written in Swift, and optimized for Apple silicon.\n\nThe tool consumes and produces [OCI-compatible container images](https://github.com/opencontainers/image-spec), so you can pull and run images from any standard container registry. You can push images that you build to those registries as well, and run the images in any other OCI-compatible application.\n\n`container` uses the [Containerization](https://github.com/apple/containerization) Swift package for low level container, image, and process management.\n\n![introductory movie showing some basic commands](./docs/assets/landing-movie.gif)\n\n## Get started\n\n### Requirements\n\nYou need a Mac with Apple silicon to run `container`. To build it, see the [BUILDING](./BUILDING.md) document.\n\n`container` is supported on macOS 26, since it takes advantage of new features and enhancements to virtualization and networking in this release. We do not support older versions of macOS and the `container` maintainers typically will not address issues that cannot be reproduced on the macOS 26.\n\n### Install or upgrade\n\nIf you're upgrading, first stop and uninstall your existing `container` (the `-k` flag keeps your user data, while `-d` removes it):\n\n```bash\ncontainer system stop\n/usr/local/bin/uninstall-container.sh -k\n```\n\nDownload the latest signed installer package for `container` from the [GitHub release page](https://github.com/apple/container/releases).\n\nTo install the tool, double-click the package file and follow the instructions. Enter your administrator password when prompted, to give the installer permission to place the installed files under `/usr/local`.\n\nStart the system service with:\n\n```bash\ncontainer system start\n```\n\n### Uninstall\n\nUse the `uninstall-container.sh` script (installed to `/usr/local/bin`) to remove `container` from your system. To remove your user data along with the tool, run:\n\n```bash\n/usr/local/bin/uninstall-container.sh -d\n```\n\nTo retain your user data so that it is available should you reinstall later, run:\n\n```bash\n/usr/local/bin/uninstall-container.sh -k\n```\n\n## Next steps\n\n- Take [a guided tour of `container`](./docs/tutorial.md) by building, running, and publishing a simple web server image.\n- Learn how to [use various `container` features](./docs/how-to.md).\n- Read a brief description and [technical overview](./docs/technical-overview.md) of `container`.\n- Browse the [full command reference](./docs/command-reference.md).\n- [Build and run](./BUILDING.md) `container` on your own development system.\n- View the project [API documentation](https://apple.github.io/container/documentation/).\n\n## Contributing\n\nContributions to `container` are welcomed and encouraged. Please see our [main contributing guide](https://github.com/apple/containerization/blob/main/CONTRIBUTING.md) for more information.\n\n## Project Status\n\nThe container project is currently under active development. Its stability, both for consuming the project as a Swift package and the `container` tool, is only guaranteed within patch versions, such as between 0.1.1 and 0.1.2. Minor version number releases may include breaking changes until we achieve a 1.0.0 release.\n",
      "stars_today": 26
    },
    {
      "id": 683347556,
      "name": "turso",
      "full_name": "tursodatabase/turso",
      "description": "Turso is an in-process SQL database, compatible with SQLite.",
      "html_url": "https://github.com/tursodatabase/turso",
      "stars": 16767,
      "forks": 706,
      "language": "Rust",
      "topics": [
        "database",
        "embedded-database",
        "sql",
        "sqlite3",
        "webassembly"
      ],
      "created_at": "2023-08-26T09:21:36Z",
      "updated_at": "2026-01-25T02:20:45Z",
      "pushed_at": "2026-01-25T01:00:45Z",
      "open_issues": 478,
      "owner": {
        "login": "tursodatabase",
        "avatar_url": "https://avatars.githubusercontent.com/u/139391156?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"assets/turso.png\" alt=\"Turso Database\" width=\"800\"/>\n  <h1 align=\"center\">Turso Database</h1>\n</p>\n\n<p align=\"center\">\n  An in-process SQL database, compatible with SQLite.\n</p>\n\n<p align=\"center\">\n  <a title=\"Build Status\" target=\"_blank\" href=\"https://github.com/tursodatabase/turso/actions/workflows/rust.yml\"><img src=\"https://img.shields.io/github/actions/workflow/status/tursodatabase/turso/rust.yml?style=flat-square\"></a>\n  <a title=\"Releases\" target=\"_blank\" href=\"https://github.com/tursodatabase/turso/releases\"><img src=\"https://img.shields.io/github/release/tursodatabase/turso?style=flat-square&color=9CF\"></a>\n  <a title=\"Rust\" target=\"_blank\" href=\"https://crates.io/crates/turso\"><img alt=\"Crate\" src=\"https://img.shields.io/crates/v/turso\"></a>\n  <a title=\"JavaScript\" target=\"_blank\" href=\"https://www.npmjs.com/package/@tursodatabase/database\"><img alt=\"NPM\" src=\"https://img.shields.io/npm/v/@tursodatabase/database\"></a>\n  <a title=\"Python\" target=\"_blank\" href=\"https://pypi.org/project/pyturso/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/pyturso\"></a>\n  <a title=\"Java\" target=\"_blank\" href=\"https://central.sonatype.com/artifact/tech.turso/turso\"><img alt=\"Maven Central\" src=\"https://img.shields.io/maven-central/v/tech.turso/turso\"></a>\n  <a title=\"MIT\" target=\"_blank\" href=\"https://github.com/tursodatabase/turso/blob/main/LICENSE.md\"><img src=\"http://img.shields.io/badge/license-MIT-orange.svg?style=flat-square\"></a>\n  <br>\n  <a title=\"GitHub Pull Requests\" target=\"_blank\" href=\"https://github.com/tursodatabase/turso/pulls\"><img src=\"https://img.shields.io/github/issues-pr-closed/tursodatabase/turso.svg?style=flat-square&color=FF9966\"></a>\n  <a title=\"GitHub Commits\" target=\"_blank\" href=\"https://github.com/tursodatabase/turso/commits/main\"><img src=\"https://img.shields.io/github/commit-activity/m/tursodatabase/turso.svg?style=flat-square\"></a>\n  <a title=\"Last Commit\" target=\"_blank\" href=\"https://github.com/tursodatabase/turso/commits/main\"><img src=\"https://img.shields.io/github/last-commit/tursodatabase/turso.svg?style=flat-square&color=FF9900\"></a>\n</p>\n<p align=\"center\">\n  <a title=\"Developer's Discord\" target=\"_blank\" href=\"https://discord.gg/jgjmyYgHwB\"><img alt=\"Chat with the Core Developers on Discord\" src=\"https://img.shields.io/discord/1258658826257961020?label=Discord&logo=Discord&style=social&label=Core%20Developers\"></a>\n</p>\n<p align=\"center\">\n  <a title=\"Users's Discord\" target=\"_blank\" href=\"https://tur.so/discord\"><img alt=\"Chat with other users of Turso (and Turso Cloud) on Discord\" src=\"https://img.shields.io/discord/933071162680958986?label=Discord&logo=Discord&style=social&label=Users\"></a>\n</p>\n\n---\n\n## About\n\nTurso Database is an in-process SQL database written in Rust, compatible with SQLite.\n\n> **âš ï¸ Warning:** This software is in BETA. It may still contain bugs and unexpected behavior. Use caution with production data and ensure you have backups.\n\n## Features and Roadmap\n\n* **SQLite compatibility** for SQL dialect, file formats, and the C API [see [document](COMPAT.md) for details]\n* **Change data capture (CDC)** for real-time tracking of database changes.\n* **Multi-language support** for\n  * [Go](bindings/go)\n  * [JavaScript](bindings/javascript)\n  * [Java](bindings/java)\n  * [Python](bindings/python)\n  * [Rust](bindings/rust)\n  * [WebAssembly](bindings/javascript)\n* **Asynchronous I/O** support on Linux with `io_uring`\n* **Cross-platform** support for Linux, macOS, Windows and browsers (through WebAssembly)\n* **Vector support** support including exact search and vector manipulation\n* **Improved schema management** including extended `ALTER` support and faster schema changes.\n\nThe database has the following experimental features:\n\n* **`BEGIN CONCURRENT`** for improved write throughput using multi-version concurrency control (MVCC).\n* **Encryption at rest** for protecting the data locally.\n* **Incremental computation** using DBSP for incremental view maintenance and query subscriptions.\n* **Full-Text-Search** powered by the awesome [tantivy](https://github.com/quickwit-oss/tantivy) library\n\nThe following features are on our current roadmap:\n\n* **Vector indexing** for fast approximate vector search, similar to [libSQL vector search](https://turso.tech/vector).\n\n## Getting Started\n\nPlease see the [Turso Database Manual](docs/manual.md) for more information.\n\n<details>\n<summary>ğŸ’» Command Line</summary>\n<br>\nYou can install the latest `turso` release with:\n\n```shell\ncurl --proto '=https' --tlsv1.2 -LsSf \\\n  https://github.com/tursodatabase/turso/releases/latest/download/turso_cli-installer.sh | sh\n```\n\nThen launch the interactive shell:\n\n```shell\n$ tursodb\n```\n\nThis will start the Turso interactive shell where you can execute SQL statements:\n\n```console\nTurso\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database\nturso> CREATE TABLE users (id INT, username TEXT);\nturso> INSERT INTO users VALUES (1, 'alice');\nturso> INSERT INTO users VALUES (2, 'bob');\nturso> SELECT * FROM users;\n1|alice\n2|bob\n```\n\nYou can also build and run the latest development version with:\n\n```shell\ncargo run\n```\n\nIf you like docker, we got you covered. Simply run this in the root folder:\n\n```bash\nmake docker-cli-build && \\\nmake docker-cli-run\n```\n\n</details>\n\n<details>\n<summary>ğŸ¦€ Rust</summary>\n<br>\n\n```console\ncargo add turso\n```\n\nExample usage:\n\n```rust\nlet db = Builder::new_local(\"sqlite.db\").build().await?;\nlet conn = db.connect()?;\n\nlet res = conn.query(\"SELECT * FROM users\", ()).await?;\n```\n</details>\n\n<details>\n<summary>âœ¨ JavaScript</summary>\n<br>\n\n```console\nnpm i @tursodatabase/database\n```\n\nExample usage:\n\n```js\nimport { connect } from '@tursodatabase/database';\n\nconst db = await connect('sqlite.db');\nconst stmt = db.prepare('SELECT * FROM users');\nconst users = stmt.all();\nconsole.log(users);\n```\n</details>\n\n<details>\n<summary>ğŸ Python</summary>\n<br>\n\n```console\nuv pip install pyturso\n```\n\nExample usage:\n\n```python\nimport turso\n\ncon = turso.connect(\"sqlite.db\")\ncur = con.cursor()\nres = cur.execute(\"SELECT * FROM users\")\nprint(res.fetchone())\n```\n</details>\n\n<details>\n<summary>ğŸ¦« Go</summary>\n<br>\n\n```console\ngo get turso.tech/database/tursogo\ngo install turso.tech/database/tursogo\n```\n\nExample usage:\n```go\nimport (\n    \"database/sql\"\n    _ \"turso.tech/database/tursogo\"\n)\n\nconn, _ = sql.Open(\"turso\", \"sqlite.db\")\ndefer conn.Close()\n\nstmt, _ := conn.Prepare(\"select * from users\")\ndefer stmt.Close()\n\nrows, _ = stmt.Query()\nfor rows.Next() {\n    var id int\n    var username string\n    _ := rows.Scan(&id, &username)\n    fmt.Printf(\"User: ID: %d, Username: %s\\n\", id, username)\n}\n```\n</details>\n\n<details>\n\n<summary>â˜•ï¸ Java</summary>\n<br>\n\nWe integrated Turso Database into JDBC. For detailed instructions on how to use Turso Database with java, please refer to\nthe [README.md under bindings/java](bindings/java/README.md).\n</details>\n\n<details>\n<summary>ğŸ¤– MCP Server Mode</summary>\n<br>\n\n\nThe Turso CLI includes a built-in [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) server that allows AI assistants to interact with your databases.\n\nStart the MCP server with:\n\n```shell\ntursodb your_database.db --mcp\n```\n\n### Configuration\n\nAdd Turso to your MCP client configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"turso\": {\n      \"command\": \"/path/to/.turso/tursodb\",\n      \"args\": [\"/path/to/your/database.db\", \"--mcp\"]\n    }\n  }\n}\n```\n\n### Available Tools\n\nThe MCP server provides nine tools for database interaction:\n\n1. **`open_database`** - Open a new database\n2. **`current_database`** - Describe the current database\n3. **`list_tables`** - List all tables in the database\n4. **`describe_table`** - Describe the structure of a specific table\n5. **`execute_query`** - Execute read-only SELECT queries\n6. **`insert_data`** - Insert new data into tables\n7. **`update_data`** - Update existing data in tables\n8. **`delete_data`** - Delete data from tables\n9. **`schema_change`** - Execute schema modification statements (CREATE TABLE, ALTER TABLE, DROP TABLE)\n\nOnce connected, you can ask your AI assistant:\n\n- \"Show me all tables in the database\"\n- \"What's the schema for the users table?\"\n- \"Find all posts with more than 100 upvotes\"\n- \"Insert a new user with name 'Alice' and email 'alice@example.com'\"\n\n### MCP Clients\n\n<details>\n<summary>Claude Code</summary>\n\nIf you're using [Claude Code](https://claude.ai/code), you can easily connect to your Turso MCP server using the built-in MCP management commands:\n\n#### Quick Setup\n\n1. **Add the MCP server** to Claude Code:\n\n   ```bash\n   claude mcp add my-database -- tursodb ./path/to/your/database.db --mcp\n   ```\n\n2. **Restart Claude Code** to activate the connection\n\n3. **Start querying** your database through natural language!\n\n#### Command Breakdown\n\n```bash\nclaude mcp add my-database -- tursodb ./path/to/your/database.db --mcp\n#              â†‘            â†‘       â†‘                           â†‘\n#              |            |       |                           |\n#              Name         |       Database path               MCP flag\n#                          Separator\n```\n\n- **`my-database`** - Choose any name for your MCP server\n- **`--`** - Required separator between Claude options and your command\n- **`tursodb`** - The Turso database CLI\n- **`./path/to/your/database.db`** - Path to your SQLite database file\n- **`--mcp`** - Enables MCP server mode\n\n#### Example Usage\n\n```bash\n# For a local project database\ncd /your/project\nclaude mcp add my-project-db -- tursodb ./data/app.db --mcp\n\n# For an absolute path\nclaude mcp add analytics-db -- tursodb /Users/you/databases/analytics.db --mcp\n\n# For a specific project (local scope)\nclaude mcp add project-db --local -- tursodb ./database.db --mcp\n```\n\n#### Managing MCP Servers\n\n```bash\n# List all configured MCP servers\nclaude mcp list\n\n# Get details about a specific server\nclaude mcp get my-database\n\n# Remove an MCP server\nclaude mcp remove my-database\n```\n\n</details>\n\n<details>\n<summary>Claude Desktop</summary>\n\nFor Claude Desktop, add the configuration to your `claude_desktop_config.json` file:\n\n```json\n{\n  \"mcpServers\": {\n    \"turso\": {\n      \"command\": \"/path/to/.turso/tursodb\",\n      \"args\": [\"./path/to/your/database.db.db\", \"--mcp\"]\n    }\n  }\n}\n```\n\n</details>\n\n<details>\n<summary>Cursor</summary>\n\nFor Cursor, configure MCP in your settings:\n\n1. Open Cursor settings\n2. Navigate to Extensions â†’ MCP\n3. Add a new server with:\n   - **Name**: `turso`\n   - **Command**: `/path/to/.turso/tursodb`\n   - **Args**: `[\"./path/to/your/database.db.db\", \"--mcp\"]`\n\nAlternatively, you can add it to your Cursor configuration file directly.\n\n</details>\n\n### Direct JSON-RPC Usage\n\nThe MCP server runs as a single process that handles multiple JSON-RPC requests over stdin/stdout. Here's how to interact with it directly:\n\n#### Example with In-Memory Database\n\n```bash\ncat << 'EOF' | tursodb --mcp\n{\"jsonrpc\": \"2.0\", \"id\": 1, \"method\": \"initialize\", \"params\": {\"protocolVersion\": \"2024-11-05\", \"capabilities\": {}, \"clientInfo\": {\"name\": \"client\", \"version\": \"1.0\"}}}\n{\"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"tools/call\", \"params\": {\"name\": \"schema_change\", \"arguments\": {\"query\": \"CREATE TABLE users (id INTEGER, name TEXT, email TEXT)\"}}}\n{\"jsonrpc\": \"2.0\", \"id\": 3, \"method\": \"tools/call\", \"params\": {\"name\": \"list_tables\", \"arguments\": {}}}\n{\"jsonrpc\": \"2.0\", \"id\": 4, \"method\": \"tools/call\", \"params\": {\"name\": \"insert_data\", \"arguments\": {\"query\": \"INSERT INTO users VALUES (1, 'Alice', 'alice@example.com')\"}}}\n{\"jsonrpc\": \"2.0\", \"id\": 5, \"method\": \"tools/call\", \"params\": {\"name\": \"execute_query\", \"arguments\": {\"query\": \"SELECT * FROM users\"}}}\nEOF\n```\n\n#### Example with Existing Database\n\n```bash\n# Working with an existing database file\ncat << 'EOF' | tursodb mydb.db --mcp\n{\"jsonrpc\": \"2.0\", \"id\": 1, \"method\": \"initialize\", \"params\": {\"protocolVersion\": \"2024-11-05\", \"capabilities\": {}, \"clientInfo\": {\"name\": \"client\", \"version\": \"1.0\"}}}\n{\"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"tools/call\", \"params\": {\"name\": \"list_tables\", \"arguments\": {}}}\nEOF\n```\n\n</details>\n\n## Contributing\n\nWe'd love to have you contribute to Turso Database! Please check out the [contribution guide] to get started.\n\n### Found a data corruption bug? Get up to $1,000.00\n\nSQLite is loved because it is the most reliable database in the world. The next evolution of SQLite has\nto match or surpass this level of reliability. Turso is built with [Deterministic Simulation Testing](simulator/)\nfrom the ground up, and is also tested by [Antithesis](https://antithesis.com).\n\nEven during Alpha, if you find a bug that leads to a data corruption and demonstrate\nhow our simulator failed to catch it, you can get up to $1,000.00. As the project matures we will\nincrease the size of the prize, and the scope of the bugs.\n\nList of rewarded cases:\n\n* B-Tree interior cell replacement issue in btrees with depth >=3 ([#2106](https://github.com/tursodatabase/turso/issues/2106))\n* Don't allow autovacuum to be flipped on non-empty databases ([#3830](https://github.com/tursodatabase/turso/pull/3830))\n\nMore details [here](https://turso.algora.io).\n\nTurso core staff are not eligible.\n\n## FAQ\n\n### Is Turso Database ready for production use?\n\nTurso Database is currently under heavy development and is **not** ready for production use.\n\n### How is Turso Database different from Turso's libSQL?\n\nTurso Database is a project to build the next evolution of SQLite in Rust, with a strong open contribution focus and features like native async support, vector search, and more. The libSQL project is also an attempt to evolve SQLite in a similar direction, but through a fork rather than a rewrite.\n\nRewriting SQLite in Rust started as an unassuming experiment, and due to its incredible success, replaces libSQL as our intended direction. At this point, libSQL is production ready, Turso Database is not - although it is evolving rapidly. More details [here](https://turso.tech/blog/we-will-rewrite-sqlite-and-we-are-going-all-in).\n\n## Publications\n\n* Pekka Enberg, Sasu Tarkoma, Jon Crowcroft Ashwin Rao (2024). Serverless Runtime / Database Co-Design With Asynchronous I/O. In _EdgeSys â€˜24_. [[PDF]](https://penberg.org/papers/penberg-edgesys24.pdf)\n* Pekka Enberg, Sasu Tarkoma, and Ashwin Rao (2023). Towards Database and Serverless Runtime Co-Design. In _CoNEXT-SW â€™23_. [[PDF](https://penberg.org/papers/penberg-conext-sw-23.pdf)] [[Slides](https://penberg.org/papers/penberg-conext-sw-23-slides.pdf)]\n\n## License\n\nThis project is licensed under the [MIT license].\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in Turso Database by you, shall be licensed as MIT, without any additional\nterms or conditions.\n\n[contribution guide]: CONTRIBUTING.md\n[MIT license]: LICENSE.md\n\n## Partners\n\nThanks to all the partners of Turso!\n\n<a href=\"https://antithesis.com/\"><img src=\"assets/antithesis.jpg\" width=\"400\"></a>\n\n<a href=\"https://blacksmith.sh\"><img src=\"assets/blacksmith.svg\" width=\"400\"></a>\n\n<a href=\"https://nyrkio.com/\"><img src=\"assets/turso-nyrkio.png\" width=\"400\"></a>\n\n## Contributors\n\nThanks to all the contributors to Turso Database!\n\n<a href=\"https://github.com/tursodatabase/turso/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=tursodatabase/turso\" />\n</a>\n",
      "stars_today": 26
    },
    {
      "id": 257485422,
      "name": "vite",
      "full_name": "vitejs/vite",
      "description": "Next generation frontend tooling. It's fast!",
      "html_url": "https://github.com/vitejs/vite",
      "stars": 77758,
      "forks": 7739,
      "language": "TypeScript",
      "topics": [
        "build-tool",
        "dev-server",
        "frontend",
        "hmr",
        "vite"
      ],
      "created_at": "2020-04-21T05:03:57Z",
      "updated_at": "2026-01-25T02:27:28Z",
      "pushed_at": "2026-01-24T10:51:12Z",
      "open_issues": 630,
      "owner": {
        "login": "vitejs",
        "avatar_url": "https://avatars.githubusercontent.com/u/65625612?v=4"
      },
      "readme": "<p align=\"center\">\n  <br>\n  <br>\n  <a href=\"https://vite.dev\" target=\"_blank\" rel=\"noopener noreferrer\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://vite.dev/vite-light.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://vite.dev/vite-dark.svg\">\n      <img alt=\"vite logo\" src=\"https://vite.dev/vite-dark.svg\" height=\"60\">\n    </picture>\n  </a>\n  <br>\n  <br>\n</p>\n<br/>\n<p align=\"center\">\n  <a href=\"https://npmjs.com/package/vite\"><img src=\"https://img.shields.io/npm/v/vite.svg\" alt=\"npm package\"></a>\n  <a href=\"https://nodejs.org/en/about/previous-releases\"><img src=\"https://img.shields.io/node/v/vite.svg\" alt=\"node compatibility\"></a>\n  <a href=\"https://github.com/vitejs/vite/actions/workflows/ci.yml\"><img src=\"https://github.com/vitejs/vite/actions/workflows/ci.yml/badge.svg?branch=main\" alt=\"build status\"></a>\n  <a href=\"https://chat.vite.dev\"><img src=\"https://img.shields.io/badge/chat-discord-blue?style=flat&logo=discord\" alt=\"discord chat\"></a>\n</p>\n<br/>\n\n# Vite âš¡\n\n> Next Generation Frontend Tooling\n\n- ğŸ’¡ Instant Server Start\n- âš¡ï¸ Lightning Fast HMR\n- ğŸ› ï¸ Rich Features\n- ğŸ“¦ Optimized Build\n- ğŸ”© Universal Plugin Interface\n- ğŸ”‘ Fully Typed APIs\n\nVite (French word for \"quick\", pronounced [`/viËt/`](https://cdn.jsdelivr.net/gh/vitejs/vite@main/docs/public/vite.mp3), like \"veet\") is a new breed of frontend build tooling that significantly improves the frontend development experience. It consists of two major parts:\n\n- A dev server that serves your source files over [native ES modules](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Modules), with [rich built-in features](https://vite.dev/guide/features.html) and astonishingly fast [Hot Module Replacement (HMR)](https://vite.dev/guide/features.html#hot-module-replacement).\n\n- A [build command](https://vite.dev/guide/build.html) that bundles your code with [Rollup](https://rollupjs.org), pre-configured to output highly optimized static assets for production.\n\nIn addition, Vite is highly extensible via its [Plugin API](https://vite.dev/guide/api-plugin.html) and [JavaScript API](https://vite.dev/guide/api-javascript.html) with full typing support.\n\n[Read the Docs to Learn More](https://vite.dev).\n\n## Packages\n\n| Package                                         | Version (click for changelogs)                                                                                                    |\n| ----------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------- |\n| [vite](packages/vite)                           | [![vite version](https://img.shields.io/npm/v/vite.svg?label=%20)](packages/vite/CHANGELOG.md)                                    |\n| [@vitejs/plugin-legacy](packages/plugin-legacy) | [![plugin-legacy version](https://img.shields.io/npm/v/@vitejs/plugin-legacy.svg?label=%20)](packages/plugin-legacy/CHANGELOG.md) |\n| [create-vite](packages/create-vite)             | [![create-vite version](https://img.shields.io/npm/v/create-vite.svg?label=%20)](packages/create-vite/CHANGELOG.md)               |\n\n## Contribution\n\nSee [Contributing Guide](CONTRIBUTING.md).\n\n## License\n\n[MIT](LICENSE).\n\n## Sponsors\n\n<p align=\"center\">\n  <a target=\"_blank\" href=\"https://github.com/sponsors/yyx990803\">\n    <img alt=\"sponsors\" src=\"https://sponsors.vuejs.org/vite.svg?v2\">\n  </a>\n</p>\n",
      "stars_today": 25
    },
    {
      "id": 33263118,
      "name": "uBlock",
      "full_name": "gorhill/uBlock",
      "description": "uBlock Origin - An efficient blocker for Chromium and Firefox. Fast and lean.",
      "html_url": "https://github.com/gorhill/uBlock",
      "stars": 61108,
      "forks": 3914,
      "language": "JavaScript",
      "topics": [
        "blocker",
        "browser-extension",
        "chromium",
        "firefox",
        "javascript",
        "ublock",
        "ublock-origin"
      ],
      "created_at": "2015-04-01T17:51:11Z",
      "updated_at": "2026-01-25T01:39:19Z",
      "pushed_at": "2026-01-23T17:32:07Z",
      "open_issues": 17,
      "owner": {
        "login": "gorhill",
        "avatar_url": "https://avatars.githubusercontent.com/u/585534?v=4"
      },
      "readme": "[![Badge Commits]][Commit Rate]\n[![Badge Issues]][Issues]\n[![Badge Localization]][Crowdin]\n[![Badge License]][License]\n[![Badge NPM]][NPM]\n[![Badge Mozilla]][Mozilla]\n[![Badge Chrome]][Chrome]\n[![Badge Edge]][Edge]\n\n***\n\n<h1 align=\"center\">\n<sub>\n<img src=\"https://github.com/gorhill/uBlock/blob/master/src/img/ublock.svg\" height=\"38\" width=\"38\">\n</sub>\nuBlock Origin (uBO)\n</h1>\n\n| Browser   | Install from ... | Status |\n| :-------: | ---------------- | ------ |\n| <img src=\"https://github.com/user-attachments/assets/b0136512-56a5-4856-8c50-4971c957a24f\" alt=\"Get uBlock Origin for Firefox\"> | <a href=\"https://addons.mozilla.org/addon/ublock-origin/\">Firefox Add-ons</a> | [uBO works best on Firefox](https://github.com/gorhill/uBlock/wiki/uBlock-Origin-works-best-on-Firefox) |\n| <img src=\"https://github.com/user-attachments/assets/3a7569f8-688b-4eb1-a643-8d0fe173aefe\" alt=\"Get uBlock Origin for Microsoft Edge\"> | <a href=\"https://microsoftedge.microsoft.com/addons/detail/ublock-origin/odfafepnkmbhccpbejgmiehpchacaeak\">Edge Add-ons</a> |\n| <img src=\"https://github.com/user-attachments/assets/938f080c-fe64-4e48-8b89-4bfceabb56e6\" alt=\"Get uBlock Origin for Opera\"> | <a href=\"https://addons.opera.com/extensions/details/ublock/\">Opera Add-ons</a> |\n| <img src=\"https://github.com/user-attachments/assets/5463ef88-873b-4516-8514-5277664cfde7\" alt=\"Get uBlock Origin for Chromium\"> | <a href=\"https://chromewebstore.google.com/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm\">Chrome Web Store</a> | <a href=\"https://github.com/uBlockOrigin/uBlock-issues/wiki/About-Google-Chrome's-%22This-extension-may-soon-no-longer-be-supported%22\">About Google Chrome's \"This extension may soon no longer be supported\"</a><br>End of support on Chrome 139 |\n| <img src=\"https://github.com/user-attachments/assets/2e9037c4-836d-44c1-a716-ba96e89daaff\" alt=\"Get uBlock Origin for Thunderbird\"> | <a href=\"https://addons.thunderbird.net/thunderbird/addon/ublock-origin/\">Thunderbird Add-ons</a> | [No longer updated and stuck at 1.49.2.](https://github.com/uBlockOrigin/uBlock-issues/issues/2928) Later versions require \"GitHub - Releases\". |\n| <img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c2/GitHub_Invertocat_Logo.svg\" height=\"50\" alt=\"Get uBlock Origin through GitHub\"> | <a href=\"https://github.com/gorhill/uBlock/releases\">GitHub - Releases</a> | Stable and development versions on Firefox, Chromium MV2, and Thunderbird. Must be placed manually into web browsers; the Chromium and Thunderbird versions usually won't auto-update.\n\n***\n\nuBlock Origin (uBO) is a CPU and memory-efficient [wide-spectrum content blocker][Blocking] for Chromium and Firefox. It blocks ads, trackers, coin miners, popups, annoying anti-blockers, malware sites, etc., by default using [EasyList][EasyList], [EasyPrivacy][EasyPrivacy], [Peter Lowe's Blocklist][Peter Lowe's Blocklist], [Online Malicious URL Blocklist][Malicious Blocklist], and uBO [filter lists][uBO Filters]. There are many other lists available to block even more. Hosts files are also supported. uBO uses the EasyList filter syntax and [extends][Extended Syntax] the syntax to work with custom rules and filters.\n\nYou may easily unselect any preselected filter lists if you think uBO blocks too much. For reference, Adblock Plus installs with only EasyList, ABP filters, and Acceptable Ads enabled by default.\n\nIt is important to note that using a blocker is **NOT** [theft]. Do not fall for this creepy idea. The _ultimate_ logical consequence of `blocking = theft` is the criminalization of the inalienable right to privacy.\n\nAds, \"unintrusive\" or not, are just the visible portion of the privacy-invading means entering your browser when you visit most sites. **uBO's primary goal is to help users neutralize these privacy-invading methods** in a way that welcomes those users who do not wish to use more technical means.\n\n***\n\n* [Documentation](#documentation)\n* [Installation](#installation)\n  * [Firefox](#firefox)\n  * [Thunderbird](#thunderbird)\n  * [Chromium](#chromium)\n  * [All Programs](#all-programs)\n  * [Enterprise Deployment](#enterprise-deployment)\n* [Release History](#release-history)\n* [Translations](#translations)\n* [About](#about)\n\n## Documentation\n\n<table>\n    <thead>\n        <tr>\n            <th>Basic Mode</th>\n            <th>Advanced Mode</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>The <a href=\"https://github.com/gorhill/uBlock/wiki/Quick-guide:-popup-user-interface\">simple popup user interface</a> for an install-it-and-forget-it type of installation that is configured optimally by default.</td>\n            <td>The <a href=\"https://github.com/gorhill/uBlock/wiki/Dynamic-filtering:-quick-guide\">advanced popup user interface</a> includes a point-and-click firewall that is configurable on a per-site basis.</td>\n        </tr>\n        <tr>\n            <td align=\"center\" valign=\"top\"><a href=\"https://github.com/gorhill/uBlock/wiki/Quick-guide:-popup-user-interface\"><img src=\"https://user-images.githubusercontent.com/585534/232531044-c4ac4dd5-0b60-4c1e-aabb-914be04b846c.png\"/></a></td>\n            <td align=\"center\" valign=\"top\"><a href=\"https://github.com/gorhill/uBlock/wiki/Dynamic-filtering:-quick-guide\"><img src=\"https://user-images.githubusercontent.com/585534/232531439-a8f81cc3-6622-45c4-8b32-7348cecf6e98.png\"/></a></td>\n        </tr>\n    </tbody>\n</table>\n\nVisit the [Wiki][Wiki] for documentation.\n\nFor support, questions, or help, visit [/r/uBlockOrigin][Reddit].\n\n## Installation\n\n[Required Permissions][Permissions]\n\n#### Firefox\n\n[Firefox Add-ons][Mozilla]\n\n[Development Builds][Beta]\n\nuBO [works best][Works Best] on Firefox and is available for desktop and Android versions.\n\n#### Thunderbird\n\n[Thunderbird Add-ons][Thunderbird]\n\nIn Thunderbird, uBlock Origin does not affect emails, just feeds.\n\n#### Chromium\n\n[Chrome Web Store][Chrome]\n\n[Microsoft Edge Add-ons][Edge] (Published by [Nicole Rolls][Nicole Rolls] until version 1.62. Ownership transfer at version 1.64.)\n\n[Opera Add-ons][Opera]\n\n[Development Builds][Chrome Dev]\n\nuBO should be compatible with any Chromium-based browser.\n\n#### All Programs\n\nDo **NOT** use uBO with any other content blocker. uBO [performs][Performance] as well as or better than most popular blockers. Other blockers can prevent uBO's privacy or anti-blocker-defusing features from working correctly.\n\n[Manual Installation][Manual Installation]\n\n#### Enterprise Deployment\n\n[Deploying uBO][Deployment]\n\n## Release History\n\n[Releases Page][Releases]\n\n## Translations\n\nHelp translate uBO via [Crowdin][Crowdin].\n\n## About\n\n[Manifesto][Manifesto]\n\n[Privacy Policy][Privacy Policy]\n\n[GPLv3 License][License]\n\nFree. Open-source. For users by users. No donations sought.\n\nIf you ever want to contribute something, think about the people working hard to maintain the filter lists you are using, which are available to use by all for free.\n\n\n<!----------------------------------------------------------------------------->\n\n[Peter Lowe's Blocklist]: https://pgl.yoyo.org/adservers/\n[Malicious Blocklist]: https://gitlab.com/malware-filter/urlhaus-filter#malicious-url-blocklist\n[Performance]: https://www.debugbear.com/blog/chrome-extensions-website-performance#the-impact-of-ad-blocking-on-website-performance\n[EasyPrivacy]: https://easylist.to/#easyprivacy\n[Thunderbird]: https://addons.thunderbird.net/thunderbird/addon/ublock-origin/\n[Chrome Dev]: https://chromewebstore.google.com/detail/ublock-origin-development/cgbcahbpdhpcegmbfconppldiemgcoii\n[EasyList]: https://easylist.to/#easylist\n[Mozilla]: https://addons.mozilla.org/addon/ublock-origin/\n[Crowdin]: https://crowdin.com/project/ublock\n[Chrome]: https://chromewebstore.google.com/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm\n[Reddit]: https://www.reddit.com/r/uBlockOrigin/\n[Theft]: https://x.com/LeaVerou/status/518154828166725632\n[Opera]: https://addons.opera.com/extensions/details/ublock/\n[Edge]: https://microsoftedge.microsoft.com/addons/detail/ublock-origin/odfafepnkmbhccpbejgmiehpchacaeak\n[NPM]: https://www.npmjs.com/package/@gorhill/ubo-core\n\n[Manifesto]: MANIFESTO.md\n[License]: LICENSE.txt\n\n[Nicole Rolls]: https://github.com/nicole-ashley\n\n<!---------------------------------[ Internal ]-------------------------------->\n\n[Manual Installation]: https://github.com/gorhill/uBlock/tree/master/dist#install\n[Extended Syntax]: https://github.com/gorhill/uBlock/wiki/Static-filter-syntax#extended-syntax\n[Privacy Policy]: https://github.com/gorhill/uBlock/wiki/Privacy-policy\n[uBO Filters]: https://github.com/uBlockOrigin/uAssets/tree/master/filters\n[Permissions]: https://github.com/gorhill/uBlock/wiki/Permissions\n[Commit Rate]: https://github.com/gorhill/uBlock/commits/master\n[Works Best]: https://github.com/gorhill/uBlock/wiki/uBlock-Origin-works-best-on-Firefox\n[Deployment]: https://github.com/gorhill/uBlock/wiki/Deploying-uBlock-Origin\n[Blocking]: https://github.com/gorhill/uBlock/wiki/Blocking-mode\n[Releases]: https://github.com/gorhill/uBlock/releases\n[Issues]: https://github.com/uBlockOrigin/uBlock-issues/issues\n[Beta]: https://github.com/gorhill/uBlock/blob/master/dist/README.md#for-beta-version\n[Wiki]: https://github.com/gorhill/uBlock/wiki\n\n<!----------------------------------[ Badges ]--------------------------------->\n\n[Badge Localization]: https://d322cqt584bo4o.cloudfront.net/ublock/localized.svg\n[Badge Commits]: https://img.shields.io/github/commit-activity/m/gorhill/ublock?label=Commits\n[Badge Mozilla]: https://img.shields.io/amo/rating/ublock-origin?label=Firefox\n[Badge License]: https://img.shields.io/badge/License-GPLv3-blue.svg\n[Badge Chrome]: https://img.shields.io/chrome-web-store/rating/cjpalhdlnbpafiamejdnhcphjbkeiagm?label=Chrome\n[Badge Edge]: https://img.shields.io/badge/dynamic/json?label=Edge&color=brightgreen&query=%24.averageRating&suffix=%2F%35&url=https%3A%2F%2Fmicrosoftedge.microsoft.com%2Faddons%2Fgetproductdetailsbycrxid%2Fodfafepnkmbhccpbejgmiehpchacaeak\n[Badge Issues]: https://img.shields.io/github/issues/uBlockOrigin/uBlock-issues\n[Badge NPM]: https://img.shields.io/npm/v/@gorhill/ubo-core\n",
      "stars_today": 24
    },
    {
      "id": 3390243,
      "name": "servo",
      "full_name": "servo/servo",
      "description": "Servo aims to empower developers with a lightweight, high-performance alternative for embedding web technologies in applications.",
      "html_url": "https://github.com/servo/servo",
      "stars": 35160,
      "forks": 3448,
      "language": "Rust",
      "topics": [
        "browser",
        "rust",
        "servo",
        "web",
        "webbrowser",
        "webengine",
        "webplatform"
      ],
      "created_at": "2012-02-08T19:07:25Z",
      "updated_at": "2026-01-25T02:26:15Z",
      "pushed_at": "2026-01-25T01:55:21Z",
      "open_issues": 3039,
      "owner": {
        "login": "servo",
        "avatar_url": "https://avatars.githubusercontent.com/u/2566135?v=4"
      },
      "readme": "# The Servo Parallel Browser Engine Project\n\nServo is a prototype web browser engine written in the\n[Rust](https://github.com/rust-lang/rust) language. It is currently developed on\n64-bit macOS, 64-bit Linux, 64-bit Windows, 64-bit OpenHarmony, and Android.\n\nServo welcomes contribution from everyone. Check out:\n\n- The [Servo Book](https://book.servo.org) for documentation\n- [servo.org](https://servo.org/) for news and guides\n\nCoordination of Servo development happens:\n- Here in the Github Issues\n- On the [Servo Zulip](https://servo.zulipchat.com/)\n- In video calls advertised in the [Servo Project](https://github.com/servo/project/issues) repo.\n\n## Getting started\n\nFor more detailed build instructions, see the Servo Book under [Getting the Code] and [Building Servo].\n\n[Getting the Code]: https://book.servo.org/building/getting-the-code.html\n[Building Servo]: https://book.servo.org/building/building.html\n\n### macOS\n\n- Download and install [Xcode](https://developer.apple.com/xcode/) and [`brew`](https://brew.sh/).\n- Install `uv`: `curl -LsSf https://astral.sh/uv/install.sh | sh` \n- Install `rustup`: `curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh`\n- Restart your shell to make sure `cargo` is available\n- Install the other dependencies: `./mach bootstrap`\n- Build servoshell: `./mach build`\n\n### Linux\n\n- Install `curl`:\n  - Arch: `sudo pacman -S --needed curl`\n  - Debian, Ubuntu: `sudo apt install curl`\n  - Fedora: `sudo dnf install curl`\n  - Gentoo: `sudo emerge net-misc/curl`\n- Install `uv`: `curl -LsSf https://astral.sh/uv/install.sh | sh` \n- Install `rustup`: `curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh`\n- Restart your shell to make sure `cargo` is available\n- Install the other dependencies: `./mach bootstrap`\n- Build servoshell: `./mach build`\n\n### Windows\n\n- Download [`uv`](https://docs.astral.sh/uv/getting-started/installation/#standalone-installer), [`choco`](https://chocolatey.org/install#individual), and [`rustup`](https://win.rustup.rs/)\n  - Be sure to select *Quick install via the Visual Studio Community installer*\n- In the Visual Studio Installer, ensure the following components are installed:\n  - **Windows 10/11 SDK (anything >= 10.0.19041.0)** (`Microsoft.VisualStudio.Component.Windows{10, 11}SDK.{>=19041}`)\n  - **MSVC v143 - VS 2022 C++ x64/x86 build tools (Latest)** (`Microsoft.VisualStudio.Component.VC.Tools.x86.x64`)\n  - **C++ ATL for latest v143 build tools (x86 & x64)** (`Microsoft.VisualStudio.Component.VC.ATL`)\n- Restart your shell to make sure `cargo` is available\n- Install the other dependencies: `.\\mach bootstrap`\n- Build servoshell: `.\\mach build`\n\n### Android\n\n- Ensure that the following environment variables are set:\n  - `ANDROID_SDK_ROOT`\n  - `ANDROID_NDK_ROOT`: `$ANDROID_SDK_ROOT/ndk/28.2.13676358/`\n `ANDROID_SDK_ROOT` can be any directory (such as `~/android-sdk`).\n  All of the Android build dependencies will be installed there.\n- Install the latest version of the [Android command-line\n  tools](https://developer.android.com/studio#command-tools) to\n  `$ANDROID_SDK_ROOT/cmdline-tools/latest`.\n- Run the following command to install the necessary components:\n  ```shell\n  sudo $ANDROID_SDK_ROOT/cmdline-tools/latest/bin/sdkmanager --install \\\n   \"build-tools;34.0.0\" \\\n   \"emulator\" \\\n   \"ndk;28.2.13676358\" \\\n   \"platform-tools\" \\\n   \"platforms;android-33\" \\\n   \"system-images;android-33;google_apis;x86_64\"\n  ```\n- Follow the instructions above for the platform you are building on\n\n### OpenHarmony\n\n- Follow the instructions above for the platform you are building on to prepare the environment.\n- Depending on the target distribution (e.g. `HarmonyOS NEXT` vs pure `OpenHarmony`) the build configuration will differ slightly.\n- Ensure that the following environment variables are set\n  - `DEVECO_SDK_HOME` (Required when targeting `HarmonyOS NEXT`)\n  - `OHOS_BASE_SDK_HOME` (Required when targeting `OpenHarmony`)\n  - `OHOS_SDK_NATIVE` (e.g. `${DEVECO_SDK_HOME}/default/openharmony/native` or `${OHOS_BASE_SDK_HOME}/${API_VERSION}/native`)\n  - `SERVO_OHOS_SIGNING_CONFIG`: Path to json file containing a valid signing configuration for the demo app.\n- Review the detailed instructions at [Building for OpenHarmony].\n- The target distribution can be modified by passing `--flavor=<default|harmonyos>` to `mach <build|package|install>`.\n",
      "stars_today": 24
    },
    {
      "id": 628160489,
      "name": "SimpMusic",
      "full_name": "maxrave-dev/SimpMusic",
      "description": "A cross-platform music app using YouTube Music for backend",
      "html_url": "https://github.com/maxrave-dev/SimpMusic",
      "stars": 7295,
      "forks": 332,
      "language": "Kotlin",
      "topics": [
        "android",
        "android-16",
        "android-app",
        "android-application",
        "android-auto",
        "compose-multiplatform",
        "exoplayer",
        "kotlin",
        "linux",
        "macos",
        "media3",
        "mp3",
        "music",
        "spotify",
        "video-streaming",
        "windows",
        "youtube",
        "youtube-music"
      ],
      "created_at": "2023-04-15T04:53:33Z",
      "updated_at": "2026-01-25T00:21:27Z",
      "pushed_at": "2026-01-20T17:48:43Z",
      "open_issues": 370,
      "owner": {
        "login": "maxrave-dev",
        "avatar_url": "https://avatars.githubusercontent.com/u/113747128?v=4"
      },
      "readme": "<div align=\"center\"> <img src=\"https://raw.githubusercontent.com/maxrave-dev/SimpMusic/main/fastlane/metadata/android/en-US/images/featureGraphic.png\"> <h1>SimpMusic</h1>  \nA FOSS YouTube Music client for Android and Desktop with many features from<br>Spotify, SponsorBlock, ReturnYouTubeDislike using Compose Multiplatform to develop.\n<br> \n<br>\n<a href=\"https://github.com/maxrave-dev/SimpMusic/releases\"><img src=\"https://img.shields.io/github/v/release/maxrave-dev/SimpMusic\"></a> <a href=\"https://github.com/maxrave-dev/SimpMusic/releases\"><img src=\"https://img.shields.io/github/downloads/maxrave-dev/SimpMusic/total\"></a> <br> <br> <a href=\"https://trendshift.io/repositories/13482\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13482\" alt=\"maxrave-dev%2FSimpMusic | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n<br>\n<br>\n<a href=\"https://www.producthunt.com/products/simpmusic/reviews?utm_source=badge-product_rating&utm_medium=badge&utm_source=badge-simpmusic\" target=\"_blank\"><img src=\"https://api.producthunt.com/widgets/embed-image/v1/product_rating.svg?product_id=903836&theme=dark\" alt=\"SimpMusic - A&#0032;FOSS&#0032;YouTube&#0032;Music&#0032;client&#0032;for&#0032;Android&#0032;with&#0032;many&#0032;features | Product Hunt\" style=\"width: 242px; height: 108px;\" width=\"242\" height=\"108\" /></a>\n<br> \n<h4>Download</h4>  \n<a href=\"https://apt.izzysoft.de/packages/com.maxrave.simpmusic/\"><img src=\"https://gitlab.com/IzzyOnDroid/repo/-/raw/master/assets/IzzyOnDroid.png\" width=\"200\"></a> \n<a href=\"https://f-droid.org/en/packages/com.maxrave.simpmusic/\"><img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\" width=\"200\"></a> \n<a href=\"https://www.openapk.net/simpmusic/com.maxrave.simpmusic/\"><img src=\"https://www.openapk.net/images/openapk-badge.png\" width=\"200\"></a> \n<a href=\"https://github.com/maxrave-dev/SimpMusic/releases\"><img src=\"https://raw.githubusercontent.com/NeoApplications/Neo-Backup/034b226cea5c1b30eb4f6a6f313e4dadcbb0ece4/badge_github.png\" width=\"200\"></a> \n<h4>Nightly Build</h4>  \n<a href=\"https://simpmusic.org/nightly-download\"><img src=\"https://github.com/maxrave-dev/SimpMusic/actions/workflows/android.yml/badge.svg\"></a><br/> <a href=\"https://simpmusic.org/nightly-download\"><img src=\"https://raw.githubusercontent.com/NeoApplications/Neo-Backup/034b226cea5c1b30eb4f6a6f313e4dadcbb0ece4/badge_github.png\" width=\"200\"></a> \n</div>  \n\n> SimpMusic is available on Desktop now!\n  \n## Features âœ¨ï¸    \n- Play music from YouTube Music or YouTube for free, without ads and in the background    \n- Browsing Home, Charts, Podcast, Moods & Genre with YouTube Music data at high speed    \n- Search everything on YouTube    \n- Analyze your playing data, create custom playlists, and sync with YouTube Music...    \n- Spotify Canvas supported    \n- Play 1080p video option with subtitle    \n- AI song suggestions    \n- Customize your playlist, synced with YouTube Music\n- Notifications from followed artists    \n- Caching and offline playback support    \n- Synced lyrics from SimpMusic Lyrics, LRCLIB, Spotify (require login) and YouTube Transcript - AI lyrics translation (BETA) (\\*)  \n- Personalize data (\\**) and multi-YouTube-account support    \n- Supports SponsorBlock and Return YouTube Dislike\n- Sleep Timer    \n- Android Auto with online content\n- Discord Rich Presence support\n- And many more!    \n  \n> (\\*) Use your OpenAI or Gemini API key    \n> (\\**) For users who chose \"Send back to Google\" feature    \n    \n> **Warning**    \n > This app is in the beta stage, so it may have many bugs and make it crash. If you find any bugs,      \n> please create an issue or contact me via email or Discord server.   \n> Because of depending on YouTube Music, the player error will happen and it's normally, please don't ask me about the stable state of this app.\n    \n## Screenshots    \n <p align=\"center\">          \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/01.png?raw=true\" width=\"200\" />          \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/02.png?raw=true\" width=\"200\" />          \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/03.png?raw=true\" width=\"200\" />          \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/04.png?raw=true\" width=\"200\" /> </p> <p align=\"center\">          \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/05.png?raw=true\" width=\"200\" />          \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/17.png?raw=true\" width=\"200\" />  \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/07.png?raw=true\" width=\"200\" />          \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/08.png?raw=true\" width=\"200\" /> </p> <p align=\"center\">          \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/09.png?raw=true\" width=\"200\" />          \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/10.png?raw=true\" width=\"200\" />         \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/11.png?raw=true\" width=\"200\" /> \n     <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/12.png?raw=true\" width=\"200\" /> </p> <p align=\"center\">    \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/13.png?raw=true\" width=\"200\" />          \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/14.png?raw=true\" width=\"200\" />         \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/15.png?raw=true\" width=\"200\" /> \n     <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/16.png?raw=true\" width=\"200\" /> </p> <p align=\"center\">  \n   <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/screenshot/06.png?raw=true\" width=\"800\" />  \n</p>\n\n #### More [screenshots](https://photos.app.goo.gl/AbieoXG5ctDrpwzp7) here.\n \n ## Data    \n- This app uses hidden API from YouTube Music with some tricks to get data from YouTube Music.    \n- Use Spotify Web API and some tricks to get Spotify Canvas and Lyrics    \n- Thanks to [InnerTune](https://github.com/z-huang/InnerTune/) for the idea to get data from YouTube Music. This repo is my inspiration to create this app.    \n- Special thanks to [SmartTube](https://github.com/yuliskov/SmartTube). This repo help me to extract the streaming URL of YouTube Music.    \n- My app is using [SponsorBlock](https://sponsor.ajay.app/) to skip sponsor in YouTube videos.    \n- ReturnYouTubeDislike for getting information on votes \n- Main lyrics data from SimpMusic Lyrics\n- Alternative lyrics data from LRCLIB. More information [LRCLIB](https://lrclib.net/)    \n \n ## Privacy    \n SimpMusic doesn't have any tracker or third-party server for collecting user data in FOSS version. If YouTube      \nlogged-in users enable \"Send back to Google\" feature, SimpMusic only uses YouTube Music Tracking API to send listening history and listening record of video to Google for better recommendations and      \nsupporting artist or YouTube Creator (For API reference,      \nsee [this](https://github.com/maxrave-dev/SimpMusic/blob/13f7ab6e5fa521b62a9fd31a1cefdc2787a1a8af/kotlinYtmusicScraper/src/main/java/com/maxrave/kotlinytmusicscraper/Ytmusic.kt#L639C4-L666C1)).\n\nWe collect crash data in the Full version to improve the app.\n   \n## Full or FOSS version\nI use [Sentry](http://sentry.io) crashlytics to catch all crashes in the Full version. [Sentry](https://github.com/getsentry/sentry) is the open-source project.\n If you don't want to be collected crash data, you must use FOSS version.\n \n## Desktop app\n\n### Before downloading the Desktop app, make sure your system installed 3 applications below:\n- [Gstreamer](https://gstreamer.freedesktop.org/download/): Required for playback audio.\n- [Yt-dlp](https://github.com/yt-dlp/yt-dlp): Required for getting streaming URL from YouTube (when using 256kps or higher quality).\n\n### Which file should I download?\n- For Windows: Download the file with extension `.msi`.\n- For macOS: Download the file with extension `.dmg`.\n- For Linux: Download the file with extension `.deb` (Debian based), `.rpm` (Red-hat based), `.AppImage` (all Linux distributions) .\n\n### Log in guide: https://www.simpmusic.org/blogs/en/how-to-log-in-on-desktop-app\n\n### Some limitations on Desktop app:\n- No offline playback support.\n- No video playback support.\n- Very buggy on some Linux distributions (because of Jetbrains not fix).\n\nPlease report issues on our Discord server if you find any bugs.\n \n## Translation    \n[![Crowdin](https://badges.crowdin.net/simpmusic/localized.svg)](https://crowdin.com/project/simpmusic)\n<br/>\nYou can help me translate this app into your language by using Crowdin [SimpMusic on Crowdin](https://crowdin.com/project/simpmusic)    \n #### Special thanks to all translators on Crowdin â¤ï¸    \n ## FAQ    \n #### 1. Wrong Lyrics?    \n Lyrics are provided by LRCLIB and other sources. Sometimes lyrics may not match perfectly with YouTube\"      \nvideoId\" parameter. So I need to use some \"String Matcher\" and \"Duration\" for search lyrics. So      \nsometimes, some songs or videos get the wrong lyrics    \n    \n#### 2. Why the name or brand is \"SimpMusic\"?    \n Simply, because I love the name. It's a combination of 'Simple' and 'Music'. But SimpMusic is not a simple app, it's all you need for a powerful music streaming app.    \n  \n#### More FAQ, join [my Discord channel](https://discord.com/channels/1136988323819298856/1349800418745778196)  \n  ## Developer/Team    \n- [maxrave-dev](https://github.com/maxrave-dev/SimpMusic): Founder/Developer/Designer    \n- [Owen Connor](https://github.com/owencz1998): Discord Server Admin.    \n- [ilianoKokoro](https://github.com/ilianoKokoro): Discord Server Admin.\n- [CrazyWolf13](https://github.com/CrazyWolf13): Issues organizer/planner.\n\nWe're looking for more contributors, all contributions are welcome!\nSee our [CODE OF CONDUCT](https://github.com/maxrave-dev/SimpMusic/blob/main/CODE_OF_CONDUCT.md)\n\nThanks for all my contributors:\n\n<a href=\"https://github.com/maxrave-dev/SimpMusic/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=maxrave-dev/SimpMusic\" />\n</a>\n\n ## Showcase\nThis project is following clean architecture and MVVM pattern (in UI, app module).\n\n ### Dependencies graph\n  <p float=\"left\">        \n  <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/main/asset/dependencies_graph.svg?raw=true\" width=\"800\"> \n  </p>\n\n ## Support & Donations \n #### Special thanks to all supporter â¤ï¸    \n <div align=\"left\"> \n <a href=\"https://simpmusic.org/\"><img alt=\"Visit the website\" height=\"50\" src=\"https://cdn.jsdelivr.net/npm/@intergrav/devins-badges@3/assets/cozy/documentation/website_vector.svg\"></a> &nbsp;        \n<a href=\"https://discord.gg/Rq5tWVM9Hg\"><img alt=\"Discord Server\" height=\"50\" src=\"https://cdn.jsdelivr.net/npm/@intergrav/devins-badges@3/assets/cozy/social/discord-plural_vector.svg\"></a> &nbsp;        \n<br> <a href=\"https://www.buymeacoffee.com/maxrave\"><img alt=\"Buy me a Coffee\" height=\"50\" src=\"https://cdn.jsdelivr.net/npm/@intergrav/devins-badges@3/assets/cozy/donate/buymeacoffee-singular_vector.svg\"></a> &nbsp;        \n<a href=\"https://liberapay.com/maxrave/\"><img alt=\"liberapay\" height=\"50\"        \nsrc=\"https://raw.githubusercontent.com/liberapay/liberapay.com/master/www/assets/liberapay/logo-v2_black-on-yellow.svg\"></a> \n</div>\n    \n ### MOMO or Vietnamese banking    \n <p float=\"left\">        \n <img src=\"https://github.com/maxrave-dev/SimpMusic/blob/dev/asset/52770992.jpg?raw=true\" width=\"300\"> \n </p>\n\n## SimpMusic is sponsored by:\n<br />\n<a href=\"https://vercel.com/oss\">\n  <img alt=\"Vercel OSS Program\" src=\"https://vercel.com/oss/program-badge.svg\" />\n</a>\n<br />\n<br />\n<a href=\"https://www.digitalocean.com/?refcode=d7f6eedfb9a9&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=badge\"><img src=\"https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%201.svg\" width=\"300\" alt=\"DigitalOcean Referral Badge\" /></a>\n<br>\n<br>\n<a href=\"https://crowdin.com\">\n<img src=\"https://support.crowdin.com/assets/logos/plate/png/crowdin-logo-with-plate.png\" width=\"300\"/>\n</a>\n<br>\n<a href=\"https://sentry.io\">\n<img src=\"https://github.com/maxrave-dev/SimpMusic/blob/dev/asset/sentry.svg?raw=true\" width=\"300\"/>\n</a>\n<br>\n<br>\n\nGet a free $200 credit over 60 days on DigitalOcean: [GET NOW](https://www.digitalocean.com/?refcode=d7f6eedfb9a9&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=badge)\n\nCrowdin and Sentry both have a free enterprise plan for Open-source projects. Follow the URLs: \n- [Open Source License Request Form | Crowdin](https://crowdin.com/page/open-source-project-setup-request)\n- [Sentry for Open Source | Sentry](https://sentry.io/for/open-source/)\n\nCheck out the Vercel open-source program:\n- https://vercel.com/open-source-program\n\n*This project is a part of SimpMusic.org Open-source project by me [maxrave-dev](https://github.com/maxrave-dev)*\n",
      "stars_today": 24
    },
    {
      "id": 145464445,
      "name": "tiptap",
      "full_name": "ueberdosis/tiptap",
      "description": "The headless rich text editor framework for web artisans.",
      "html_url": "https://github.com/ueberdosis/tiptap",
      "stars": 34745,
      "forks": 2850,
      "language": "TypeScript",
      "topics": [
        "editor",
        "javascript",
        "js",
        "prosemirror",
        "react",
        "renderless-components",
        "rich-text",
        "tiptap",
        "vue",
        "wysiwyg",
        "wysiwyg-editor"
      ],
      "created_at": "2018-08-20T19:58:58Z",
      "updated_at": "2026-01-25T02:27:31Z",
      "pushed_at": "2026-01-24T16:52:19Z",
      "open_issues": 846,
      "owner": {
        "login": "ueberdosis",
        "avatar_url": "https://avatars.githubusercontent.com/u/16939337?v=4"
      },
      "readme": "![Tiptap Editor](.github/assets/cover.png)\n\n[![LFX Health Score](https://insights.production.lfx.dev/api/badge/health-score?project=tiptap)](https://insights.linuxfoundation.org/project/tiptap)\n[![Build Status](https://github.com/ueberdosis/tiptap/actions/workflows/build.yml/badge.svg)](https://github.com/ueberdosis/tiptap/actions/workflows/build.yml)\n[![Version](https://img.shields.io/npm/v/@tiptap/core.svg?label=version)](https://www.npmjs.com/package/@tiptap/core)\n[![Downloads](https://img.shields.io/npm/dm/@tiptap/core.svg)](https://npmcharts.com/compare/@tiptap/core?minimal=true)\n[![License](https://img.shields.io/npm/l/@tiptap/core.svg)](https://www.npmjs.com/package/@tiptap/core)\n[![Chat](https://img.shields.io/badge/chat-on%20discord-7289da.svg?sanitize=true)](https://discord.gg/WtJ49jGshW)\n[![Sponsor](https://img.shields.io/static/v1?label=Sponsor&message=%E2%9D%A4&logo=GitHub)](https://github.com/sponsors/ueberdosis)\n\n# Tiptap Editor\n\nThe Tiptap Editor is a headless, framework-agnostic rich text editor that's customizable and extendable through extensions. Its headless nature means it comes without a set user interface, offering full design freedom (for a jumpstart, see linked [UI templates](#examples-codesandbox-and-ui-templates) below). Tiptap is based on the highly reliable [ProseMirror](https://github.com/ProseMirror/prosemirror) library.\n\nTiptap Editor is complemented by the collaboration open-source backend [Hocuspocus](https://github.com/ueberdosis/hocuspocus). Both the Editor and Hocuspocus form the foundation of the [Tiptap Suite](https://tiptap.dev/).\n\n### How does the Tiptap Editor work?\n\n- **Headless Framework:** Tiptap does not rely on a user interface. So there is no need for class overrides or code hacks. If you do need an example UI feel free to browse our [UI templates](#examples-codesandbox-and-ui-templates) linked below.\n- **Framework-agnostic:** The Tiptap Editor is designed to work across different frontend frameworks. This means whether you're using Vue, React, or plain JavaScript, Tiptap integrates without compatibility issues.\n- **Extension based:** Extensions in Tiptap allow for a tailored editing experience, from simple text styling to advanced features like drag-and-drop block editing. You have the option to choose from over 100 extensions available in the [documentation](https://tiptap.dev/docs/editor/extensions) and [community](https://github.com/ueberdosis/awesome-tiptap/#community-extensions) to enhance your editor's functionality.\n- **Customize your UX:** The editor was built to give you control to define your own [extensions](https://tiptap.dev/docs/editor/guide/custom-extensions) and [nodes](https://tiptap.dev/docs/editor/api/nodes).\n\n### Editor Pro Extensions\n\nThe **Pro Extensions** are a set of advanced functionalities that enhance the capabilities of the Tiptap Editor. They are additional features that can be integrated into the base editor to provide more sophisticated editing options.\n\nKey functionalities include collaborative editing, commenting, versioning, document conversion and AI related features.\nReview the docs right [here](https://tiptap.dev/docs/editor/extensions).\n\nPro Extensions need a valid subscription.\n\n### Make your editor collaborative\n\nInterested in collaborative editing? Check out our open-source package [Hocuspocus](https://github.com/ueberdosis/hocuspocus) - a collaboration backend built around the CRDT power of [Yjs](https://github.com/yjs/yjs). Hocuspocus serves as the backbone for the [Tiptap Suite](https://tiptap.dev/).\n\n## Documentation\n\nFor more detailed information, make sure to check out our [documentation](https://tiptap.dev/docs/editor/installation). If you encounter any problems or have suggestions for our system, please open an issue.\n\n### Examples, CodeSandbox and UI Templates\n\nHave a look at the [examples to see Tiptap in action](https://tiptap.dev/examples) or review and fork our codesandboxes.\n\n- [Basic example of the Tiptap editor.](https://codesandbox.io/p/devbox/editor-9x9dkd?embed=1&file=%2Fsrc%2FApp.js)\n- [Collaboration ready Tiptap CodeSandbox](https://codesandbox.io/p/devbox/collaboration-4stk94)\n- React notion-like block editor template: [Demo](https://templates.tiptap.dev/)\n\n## About Tiptap\n\nTiptap is a collection of developer components based on open-source technology, forming the basis of our advanced, paid features. It includes the open-source editor component, collaboration features, Content AI, and Tiptap Cloud. We are developing open-source products that also shape our paid features. We're committed to improving both, ensuring quality and reliability in every update.\n\nFor more details, visit the Tiptap [documentation](https://tiptap.dev/docs/editor/introduction) or [website](https://tiptap.dev/).\n\n### Community\n\nFor help, discussion about best practices, or any other conversation that would benefit from being searchable:\n\n[Discuss Tiptap on GitHub](https://github.com/ueberdosis/tiptap/discussions)\n\n### Sponsors ğŸ’–\n\n<table>\n  <tr>\n    <td align=\"center\">\n      <a href=\"https://www.complish.app/\">\n        <img src=\"https://uploads-ssl.webflow.com/5fa93d27380666789a1cbbd3/5fae50824b4d2d06f3d2898f_Frame%20374.png\" width=\"25\"><br>\n        <strong>Complish</strong>\n      </a>\n    </td>\n    <td align=\"center\">\n      <a href=\"https://www.storyblok.com/\">\n        <img src=\"https://unavatar.io/github/storyblok\" width=\"25\"><br>\n        <strong>Storyblok</strong>\n      </a>\n    </td>\n    <td align=\"center\">\n      <a href=\"https://posthog.com/\">\n        <img src=\"https://unavatar.io/github/posthog\" width=\"25\"><br>\n        <strong>PostHog</strong>\n      </a>\n    </td>\n    <td align=\"center\" width=\"100\">\n      <a href=\"https://reflect.app/\">\n        <img src=\"https://unavatar.io/reflect.app\" width=\"25\"><br>\n        <strong>Reflect</strong>\n      </a>\n    </td>\n    <td align=\"center\" width=\"100\">\n      <a href=\"https://ziffmedia.com/\">\n        <img src=\"https://unavatar.io/github/ziffmedia\" width=\"25\"><br>\n        <strong>Ziff Media</strong>\n      </a>\n    </td>\n    <td align=\"center\" width=\"100\">\n      <a href=\"https://www.basewell.com/\">\n        <img src=\"https://unavatar.io/github/Basewell\" width=\"25\"><br>\n        <strong>Basewell</strong>\n      </a>\n    </td>\n    <td align=\"center\" width=\"100\">\n      <a href=\"https://poggio.io\">\n        <img src=\"https://unavatar.io/github/poggiolabs\" width=\"25\"><br>\n        <strong>Poggio</strong>\n      </a>\n    </td>\n  </tr>\n</table>\n\n[iFixit](https://www.ifixit.com/), [ApostropheCMS](https://apostrophecms.com/), [Novadiscovery](http://www.novadiscovery.com/), [Omics Data Automation](https://www.omicsautomation.com), [Flow Mobile](https://www.flowmobile.app/), [DocIQ](https://www.dociq.io/) and [hundreds of awesome individuals](https://github.com/sponsors/ueberdosis).\n\n### Contributing\n\nFeel like adding some magic of your own to Tiptap Editor Core? We welcome contributions! Please see our [CONTRIBUTING](CONTRIBUTING.md) guidelines for how to get started.\n\n### Contributors\n\n[Sam Willis](https://github.com/samwillis),\n[Brian Hung](https://github.com/BrianHung),\n[Dirk Holtwick](https://github.com/holtwick),\n[Sam Duvall](https://github.com/SamDuvall),\n[Christoph Flathmann](https://github.com/Chrissi2812),\n[Erick Wilder](https://github.com/erickwilder),\n[Marius Tolzmann](https://github.com/mariux),\n[jjangga0214](https://github.com/jjangga0214),\n[Maya Nedeljkovich](https://github.com/mayacoda),\n[Ryan Bliss](https://github.com/ryanbliss),\n[Gregor](https://github.com/gambolputty) and [many more](../../contributors).\n\n## License\n\nThe MIT License (MIT). Please see [License File](LICENSE.md) for more information.\n",
      "stars_today": 23
    },
    {
      "id": 626896474,
      "name": "SafeLine",
      "full_name": "chaitin/SafeLine",
      "description": "SafeLine is a self-hosted WAF(Web Application Firewall) / reverse proxy to protect your web apps from attacks and exploits.",
      "html_url": "https://github.com/chaitin/SafeLine",
      "stars": 20248,
      "forks": 1299,
      "language": "Go",
      "topics": [
        "api-gateway",
        "application-security",
        "appsec",
        "blueteam",
        "bruteforce",
        "captcha",
        "cve",
        "cybersecurity",
        "firewall",
        "hackers",
        "http-flood",
        "security",
        "self-hosted",
        "sql-injection",
        "vulnerability",
        "waf",
        "web-application-firewall",
        "web-security",
        "websecurity",
        "xss"
      ],
      "created_at": "2023-04-12T11:30:14Z",
      "updated_at": "2026-01-25T00:42:45Z",
      "pushed_at": "2025-11-05T08:13:12Z",
      "open_issues": 63,
      "owner": {
        "login": "chaitin",
        "avatar_url": "https://avatars.githubusercontent.com/u/7302766?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"/images/banner.png\" width=\"400\" />\n</p>\n\n<h4 align=\"center\">\n  SafeLine - Make your web apps secure\n</h4>\n\n<p align=\"center\">\n  <a target=\"_blank\" href=\"https://ly.safepoint.cloud/laA8asp\">ğŸ  Website</a> &nbsp; | &nbsp;\n  <a target=\"_blank\" href=\"https://ly.safepoint.cloud/w2AeHhb\">ğŸ“– Docs</a> &nbsp; | &nbsp;\n  <a target=\"_blank\" href=\"https://ly.safepoint.cloud/hSMd4SH\">ğŸ” Live Demo</a> &nbsp; | &nbsp;\n  <a target=\"_blank\" href=\"https://discord.gg/SVnZGzHFvn\">ğŸ™‹â€â™‚ï¸ Discord</a> &nbsp; | &nbsp;\n  <a target=\"_blank\" href=\"/README_CN.md\">ä¸­æ–‡ç‰ˆ</a>\n</p>\n\n## ğŸ‘‹ INTRODUCTION\n\nSafeLine is a self-hosted **`WAF(Web Application Firewall)`** to protect your web apps from attacks and exploits.\n\nA web application firewall helps protect web apps by filtering and monitoring HTTP traffic between a web application and the Internet. It typically protects web apps from attacks such as `SQL injection`, `XSS`, `code injection`, `os command injection`, `CRLF injection`, `ldap injection`, `xpath injection`, `RCE`, `XXE`, `SSRF`, `path traversal`, `backdoor`, `bruteforce`, `http-flood`, `bot abused`, among others.\n\n#### ğŸ’¡ How It Works\n\n<img src=\"/images/how-it-works.png\" width=\"800\" />\n\nBy deploying a WAF in front of a web application, a shield is placed between the web application and the Internet. While a proxy server protects a client machineâ€™s identity by using an intermediary, a WAF is a type of reverse-proxy, protecting the server from exposure by having clients pass through the WAF before reaching the server.\n\nA WAF protects your web apps by filtering, monitoring, and blocking any malicious HTTP/S traffic traveling to the web application, and prevents any unauthorized data from leaving the app. It does this by adhering to a set of policies that help determine what traffic is malicious and what traffic is safe. Just as a proxy server acts as an intermediary to protect the identity of a client, a WAF operates in similar fashion but acting as a reverse proxy intermediary that protects the web app server from a potentially malicious client.\n\nits core capabilities include:\n\n- Defenses for web attacks\n- Proactive bot abused defense \n- HTML & JS code encryption\n- IP-based rate limiting\n- Web Access Control List\n\n#### âš¡ï¸ Screenshots\n\n| <img src=\"./images/screenshot-1.png\" width=370 /> | <img src=\"./images/screenshot-2.png\" width=370 /> |\n| ------------------------------------------------- | ------------------------------------------------- | \n| <img src=\"./images/screenshot-3.png\" width=370 /> | <img src=\"./images/screenshot-4.png\" width=370 /> | \n\nGet [Live Demo](https://demo.waf.chaitin.com:9443/)\n\n## ğŸ”¥ FEATURES\n\nList of the main features as follows:\n\n- **`Block Web Attacks`**\n  - It defenses for all of web attacks, such as `SQL injection`, `XSS`, `code injection`, `os command injection`, `CRLF injection`, `XXE`, `SSRF`, `path traversal` and so on.\n- **`Rate Limiting`**\n  - Defend your web apps against `DoS attacks`, `bruteforce attempts`, `traffic surges`, and other types of abuse by throttling traffic that exceeds defined limits.\n- **`Anti-Bot Challenge`**\n  - Anti-Bot challenges to protect your website from `bot attacks`, humen users will be allowed, crawlers and bots will be blocked.\n- **`Authentication Challenge`**\n  - When authentication challenge turned on, visitors need to enter the password, otherwise they will be blocked.\n- **`Dynamic Protection`**\n  - When dynamic protection turned on, html and js codes in your web server will be dynamically encrypted by each time you visit.\n\n#### ğŸ§© Showcases\n\n|                               | Legitimate User                                     | Malicious User                                                   |\n| ----------------------------- | --------------------------------------------------- | ---------------------------------------------------------------- | \n| **`Block Web Attacks`**       | <img src=\"./images/skeleton.png\" width=270 />       | <img src=\"./images/blocked-for-attack-detected.png\" width=270 /> |\n| **`Rate Limiting`**           | <img src=\"./images/skeleton.png\" width=270 />       | <img src=\"./images/blocked-for-access-too-fast.png\" width=270 /> |\n| **`Anti-Bot Challenge`**       | <img src=\"./images/captcha-1.gif\" width=270 />      | <img src=\"./images/captcha-2.gif\" width=270 />                     |\n| **`Auth Challenge`**          | <img src=\"./images/auth-1.gif\" width=270 />         | <img src=\"./images/auth-2.gif\" width=270 />                        |\n| **`HTML Dynamic Protection`** | <img src=\"./images/dynamic-html-1.png\" width=270 /> | <img src=\"./images/dynamic-html-2.png\" width=270 />              |\n| **`JS Dynamic Protection`**   | <img src=\"./images/dynamic-js-1.png\" width=270 />   | <img src=\"./images/dynamic-js-2.png\" width=270 />                | \n\n## ğŸš€ Quickstart\n\n> [!WARNING]\n> ä¸­å›½å¤§é™†ç”¨æˆ·å®‰è£…å›½é™…ç‰ˆå¯èƒ½ä¼šå¯¼è‡´æ— æ³•è¿æ¥äº‘æœåŠ¡ï¼Œè¯·æŸ¥çœ‹ [ä¸­æ–‡ç‰ˆå®‰è£…æ–‡æ¡£](https://docs.waf-ce.chaitin.cn/zh/%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/%E5%AE%89%E8%A3%85%E9%9B%B7%E6%B1%A0)\n\n#### ğŸ“¦ Installing\n\nInformation on how to install SafeLine can be found in the [Install Guide](https://docs.waf.chaitin.com/en/GetStarted/Deploy)\n\n#### âš™ï¸ Protecting Web Apps\n\nto see [Configuration](https://docs.waf.chaitin.com/en/GetStarted/AddApplication)\n\n## ğŸ“‹ More Informations\n\n#### Effect Evaluation\n\n| Metric            | ModSecurity, Level 1 | CloudFlare, Free     | SafeLine, Balance      | SafeLine, Strict      |\n| ----------------- | -------------------- | -------------------- | ---------------------- | --------------------- |\n| Total Samples     | 33669                | 33669                | 33669                  | 33669                 |\n| **Detection**     | 69.74%               | 10.70%               | 71.65%                 | **76.17%**            |\n| **False Positive**| 17.58%               | 0.07%                | **0.07%**              | 0.22%                 |\n| **Accuracy**      | 82.20%               | 98.40%               | **99.45%**             | 99.38%                |\n\n\n#### Is SafeLine Production-Ready?\n\nYes, SafeLine is production-ready.\n\n- Over 180,000 installations worldwide\n- Protecting over 1,000,000 Websites\n- Handling over 30,000,000,000 HTTP Requests Daily\n\n#### ğŸ™‹â€â™‚ï¸ Community\n\nJoin our [Discord](https://discord.gg/SVnZGzHFvn) to get community support, the core team members are identified by the STAFF role in Discord.\n\n- channel [#feedback](https://discord.com/channels/1243085666485534830/1243120292822253598): for new features discussion.\n- channel [#FAQ](https://discord.com/channels/1243085666485534830/1263761679619981413): for FAQ.\n- channel [#general](https://discord.com/channels/1243085666485534830/1243115843919806486): for any other questions.\n\nSeveral contact options exist for our community, the primary one being Discord. These are in addition to GitHub issues for creating a new issue.\n\n<p align=\"left\">\n  <a target=\"_blank\" href=\"https://discord.gg/SVnZGzHFvn\"><img src=\"https://img.shields.io/badge/Discord-5865F2?style=flat&logo=discord&logoColor=white\"></a> &nbsp;\n  <a target=\"_blank\" href=\"https://x.com/safeline_waf\"><img src=\"https://img.shields.io/badge/X.com-000000?style=flat&logo=x&logoColor=white\"></a> &nbsp;\n  <a target=\"_blank\" href=\"/images/wechat.png\"><img src=\"https://img.shields.io/badge/WeChat-07C160?style=flat&logo=wechat&logoColor=white\"></a>\n</p>\n\n#### ğŸ’ª PRO Edition\n\nComing soon!\n\n#### ğŸ“ License\n\nSee [LICENSE](/LICENSE.md) for details.\n",
      "stars_today": 22
    },
    {
      "id": 315035371,
      "name": "amnezia-client",
      "full_name": "amnezia-vpn/amnezia-client",
      "description": "Amnezia VPN Client (Desktop+Mobile)",
      "html_url": "https://github.com/amnezia-vpn/amnezia-client",
      "stars": 9716,
      "forks": 686,
      "language": "C++",
      "topics": [
        "cloak",
        "gfw",
        "ikev2",
        "openvpn",
        "shadowsocks",
        "vpn",
        "vpn-client",
        "vpn-server",
        "wireguard"
      ],
      "created_at": "2020-11-22T12:44:43Z",
      "updated_at": "2026-01-24T23:03:42Z",
      "pushed_at": "2026-01-23T11:33:32Z",
      "open_issues": 572,
      "owner": {
        "login": "amnezia-vpn",
        "avatar_url": "https://avatars.githubusercontent.com/u/74861536?v=4"
      },
      "readme": "# Amnezia VPN\n\n### _The best client for self-hosted VPN_\n\n\n[![Build Status](https://github.com/amnezia-vpn/amnezia-client/actions/workflows/deploy.yml/badge.svg?branch=dev)](https://github.com/amnezia-vpn/amnezia-client/actions/workflows/deploy.yml?query=branch:dev)\n[![Gitpod ready-to-code](https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod)](https://gitpod.io/#https://github.com/amnezia-vpn/amnezia-client)\n\n### [English]([https://github.com/amnezia-vpn/amnezia-client/blob/dev/README_RU.md](https://github.com/amnezia-vpn/amnezia-client/tree/dev?tab=readme-ov-file#)) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](https://github.com/amnezia-vpn/amnezia-client/blob/dev/README_RU.md)\n\n\n[Amnezia](https://amnezia.org?utm_source=github&utm_campaign=amnezia_website-readme-en) is an open-source VPN client, with a key feature that enables you to deploy your own VPN server on your server.\n\n[![Image](https://github.com/amnezia-vpn/amnezia-client/blob/dev/metadata/img-readme/uipic4.png)](https://amnezia.org)\n\n### [Website](https://amnezia.org?utm_source=github&utm_campaign=amnezia_website-readme-en) | [Alt website link](https://storage.googleapis.com/amnezia/amnezia.org?utm_source=github&utm_campaign=amnezia_website-readme-en-mirror) | [Documentation](https://docs.amnezia.org) | [Troubleshooting](https://docs.amnezia.org/troubleshooting)\n\n> [!TIP]\n> If the [Amnezia website](https://amnezia.org?utm_source=github&utm_campaign=amnezia_website-readme-en) is blocked in your region, you can use an [Alternative website link](https://storage.googleapis.com/amnezia/amnezia.org?utm_source=github&utm_campaign=amnezia_website-readme-en-mirror).\n\n<a href=\"https://amnezia.org/en/downloads?utm_source=github&utm_campaign=amnezia_button-readme-en\"><img src=\"https://github.com/amnezia-vpn/amnezia-client/blob/dev/metadata/img-readme/download-website.svg\" width=\"150\" style=\"max-width: 100%; margin-right: 10px\"></a>\n<a href=\"https://storage.googleapis.com/amnezia/amnezia.org?m-path=/en/downloads&utm_source=github&utm_campaign=amnezia_button-readme-en-mirrow\"><img src=\"https://github.com/amnezia-vpn/amnezia-client/blob/dev/metadata/img-readme/download-alt.svg\" width=\"150\" style=\"max-width: 100%;\"></a>\n\n[All releases](https://github.com/amnezia-vpn/amnezia-client/releases)\n\n<br/>\n\n<a href=\"https://www.testiny.io\"><img src=\"https://github.com/amnezia-vpn/amnezia-client/blob/dev/metadata/img-readme/testiny.png\" height=\"28px\"></a>\n\n## Features\n\n- Very easy to use - enter your IP address, SSH login, password and Amnezia will automatically install VPN docker containers to your server and connect to the VPN.\n- Classic VPN-protocols: OpenVPN, WireGuard and IKEv2 protocols.\n- Protocols with traffic Masking (Obfuscation): OpenVPN over [Cloak](https://github.com/cbeuw/Cloak) plugin, Shadowsocks (OpenVPN over Shadowsocks), [AmneziaWG](https://docs.amnezia.org/documentation/amnezia-wg/) and XRay.\n- Split tunneling support - add any sites to the client to enable VPN only for them or add Apps (only for Android and Desktop).\n- Windows, MacOS, Linux, Android, iOS releases.\n- Support for AmneziaWG protocol configuration on [Keenetic beta firmware](https://docs.keenetic.com/ua/air/kn-1611/en/6319-latest-development-release.html#UUID-186c4108-5afd-c10b-f38a-cdff6c17fab3_section-idm33192196168192-improved).\n\n## Links\n\n- [https://amnezia.org](https://amnezia.org) - Project website | [Alternative link (mirror)](https://storage.googleapis.com/kldscp/amnezia.org)\n- [https://docs.amnezia.org](https://docs.amnezia.org) - Documentation\n- [https://www.reddit.com/r/AmneziaVPN](https://www.reddit.com/r/AmneziaVPN) - Reddit  \n- [https://t.me/amnezia_vpn_en](https://t.me/amnezia_vpn_en) - Telegram support channel (English) \n- [https://t.me/amnezia_vpn_ir](https://t.me/amnezia_vpn_ir) - Telegram support channel (Farsi) \n- [https://t.me/amnezia_vpn_mm](https://t.me/amnezia_vpn_mm) - Telegram support channel (Myanmar)  \n- [https://t.me/amnezia_vpn](https://t.me/amnezia_vpn) - Telegram support channel (Russian)\n- [https://vpnpay.io/en/amnezia-premium/](https://vpnpay.io/en/amnezia-premium/) - Amnezia Premium\n\n## Tech\n\nAmneziaVPN uses several open-source projects to work:\n\n- [OpenSSL](https://www.openssl.org/)\n- [OpenVPN](https://openvpn.net/)\n- [Shadowsocks](https://shadowsocks.org/)\n- [Qt](https://www.qt.io/)\n- [LibSsh](https://libssh.org) - forked from Qt Creator\n- and more...\n\n## Checking out the source code\n\nMake sure to pull all submodules after checking out the repo.\n\n```bash\ngit submodule update --init --recursive\n```\n\n## Development\n\nWant to contribute? Welcome!\n\n### Help with translations\n\nDownload the most actual translation files.\n\nGo to [\"Actions\" tab](https://github.com/amnezia-vpn/amnezia-client/actions?query=is%3Asuccess+branch%3Adev), click on the first line.\nThen scroll down to the \"Artifacts\" section and download \"AmneziaVPN_translations\".\n\nUnzip this file.\nEach *.ts file contains strings for one corresponding language.\n\nTranslate or correct some strings in one or multiple *.ts files and commit them back to this repository into the ``client/translations`` folder.\nYou can do it via a web-interface or any other method you're familiar with.\n\n### Building sources and deployment\n\nCheck deploy folder for build scripts. \n\n### How to build an iOS app from source code on MacOS\n\n1. First, make sure you have [XCode](https://developer.apple.com/xcode/) installed, at least version 14 or higher.\n\n2. We use QT to generate the XCode project. We need QT version 6.6.2. Install QT for MacOS [here](https://doc.qt.io/qt-6/macos.html) or [QT Online Installer](https://www.qt.io/download-open-source). Required modules:\n   - MacOS\n   - iOS\n   - Qt 5 Compatibility Module\n   - Qt Shader Tools\n   - Additional Libraries:\n     - Qt Image Formats\n     - Qt Multimedia\n     - Qt Remote Objects \n\n3. Install CMake if required. We recommend CMake version 3.25. You can install CMake [here](https://cmake.org/download/)\n\n4. You also need to install go >= v1.16. If you don't have it installed already,\ndownload go from the [official website](https://golang.org/dl/) or use Homebrew. \nThe latest version is recommended. Install gomobile\n```bash\nexport PATH=$PATH:~/go/bin\ngo install golang.org/x/mobile/cmd/gomobile@latest\ngomobile init\n```\n\n5. Build the project\n```bash\nexport QT_BIN_DIR=\"<PATH-TO-QT-FOLDER>/Qt/<QT-VERSION>/ios/bin\"\nexport QT_MACOS_ROOT_DIR=\"<PATH-TO-QT-FOLDER>/Qt/<QT-VERSION>/macos\"\nexport QT_IOS_BIN=$QT_BIN_DIR\nexport PATH=$PATH:~/go/bin\nmkdir build-ios\n$QT_IOS_BIN/qt-cmake . -B build-ios -GXcode -DQT_HOST_PATH=$QT_MACOS_ROOT_DIR\n```\nReplace PATH-TO-QT-FOLDER and QT-VERSION to your environment\n\n\nIf you get `gomobile: command not found` make sure to set PATH to the location \nof the bin folder where gomobile was installed. Usually, it's in `GOPATH`.\n```bash\nexport PATH=$(PATH):/path/to/GOPATH/bin\n```\n\n6. Open the XCode project. You can then run /test/archive/ship the app.\n\nIf the build fails with the following error\n```\nmake: *** \n[$(PROJECTDIR)/client/build/AmneziaVPN.build/Debug-iphoneos/wireguard-go-bridge/goroot/.prepared] \nError 1\n```\nAdd a user-defined variable to both AmneziaVPN and WireGuardNetworkExtension targets' build settings with\nkey `PATH` and value `${PATH}/path/to/bin/folder/with/go/executable`, e.g. `${PATH}:/usr/local/go/bin`.\n\nif the above error persists on your M1 Mac, then most probably you need to install arch based CMake \n```\narch -arm64 brew install cmake\n```\n\nBuild might fail with the \"source files not found\" error the first time you try it, because the modern XCode build system compiles dependencies in parallel, and some dependencies end up being built after the ones that\nrequire them. In this case, simply restart the build.\n\n## How to build the Android app\n\n_Tested on Mac OS_\n\nThe Android app has the following requirements:\n* JDK 11\n* Android platform SDK 33\n* CMake 3.25.0\n\nAfter you have installed QT, QT Creator, and Android Studio, you need to configure QT Creator correctly.\n\n- Click in the top menu bar on `QT Creator` -> `Preferences` -> `Devices` and select the tab `Android`.\n- Set path to JDK 11\n- Set path to Android SDK (`$ANDROID_HOME`)\n\nIn case you get errors regarding missing SDK or 'SDK manager not running', you cannot fix them by correcting the paths. If you have some spare GBs on your disk, you can let QT Creator install all requirements by choosing an empty folder for `Android SDK location` and clicking on `Set Up SDK`. Be aware: This will install a second Android SDK and NDK on your machine!Â \nDouble-check that the right CMake version is configured: Â Click on `QT Creator` -> `Preferences` and click on the side menu on `Kits`. Under the center content view's `Kits` tab, you'll find an entry for `CMake Tool`. If the default selected CMake version is lower than 3.25.0, install on your system CMake >= 3.25.0 and choose `System CMake at <path>` from the drop-down list. If this entry is missing, you either have not installed CMake yet or QT Creator hasn't found the path to it. In that case, click in the preferences window on the side menu item `CMake`, then on the tab `Tools` in the center content view, and finally on the button `Add` to set the path to your installed CMake.Â \nPlease make sure that you have selected Android Platform SDK 33 for your project: click in the main view's side menu on `Projects`, and on the left, you'll see a section `Build & Run` showing different Android build targets. You can select any of them, Amnezia VPN's project setup is designed in a way that all Android targets will be built. Click on the targets submenu item `Build` and scroll in the center content view to `Build Steps`. Click on `Details` at the end of the headline `Build Android APK` (the `Details` button might be hidden in case the QT Creator Window is not running in full screen!). Here we are: Choose `android-33` as `Android Build Platform SDK`.\n\nThat's it! You should be ready to compile the project from QT Creator!\n\n### Development flow\n\nAfter you've hit the build button, QT-Creator copies the whole project to a folder in the repository parent directory. The folder should look something like `build-amnezia-client-Android_Qt_<version>_Clang_<architecture>-<BuildType>`.\nIf you want to develop Amnezia VPNs Android components written in Kotlin, such as components using system APIs, you need to import the generated project in Android Studio with `build-amnezia-client-Android_Qt_<version>_Clang_<architecture>-<BuildType>/client/android-build` as the projects root directory. While you should be able to compile the generated project from Android Studio, you cannot work directly in the repository's Android project. So whenever you are confident with your work in the generated project, you'll need to copy and paste the affected files to the corresponding path in the repository's Android project so that you can add and commit your changes!\n\nYou may face compiling issues in QT Creator after you've worked in Android Studio on the generated project. Just do a `./gradlew clean` in the generated project's root directory (`<path>/client/android-build/.`) and you should be good to go.\n\n## License\n\nGPL v3.0\n\n## Donate\n\nPatreon: [https://www.patreon.com/amneziavpn](https://www.patreon.com/amneziavpn)\n\nBitcoin: bc1qmhtgcf9637rl3kqyy22r2a8wa8laka4t9rx2mf <br>\nUSDT BEP20: 0x6abD576765a826f87D1D95183438f9408C901bE4 <br>\nUSDT TRC20: TELAitazF1MZGmiNjTcnxDjEiH5oe7LC9d <br>\nXMR: 48spms39jt1L2L5vyw2RQW6CXD6odUd4jFu19GZcDyKKQV9U88wsJVjSbL4CfRys37jVMdoaWVPSvezCQPhHXUW5UKLqUp3 <br> \nTON: UQDpU1CyKRmg7L8mNScKk9FRc2SlESuI7N-Hby4nX-CcVmns\n## Acknowledgments\n\nThis project is tested with BrowserStack.\nWe express our gratitude to [BrowserStack](https://www.browserstack.com) for supporting our project.\n",
      "stars_today": 22
    },
    {
      "id": 70107786,
      "name": "next.js",
      "full_name": "vercel/next.js",
      "description": "The React Framework",
      "html_url": "https://github.com/vercel/next.js",
      "stars": 137316,
      "forks": 30341,
      "language": "JavaScript",
      "topics": [
        "blog",
        "browser",
        "compiler",
        "components",
        "hybrid",
        "nextjs",
        "node",
        "react",
        "server-rendering",
        "ssg",
        "static",
        "static-site-generator",
        "universal",
        "vercel"
      ],
      "created_at": "2016-10-05T23:32:51Z",
      "updated_at": "2026-01-25T02:09:45Z",
      "pushed_at": "2026-01-25T01:49:54Z",
      "open_issues": 3267,
      "owner": {
        "login": "vercel",
        "avatar_url": "https://avatars.githubusercontent.com/u/14985020?v=4"
      },
      "readme": "<div align=\"center\">\n  <a href=\"https://nextjs.org\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://assets.vercel.com/image/upload/v1662130559/nextjs/Icon_dark_background.png\">\n      <img alt=\"Next.js logo\" src=\"https://assets.vercel.com/image/upload/v1662130559/nextjs/Icon_light_background.png\" height=\"128\">\n    </picture>\n  </a>\n  <h1>Next.js</h1>\n\n<a href=\"https://vercel.com\"><img alt=\"Vercel logo\" src=\"https://img.shields.io/badge/MADE%20BY%20Vercel-000000.svg?style=for-the-badge&logo=Vercel&labelColor=000\"></a>\n<a href=\"https://www.npmjs.com/package/next\"><img alt=\"NPM version\" src=\"https://img.shields.io/npm/v/next.svg?style=for-the-badge&labelColor=000000\"></a>\n<a href=\"https://github.com/vercel/next.js/blob/canary/license.md\"><img alt=\"License\" src=\"https://img.shields.io/npm/l/next.svg?style=for-the-badge&labelColor=000000\"></a>\n<a href=\"https://github.com/vercel/next.js/discussions\"><img alt=\"Join the community on GitHub\" src=\"https://img.shields.io/badge/Join%20the%20community-blueviolet.svg?style=for-the-badge&logo=Next.js&labelColor=000000&logoWidth=20\"></a>\n\n</div>\n\n## Getting Started\n\nUsed by some of the world's largest companies, Next.js enables you to create full-stack web applications by extending the latest React features, and integrating powerful Rust-based JavaScript tooling for the fastest builds.\n\n- Visit our [Learn Next.js](https://nextjs.org/learn) course to get started with Next.js.\n- Visit the [Next.js Showcase](https://nextjs.org/showcase) to see more sites built with Next.js.\n\n## Documentation\n\nVisit [https://nextjs.org/docs](https://nextjs.org/docs) to view the full documentation.\n\n## Community\n\nThe Next.js community can be found on [GitHub Discussions](https://github.com/vercel/next.js/discussions) where you can ask questions, voice ideas, and share your projects with other people.\n\nTo chat with other community members you can join the Next.js [Discord](https://nextjs.org/discord) server.\n\nDo note that our [Code of Conduct](https://github.com/vercel/next.js/blob/canary/CODE_OF_CONDUCT.md) applies to all Next.js community channels. Users are **highly encouraged** to read and adhere to it to avoid repercussions.\n\n## Contributing\n\nContributions to Next.js are welcome and highly appreciated. However, before you jump right into it, we would like you to review our [Contribution Guidelines](/contributing.md) to make sure you have a smooth experience contributing to Next.js.\n\n### Good First Issues:\n\nWe have a list of **[good first issues](https://github.com/vercel/next.js/labels/good%20first%20issue)** that contain bugs that have a relatively limited scope. This is a great place for newcomers and beginners alike to get started, gain experience, and get familiar with our contribution process.\n\n---\n## Security\n\nIf you believe you have found a security vulnerability in Next.js, we encourage you to **_responsibly disclose this and NOT open a public issue_**.\n\nTo participate in our Open Source Software Bug Bounty program, please email [responsible.disclosure@vercel.com](mailto:responsible.disclosure@vercel.com). We will add you to the program and provide further instructions for submitting your report.\n",
      "stars_today": 20
    },
    {
      "id": 42489829,
      "name": "rustlings",
      "full_name": "rust-lang/rustlings",
      "description": ":crab: Small exercises to get you used to reading and writing Rust code!",
      "html_url": "https://github.com/rust-lang/rustlings",
      "stars": 61571,
      "forks": 11108,
      "language": "Rust",
      "topics": [
        "beginner-friendly",
        "exercises",
        "rust",
        "rustlings"
      ],
      "created_at": "2015-09-15T02:25:18Z",
      "updated_at": "2026-01-24T23:35:34Z",
      "pushed_at": "2026-01-22T13:32:05Z",
      "open_issues": 79,
      "owner": {
        "login": "rust-lang",
        "avatar_url": "https://avatars.githubusercontent.com/u/5430905?v=4"
      },
      "readme": "# [Rustlings](https://rustlings.rust-lang.org) ğŸ¦€\n\nSmall exercises to get you used to reading and writing [Rust](https://www.rust-lang.org) code - _Recommended in parallel to reading [the official Rust book](https://doc.rust-lang.org/book) ğŸ“šï¸_\n\nVisit the **website** for a demo, info about setup and more:\n\n## â¡ï¸ [rustlings.rust-lang.org](https://rustlings.rust-lang.org) â¬…ï¸\n",
      "stars_today": 20
    },
    {
      "id": 976397066,
      "name": "migu_video",
      "full_name": "develop202/migu_video",
      "description": null,
      "html_url": "https://github.com/develop202/migu_video",
      "stars": 713,
      "forks": 341,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2025-05-02T03:25:35Z",
      "updated_at": "2026-01-25T02:14:59Z",
      "pushed_at": "2026-01-24T23:18:21Z",
      "open_issues": 9,
      "owner": {
        "login": "develop202",
        "avatar_url": "https://avatars.githubusercontent.com/u/131328481?v=4"
      },
      "readme": "# ä½¿ç”¨æ–¹å¼\r\n\r\nè´¦å·ğŸ”äº†ã€‚~~åªæœ‰æ ‡æ¸…..~~ é«˜æ¸…ä¸ºä¸»ğŸ˜… giteeä»“åº“è¢«æ”¹ç§æœ‰äº†..\r\n\r\n~~gitee ipè¢«banï¼Œä»“åº“é“¾æ¥å·²å¤±æ•ˆ~~\r\n\r\nä»“åº“åœ°å€ä¸´æ—¶å¤æ´»ï¼Œèƒ½æ´»å¤šä¹…çœ‹è¿æ°”ï¼Œå­˜åœ¨é¢‘é“ç¼ºå¤±æˆ–æ— æ³•æ’­æ”¾çš„é—®é¢˜ï¼Œå›æ”¾åŠŸèƒ½ä»…miguæºç”Ÿæ•ˆï¼Œè¿˜åœ¨æµ‹è¯•ã€‚\r\n\r\nè®¿é—®åœ°å€(å¯å›çœ‹å½“å¤©å†…å®¹)\r\n\r\n```\r\nhttps://raw.githubusercontent.com/develop202/migu_video/refs/heads/main/interface.txt\r\n\r\nhttps://develop202.github.io/migu_video/interface.txt\r\n```\r\n\r\nç½‘ç»œç¯å¢ƒå·®çš„è¯å¯ä»¥ç”¨è¿™ä¸ª(ä¸ä¸€å®šç¨³å®š,å…¶ä»–åŠ é€Ÿç½‘ç«™ä¹Ÿå¯ä»¥)\r\n\r\n```\r\nhttps://gh-proxy.com/https://raw.githubusercontent.com/develop202/migu_video/refs/heads/main/interface.txt\r\n```\r\n\r\n# æœ¬åœ°éƒ¨ç½²\r\n\r\n> [!warning]\r\n> æ³¨æ„äº‹é¡¹\r\n>\r\n> 1. ç™»å½•åä½¿ç”¨ä¸ä¿è¯å®‰å…¨ï¼Œè¯·è°¨æ…ä½¿ç”¨\r\n> 1. éœ€è¦å›½å†…IPæ‰å¯æ­£å¸¸è®¿é—®\r\n\r\n## é…ç½®\r\n\r\né»˜è®¤æœ¬æœºå’Œå±€åŸŸç½‘å¯ç”¨ï¼Œæä¾›è‡ªå®šä¹‰tokenï¼Œæ ¼å¼: <http://ip:port/mpass/userid/token>ï¼ˆæœªè®¾ç½®mpassè¯·åˆ é™¤ï¼‰ï¼Œä½¿ç”¨æ­¤æ–¹å¼å»ºè®®æŠŠç”»è´¨æ”¹åˆ°è“å…‰æˆ–æ›´é«˜<br>\r\né…ç½®ä¿¡æ¯å¦‚ä¸‹:\r\n\r\n| å˜é‡å          | é»˜è®¤å€¼ | ç±»å‹    | ä»‹ç»                                                                                      |\r\n| --------------- | ------ | ------- | ----------------------------------------------------------------------------------------- |\r\n| muserId         |        | string  | ç”¨æˆ·id<br>å¯åœ¨ç½‘é¡µç«¯ç™»å½•è·å–                                                              |\r\n| mtoken          |        | string  | ç”¨æˆ·token<br>å¯åœ¨ç½‘é¡µç«¯ç™»å½•è·å–                                                           |\r\n| mport           | 1234   | number  | æœ¬åœ°è¿è¡Œç«¯å£å·                                                                            |\r\n| mhost           |        | string  | å…¬ç½‘/è‡ªå®šä¹‰è®¿é—®åœ°å€<br>æ ¼å¼<http://ip:port>                                               |\r\n| mrateType       | 3      | number  | ç”»è´¨<br>2: æ ‡æ¸…<br>3: é«˜æ¸…<br>4: è“å…‰<br>7: åŸç”»<br>9: 4k<br>ps:è“å…‰åŠä»¥ä¸Šéœ€è¦ç™»å½•ä¸”æœ‰VIP |\r\n| mpass           |        | string  | è®¿é—®å¯†ç  å¤§å°å†™å­—æ¯å’Œæ•°å­—<br>æ·»åŠ åè®¿é—®æ ¼å¼ <http://ip:port/mpass/>...                    |\r\n| menableHDR      | true   | boolean | æ˜¯å¦å¼€å¯HDR                                                                               |\r\n| menableH265     | true   | boolean | æ˜¯å¦å¼€å¯h265(åŸç”»ç”»è´¨)ï¼Œå¼€å¯åå¯èƒ½å­˜åœ¨å…¼å®¹æ€§é—®é¢˜ï¼Œæ¯”å¦‚æµè§ˆå™¨æ’­æ”¾æ²¡æœ‰ç”»é¢                  |\r\n| mupdateInterval | 6      | string  | èŠ‚ç›®ä¿¡æ¯æ›´æ–°é—´éš”ï¼Œå•ä½å°æ—¶ï¼Œä¸å»ºè®®è®¾ç½®å¤ªçŸ­                                                |\r\n\r\n## node\r\n\r\n### ç¯å¢ƒè¦æ±‚\r\n\r\néœ€è¦ NodeJS 18+ ç¯å¢ƒ\r\n\r\n### å®‰è£…\r\n\r\n```shell\r\ngit clone git@github.com:develop202/migu_video.git\r\ncd migu_video\r\n```\r\n\r\n### è¿è¡Œ\r\n\r\n```shell\r\nnode app.js\r\n```\r\n\r\nè‹¥éœ€è¦ä¿®æ”¹é…ç½®ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤\r\nMac/Linux:\r\n\r\n```shell\r\nmport=3000 mhost=\"http://localhost:3000\" node app.js\r\n```\r\n\r\nWindowsä¸‹ä½¿ç”¨git-bashç­‰ç»ˆç«¯:\r\n\r\n```shell\r\nset mport=3000 && set mhost=\"http://localhost:3000\" && node app.js\r\n```\r\n\r\nWindowsä¸‹ä½¿ç”¨PowerShellç­‰ç»ˆç«¯:\r\n\r\n```shell\r\n$Env:mport=3000; $Env:mhost=\"http://localhost:3000\"; node app.js\r\n```\r\n\r\n## docker\r\n\r\nåˆæ¬¡ä½¿ç”¨ï¼Œå¦‚æœ‰é”™è¯¯è¿˜è¯·å¤§ä½¬æŒ‡æ­£ã€‚\r\n\r\n### å®‰è£…\r\n\r\n```shell\r\ndocker pull develop767/migu_video:latest\r\n```\r\n\r\n### è¿è¡Œ\r\n\r\n```shell\r\ndocker run -p 1234:1234 --name migu_video develop767/migu_video\r\n```\r\n\r\nè‹¥éœ€è¦ä¿®æ”¹é…ç½®ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤\r\n\r\n```shell\r\ndocker run -p 3000:3000 -e mport=3000 -e mhost=\"http://localhost:3000\" --name migu_video develop767/migu_video\r\n```\r\n\r\n### æ„å»º\r\n\r\nè‹¥éœ€è¦æ‰‹åŠ¨æ„å»ºé•œåƒï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤\r\n\r\n```shell\r\ndocker build -t migu_video .\r\n```\r\n\r\n# å…è´£å£°æ˜\r\n\r\n> [!important]\r\n>\r\n> 1. æœ¬ä»“åº“ä»…ä¾›å­¦ä¹ ä½¿ç”¨ï¼Œè¯·å°Šé‡ç‰ˆæƒï¼Œè¯·å‹¿åˆ©ç”¨æ­¤ä»“åº“ä»äº‹å•†ä¸šè¡Œä¸ºåŠéæ³•ç”¨é€”!\r\n> 2. ä½¿ç”¨æœ¬ä»“åº“çš„è¿‡ç¨‹ä¸­å¯èƒ½ä¼šäº§ç”Ÿç‰ˆæƒæ•°æ®ã€‚å¯¹äºè¿™äº›ç‰ˆæƒæ•°æ®ï¼Œæœ¬ä»“åº“ä¸æ‹¥æœ‰å®ƒä»¬çš„æ‰€æœ‰æƒã€‚ä¸ºäº†é¿å…ä¾µæƒï¼Œä½¿ç”¨è€…åŠ¡å¿…åœ¨ 24å°æ—¶å†…æ¸…é™¤ä½¿ç”¨æœ¬ä»“åº“çš„è¿‡ç¨‹ä¸­æ‰€äº§ç”Ÿçš„ç‰ˆæƒæ•°æ®ã€‚\r\n> 3. ç”±äºä½¿ç”¨æœ¬ä»“åº“äº§ç”Ÿçš„åŒ…æ‹¬ç”±äºæœ¬åè®®æˆ–ç”±äºä½¿ç”¨æˆ–æ— æ³•ä½¿ç”¨æœ¬ä»“åº“è€Œå¼•èµ·çš„ä»»ä½•æ€§è´¨çš„ä»»ä½•ç›´æ¥ã€é—´æ¥ã€ç‰¹æ®Šã€å¶ç„¶æˆ–ç»“æœæ€§æŸå®³ï¼ˆåŒ…æ‹¬ä½†ä¸é™äºå› å•†èª‰æŸå¤±ã€åœå·¥ã€è®¡ç®—æœºæ•…éšœæˆ–æ•…éšœå¼•èµ·çš„æŸå®³èµ”å¿ï¼Œæˆ–ä»»ä½•åŠæ‰€æœ‰å…¶ä»–å•†ä¸šæŸå®³æˆ–æŸå¤±ï¼‰ç”±ä½¿ç”¨è€…è´Ÿè´£ã€‚\r\n> 4. **ç¦æ­¢åœ¨è¿åå½“åœ°æ³•å¾‹æ³•è§„çš„æƒ…å†µä¸‹ä½¿ç”¨æœ¬ä»“åº“ã€‚** å¯¹äºä½¿ç”¨è€…åœ¨æ˜çŸ¥æˆ–ä¸çŸ¥å½“åœ°æ³•å¾‹æ³•è§„ä¸å…è®¸çš„æƒ…å†µä¸‹ä½¿ç”¨æœ¬ä»“åº“æ‰€é€ æˆçš„ä»»ä½•è¿æ³•è¿è§„è¡Œä¸ºç”±ä½¿ç”¨è€…æ‰¿æ‹…ï¼Œæœ¬ä»“åº“ä¸æ‰¿æ‹…ç”±æ­¤é€ æˆçš„ä»»ä½•ç›´æ¥ã€é—´æ¥ã€ç‰¹æ®Šã€å¶ç„¶æˆ–ç»“æœæ€§è´£ä»»ã€‚\r\n> 5. å¦‚æœå®˜æ–¹å¹³å°è§‰å¾—æœ¬ä»“åº“ä¸å¦¥ï¼Œå¯è”ç³»æœ¬ä»“åº“æ›´æ”¹æˆ–ç§»é™¤ã€‚\r\n",
      "stars_today": 19
    },
    {
      "id": 391055597,
      "name": "DSA-Bootcamp-Java",
      "full_name": "kunal-kushwaha/DSA-Bootcamp-Java",
      "description": "This repository consists of the code samples, assignments, and notes for the Java data structures & algorithms + interview preparation bootcamp of WeMakeDevs.",
      "html_url": "https://github.com/kunal-kushwaha/DSA-Bootcamp-Java",
      "stars": 21702,
      "forks": 13004,
      "language": "Java",
      "topics": [
        "algorithms",
        "competitive-programming",
        "data-structures",
        "faang-interview",
        "faang-preparation",
        "faang-questions",
        "google-interview",
        "interview-preparation",
        "java",
        "leetcode",
        "leetcode-java",
        "leetcode-solutions",
        "math"
      ],
      "created_at": "2021-07-30T12:23:25Z",
      "updated_at": "2026-01-24T20:14:22Z",
      "pushed_at": "2024-08-18T08:21:57Z",
      "open_issues": 629,
      "owner": {
        "login": "kunal-kushwaha",
        "avatar_url": "https://avatars.githubusercontent.com/u/42698533?v=4"
      },
      "readme": "# DSA + Interview preparation bootcamp\n- Subscribe to the [YouTube channel](https://www.youtube.com/KunalKushwaha?sub_confirmation=1)\n- [Lectures](https://www.youtube.com/playlist?list=PL9gnSGHSqcnr_DxHsP7AW9ftq0AtAyYqJ)\n- [Course website](https://www.techwithkunal.com/courses/dsa)\n- [Assignments](https://github.com/kunal-kushwaha/DSA-Bootcamp-Java/tree/main/assignments) (solutions can be found on LeetCode)\n",
      "stars_today": 18
    },
    {
      "id": 180687624,
      "name": "trivy",
      "full_name": "aquasecurity/trivy",
      "description": "Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more",
      "html_url": "https://github.com/aquasecurity/trivy",
      "stars": 31107,
      "forks": 2890,
      "language": "Go",
      "topics": [
        "containers",
        "devsecops",
        "docker",
        "go",
        "golang",
        "hacktoberfest",
        "iac",
        "infrastructure-as-code",
        "kubernetes",
        "misconfiguration",
        "security",
        "security-tools",
        "vulnerability",
        "vulnerability-detection",
        "vulnerability-scanners"
      ],
      "created_at": "2019-04-11T01:01:07Z",
      "updated_at": "2026-01-25T01:32:02Z",
      "pushed_at": "2026-01-24T04:22:19Z",
      "open_issues": 208,
      "owner": {
        "login": "aquasecurity",
        "avatar_url": "https://avatars.githubusercontent.com/u/12783832?v=4"
      },
      "readme": "<div align=\"center\">\n<img src=\"docs/imgs/logo.png\" width=\"200\">\n\n[![GitHub Release][release-img]][release]\n[![Test][test-img]][test]\n[![Go Report Card][go-report-img]][go-report]\n[![License: Apache-2.0][license-img]][license]\n[![GitHub Downloads][github-downloads-img]][release]\n![Docker Pulls][docker-pulls]\n\n[ğŸ“– Documentation][docs]\n</div>\n\nTrivy ([pronunciation][pronunciation]) is a comprehensive and versatile security scanner.\nTrivy has *scanners* that look for security issues, and *targets* where it can find those issues.\n\nTargets (what Trivy can scan):\n\n- Container Image\n- Filesystem\n- Git Repository (remote)\n- Virtual Machine Image\n- Kubernetes\n\nScanners (what Trivy can find there):\n\n- OS packages and software dependencies in use (SBOM)\n- Known vulnerabilities (CVEs)\n- IaC issues and misconfigurations\n- Sensitive information and secrets\n- Software licenses\n\nTrivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the [Scanning Coverage] page.\n\nTo learn more, go to the [Trivy homepage][homepage] for feature highlights, or to the [Documentation site][docs] for detailed information.\n\n## Quick Start\n\n### Get Trivy\n\nTrivy is available in most common distribution channels. The full list of installation options is available in the [Installation] page. Here are a few popular examples:\n\n- `brew install trivy`\n- `docker run aquasec/trivy`\n- Download binary from <https://github.com/aquasecurity/trivy/releases/latest/>\n- See [Installation] for more\n\nTrivy is integrated with many popular platforms and applications. The complete list of integrations is available in the [Ecosystem] page. Here are a few popular examples:\n\n- [GitHub Actions](https://github.com/aquasecurity/trivy-action)\n- [Kubernetes operator](https://github.com/aquasecurity/trivy-operator)\n- [VS Code plugin](https://github.com/aquasecurity/trivy-vscode-extension)\n- See [Ecosystem] for more\n\n### Canary builds\nThere are canary builds ([Docker Hub](https://hub.docker.com/r/aquasec/trivy/tags?page=1&name=canary), [GitHub](https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary), [ECR](https://gallery.ecr.aws/aquasecurity/trivy#canary) images and [binaries](https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml)) generated with every push to the main branch.\n\nPlease be aware: canary builds might have critical bugs, so they are not recommended for use in production.\n\n### General usage\n\n```bash\ntrivy <target> [--scanners <scanner1,scanner2>] <subject>\n```\n\nExamples:\n\n```bash\ntrivy image python:3.4-alpine\n```\n\n<details>\n<summary>Result</summary>\n\nhttps://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov\n\n</details>\n\n```bash\ntrivy fs --scanners vuln,secret,misconfig myproject/\n```\n\n<details>\n<summary>Result</summary>\n\nhttps://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov\n\n</details>\n\n```bash\ntrivy k8s --report summary cluster\n```\n\n<details>\n<summary>Result</summary>\n\n![k8s summary](docs/imgs/trivy-k8s.png)\n\n</details>\n\n## FAQ\n\n### How to pronounce the name \"Trivy\"?\n\n`tri` is pronounced like **tri**gger, `vy` is pronounced like en**vy**.\n\n## Want more? Check out Aqua\n\nIf you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.  \nYou can find a high level comparison table specific to Trivy users [here](https://trivy.dev/docs/latest/commercial/compare/).\nIn addition check out the <https://aquasec.com> website for more information about our products and services.\nIf you'd like to contact Aqua or request a demo, please use this form: <https://www.aquasec.com/demo>\n\n## Community\n\nTrivy is an [Aqua Security][aquasec] open source project.  \nLearn about our open source work and portfolio [here][oss].  \nContact us about any matter by opening a GitHub Discussion [here][discussions]\n\nPlease ensure to abide by our [Code of Conduct][code-of-conduct] during all interactions.\n\n[test]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml\n[test-img]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg\n[go-report]: https://goreportcard.com/report/github.com/aquasecurity/trivy\n[go-report-img]: https://goreportcard.com/badge/github.com/aquasecurity/trivy\n[release]: https://github.com/aquasecurity/trivy/releases\n[release-img]: https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github\n[github-downloads-img]: https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github\n[docker-pulls]: https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&label=docker%20pulls%20%2F%20trivy\n[license]: https://github.com/aquasecurity/trivy/blob/main/LICENSE\n[license-img]: https://img.shields.io/badge/License-Apache%202.0-blue.svg\n[homepage]: https://trivy.dev\n[docs]: https://trivy.dev/docs/latest/\n[pronunciation]: #how-to-pronounce-the-name-trivy\n[code-of-conduct]: https://github.com/aquasecurity/community/blob/main/CODE_OF_CONDUCT.md\n\n[Installation]:https://trivy.dev/docs/latest/getting-started/installation/\n[Ecosystem]: https://trivy.dev/docs/latest/ecosystem/\n[Scanning Coverage]: https://trivy.dev/docs/latest/coverage/\n\n[alpine]: https://ariadne.space/2021/06/08/the-vulnerability-remediation-lifecycle-of-alpine-containers/\n[rego]: https://www.openpolicyagent.org/docs/latest/#rego\n[sigstore]: https://www.sigstore.dev/\n\n[aquasec]: https://aquasec.com\n[oss]: https://www.aquasec.com/products/open-source-projects/\n[discussions]: https://github.com/aquasecurity/trivy/discussions\n",
      "stars_today": 17
    },
    {
      "id": 155297903,
      "name": "dozzle",
      "full_name": "amir20/dozzle",
      "description": "Realtime log viewer for containers.  Supports Docker, Swarm and K8s. ",
      "html_url": "https://github.com/amir20/dozzle",
      "stars": 11214,
      "forks": 486,
      "language": "Go",
      "topics": [
        "docker",
        "docker-container",
        "golang",
        "k8s",
        "log",
        "logging",
        "logging-server",
        "real-time",
        "sever-events",
        "swarm",
        "vuejs"
      ],
      "created_at": "2018-10-30T00:05:23Z",
      "updated_at": "2026-01-25T01:14:25Z",
      "pushed_at": "2026-01-25T00:56:48Z",
      "open_issues": 5,
      "owner": {
        "login": "amir20",
        "avatar_url": "https://avatars.githubusercontent.com/u/260667?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"assets/logo.svg\" alt=\"Dozzle Logo\" width=\"200\"/>\n</p>\n\n# Dozzle - [dozzle.dev](https://dozzle.dev/)\n\nDozzle is a small lightweight application with a web based interface to monitor Docker logs. It doesnâ€™t store any log files. It is for live monitoring of your container logs only.\n\nhttps://github.com/user-attachments/assets/66a7b4b2-d6c9-4fca-ab04-aef6cd7c0c31\n\n[![Docker Image Size (latest by date)](https://img.shields.io/docker/image-size/amir20/dozzle)](https://hub.docker.com/r/amir20/dozzle/)\n[![Docker Pulls](https://img.shields.io/docker/pulls/amir20/dozzle.svg)](https://hub.docker.com/r/amir20/dozzle/)\n[![Docker Version](https://img.shields.io/docker/v/amir20/dozzle?sort=semver)](https://hub.docker.com/r/amir20/dozzle/)\n![Test](https://github.com/amir20/dozzle/workflows/Test/badge.svg)\n\n> [!NOTE]\n> If you like Dozzle, check out [`dtop`](https://github.com/amir20/dtop) which is a top like application for monitoring Docker containers. It integrates with Dozzle to allow for linking directly to container logs.\n\n## Features\n\n- Intelligent fuzzy search for container names ğŸ¤–\n- Search logs using regex ğŸ”¦\n- Search logs using [SQL queries](https://dozzle.dev/guide/sql-engine) ğŸ“Š\n- Small memory footprint ğŸ\n- Split screen for viewing multiple logs\n- Live stats with memory and CPU usage\n- Multi-user [authentication](https://dozzle.dev/guide/authentication) with support for proxy forward authorization ğŸš¨\n- [Swarm](https://dozzle.dev/guide/swarm-mode) mode support ğŸ³\n- [Agent](https://dozzle.dev/guide/agent) mode for monitoring multiple Docker hosts ğŸ•µï¸â€â™‚ï¸\n- Dark mode ğŸŒ™\n\nDozzle has been tested with hundreds of containers. However, it doesn't support offline searching. Products like [Loggly](https://www.loggly.com), [Papertrail](https://papertrailapp.com) or [Kibana](https://www.elastic.co/products/kibana) are more suited for full search capabilities.\n\n## Getting Started\n\nDozzle is a small container (7 MB compressed). Pull the latest release with:\n\n    $ docker pull amir20/dozzle:latest\n\n### Running Dozzle\n\nThe simplest way to use dozzle is to run the docker container. Also, mount the Docker Unix socket with `--volume` to `/var/run/docker.sock`:\n\n    $ docker run --name dozzle -d --volume=/var/run/docker.sock:/var/run/docker.sock -p 8080:8080 amir20/dozzle:latest\n\nDozzle will be available at [http://localhost:8080/](http://localhost:8080/).\n\nHere is the Docker Compose file:\n\n    services:\n      dozzle:\n        container_name: dozzle\n        image: amir20/dozzle:latest\n        volumes:\n          - /var/run/docker.sock:/var/run/docker.sock\n        ports:\n          - 8080:8080\n\nFor advanced options like [authentication](https://dozzle.dev/guide/authentication), [remote hosts](https://dozzle.dev/guide/remote-hosts) or common [questions](https://dozzle.dev/guide/faq) see documentation at [dozzle.dev](https://dozzle.dev/guide/getting-started).\n\n## Swarm Mode\n\nDozzle works with Docker Swarm mode. You can run Dozzle as a global service with:\n\n    $ docker service create --name dozzle --env DOZZLE_MODE=swarm --mode global --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock -p 8080:8080 amir20/dozzle:latest\n\nSee the [Swarm Mode](https://dozzle.dev/guide/swarm-mode) documentation for more details.\n\n## Agent Mode\n\nDozzle can be used to monitor multiple Docker hosts. You can run Dozzle in agent mode with:\n\n    $ docker run -v /var/run/docker.sock:/var/run/docker.sock -p 7007:7007 amir20/dozzle:latest agent\n\nSee the [Agent Mode](https://dozzle.dev/guide/agent) documentation for more details.\n\n## Technical Details\n\nDozzle users automatic API negotiation which works with most Docker configurations. Dozzle also works with [Colima](https://github.com/abiosoft/colima) and [Podman](https://podman.io/).\n\n### Installation on podman\n\nBy default Podman doesn't have a background process but you can enable this for Dozzle to work.\n\nVerify first if your podman installation has enabled remote socket:\n\n```\npodman info\n```\n\nWhen you get under the key remote socket output like this, its already enabled:\n\n```\n  remoteSocket:\n    exists: true\n    path: /run/user/1000/podman/podman.sock\n```\n\nIf it's not enabled please follow [this tutorial](https://github.com/containers/podman/blob/main/docs/tutorials/socket_activation.md) to enable it.\n\nOnce you have the podman remote socket you can run Dozzle on podman.\n\n```\npodman run --volume=/run/user/1000/podman/podman.sock:/var/run/docker.sock -d -p 8080:8080 docker.io/amir20/dozzle:latest\n```\n\nAdditionally you have to create a fake engine-id to prevent `host not found` errors. Podman doesn't generate an engine-id like Docker by itself due to its daemonless architecture.\n\nUnder `/var/lib/docker` create a file named `engine-id`. On a system with Podman you will have to create the folder path as well. Inside the file place the UUID, for instance using `uuidgen > engine-id`. After that the file should have an identifier that looks like this: `b9f1d7fc-b459-4b6e-9f7a-e3d1cd2e14a9`.\n\nFor more details check [Podman Infos](docs/guide/podman.md) or the [FAQ](docs/guide/faq.md#i-am-seeing-host-not-found-error-in-the-logs-how-do-i-fix-it)\n\n## Security\n\nDozzle supports file based authentication and forward proxy like [Authelia](https://www.authelia.com/). These are documented at https://dozzle.dev/guide/authentication.\n\n## Analytics collected\n\nDozzle collects anonymous user configurations using Google Analytics. Why? Dozzle is an open source project with no funding. As a result, there is no time to do user studies of Dozzle. Analytics is collected to prioritize features and fixes based on how people use Dozzle. This data is completely public and can be viewed live using [ Data Studio dashboard](https://datastudio.google.com/s/naeIu0MiWsY).\n\nIf you do not want to be tracked at all, see the `--no-analytics` flag below.\n\n## Environment variables and configuration\n\nDozzle follows the [12-factor](https://12factor.net/) model. Configurations can use the CLI flags or environment variables. See documentation at [https://dozzle.dev/guide/supported-env-vars](https://dozzle.dev/guide/supported-env-vars) for more details.\n\n## Support\n\nThere are many ways you can support Dozzle:\n\n- Use it! Write about it! Star it! If you love Dozzle, drop me a line and tell me what you love.\n- Blog about Dozzle to spread the word. If you are good at writing send PRs to improve the documentation at [dozzle.dev](https://dozzle.dev/)\n- Sponsor my work at https://www.buymeacoffee.com/amirraminfar\n\n<a href=\"https://www.buymeacoffee.com/amirraminfar\" target=\"_blank\"><img src=\"https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png\" alt=\"Buy Me A Coffee\" style=\"height: 60px !important;width: 217px !important;\" ></a>\n\n## License\n\n[MIT](LICENSE)\n\n## Building\n\nTo build and test locally:\n\n1. Install [NodeJs](https://nodejs.org/en/download/) and [pnpm](https://pnpm.io/installation).\n2. Install [Go](https://go.dev/doc/install).\n3. Install tools with `make tools`.\n4. Install node modules `pnpm install`.\n5. Run `make dev` to start a development server with hot reload.\n",
      "stars_today": 17
    },
    {
      "id": 59929513,
      "name": "skim",
      "full_name": "skim-rs/skim",
      "description": "Fuzzy Finder in rust!",
      "html_url": "https://github.com/skim-rs/skim",
      "stars": 6436,
      "forks": 235,
      "language": "Rust",
      "topics": [
        "fuzzyfinder",
        "rust",
        "skim"
      ],
      "created_at": "2016-05-29T06:24:46Z",
      "updated_at": "2026-01-24T21:33:46Z",
      "pushed_at": "2026-01-24T15:48:01Z",
      "open_issues": 35,
      "owner": {
        "login": "skim-rs",
        "avatar_url": "https://avatars.githubusercontent.com/u/187454154?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://crates.io/crates/skim\">\n    <img src=\"https://img.shields.io/crates/v/skim.svg\" alt=\"Crates.io\" />\n  </a>\n  <a href=\"https://github.com/skim-rs/skim/actions?query=workflow%3A%22Build+%26+Test%22+event%3Apush\">\n    <img src=\"https://github.com/skim-rs/skim/actions/workflows/test.yml/badge.svg?event=push\" alt=\"Build & Test\" />\n  </a>\n  <a href=\"https://repology.org/project/skim-fuzzy-finder/versions\">\n    <img src=\"https://repology.org/badge/tiny-repos/skim-fuzzy-finder.svg\" alt=\"Packaging status\" />\n  </a>\n  <a href=\"https://discord.gg/23PuxttufP\">\n    <img alt=\"Skim Discord\" src=\"https://img.shields.io/discord/1031830957432504361?label=&color=7389d8&labelColor=6a7ec2&logoColor=ffffff&logo=discord\" />\n  </a>\n  <a href=\"https://ratatui.rs\">\n    <img alt=\"Built with Ratatui\" src=\"https://ratatui.rs/built-with-ratatui/badge.svg\" />\n  </a>\n</p>\n\n> Life is short, skim!\n\nWe spend so much of our time navigating through files, lines, and commands. That's where Skim comes in!\nIt's a powerful fuzzy finder designed to make your workflow faster and more efficient.\n\n[![skim demo](https://asciinema.org/a/pIfwazaM0mTHA8F7qRbjrqOnm.svg)](https://asciinema.org/a/pIfwazaM0mTHA8F7qRbjrqOnm)\n\nSkim provides a single executable called `sk`. Think of it as a smarter alternative to tools like\n`grep` - once you try it, you'll wonder how you ever lived without it!\n\n# Table of contents\n\n- [Installation](#installation)\n   * [Package Managers](#package-managers)\n   * [Manually](#manually)\n- [Usage](#usage)\n   * [As Vim plugin](#as-vim-plugin)\n   * [As filter](#as-filter)\n   * [As Interactive Interface](#as-interactive-interface)\n   * [Shell Bindings](#shell-bindings)\n   * [Key Bindings](#key-bindings)\n   * [Search Syntax](#search-syntax)\n   * [exit code](#exit-code)\n- [Tools compatible with `skim`](#tools-compatible-with-skim)\n   * [fzf-lua neovim plugin](#fzf-lua-neovim-plugin)\n   * [nu_plugin_skim](#nu_plugin_skim)\n- [Customization](#customization)\n   * [Keymap](#keymap)\n   * [Sort Criteria](#sort-criteria)\n   * [Color Scheme](#color-scheme)\n   * [Misc](#misc)\n- [Advanced Topics](#advanced-topics)\n   * [Interactive mode](#interactive-mode)\n      + [How does it work?](#how-does-it-work)\n   * [Executing external programs](#executing-external-programs)\n   * [Preview Window](#preview-window)\n      + [How does it work?](#how-does-it-work-1)\n   * [Fields support](#fields-support)\n   * [Use as a library](#use-as-a-library)\n- [FAQ](#faq)\n   * [How to ignore files?](#how-to-ignore-files)\n   * [Some files are not shown in Vim plugin](#some-files-are-not-shown-in-vim-plugin)\n- [Differences from fzf](#differences-from-fzf)\n- [How to contribute](#how-to-contribute)\n- [Troubleshooting](#troubleshooting)\n   * [No line feed issues with nix, FreeBSD, termux](#no-line-feed-issues-with-nix-freebsd-termux)\n\n# Installation\n\nThe skim project contains several components:\n\n1. `sk` executable - the core program\n2. Vim/Nvim plugin - to call `sk` inside Vim/Nvim. Check [skim.vim](https://github.com/skim-rs/skim/blob/master/plugin/skim.vim) for Vim support.\n\n## Package Managers\n\n| OS             | Package Manager   | Command                      |\n| -------------- | ----------------- | ---------------------------- |\n| macOS          | Homebrew          | `brew install sk`            |\n| macOS          | MacPorts          | `sudo port install skim`     |\n| Alpine         | apk               | `apk add skim`               |\n| Arch           | pacman            | `pacman -S skim`             |\n| Gentoo         | Portage           | `emerge --ask app-misc/skim` |\n| Guix           | guix              | `guix install skim`          |\n| Void           | XBPS              | `xbps-install -S skim`       |\n\n<a href=\"https://repology.org/project/skim-fuzzy-finder/versions\">\n    <img src=\"https://repology.org/badge/vertical-allrepos/skim-fuzzy-finder.svg?columns=4\" alt=\"Packaging status\">\n</a>\n\n## Manually\n\nAny of the following applies:\n\n- Using the install script:\n    ```sh\n    # Always check the content of the script before running it !\n    $ curl --proto '=https' --tlsv1.2 -LsSf https://github.com/skim-rs/skim/releases/latest/download/skim-installer.sh | sh\n    ```\n- Using Binary: Simply [download the sk executable](https://github.com/skim-rs/skim/releases) directly.\n- Install from [crates.io](https://crates.io/): Run `cargo +nightly install skim` (or `cargo install skim --no-default-features --features cli` if you don't like using nightly rust, which will make you lose the `frizbee` typo-resistant matcher)\n- Build Manually:\n    ```sh\n    $ git clone --depth 1 git@github.com:skim-rs/skim.git ~/.skim\n    $ cd ~/.skim\n    $ cargo +nightly install\n    $ cargo +nightly build --release\n    $ # Add the resulting `target/release/sk` executable to your PATH\n    ```\n\nYou will then have access to:\n\n- The man page, which you can either write to the correct path or run `man --local-file <(sk --man)`\n- The shell completions (and optional keybinds), using `source <(sk --shell \\<shell> \\[--shell-bindings])`, see below for details\n\n# Usage\n\nSkim can be used either as a general filter (similar to `grep`) or as an interactive\ninterface for running commands.\n\n## As Vim plugin (on neovim, checkout [fzf-lua](https://github.com/ibhagwan/fzf-lua) with the skim profile)\n\nVia vim-plug (recommended):\n\nInstall skim, then :\n\n```vim\nPlug 'skim-rs/skim'\n```\n\n\n## As filter\n\nHere are some examples to get you started:\n\n```bash\n# directly invoke skim\nsk\n\n# Or pipe some input to it (press TAB key to select multiple items when -m is enabled)\nvim $(find . -name \"*.rs\" | sk -m)\n```\nThis last command lets you select files with the \".rs\" extension and opens\nyour selections in Vim - a great time-saver for developers!\n\n## As Interactive Interface\n\n`skim` can invoke other commands dynamically. Normally you would want to\nintegrate it with [grep](https://www.gnu.org/software/grep/),\n[ack](https://github.com/petdance/ack2),\n[ag](https://github.com/ggreer/the_silver_searcher), or\n[rg](https://github.com/BurntSushi/ripgrep) for searching contents in a\nproject directory:\n\n```sh\n# works with grep\nsk --ansi -i -c 'grep -rI --color=always --line-number \"{}\" .'\n# works with ack\nsk --ansi -i -c 'ack --color \"{}\"'\n# works with ag\nsk --ansi -i -c 'ag --color \"{}\"'\n# works with rg\nsk --ansi -i -c 'rg --color=always --line-number \"{}\"'\n```\n\n> **Note**: In these examples, `{}` will be literally expanded to the current input query.\n> This means these examples will search for the exact query string, not fuzzily.\n> For fuzzy searching, pipe the command output into `sk` without using interactive mode.\n\n![interactive mode demo](https://cloud.githubusercontent.com/assets/1527040/21603930/655d859a-d1db-11e6-9fec-c25099d30a12.gif)\n\n## Shell Bindings\n\nBindings for Fish, Bash and Zsh are available in the `shell` directory:\n- `completion.{shell}` contains the completion scripts for `sk` cli usage\n- `key-bindings.{shell}` contains key-binds and shell integrations:\n    - `ctrl-t` to select a file through `sk`\n    - `ctrl-r` to select an history entry through `sk`\n    - `alt-c`  to `cd` into a directory selected through `sk`\n    - (not available in `fish`) `**` to complete file paths, for example `ls **<tab>` will show a `sk` widget to select a folder\n\nTo enable these features, source the `key-bindings.{shell}` file and set up completions according to your shell's documentation or see below.\n\n### Shell Completions\n\nYou can generate shell completions for your preferred shell using the `--shell` flag with one of the supported shells: `bash`, `zsh`, `fish`, `powershell`, or `elvish`:\n\n> **Note:** While PowerShell completions are supported, Windows is not supported for now.\n\n#### Option 1: Source directly in your current shell session\n\n```sh\n# For bash\nsource <(sk --shell bash)\n\n# For zsh\nsource <(sk --shell zsh)\n\n# For fish\nsk --shell fish | source\n```\n\n#### Option 2: Save to a file to be loaded automatically on shell startup\n\n```sh\n# For bash, add to ~/.bashrc\necho 'source <(sk --shell bash)' >> ~/.bashrc  # Or save to ~/.bash_completion\n\n# For zsh, add to ~/.zshrc\nsk --shell zsh > ~/.zfunc/_sk  # Create ~/.zfunc directory and add to fpath in ~/.zshrc\n\n# For fish, add to ~/.config/fish/completions/\nsk --shell fish > ~/.config/fish/completions/sk.fish\n```\n\n## Key Bindings\n\nSome commonly used key bindings:\n\n| Key               | Action                                     |\n|------------------:|--------------------------------------------|\n| Enter             | Accept (select current one and quit)       |\n| ESC/Ctrl-G        | Abort                                      |\n| Ctrl-P/Up         | Move cursor up                             |\n| Ctrl-N/Down       | Move cursor Down                           |\n| TAB               | Toggle selection and move down (with `-m`) |\n| Shift-TAB         | Toggle selection and move up (with `-m`)   |\n\nFor a complete list of key bindings, refer to the [man\npage](https://github.com/skim-rs/skim/blob/master/man/man1/sk.1) (`man sk`).\n\n## Search Syntax\n\n`skim` borrows `fzf`'s syntax for matching items:\n\n| Token    | Match type                 | Description                       |\n|----------|----------------------------|-----------------------------------|\n| `text`   | fuzzy-match                | items that match `text`           |\n| `^music` | prefix-exact-match         | items that start with `music`     |\n| `.mp3$`  | suffix-exact-match         | items that end with `.mp3`        |\n| `'wild`  | exact-match (quoted)       | items that include `wild`         |\n| `!fire`  | inverse-exact-match        | items that do not include `fire`  |\n| `!.mp3$` | inverse-suffix-exact-match | items that do not end with `.mp3` |\n\n`skim` also supports the combination of tokens.\n\n- Whitespace has the meaning of `AND`. With the term `src main`, `skim` will search\n    for items that match **both** `src` and `main`.\n- ` | ` means `OR` (note the spaces around `|`). With the term `.md$ |\n    .markdown$`, `skim` will search for items ends with either `.md` or\n    `.markdown`.\n- `OR` has higher precedence. For example, `readme .md$ | .markdown$` is interpreted as\n    `readme AND (.md$ OR .markdown$)`.\n\n- When using the `--split-match` option, each part around spaces or `|` will be matched in a split way:\n    - If the option's value (defaulting to `:`) is absent from the query, do a normal match\n    - If it is present, match everything before to everything before it in the items, and everything after it (including potential other occurences of the delimiter) to the part after it in the items. This is particularly useful when piping in input from `rg` to match on both file name and content.\n\nIf you prefer using regular expressions, `skim` offers a `regex` mode:\n\n```sh\nsk --regex\n```\n\nYou can switch to `regex` mode dynamically by pressing `Ctrl-R` (Rotate Mode).\n\n## exit code\n\n| Exit Code | Meaning                             |\n|-----------|-------------------------------------|\n| 0         | Exited normally                     |\n| 1         | No Match found                      |\n| 130       | Aborted by Ctrl-C/Ctrl-G/ESC/etc... |\n\n# Tools compatible with `skim`\n\nThese tools are or aim to be compatible with `skim`:\n\n## [fzf-lua neovim plugin](https://github.com/ibhagwan/fzf-lua)\n\nA [neovim](https://neovim.io) plugin allowing fzf and skim to be used in a to navigate your code.\n\nInstall it with your package manager, following the README. For instance, with `lazy.nvim`:\n\n```lua\n{\n  \"ibhagwan/fzf-lua\",\n  -- enable `sk` support instead of the default `fzf`\n  opts = {'skim'}\n}\n```\n\n## [nu_plugin_skim](https://github.com/idanarye/nu_plugin_skim)\n\nA [nushell](https://www.nushell.sh/) plugin to allow for better interaction between skim and nushell.\n\nFollowing the instruction in the plugin's README, you can install it with cargo:\n```nu\ncargo install nu_plugin_skim\nplugin add ~/.cargo/bin/nu_plugin_skim\n```\n\n# Customization\n\nThe doc here is only a preview, please check the man page (`man sk`) for a full\nlist of options.\n\n## Keymap\n\nSpecify the bindings with comma separated pairs (no space allowed). For example:\n\n```sh\nsk --bind 'alt-a:select-all,alt-d:deselect-all'\n```\n\nAdditionally, use `+` to concatenate actions, such as `execute-silent(echo {} | pbcopy)+abort`.\n\nSee the _KEY BINDINGS_ section of the man page for details.\n\n## Sort Criteria\n\nThere are five sort keys for results: `score, index, begin, end, length`. You can\nspecify how the records are sorted by `sk --tiebreak score,index,-begin` or any\nother order you want.\n\n## Color Scheme\n\nYou probably have your own aesthetic preferences! Fortunately, you aren't\nlimited to the default appearance - Skim supports comprehensive customization of its color scheme.\n\n```sh\n--color=[BASE_SCHEME][,COLOR:ANSI]\n```\n\nSkim also respects the `NO_COLOR` environment variable. Set it to anything and `sk` (and many other terminal apps) will disable all colored output. See [no-color.org](https://no-color.org/) for more details.\n\n### Available Base Color Schemes\n\nSkim comes with several built-in color schemes that you can use as a starting point:\n\n```sh\nsk --color=dark      # Default dark theme (256 colors)\nsk --color=light     # Light theme (256 colors)\nsk --color=16        # Simple 16-color theme\nsk --color=bw        # Minimal black & white theme (no colors, just styles)\nsk --color=none      # Minimal black & white theme (no colors, no styles)\nsk --color=molokai   # Molokai-inspired theme (256 colors)\n```\n\n### Customizing Colors\n\nYou can customize individual UI elements by specifying color values after the base scheme:\n\n```sh\nsk --color=light,fg:232,bg:255,current_bg:116,info:27\n```\n\nColors can be specified in several ways:\n\n- ANSI colors (0-255): `sk --color=fg:232,bg:255`\n- RGB hex values: `sk --color=fg:#FF0000` (red text)\n\n### Available Color Customization Options\n\nThe following UI elements can be customized:\n\n| Element            | Description                                 | Example                        |\n|--------------------|---------------------------------------------|--------------------------------|\n| `fg`               | Normal text foreground color                | `--color=fg:232`               |\n| `bg`               | Normal text background color                | `--color=bg:255`               |\n| `matched`          | Matched text in search results              | `--color=matched:108`          |\n| `matched_bg`       | Background of matched text                  | `--color=matched_bg:0`         |\n| `current`          | Current line foreground color               | `--color=current:254`          |\n| `current_bg`       | Current line background color               | `--color=current_bg:236`       |\n| `current_match`    | Matched text in current line                | `--color=current_match:151`    |\n| `current_match_bg` | Background of matched text in current line  | `--color=current_match_bg:236` |\n| `spinner`          | Progress indicator color                    | `--color=spinner:148`          |\n| `info`             | Information line color                      | `--color=info:144`             |\n| `prompt`           | Prompt color                                | `--color=prompt:110`           |\n| `cursor`           | Cursor color                                | `--color=cursor:161`           |\n| `selected`         | Selected item marker color                  | `--color=selected:168`         |\n| `header`           | Header text color                           | `--color=header:109`           |\n| `border`           | Border color for preview/layout             | `--color=border:59`            |\n\n### Examples\n\n```sh\n# Use light theme but change the current line background\nsk --color=light,current_bg:24\n\n# Custom theme with multiple colors\nsk --color=dark,matched:#00FF00,current:#FFFFFF,current_bg:#000080\n\n# High contrast theme\nsk --color=fg:232,bg:255,matched:160,current:255,current_bg:20\n```\n\nFor more details, check the man page (`man sk`).\n\n## Misc\n\n- `--ansi`: to parse ANSI color codes (e.g., `\\e[32mABC`) of the data source\n- `--regex`: use the query as regular expression to match the data source\n\n# Advanced Topics\n\n## Interactive mode\n\nIn **interactive mode**, you can invoke a command dynamically. Try it out:\n\n```sh\nsk --ansi -i -c 'rg --color=always --line-number \"{}\"'\n```\n\n### How does it work?\n\n![How Skim's interactive mode works](https://user-images.githubusercontent.com/1527040/53381293-461ce380-39ab-11e9-8e86-7c3bbfd557bc.png)\n\n- Skim  accepts two kinds of sources: Command output or piped input\n- Skim has two kinds of prompts: A query prompt to specify the query pattern and a\n    command prompt to specify the \"arguments\" of the command\n- `-c` is used to specify the command to execute and defaults to `SKIM_DEFAULT_COMMAND`\n- `-i` tells skim to open command prompt on startup, which will show `c>` by default.\n\nTo further narrow down the results returned by the command, press\n`Ctrl-Q` to toggle interactive mode.\n\n## Executing external programs\n\nYou can configure key bindings to start external processes without leaving Skim (`execute`, `execute-silent`).\n\n```sh\n# Press F1 to open the file with less without leaving skim\n# Press CTRL-Y to copy the line to clipboard and aborts skim (requires pbcopy)\nsk --bind 'f1:execute(less -f {}),ctrl-y:execute-silent(echo {} | pbcopy)+abort'\n```\n\n## Preview Window\n\nThis is a great feature of fzf that skim borrows. For example, we use 'ag' to\nfind the matched lines, and once we narrow down to the target lines, we want to\nfinally decide which lines to pick by checking the context around the line.\n`grep` and `ag` have the option `--context`, and skim can make use of `--context` for\na better preview window. For example:\n\n```sh\nsk --ansi -i -c 'ag --color \"{}\"' --preview \"preview.sh {}\"\n```\n\n(Note that [preview.sh](https://github.com/junegunn/fzf.vim/blob/master/bin/preview.sh) is a script to print the context given filename:lines:columns)\n\nYou get things like this:\n\n![preview demo](https://user-images.githubusercontent.com/1527040/30677573-0cee622e-9ebf-11e7-8316-c741324ecb3a.png)\n\n### How does it work?\n\nIf the preview command is given by the `--preview` option, skim will replace the\n`{}` with the current highlighted line surrounded by single quotes, call the\ncommand to get the output, and print the output on the preview window.\n\nSometimes you don't need the whole line for invoking the command. In this case\nyou can use `{}`, `{1..}`, `{..3}` or `{1..5}` to select the fields. The\nsyntax is explained in the section [Fields Support](#filds-support).\n\nLastly, you might want to configure the position of preview window with `--preview-window`:\n- `--preview-window up:30%` to put the window in the up position with height\n    30% of the total height of skim.\n- `--preview-window left:10:wrap` to specify the `wrap` allows the preview\n    window to wrap the output of the preview command.\n- `--preview-window wrap:hidden` to hide the preview window at startup, later\n    it can be shown by the action `toggle-preview`.\n\n## Fields support\n\nNormally only plugin users need to understand this.\n\nFor example, you have the data source with the format:\n\n```sh\n<filename>:<line number>:<column number>\n```\n\nHowever, you want to search `<filename>` only when typing in queries. That\nmeans when you type `21`, you want to find a `<filename>` that contains `21`,\nbut not matching line number or column number.\n\nYou can use `sk --delimiter ':' --nth 1` to achieve this.\n\nYou can also use `--with-nth` to re-arrange the order of fields.\n\n**Range Syntax**\n\n- `<num>` -- to specify the `num`-th fields, starting with 1.\n- `start..` -- starting from the `start`-th fields and the rest.\n- `..end` -- starting from the `0`-th field, all the way to `end`-th field,\n    including `end`.\n- `start..end` -- starting from `start`-th field, all the way to `end`-th\n    field, including `end`.\n\n## Use as a library\n\nSkim can be used as a library in your Rust crates.\n\nFirst, add skim into your `Cargo.toml`:\n\n```toml\n[dependencies]\nskim = { version = \"<version>\", default-features = false, features = [..] }\n```\n\n_Note on features_:\n    - the `cli` feature is required to use skim as a cli, it *should* not be needed when using it as a library.\n    - the `nightly-frizbee` feature adds the frizbee algorithm, but requires cargo nigthly.\n\nThen try to run this simple example:\n\n```rust\nextern crate skim;\nuse skim::prelude::*;\nuse std::io::Cursor;\n\npub fn main() {\n    let options = SkimOptionsBuilder::default()\n        .height(String::from(\"50%\"))\n        .multi(true)\n        .build()\n        .unwrap();\n\n    let input = \"aaaaa\\nbbbb\\nccc\".to_string();\n\n    // `SkimItemReader` is a helper to turn any `BufRead` into a stream of `SkimItem`\n    // `SkimItem` was implemented for `AsRef<str>` by default\n    let item_reader = SkimItemReader::default();\n    let items = item_reader.of_bufread(Cursor::new(input));\n\n    // `run_with` would read and show items from the stream\n    let selected_items = Skim::run_with(&options, Some(items))\n        .map(|out| out.selected_items)\n        .unwrap_or_else(|| Vec::new());\n\n    for item in selected_items.iter() {\n        println!(\"{}\", item.output());\n    }\n}\n```\n\nGiven an `Option<SkimItemReceiver>`, skim will read items accordingly, do its\njob and bring us back the user selection including the selected items, the\nquery, etc. Note that:\n\n- `SkimItemReceiver` is `crossbeam::channel::Receiver<Arc<dyn SkimItem>>`\n- If it is none, it will invoke the given command and read items from command output\n- Otherwise, it will read the items from the (crossbeam) channel.\n\nTrait `SkimItem` is provided to customize how a line could be displayed,\ncompared and previewed. It is implemented by default for `AsRef<str>`\n\nPlus, `SkimItemReader` is a helper to convert a `BufRead` into\n`SkimItemReceiver` (we can easily turn a `File` or `String` into `BufRead`),\nso that you could deal with strings or files easily.\n\nCheck out more examples under the [examples/](https://github.com/skim-rs/skim/tree/master/skim/examples) directory.\n\n# FAQ\n\n## How to ignore files?\n\nSkim invokes `find .` to fetch a list of files for filtering. You can override\nthis by setting the environment variable `SKIM_DEFAULT_COMMAND`. For example:\n\n```sh\n$ SKIM_DEFAULT_COMMAND=\"fd --type f || git ls-tree -r --name-only HEAD || rg --files || find .\"\n$ sk\n```\n\nYou could put it in your `.bashrc` or `.zshrc` if you like it to be default.\n\n## Some files are not shown in Vim plugin\n\nIf you use the Vim plugin and execute the `:SK` command, you may find some\nof your files not shown.\n\nAs described in [#3](https://github.com/skim-rs/skim/issues/3), in the Vim\nplugin, `SKIM_DEFAULT_COMMAND` is set to the command by default:\n\n```vim\nlet $SKIM_DEFAULT_COMMAND = \"git ls-tree -r --name-only HEAD || rg --files || ag -l -g \\\"\\\" || find .\"\n```\n\nThis means files not recognized by git won't be shown. You can either override the\ndefault with `let $SKIM_DEFAULT_COMMAND = ''` or locate the missing files by\nyourself.\n\n# Differences from fzf\n\n[fzf](https://github.com/junegunn/fzf) is a command-line fuzzy finder written\nin Go and [skim](https://github.com/skim-rs/skim) tries to implement a new one\nin Rust!\n\nThis project is written from scratch. Some decisions of implementation are\ndifferent from fzf. For example:\n\n1. `skim` has an interactive mode.\n2. `skim` supports pre-selection.\n3. The fuzzy search algorithm is different.\n\nMore generally, `skim`'s maintainers allow themselves some freedom of implementation.\nThe goal is to keep `skim` as feature-full as `fzf` is, but the command flags might differ.\n\n# How to contribute\n\n[Create new issues](https://github.com/skim-rs/skim/issues/new) if you encounter any bugs\nor have any ideas. Pull requests are warmly welcomed.\n\n# Troubleshooting\n\nTo troubleshoot what's happening, you can set the environment variable `RUST_LOG` to either `debug` or even `trace`, and set `--log-file` to a path. You can then read those logs during or after the execution to better understand what's happening. Don't hesitate to add those logs to an issue if you need help.\n\n## No line feed issues with nix, FreeBSD, termux\n\nIf you encounter display issues like:\n\n```bash\n$ for n in {1..10}; do echo \"$n\"; done | sk\n  0/10 0/0.> 10/10  10  9  8  7  6  5  4  3  2> 1\n```\n\nFor example\n\n- https://github.com/skim-rs/skim/issues/412\n- https://github.com/skim-rs/skim/issues/455\n\nYou need to set TERMINFO or TERMINFO_DIRS to the path of a correct terminfo database path\n\nFor example, with termux, you can add this in your bashrc:\n\n```\nexport TERMINFO=/data/data/com.termux/files/usr/share/terminfo\n```\n\n# Benchmarks\n\nThe `bench.sh` script is available to benchmark the code.\n\nYou can use it directly using `./bench.sh <binary> -n <number of items> -r <number of runs>`, or generate the data using `./bench.sh -g <output file> -n <number of items>`, then `./bench.sh <binary> -f <file> -r <number of runs>`\n",
      "stars_today": 17
    },
    {
      "id": 350501380,
      "name": "BotW-BetterVR",
      "full_name": "Crementif/BotW-BetterVR",
      "description": "A project aimed at providing a better PC VR mode for BotW using the Cemu emulator",
      "html_url": "https://github.com/Crementif/BotW-BetterVR",
      "stars": 983,
      "forks": 174,
      "language": "C++",
      "topics": [],
      "created_at": "2021-03-22T21:59:14Z",
      "updated_at": "2026-01-24T23:03:41Z",
      "pushed_at": "2026-01-24T14:48:07Z",
      "open_issues": 63,
      "owner": {
        "login": "Crementif",
        "avatar_url": "https://avatars.githubusercontent.com/u/26669564?v=4"
      },
      "readme": "# <img width=\"3840\" height=\"1037\" alt=\"BetterVRLogo(1)\" src=\"https://github.com/user-attachments/assets/4f6d6ce2-daed-4411-a5c4-8c5d288ac921\" />\n\nBetterVR is a VR mod/hook that adds a PC-VR mode for BotW using the Wii U emulator called Cemu.\n\nIt currently supports the following features:\n* Fully stereo-rendered with 6DOF. No alternated eye rendering is used.\n* Full hands and arms support. You can deck yourself out in all the fanciest clothes.\n* Wield weapons, torches and bokoblin arms into combat.\n* Gestures to equip and throw weapons.\n* Use motion controls to interact with the world to solve puzzles or start fires.\n* Large mod compatibility. BetterVR only modifies the code and no game data. Most other mods should be compatible.\n* Optional third-person mode (though its a bit broken at the moment).\n\n### Requirements\n\n#### Supported VR headsets:\n\nThe app currently utilizes OpenXR, which is supported on all the major headsets (Valve Index, HTC Vive, Oculus Rift, Meta Quest,\nWindows Mixed Reality etc.). However, controller bindings are currently only provided for Oculus Touch controllers.\nWhile more integrated solutions are being found out, there's probably ways to setup OpenXR mappings through SteamVR or other applications.\n\n#### Other Requirements:\n\n* A gaming PC with a CPU that is good at single-threaded workloads (a recent Intel i5 or Ryzen 5 are recommended at least)!\n\n* A legal copy of BotW for the Wii U.\n\n* Windows OS. [It doesn't work under Linux (even with Wine/Proton) for now](https://github.com/Crementif/BotW-BetterVR/issues/18).\n\n* A properly set up [Cemu](http://cemu.info/) emulator that's able to run at 60FPS or higher. See [this guide](https://cemu.cfw.guide/) for more info.\n  * **Before reporting issues, make sure that you have a WORKING version of the game that can go in-game on your PC before you install this mod!**  \n\n* A recent Cemu version. Only Cemu 2.6 is tested to work.\n\n> [!WARNING]\n> ### Current Limitations & Known Issues\n> Since this is an unofficial mod and not a VR port, some things do not work perfectly (yet).  \n> Some issues will be much easier to fix then others.  \n> The game is fully tested to be completeable, from start to finish.\n> \n> If you want to help to improve the mod and tackle some of these issues, reach out in the ZBW Development Channel in the [Flat2VR Discord](https://discord.com/invite/flat2vr) for extra info, context and requirements!\n>\n> **Important Issues:**\n> * Weapons might deregister rarely (after breaking?). You might have to drop and pick it up again.\n> * ~~Gravity is higher. Jumping isn't affected, but some shrines might require creative solutions/glitches for now.~~ This is fixed now!\n> * ~~Third-person mode (and cutscenes) often has the player being partially/largely invisible.~~ This is fixed now!\n> * ~~Climbing ladders requires looking away with the camera using your controller stick.~~ This is fixed now!\n> * ~~Some towers can't be unlocked and cause the cutscene to softlock.~~ This is fixed now!\n> * ~~Our AMD GPU system has a crash after the load screen, which we're working on fixing.~~ This is fixed now!\n> * ~~**Weapon Glitch:** Sometimes weapons will stop registering hits on enemies.~~\n\n**Audio & Visuals**\n- ~~Slight audio crackling may occur when loading the game or opening menus quickly.~~ This is fixed now!\n- The game becomes slowly brighter. Seems to happen (more?) after each loading screen or shrine?\n- Some voice-acted cutscenes or timed text cutscenes are sped-up and have overlapping text/voices.\n- While inside the Divine Beasts, skyboxes appear to sway with the camera more then intended.\n- Stamina wheel is weirdly positioned.\n- There's a very small chance that the screen stays black after exiting any menus, which requires restarting the game to continue.\n\n**Gameplay & Combat**\n- ~~Flurry Rush can be triggered but does not work.~~ This is fixed now!\n- ~~Motion control shrines aren't supported yet. There's only a few of these in the game so mark them on your map until its fixed.~~\n- Bow Aiming is done via a crosshair on the VR headset. Bow support might be added at some point.\n- Enemies will ocassionally not detect you\n- No roomscale support. You can freely move around your room, but enemies and physics will use your center point. \n\n**Traversal & Physics**\n- ~~Exiting the water while swimming can be difficult at certain angles. Swim dashing sometimes doesn't work.~~ This is now fixed!\n- Magnesis & Stasis aim is off-center at far distances. Point your gaze to the **right** of the object to highlight it.\n- Shrine exits require looking at the bottom of the altar from a slight distance before the prompt might appear.\n- Climbing ladders require jumping up the ladder to go up and you have to look at the ladder.\n- You can get stuck behind ladders sometimes, especially when you stop moving at the very top of the ladder while climbing down. So keep moving at the start!\n\n### Mod Installation\n\n1. Download the latest release of the mod from the [Releases](https://github.com/Crementif/BotW-BetterVR/releases) page.\n\n2. Extract the contents of the downloaded `.zip` file into the same folder where your `Cemu.exe` is stored.\n   There should now be **at least** .dll, .json and multiple .bat files in the same folder as your `Cemu.exe`.\n   \n3. Open Cemu normally through the `Cemu.exe` (not the .bat file!).\n    - Cemu's window title should state Cemu 2.6 or newer. Any older version isn't supported.\n    - The game should say V208 inside the update column in Cemu's game list. Otherwise it's outdated/not updated, and won't work.\n    - Go to `Options`->`General Settings`, and then under the `Graphics` tab make sure that you're using Vulkan, that the right GPU is selected and that VSync is turned off.\n    \n    If all that is true, continue to the next step by closing the settings window and then Cemu entirely. Otherwise, fix those issues before continuing.\n\n4. Double-click on `BetterVR LAUNCH CEMU IN VR.bat` to start Cemu. This'll install the graphic pack automatically to the right folder.\n\n5. Go to `Options`-> `Graphic packs`-> `The Legend of Zelda: Breath of the Wild` and make sure that the graphic pack named `BetterVR` is enabled.\n   This is ALSO where you can change any VR settings like the first/third-person mode etc.  \n   **You'll also want to enable the FPS++ graphic pack, or else the game will crash!**  \n   **While you're inside the graphic packs menu, make sure that you've clicked on the Download Community Graphic Packs button to update your graphic packs!**  \n   **You can't change the BetterVR options while you're in-game.**  \n\n6. For an enjoyable experience you should change some other graphic packs in this same window too:\n   - `Graphics` graphic pack: Use any (non-ultrawide!) resolution of 1440p (2k) or higher for clarity. Also change anti-aliasing to Nvidia FXAA.\n      **Make sure that you don't use a resolution under 1280x720, or else the game will never show up!**\n   - `FPS++` graphic pack: Change the FPS limit to at least 120FPS or 144FPS. The OpenXR headset will dictate the framerate anyway.\n   - `Enhancements`: graphic pack: Change anisotropic filtering to 16x and use your preferred preset.\n   - Any other settings like shadows, draw distance etc. You can always play around with this to see what the performance hit is.  \n\n7. Close the settings and start the game like normal from Cemu's game list. You can now put on your VR headset and if installed correctly it should now work!\n\nFrom now on you can play the game in VR by just starting the `BetterVR LAUNCH CEMU IN VR.bat` file.  \nIf you want to undo the installation (temporarily) to play the game without VR, use the `BetterVR UNINSTALL.bat` file.  \nYou can just use the `BetterVR LAUNCH CEMU IN VR.bat` file to reinstall and start the VR mod again.\n\n### Controls\n\n<img width=\"2366\" height=\"3423\" alt=\"image\" src=\"https://github.com/user-attachments/assets/ff44b2d8-ef64-417f-8f72-f7ff887f00c2\" />\n\n\n---\n\n### Technical Overview\n#### Rendering an image to the VR headset\nThis mod ships with no game files, so you might ask how it works.\n\nThe game starts with the BetterVR Vulkan layer enabled. The Vulkan layer, which comes in the form of the .DLL file, is then able to intercept the Vulkan commands that Cemu submits so that we can get the final frame to render to the VR headset and draw the debugging tools.\n\nA technical hurdle here was that due to OpenXR frameworks not being designed to be instantiated inside something that is intercepting Vulkan commands, this mod utilizes Vulkan <-> D3D12 interop to pipe the rendered output from Vulkan to a D3D12 application that's *just* used for rendering the captured image to the VR headset. That way the OpenXR framework is just interacting with root-level rendering handles, instead of what'd occur in the Vulkan hook.\n\nUsing an external DLL originally made a lot of sense when Cemu wasn't open-sourced (though it also makes it slightly less tied to a specific emulator or version of Cemu, and prevents a VR specific version of Cemu that'll quickly become outdated). In hindsight, it probably would've saved a lot of time spent trying to get the mod to work without using D3D12.\n\n#### How to make it VR\nHowever, while drawing the game's rendered output to the VR headset is one thing, getting a native game to render a 3D image is a whole other thing. For that, the mod has a bunch of PowerPC assembly patches (the Wii U has a PowerPC CPU) to modify the game's code. For example, an important patch is to make it so that the game renders two frames before updating all of the game's systems and objects that are on-screen. Then, among many other patches, you'll also find patches that change the camera or player model positions each frame, or trigger an attack.\n\nUsually the assembly code will call into the C++ code if it wants to do complicated algebra to specify where the camera or Link's hands should be for example. And some assembly patches use a clearing instruction for the Wii U's GPU which, after being translated, will signal the Vulkan hook to send the almost-finished final game image to the D3D12 code where it can present it inside the VR headset.\n\nAdditionally, since combat is a large part of the original game, there's also a new swing and stab detection system that allows the player to cut trees and enemies down when they execute proper swings and stabbing motions. This prevents a situation where weapon hitboxes are abused to instantly stagger an enemy. There's plans for an even deeper integration, but as of today that's about it. This is fully optional since the mod still features an attack button, but the latter will offer a lot more immersion.\n\nUnderstanding how the game works, finding and patching the exact parts inside the game's executable is by far the most difficult part and it took thousands of hours of reverse-engineering. Its without a doubt the most time consuming task of this VR mod, especially since this game uses a custom C++ engine of which is not much known about other then the good work of the (largely unfinished, but still very helpful) decompilation project.\n\nIf you want to know more about the technical details, feel free to ask in the BetterVR related channels in the [Flat2VR Discord server](https://discord.com/invite/flat2vr).\nThere's enough that was skipped over or left out in this explanation.\n\n\n### Build Instructions (For Developers)\n\n1. Install the latest Vulkan SDK from https://vulkan.lunarg.com/sdk/home#windows and make sure that VULKAN_SDK was added\n   to your environment variables.\n\n2. Install [vcpkg](https://github.com/microsoft/vcpkg) (make sure to run the bootstrap and install commands it mentions) and use the following command to install the required dependencies:\n   `vcpkg install openxr-loader:x64-windows-static-md glm:x64-windows-static-md vulkan-headers:x64-windows-static-md imgui:x64-windows-static-md`\n\n3. Change the CMakeUserPresets.json file to contain the directory where you've stored vcpkg. Its currently hardcoded.\n   If you want to use [Meta XR Simulator](https://developers.meta.com/horizon/downloads/package/meta-xr-simulator-windows/) (which is quite helpful during debugging), you should change its path now too.\n   **Meta XR Simulator doesn't work unless you edit the `[install folder]/config/sim_core_configuration.json` file from `    \"disable_interop\": false,` to `    \"disable_interop\": true,`.**\n\n4. [Optional] Download and extract a new Cemu installation to the Cemu folder that's included.\n   This step is technically not required, but it's the default install location and makes debugging much easier.\n\n5. Use Clion or Visual Studio to open the CMake project. Make sure that it's compiling a x64 build.\n\n6. If you want to use it outside visual studio, you can go to the `/[cmake-output-folder]/bin/` folder for the BetterVR_Layer.dll.\n   The `BetterVR_Layer.json` and `Launch_BetterVR.bat` can be found in the [resources](/resources) folder.\n   Then you can launch Cemu with the hook using the Launch_BetterVR.bat file to start Cemu with the hook.\n\n\n### Credits\nCrementif: Main Developer  \nAcudofy: Sword & stab analysis system  \nHolydh: Developed the input systems  \nleoetlino: For the [BotW Decomp project](https://github.com/zeldaret/botw), which was very useful  \nExzap: Technical support and optimization help  \nMako Marci: Edited the trailer  \nTim, Mako Marci, Solarwolf07 & Elliott Tate: Helped with testing, recording, feedback and support  \n\n### Licenses\n\nThis project is licensed under the MIT license.\nBetterVR also uses the following libraries:\n - [vkroots (MIT licensed)](https://github.com/Joshua-Ashton/vkroots/blob/main/LICENSES/MIT.txt)\n - [imgui (MIT licensed)](https://github.com/ocornut/imgui/blob/master/LICENSE.txt)\n - [ImPlot3D (MIT licensed)](https://github.com/brenocq/implot3d/blob/main/LICENSE)\n - [ImPlot (MIT licensed)](https://github.com/epezent/implot/blob/master/LICENSE)\n",
      "stars_today": 17
    },
    {
      "id": 29261473,
      "name": "minio",
      "full_name": "minio/minio",
      "description": "MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.",
      "html_url": "https://github.com/minio/minio",
      "stars": 59893,
      "forks": 6915,
      "language": "Go",
      "topics": [
        "amazon-s3",
        "cloud",
        "cloudnative",
        "cloudstorage",
        "go",
        "k8s",
        "kubernetes",
        "multi-cloud",
        "multi-cloud-kubernetes",
        "objectstorage",
        "s3",
        "storage"
      ],
      "created_at": "2015-01-14T19:23:58Z",
      "updated_at": "2026-01-25T01:33:10Z",
      "pushed_at": "2026-01-06T02:02:20Z",
      "open_issues": 79,
      "owner": {
        "login": "minio",
        "avatar_url": "https://avatars.githubusercontent.com/u/695951?v=4"
      },
      "readme": "# Maintenance Mode\n\n**This project is currently under maintenance and is not accepting new changes.**\n\n**Alternate Options:**\n\n- **AIStor Free**: Fully featured, standalone version of AIStor for community use. Download a free license key from [Free license download](https://min.io/download)\n- **AIStor Enterprise**:  Fully featured, Distributed version of AIStor for commercial enterprise use. [Subscription](https://www.min.io/pricing)\n\nLearn more about [subscription tiers](https://blog.min.io/introducing-new-subscription-tiers-for-minio-aistor-free-enterprise-lite-and-enterprise/)\n\n---\n\n# MinIO Quickstart Guide\n\n[![Slack](https://slack.min.io/slack?type=svg)](https://slack.min.io) [![Docker Pulls](https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800)](https://hub.docker.com/r/minio/minio/) [![license](https://img.shields.io/badge/license-AGPL%20V3-blue)](https://github.com/minio/minio/blob/master/LICENSE)\n\n[![MinIO](https://raw.githubusercontent.com/minio/minio/master/.github/logo.svg?sanitize=true)](https://min.io)\n\nMinIO is a high-performance, S3-compatible object storage solution released under the GNU AGPL v3.0 license.\nDesigned for speed and scalability, it powers AI/ML, analytics, and data-intensive workloads with industry-leading performance.\n\n- S3 API Compatible â€“ Seamless integration with existing S3 tools\n- Built for AI & Analytics â€“ Optimized for large-scale data pipelines\n- High Performance â€“ Ideal for demanding storage workloads.\n\nThis README provides instructions for building MinIO from source and deploying onto baremetal hardware.\nUse the [MinIO Documentation](https://github.com/minio/docs) project to build and host a local copy of the documentation.\n\n## MinIO is Open Source Software\n\nWe designed MinIO as Open Source software for the Open Source software community. We encourage the community to remix, redesign, and reshare MinIO under the terms of the AGPLv3 license.\n\nAll usage of MinIO in your application stack requires validation against AGPLv3 obligations, which include but are not limited to the release of modified code to the community from which you have benefited. Any commercial/proprietary usage of the AGPLv3 software, including repackaging or reselling services/features, is done at your own risk.\n\nThe AGPLv3 provides no obligation by any party to support, maintain, or warranty the original or any modified work.\nAll support is provided on a best-effort basis through Github and our [Slack](https//slack.min.io) channel, and any member of the community is welcome to contribute and assist others in their usage of the software.\n\nMinIO [AIStor](https://www.min.io/product/aistor) includes enterprise-grade support and licensing for workloads which require commercial or proprietary usage and production-level SLA/SLO-backed support. For more information, [reach out for a quote](https://min.io/pricing).\n\n## Source-Only Distribution\n\n**Important:** The MinIO community edition is now distributed as source code only. We will no longer provide pre-compiled binary releases for the community version.\n\n### Installing Latest MinIO Community Edition\n\nTo use MinIO community edition, you have two options:\n\n1. **Install from source** using `go install github.com/minio/minio@latest` (recommended)\n2. **Build a Docker image** from the provided Dockerfile\n\nSee the sections below for detailed instructions on each method.\n\n### Legacy Binary Releases\n\nHistorical pre-compiled binary releases remain available for reference but are no longer maintained:\n- GitHub Releases: https://github.com/minio/minio/releases\n- Direct downloads: https://dl.min.io/server/minio/release/\n\n**These legacy binaries will not receive updates.** We strongly recommend using source builds for access to the latest features, bug fixes, and security updates.\n\n## Install from Source\n\nUse the following commands to compile and run a standalone MinIO server from source.\nIf you do not have a working Golang environment, please follow [How to install Golang](https://golang.org/doc/install). Minimum version required is [go1.24](https://golang.org/dl/#stable)\n\n```sh\ngo install github.com/minio/minio@latest\n```\n\nYou can alternatively run `go build` and use the `GOOS` and `GOARCH` environment variables to control the OS and architecture target.\nFor example:\n\n```\nenv GOOS=linux GOARCh=arm64 go build\n```\n\nStart MinIO by running `minio server PATH` where `PATH` is any empty folder on your local filesystem.\n\nThe MinIO deployment starts using default root credentials `minioadmin:minioadmin`.\nYou can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server.\nPoint a web browser running on the host machine to <http://127.0.0.1:9000> and log in with the root credentials.\nYou can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.\n\nYou can also connect using any S3-compatible tool, such as the MinIO Client `mc` commandline tool:\n\n```sh\nmc alias set local http://localhost:9000 minioadmin minioadmin\nmc admin info local\n```\n\nSee [Test using MinIO Client `mc`](#test-using-minio-client-mc) for more information on using the `mc` commandline tool.\nFor application developers, see <https://docs.min.io/enterprise/aistor-object-store/developers/sdk/> to view MinIO SDKs for supported languages.\n\n> [!NOTE]\n> Production environments using compiled-from-source MinIO binaries do so at their own risk.\n> The AGPLv3 license provides no warranties nor liabilites for any such usage.\n\n## Build Docker Image\n\nYou can use the `docker build .` command to build a Docker image on your local host machine.\nYou must first [build MinIO](#install-from-source) and ensure the `minio` binary exists in the project root.\n\nThe following command builds the Docker image using the default `Dockerfile` in the root project directory with the repository and image tag `myminio:minio`\n\n```sh\ndocker build -t myminio:minio .\n```\n\nUse `docker image ls` to confirm the image exists in your local repository.\nYou can run the server using standard Docker invocation:\n\n```sh\ndocker run -p 9000:9000 -p 9001:9001 myminio:minio server /tmp/minio --console-address :9001\n```\n\nComplete documentation for building Docker containers, managing custom images, or loading images into orchestration platforms is out of scope for this documentation.\nYou can modify the `Dockerfile` and `dockerscripts/docker-entrypoint.sh` as-needed to reflect your specific image requirements.\n\nSee the [MinIO Container](https://docs.min.io/community/minio-object-store/operations/deployments/baremetal-deploy-minio-as-a-container.html#deploy-minio-container) documentation for more guidance on running MinIO within a Container image.\n\n## Install using Helm Charts\n\nThere are two paths for installing MinIO onto Kubernetes infrastructure:\n\n- Use the [MinIO Operator](https://github.com/minio/operator)\n- Use the community-maintained [Helm charts](https://github.com/minio/minio/tree/master/helm/minio)\n\nSee the [MinIO Documentation](https://docs.min.io/community/minio-object-store/operations/deployments/kubernetes.html) for guidance on deploying using the Operator.\nThe Community Helm chart has instructions in the folder-level README.\n\n## Test MinIO Connectivity\n\n### Test using MinIO Console\n\nMinIO Server comes with an embedded web based object browser.\nPoint your web browser to <http://127.0.0.1:9000> to ensure your server has started successfully.\n\n> [!NOTE]\n> MinIO runs console on random port by default, if you wish to choose a specific port use `--console-address` to pick a specific interface and port.\n\n### Test using MinIO Client `mc`\n\n`mc` provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage services.\n\nThe following commands set a local alias, validate the server information, create a bucket, copy data to that bucket, and list the contents of the bucket.\n\n```sh\nmc alias set local http://localhost:9000 minioadmin minioadmin\nmc admin info\nmc mb data\nmc cp ~/Downloads/mydata data/\nmc ls data/\n```\n\nFollow the MinIO Client [Quickstart Guide](https://docs.min.io/community/minio-object-store/reference/minio-mc.html#quickstart) for further instructions.\n\n## Explore Further\n\n- [The MinIO documentation website](https://docs.min.io/community/minio-object-store/index.html)\n- [MinIO Erasure Code Overview](https://docs.min.io/community/minio-object-store/operations/concepts/erasure-coding.html)\n- [Use `mc` with MinIO Server](https://docs.min.io/community/minio-object-store/reference/minio-mc.html)\n- [Use `minio-go` SDK with MinIO Server](https://docs.min.io/enterprise/aistor-object-store/developers/sdk/go/)\n\n## Contribute to MinIO Project\n\nPlease follow MinIO [Contributor's Guide](https://github.com/minio/minio/blob/master/CONTRIBUTING.md) for guidance on making new contributions to the repository.\n\n## License\n\n- MinIO source is licensed under the [GNU AGPLv3](https://github.com/minio/minio/blob/master/LICENSE).\n- MinIO [documentation](https://github.com/minio/minio/tree/master/docs) is licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).\n- [License Compliance](https://github.com/minio/minio/blob/master/COMPLIANCE.md)\n",
      "stars_today": 16
    },
    {
      "id": 156939672,
      "name": "onnxruntime",
      "full_name": "microsoft/onnxruntime",
      "description": "ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator",
      "html_url": "https://github.com/microsoft/onnxruntime",
      "stars": 19081,
      "forks": 3667,
      "language": "C++",
      "topics": [
        "ai-framework",
        "deep-learning",
        "hardware-acceleration",
        "machine-learning",
        "neural-networks",
        "onnx",
        "pytorch",
        "scikit-learn",
        "tensorflow"
      ],
      "created_at": "2018-11-10T02:22:53Z",
      "updated_at": "2026-01-25T01:32:41Z",
      "pushed_at": "2026-01-25T01:50:55Z",
      "open_issues": 1227,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "<p align=\"center\"><img width=\"50%\" src=\"docs/images/ONNX_Runtime_logo_dark.png\" /></p>\n\n**ONNX Runtime is a cross-platform inference and training machine-learning accelerator**.\n\n**ONNX Runtime inference** can enable faster customer experiences and lower costs, supporting models from deep learning frameworks such as PyTorch and TensorFlow/Keras as well as classical machine learning libraries such as scikit-learn, LightGBM, XGBoost, etc. ONNX Runtime is compatible with different hardware, drivers, and operating systems, and provides optimal performance by leveraging hardware accelerators where applicable alongside graph optimizations and transforms. [Learn more &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-inferencing)\n\n**ONNX Runtime training** can accelerate the model training time on multi-node NVIDIA GPUs for transformer models with a one-line addition for existing PyTorch training scripts. [Learn more &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-training)\n\n## Get Started & Resources\n\n* **General Information**: [onnxruntime.ai](https://onnxruntime.ai)\n\n* **Usage documentation and tutorials**: [onnxruntime.ai/docs](https://onnxruntime.ai/docs)\n\n* **YouTube video tutorials**: [youtube.com/@ONNXRuntime](https://www.youtube.com/@ONNXRuntime)\n\n* [**Upcoming Release Roadmap**](https://onnxruntime.ai/roadmap)\n\n* **Companion sample repositories**:\n  - ONNX Runtime Inferencing: [microsoft/onnxruntime-inference-examples](https://github.com/microsoft/onnxruntime-inference-examples)\n  - ONNX Runtime Training: [microsoft/onnxruntime-training-examples](https://github.com/microsoft/onnxruntime-training-examples)\n\n## Releases\n\nThe current release and past releases can be found here: https://github.com/microsoft/onnxruntime/releases.\n\nFor details on the upcoming release, including release dates, announcements, features, and guidance on submitting feature requests, please visit the release roadmap: https://onnxruntime.ai/roadmap.\n\n## Data/Telemetry\n\nWindows distributions of this project may collect usage data and send it to Microsoft to help improve our products and services. See the [privacy statement](docs/Privacy.md) for more details.\n\n## Contributions and Feedback\n\nWe welcome contributions! Please see the [contribution guidelines](CONTRIBUTING.md).\n\nFor feature requests or bug reports, please file a [GitHub Issue](https://github.com/Microsoft/onnxruntime/issues).\n\nFor general discussion or questions, please use [GitHub Discussions](https://github.com/microsoft/onnxruntime/discussions).\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## License\n\nThis project is licensed under the [MIT License](LICENSE).\n",
      "stars_today": 15
    },
    {
      "id": 359952601,
      "name": "pgvector",
      "full_name": "pgvector/pgvector",
      "description": "Open-source vector similarity search for Postgres",
      "html_url": "https://github.com/pgvector/pgvector",
      "stars": 19457,
      "forks": 1035,
      "language": "C",
      "topics": [
        "approximate-nearest-neighbor-search",
        "nearest-neighbor-search"
      ],
      "created_at": "2021-04-20T21:13:52Z",
      "updated_at": "2026-01-25T01:40:11Z",
      "pushed_at": "2026-01-22T00:41:05Z",
      "open_issues": 13,
      "owner": {
        "login": "pgvector",
        "avatar_url": "https://avatars.githubusercontent.com/u/98363230?v=4"
      },
      "readme": "# pgvector\n\nOpen-source vector similarity search for Postgres\n\nStore your vectors with the rest of your data. Supports:\n\n- exact and approximate nearest neighbor search\n- single-precision, half-precision, binary, and sparse vectors\n- L2 distance, inner product, cosine distance, L1 distance, Hamming distance, and Jaccard distance\n- any [language](#languages) with a Postgres client\n\nPlus [ACID](https://en.wikipedia.org/wiki/ACID) compliance, point-in-time recovery, JOINs, and all of the other [great features](https://www.postgresql.org/about/) of Postgres\n\n[![Build Status](https://github.com/pgvector/pgvector/actions/workflows/build.yml/badge.svg)](https://github.com/pgvector/pgvector/actions)\n\n## Installation\n\n### Linux and Mac\n\nCompile and install the extension (supports Postgres 13+)\n\n```sh\ncd /tmp\ngit clone --branch v0.8.1 https://github.com/pgvector/pgvector.git\ncd pgvector\nmake\nmake install # may need sudo\n```\n\nSee the [installation notes](#installation-notes---linux-and-mac) if you run into issues\n\nYou can also install it with [Docker](#docker), [Homebrew](#homebrew), [PGXN](#pgxn), [APT](#apt), [Yum](#yum), [pkg](#pkg), [APK](#apk), or [conda-forge](#conda-forge), and it comes preinstalled with [Postgres.app](#postgresapp) and many [hosted providers](#hosted-postgres). There are also instructions for [GitHub Actions](https://github.com/pgvector/setup-pgvector).\n\n### Windows\n\nEnsure [C++ support in Visual Studio](https://learn.microsoft.com/en-us/cpp/build/building-on-the-command-line?view=msvc-170#download-and-install-the-tools) is installed and run `x64 Native Tools Command Prompt for VS [version]` as administrator. Then use `nmake` to build:\n\n```cmd\nset \"PGROOT=C:\\Program Files\\PostgreSQL\\18\"\ncd %TEMP%\ngit clone --branch v0.8.1 https://github.com/pgvector/pgvector.git\ncd pgvector\nnmake /F Makefile.win\nnmake /F Makefile.win install\n```\n\nSee the [installation notes](#installation-notes---windows) if you run into issues\n\nYou can also install it with [Docker](#docker) or [conda-forge](#conda-forge).\n\n## Getting Started\n\nEnable the extension (do this once in each database where you want to use it)\n\n```tsql\nCREATE EXTENSION vector;\n```\n\nCreate a vector column with 3 dimensions\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding vector(3));\n```\n\nInsert vectors\n\n```sql\nINSERT INTO items (embedding) VALUES ('[1,2,3]'), ('[4,5,6]');\n```\n\nGet the nearest neighbors by L2 distance\n\n```sql\nSELECT * FROM items ORDER BY embedding <-> '[3,1,2]' LIMIT 5;\n```\n\nAlso supports inner product (`<#>`), cosine distance (`<=>`), and L1 distance (`<+>`)\n\nNote: `<#>` returns the negative inner product since Postgres only supports `ASC` order index scans on operators\n\n## Storing\n\nCreate a new table with a vector column\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding vector(3));\n```\n\nOr add a vector column to an existing table\n\n```sql\nALTER TABLE items ADD COLUMN embedding vector(3);\n```\n\nAlso supports [half-precision](#half-precision-vectors), [binary](#binary-vectors), and [sparse](#sparse-vectors) vectors\n\nInsert vectors\n\n```sql\nINSERT INTO items (embedding) VALUES ('[1,2,3]'), ('[4,5,6]');\n```\n\nOr load vectors in bulk using `COPY` ([example](https://github.com/pgvector/pgvector-python/blob/master/examples/loading/example.py))\n\n```sql\nCOPY items (embedding) FROM STDIN WITH (FORMAT BINARY);\n```\n\nUpsert vectors\n\n```sql\nINSERT INTO items (id, embedding) VALUES (1, '[1,2,3]'), (2, '[4,5,6]')\n    ON CONFLICT (id) DO UPDATE SET embedding = EXCLUDED.embedding;\n```\n\nUpdate vectors\n\n```sql\nUPDATE items SET embedding = '[1,2,3]' WHERE id = 1;\n```\n\nDelete vectors\n\n```sql\nDELETE FROM items WHERE id = 1;\n```\n\n## Querying\n\nGet the nearest neighbors to a vector\n\n```sql\nSELECT * FROM items ORDER BY embedding <-> '[3,1,2]' LIMIT 5;\n```\n\nSupported distance functions are:\n\n- `<->` - L2 distance\n- `<#>` - (negative) inner product\n- `<=>` - cosine distance\n- `<+>` - L1 distance\n- `<~>` - Hamming distance (binary vectors)\n- `<%>` - Jaccard distance (binary vectors)\n\nGet the nearest neighbors to a row\n\n```sql\nSELECT * FROM items WHERE id != 1 ORDER BY embedding <-> (SELECT embedding FROM items WHERE id = 1) LIMIT 5;\n```\n\nGet rows within a certain distance\n\n```sql\nSELECT * FROM items WHERE embedding <-> '[3,1,2]' < 5;\n```\n\nNote: Combine with `ORDER BY` and `LIMIT` to use an index\n\n#### Distances\n\nGet the distance\n\n```sql\nSELECT embedding <-> '[3,1,2]' AS distance FROM items;\n```\n\nFor inner product, multiply by -1 (since `<#>` returns the negative inner product)\n\n```tsql\nSELECT (embedding <#> '[3,1,2]') * -1 AS inner_product FROM items;\n```\n\nFor cosine similarity, use 1 - cosine distance\n\n```sql\nSELECT 1 - (embedding <=> '[3,1,2]') AS cosine_similarity FROM items;\n```\n\n#### Aggregates\n\nAverage vectors\n\n```sql\nSELECT AVG(embedding) FROM items;\n```\n\nAverage groups of vectors\n\n```sql\nSELECT category_id, AVG(embedding) FROM items GROUP BY category_id;\n```\n\n## Indexing\n\nBy default, pgvector performs exact nearest neighbor search, which provides perfect recall.\n\nYou can add an index to use approximate nearest neighbor search, which trades some recall for speed. Unlike typical indexes, you will see different results for queries after adding an approximate index.\n\nSupported index types are:\n\n- [HNSW](#hnsw)\n- [IVFFlat](#ivfflat)\n\n## HNSW\n\nAn HNSW index creates a multilayer graph. It has better query performance than IVFFlat (in terms of speed-recall tradeoff), but has slower build times and uses more memory. Also, an index can be created without any data in the table since there isnâ€™t a training step like IVFFlat.\n\nAdd an index for each distance function you want to use.\n\nL2 distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l2_ops);\n```\n\nNote: Use `halfvec_l2_ops` for `halfvec` and `sparsevec_l2_ops` for `sparsevec` (and similar with the other distance functions)\n\nInner product\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_ip_ops);\n```\n\nCosine distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_cosine_ops);\n```\n\nL1 distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l1_ops);\n```\n\nHamming distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding bit_hamming_ops);\n```\n\nJaccard distance\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding bit_jaccard_ops);\n```\n\nSupported types are:\n\n- `vector` - up to 2,000 dimensions\n- `halfvec` - up to 4,000 dimensions\n- `bit` - up to 64,000 dimensions\n- `sparsevec` - up to 1,000 non-zero elements\n\n### Index Options\n\nSpecify HNSW parameters\n\n- `m` - the max number of connections per layer (16 by default)\n- `ef_construction` - the size of the dynamic candidate list for constructing the graph (64 by default)\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l2_ops) WITH (m = 16, ef_construction = 64);\n```\n\nA higher value of `ef_construction` provides better recall at the cost of index build time / insert speed.\n\n### Query Options\n\nSpecify the size of the dynamic candidate list for search (40 by default)\n\n```sql\nSET hnsw.ef_search = 100;\n```\n\nA higher value provides better recall at the cost of speed.\n\nUse `SET LOCAL` inside a transaction to set it for a single query\n\n```sql\nBEGIN;\nSET LOCAL hnsw.ef_search = 100;\nSELECT ...\nCOMMIT;\n```\n\n### Index Build Time\n\nIndexes build significantly faster when the graph fits into `maintenance_work_mem`\n\n```sql\nSET maintenance_work_mem = '8GB';\n```\n\nA notice is shown when the graph no longer fits\n\n```text\nNOTICE:  hnsw graph no longer fits into maintenance_work_mem after 100000 tuples\nDETAIL:  Building will take significantly more time.\nHINT:  Increase maintenance_work_mem to speed up builds.\n```\n\nNote: Do not set `maintenance_work_mem` so high that it exhausts the memory on the server\n\nLike other index types, itâ€™s faster to create an index after loading your initial data\n\nYou can also speed up index creation by increasing the number of parallel workers (2 by default)\n\n```sql\nSET max_parallel_maintenance_workers = 7; -- plus leader\n```\n\nFor a large number of workers, you may need to increase `max_parallel_workers` (8 by default)\n\nThe [index options](#index-options) also have a significant impact on build time (use the defaults unless seeing low recall)\n\n### Indexing Progress\n\nCheck [indexing progress](https://www.postgresql.org/docs/current/progress-reporting.html#CREATE-INDEX-PROGRESS-REPORTING)\n\n```sql\nSELECT phase, round(100.0 * blocks_done / nullif(blocks_total, 0), 1) AS \"%\" FROM pg_stat_progress_create_index;\n```\n\nThe phases for HNSW are:\n\n1. `initializing`\n2. `loading tuples`\n\n## IVFFlat\n\nAn IVFFlat index divides vectors into lists, and then searches a subset of those lists that are closest to the query vector. It has faster build times and uses less memory than HNSW, but has lower query performance (in terms of speed-recall tradeoff).\n\nThree keys to achieving good recall are:\n\n1. Create the index *after* the table has some data\n2. Choose an appropriate number of lists - a good place to start is `rows / 1000` for up to 1M rows and `sqrt(rows)` for over 1M rows\n3. When querying, specify an appropriate number of [probes](#query-options) (higher is better for recall, lower is better for speed) - a good place to start is `sqrt(lists)`\n\nAdd an index for each distance function you want to use.\n\nL2 distance\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding vector_l2_ops) WITH (lists = 100);\n```\n\nNote: Use `halfvec_l2_ops` for `halfvec` (and similar with the other distance functions)\n\nInner product\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding vector_ip_ops) WITH (lists = 100);\n```\n\nCosine distance\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);\n```\n\nHamming distance\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding bit_hamming_ops) WITH (lists = 100);\n```\n\nSupported types are:\n\n- `vector` - up to 2,000 dimensions\n- `halfvec` - up to 4,000 dimensions\n- `bit` - up to 64,000 dimensions\n\n### Query Options\n\nSpecify the number of probes (1 by default)\n\n```sql\nSET ivfflat.probes = 10;\n```\n\nA higher value provides better recall at the cost of speed, and it can be set to the number of lists for exact nearest neighbor search (at which point the planner wonâ€™t use the index)\n\nUse `SET LOCAL` inside a transaction to set it for a single query\n\n```sql\nBEGIN;\nSET LOCAL ivfflat.probes = 10;\nSELECT ...\nCOMMIT;\n```\n\n### Index Build Time\n\nSpeed up index creation on large tables by increasing the number of parallel workers (2 by default)\n\n```sql\nSET max_parallel_maintenance_workers = 7; -- plus leader\n```\n\nFor a large number of workers, you may also need to increase `max_parallel_workers` (8 by default)\n\n### Indexing Progress\n\nCheck [indexing progress](https://www.postgresql.org/docs/current/progress-reporting.html#CREATE-INDEX-PROGRESS-REPORTING)\n\n```sql\nSELECT phase, round(100.0 * tuples_done / nullif(tuples_total, 0), 1) AS \"%\" FROM pg_stat_progress_create_index;\n```\n\nThe phases for IVFFlat are:\n\n1. `initializing`\n2. `performing k-means`\n3. `assigning tuples`\n4. `loading tuples`\n\nNote: `%` is only populated during the `loading tuples` phase\n\n## Filtering\n\nThere are a few ways to index nearest neighbor queries with a `WHERE` clause.\n\n```sql\nSELECT * FROM items WHERE category_id = 123 ORDER BY embedding <-> '[3,1,2]' LIMIT 5;\n```\n\nA good place to start is creating an index on the filter column. This can provide fast, exact nearest neighbor search in many cases. Postgres has a number of [index types](https://www.postgresql.org/docs/current/indexes-types.html) for this: B-tree (default), hash, GiST, SP-GiST, GIN, and BRIN.\n\n```sql\nCREATE INDEX ON items (category_id);\n```\n\nFor multiple columns, consider a [multicolumn index](https://www.postgresql.org/docs/current/indexes-multicolumn.html).\n\n```sql\nCREATE INDEX ON items (location_id, category_id);\n```\n\nExact indexes work well for conditions that match a low percentage of rows. Otherwise, [approximate indexes](#indexing) can work better.\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l2_ops);\n```\n\nWith approximate indexes, filtering is applied *after* the index is scanned. If a condition matches 10% of rows, with HNSW and the default `hnsw.ef_search` of 40, only 4 rows will match on average. For more rows, increase `hnsw.ef_search`.\n\n```sql\nSET hnsw.ef_search = 200;\n```\n\nStarting with 0.8.0, you can enable [iterative index scans](#iterative-index-scans), which will automatically scan more of the index when needed.\n\n```sql\nSET hnsw.iterative_scan = strict_order;\n```\n\nIf filtering by only a few distinct values, consider [partial indexing](https://www.postgresql.org/docs/current/indexes-partial.html).\n\n```sql\nCREATE INDEX ON items USING hnsw (embedding vector_l2_ops) WHERE (category_id = 123);\n```\n\nIf filtering by many different values, consider [partitioning](https://www.postgresql.org/docs/current/ddl-partitioning.html).\n\n```sql\nCREATE TABLE items (embedding vector(3), category_id int) PARTITION BY LIST(category_id);\n```\n\n## Iterative Index Scans\n\nWith approximate indexes, queries with filtering can return less results since filtering is applied *after* the index is scanned. Starting with 0.8.0, you can enable iterative index scans, which will automatically scan more of the index until enough results are found (or it reaches `hnsw.max_scan_tuples` or `ivfflat.max_probes`).\n\nIterative scans can use strict or relaxed ordering.\n\nStrict ensures results are in the exact order by distance\n\n```sql\nSET hnsw.iterative_scan = strict_order;\n```\n\nRelaxed allows results to be slightly out of order by distance, but provides better recall\n\n```sql\nSET hnsw.iterative_scan = relaxed_order;\n# or\nSET ivfflat.iterative_scan = relaxed_order;\n```\n\nWith relaxed ordering, you can use a [materialized CTE](https://www.postgresql.org/docs/current/queries-with.html#QUERIES-WITH-CTE-MATERIALIZATION) to get strict ordering\n\n```sql\nWITH relaxed_results AS MATERIALIZED (\n    SELECT id, embedding <-> '[1,2,3]' AS distance FROM items WHERE category_id = 123 ORDER BY distance LIMIT 5\n) SELECT * FROM relaxed_results ORDER BY distance + 0;\n```\n\nNote: `+ 0` is needed for Postgres 17+\n\nFor queries that filter by distance, use a materialized CTE and place the distance filter outside of it for best performance (due to the [current behavior](https://www.postgresql.org/message-id/flat/CAOdR5yGUoMQ6j7M5hNUXrySzaqZVGf_Ne%2B8fwZMRKTFxU1nbJg%40mail.gmail.com) of the Postgres executor)\n\n```sql\nWITH nearest_results AS MATERIALIZED (\n    SELECT id, embedding <-> '[1,2,3]' AS distance FROM items ORDER BY distance LIMIT 5\n) SELECT * FROM nearest_results WHERE distance < 5 ORDER BY distance;\n```\n\nNote: Place any other filters inside the CTE\n\n### Iterative Scan Options\n\nSince scanning a large portion of an approximate index is expensive, there are options to control when a scan ends.\n\n#### HNSW\n\nSpecify the max number of tuples to visit (20,000 by default)\n\n```sql\nSET hnsw.max_scan_tuples = 20000;\n```\n\nNote: This is approximate and does not affect the initial scan\n\nSpecify the max amount of memory to use, as a multiple of `work_mem` (1 by default)\n\n```sql\nSET hnsw.scan_mem_multiplier = 2;\n```\n\nNote: Try increasing this if increasing `hnsw.max_scan_tuples` does not improve recall\n\n#### IVFFlat\n\nSpecify the max number of probes\n\n```sql\nSET ivfflat.max_probes = 100;\n```\n\nNote: If this is lower than `ivfflat.probes`, `ivfflat.probes` will be used\n\n## Half-Precision Vectors\n\nUse the `halfvec` type to store half-precision vectors\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding halfvec(3));\n```\n\n## Half-Precision Indexing\n\nIndex vectors at half precision for smaller indexes\n\n```sql\nCREATE INDEX ON items USING hnsw ((embedding::halfvec(3)) halfvec_l2_ops);\n```\n\nGet the nearest neighbors\n\n```sql\nSELECT * FROM items ORDER BY embedding::halfvec(3) <-> '[1,2,3]' LIMIT 5;\n```\n\n## Binary Vectors\n\nUse the `bit` type to store binary vectors ([example](https://github.com/pgvector/pgvector-python/blob/master/examples/imagehash/example.py))\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding bit(3));\nINSERT INTO items (embedding) VALUES ('000'), ('111');\n```\n\nGet the nearest neighbors by Hamming distance\n\n```sql\nSELECT * FROM items ORDER BY embedding <~> '101' LIMIT 5;\n```\n\nAlso supports Jaccard distance (`<%>`)\n\n## Binary Quantization\n\nUse expression indexing for binary quantization\n\n```sql\nCREATE INDEX ON items USING hnsw ((binary_quantize(embedding)::bit(3)) bit_hamming_ops);\n```\n\nGet the nearest neighbors by Hamming distance\n\n```sql\nSELECT * FROM items ORDER BY binary_quantize(embedding)::bit(3) <~> binary_quantize('[1,-2,3]') LIMIT 5;\n```\n\nRe-rank by the original vectors for better recall\n\n```sql\nSELECT * FROM (\n    SELECT * FROM items ORDER BY binary_quantize(embedding)::bit(3) <~> binary_quantize('[1,-2,3]') LIMIT 20\n) ORDER BY embedding <=> '[1,-2,3]' LIMIT 5;\n```\n\n## Sparse Vectors\n\nUse the `sparsevec` type to store sparse vectors\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding sparsevec(5));\n```\n\nInsert vectors\n\n```sql\nINSERT INTO items (embedding) VALUES ('{1:1,3:2,5:3}/5'), ('{1:4,3:5,5:6}/5');\n```\n\nThe format is `{index1:value1,index2:value2}/dimensions` and indices start at 1 like SQL arrays\n\nGet the nearest neighbors by L2 distance\n\n```sql\nSELECT * FROM items ORDER BY embedding <-> '{1:3,3:1,5:2}/5' LIMIT 5;\n```\n\n## Hybrid Search\n\nUse together with Postgres [full-text search](https://www.postgresql.org/docs/current/textsearch-intro.html) for hybrid search.\n\n```sql\nSELECT id, content FROM items, plainto_tsquery('hello search') query\n    WHERE textsearch @@ query ORDER BY ts_rank_cd(textsearch, query) DESC LIMIT 5;\n```\n\nYou can use [Reciprocal Rank Fusion](https://github.com/pgvector/pgvector-python/blob/master/examples/hybrid_search/rrf.py) or a [cross-encoder](https://github.com/pgvector/pgvector-python/blob/master/examples/hybrid_search/cross_encoder.py) to combine results.\n\n## Indexing Subvectors\n\nUse expression indexing to index subvectors\n\n```sql\nCREATE INDEX ON items USING hnsw ((subvector(embedding, 1, 3)::vector(3)) vector_cosine_ops);\n```\n\nGet the nearest neighbors by cosine distance\n\n```sql\nSELECT * FROM items ORDER BY subvector(embedding, 1, 3)::vector(3) <=> subvector('[1,2,3,4,5]'::vector, 1, 3) LIMIT 5;\n```\n\nRe-rank by the full vectors for better recall\n\n```sql\nSELECT * FROM (\n    SELECT * FROM items ORDER BY subvector(embedding, 1, 3)::vector(3) <=> subvector('[1,2,3,4,5]'::vector, 1, 3) LIMIT 20\n) ORDER BY embedding <=> '[1,2,3,4,5]' LIMIT 5;\n```\n\n## Performance\n\n### Tuning\n\nUse a tool like [PgTune](https://pgtune.leopard.in.ua/) to set initial values for Postgres server parameters. For instance, `shared_buffers` should typically be 25% of the serverâ€™s memory. You can find the config file with:\n\n```sql\nSHOW config_file;\n```\n\nAnd check individual settings with:\n\n```sql\nSHOW shared_buffers;\n```\n\nBe sure to restart Postgres for changes to take effect.\n\n### Loading\n\nUse `COPY` for bulk loading data ([example](https://github.com/pgvector/pgvector-python/blob/master/examples/loading/example.py)).\n\n```sql\nCOPY items (embedding) FROM STDIN WITH (FORMAT BINARY);\n```\n\nAdd any indexes *after* loading the initial data for best performance.\n\n### Indexing\n\nSee index build time for [HNSW](#index-build-time) and [IVFFlat](#index-build-time-1).\n\nIn production environments, create indexes concurrently to avoid blocking writes.\n\n```sql\nCREATE INDEX CONCURRENTLY ...\n```\n\n### Querying\n\nUse `EXPLAIN (ANALYZE, BUFFERS)` to debug performance.\n\n```sql\nEXPLAIN (ANALYZE, BUFFERS) SELECT * FROM items ORDER BY embedding <-> '[3,1,2]' LIMIT 5;\n```\n\n#### Exact Search\n\nTo speed up queries without an index, increase `max_parallel_workers_per_gather`.\n\n```sql\nSET max_parallel_workers_per_gather = 4;\n```\n\nIf vectors are normalized to length 1 (like [OpenAI embeddings](https://platform.openai.com/docs/guides/embeddings/which-distance-function-should-i-use)), use inner product for best performance.\n\n```tsql\nSELECT * FROM items ORDER BY embedding <#> '[3,1,2]' LIMIT 5;\n```\n\n#### Approximate Search\n\nTo speed up queries with an IVFFlat index, increase the number of inverted lists (at the expense of recall).\n\n```sql\nCREATE INDEX ON items USING ivfflat (embedding vector_l2_ops) WITH (lists = 1000);\n```\n\n### Vacuuming\n\nVacuuming can take a while for HNSW indexes. Speed it up by reindexing first.\n\n```sql\nREINDEX INDEX CONCURRENTLY index_name;\nVACUUM table_name;\n```\n\n## Monitoring\n\nMonitor performance with [pg_stat_statements](https://www.postgresql.org/docs/current/pgstatstatements.html) (be sure to add it to `shared_preload_libraries`).\n\n```sql\nCREATE EXTENSION pg_stat_statements;\n```\n\nGet the most time-consuming queries with:\n\n```sql\nSELECT query, calls, ROUND((total_plan_time + total_exec_time) / calls) AS avg_time_ms,\n    ROUND((total_plan_time + total_exec_time) / 60000) AS total_time_min\n    FROM pg_stat_statements ORDER BY total_plan_time + total_exec_time DESC LIMIT 20;\n```\n\nMonitor recall by comparing results from approximate search with exact search.\n\n```sql\nBEGIN;\nSET LOCAL enable_indexscan = off; -- use exact search\nSELECT ...\nCOMMIT;\n```\n\n## Scaling\n\nScale pgvector the same way you scale Postgres.\n\nScale vertically by increasing memory, CPU, and storage on a single instance. Use existing tools to [tune parameters](#tuning) and [monitor performance](#monitoring).\n\nScale horizontally with [replicas](https://www.postgresql.org/docs/current/hot-standby.html), or use [Citus](https://github.com/citusdata/citus) or another approach for sharding ([example](https://github.com/pgvector/pgvector-python/blob/master/examples/citus/example.py)).\n\n## Languages\n\nUse pgvector from any language with a Postgres client. You can even generate and store vectors in one language and query them in another.\n\nLanguage | Libraries / Examples\n--- | ---\nAda | [pgvector-ada](https://github.com/pgvector/pgvector-ada)\nAlgol | [pgvector-algol](https://github.com/pgvector/pgvector-algol)\nC | [pgvector-c](https://github.com/pgvector/pgvector-c)\nC++ | [pgvector-cpp](https://github.com/pgvector/pgvector-cpp)\nC#, F#, Visual Basic | [pgvector-dotnet](https://github.com/pgvector/pgvector-dotnet)\nCOBOL | [pgvector-cobol](https://github.com/pgvector/pgvector-cobol)\nCrystal | [pgvector-crystal](https://github.com/pgvector/pgvector-crystal)\nD | [pgvector-d](https://github.com/pgvector/pgvector-d)\nDart | [pgvector-dart](https://github.com/pgvector/pgvector-dart)\nElixir | [pgvector-elixir](https://github.com/pgvector/pgvector-elixir)\nErlang | [pgvector-erlang](https://github.com/pgvector/pgvector-erlang)\nFortran | [pgvector-fortran](https://github.com/pgvector/pgvector-fortran)\nGleam | [pgvector-gleam](https://github.com/pgvector/pgvector-gleam)\nGo | [pgvector-go](https://github.com/pgvector/pgvector-go)\nHaskell | [pgvector-haskell](https://github.com/pgvector/pgvector-haskell)\nJava, Kotlin, Groovy, Scala | [pgvector-java](https://github.com/pgvector/pgvector-java)\nJavaScript, TypeScript | [pgvector-node](https://github.com/pgvector/pgvector-node)\nJulia | [Pgvector.jl](https://github.com/pgvector/Pgvector.jl)\nLisp | [pgvector-lisp](https://github.com/pgvector/pgvector-lisp)\nLua | [pgvector-lua](https://github.com/pgvector/pgvector-lua)\nNim | [pgvector-nim](https://github.com/pgvector/pgvector-nim)\nOCaml | [pgvector-ocaml](https://github.com/pgvector/pgvector-ocaml)\nPascal | [pgvector-pascal](https://github.com/pgvector/pgvector-pascal)\nPerl | [pgvector-perl](https://github.com/pgvector/pgvector-perl)\nPHP | [pgvector-php](https://github.com/pgvector/pgvector-php)\nProlog | [pgvector-prolog](https://github.com/pgvector/pgvector-prolog)\nPython | [pgvector-python](https://github.com/pgvector/pgvector-python)\nR | [pgvector-r](https://github.com/pgvector/pgvector-r)\nRacket | [pgvector-racket](https://github.com/pgvector/pgvector-racket)\nRaku | [pgvector-raku](https://github.com/pgvector/pgvector-raku)\nRuby | [pgvector-ruby](https://github.com/pgvector/pgvector-ruby), [Neighbor](https://github.com/ankane/neighbor)\nRust | [pgvector-rust](https://github.com/pgvector/pgvector-rust)\nSwift | [pgvector-swift](https://github.com/pgvector/pgvector-swift)\nTcl | [pgvector-tcl](https://github.com/pgvector/pgvector-tcl)\nZig | [pgvector-zig](https://github.com/pgvector/pgvector-zig)\n\n## Frequently Asked Questions\n\n#### How many vectors can be stored in a single table?\n\nA non-partitioned table has a limit of 32 TB by default in Postgres. A partitioned table can have thousands of partitions of that size.\n\n#### Is replication supported?\n\nYes, pgvector uses the write-ahead log (WAL), which allows for replication and point-in-time recovery.\n\n#### What if I want to index vectors with more than 2,000 dimensions?\n\nYou can use [half-precision vectors](#half-precision-vectors) or [half-precision indexing](#half-precision-indexing) to index up to 4,000 dimensions or [binary quantization](#binary-quantization) to index up to 64,000 dimensions. Other options are [indexing subvectors](#indexing-subvectors) (for models that support it) or [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction).\n\n#### Can I store vectors with different dimensions in the same column?\n\nYou can use `vector` as the type (instead of `vector(n)`).\n\n```sql\nCREATE TABLE embeddings (model_id bigint, item_id bigint, embedding vector, PRIMARY KEY (model_id, item_id));\n```\n\nHowever, you can only create indexes on rows with the same number of dimensions (using [expression](https://www.postgresql.org/docs/current/indexes-expressional.html) and [partial](https://www.postgresql.org/docs/current/indexes-partial.html) indexing):\n\n```sql\nCREATE INDEX ON embeddings USING hnsw ((embedding::vector(3)) vector_l2_ops) WHERE (model_id = 123);\n```\n\nand query with:\n\n```sql\nSELECT * FROM embeddings WHERE model_id = 123 ORDER BY embedding::vector(3) <-> '[3,1,2]' LIMIT 5;\n```\n\n#### Can I store vectors with more precision?\n\nYou can use the `double precision[]` or `numeric[]` type to store vectors with more precision.\n\n```sql\nCREATE TABLE items (id bigserial PRIMARY KEY, embedding double precision[]);\n\n-- use {} instead of [] for Postgres arrays\nINSERT INTO items (embedding) VALUES ('{1,2,3}'), ('{4,5,6}');\n```\n\nOptionally, add a [check constraint](https://www.postgresql.org/docs/current/ddl-constraints.html) to ensure data can be converted to the `vector` type and has the expected dimensions.\n\n```sql\nALTER TABLE items ADD CHECK (vector_dims(embedding::vector) = 3);\n```\n\nUse [expression indexing](https://www.postgresql.org/docs/current/indexes-expressional.html) to index (at a lower precision):\n\n```sql\nCREATE INDEX ON items USING hnsw ((embedding::vector(3)) vector_l2_ops);\n```\n\nand query with:\n\n```sql\nSELECT * FROM items ORDER BY embedding::vector(3) <-> '[3,1,2]' LIMIT 5;\n```\n\n#### Do indexes need to fit into memory?\n\nNo, but like other index types, youâ€™ll likely see better performance if they do. You can get the size of an index with:\n\n```sql\nSELECT pg_size_pretty(pg_relation_size('index_name'));\n```\n\n## Troubleshooting\n\n#### Why isnâ€™t a query using an index?\n\nThe query needs to have an `ORDER BY` and `LIMIT`, and the `ORDER BY` must be the result of a distance operator (not an expression) in ascending order.\n\n```sql\n-- index\nORDER BY embedding <=> '[3,1,2]' LIMIT 5;\n\n-- no index\nORDER BY 1 - (embedding <=> '[3,1,2]') DESC LIMIT 5;\n```\n\nYou can encourage the planner to use an index for a query with:\n\n```sql\nBEGIN;\nSET LOCAL enable_seqscan = off;\nSELECT ...\nCOMMIT;\n```\n\nAlso, if the table is small, a table scan may be faster.\n\n#### Why isnâ€™t a query using a parallel table scan?\n\nThe planner doesnâ€™t consider [out-of-line storage](https://www.postgresql.org/docs/current/storage-toast.html) in cost estimates, which can make a serial scan look cheaper. You can reduce the cost of a parallel scan for a query with:\n\n```sql\nBEGIN;\nSET LOCAL min_parallel_table_scan_size = 1;\nSET LOCAL parallel_setup_cost = 1;\nSELECT ...\nCOMMIT;\n```\n\nor choose to store vectors inline:\n\n```sql\nALTER TABLE items ALTER COLUMN embedding SET STORAGE PLAIN;\n```\n\n#### Why are there less results for a query after adding an HNSW index?\n\nResults are limited by the size of the dynamic candidate list (`hnsw.ef_search`), which is 40 by default. There may be even less results due to dead tuples or filtering conditions in the query. Enabling [iterative index scans](#iterative-index-scans) can help address this.\n\nAlso, note that `NULL` vectors are not indexed (as well as zero vectors for cosine distance).\n\n#### Why are there less results for a query after adding an IVFFlat index?\n\nThe index was likely created with too little data for the number of lists. Drop the index until the table has more data.\n\n```sql\nDROP INDEX index_name;\n```\n\nResults can also be limited by the number of probes (`ivfflat.probes`). Enabling [iterative index scans](#iterative-index-scans) can address this.\n\nAlso, note that `NULL` vectors are not indexed (as well as zero vectors for cosine distance).\n\n## Reference\n\n- [Vector](#vector-type)\n- [Halfvec](#halfvec-type)\n- [Bit](#bit-type)\n- [Sparsevec](#sparsevec-type)\n\n### Vector Type\n\nEach vector takes `4 * dimensions + 8` bytes of storage. Each element is a single-precision floating-point number (like the `real` type in Postgres), and all elements must be finite (no `NaN`, `Infinity` or `-Infinity`). Vectors can have up to 16,000 dimensions.\n\n### Vector Operators\n\nOperator | Description | Added\n--- | --- | ---\n\\+ | element-wise addition |\n\\- | element-wise subtraction |\n\\* | element-wise multiplication | 0.5.0\n\\|\\| | concatenate | 0.7.0\n<-> | Euclidean distance |\n<#> | negative inner product |\n<=> | cosine distance |\n<+> | taxicab distance | 0.7.0\n\n### Vector Functions\n\nFunction | Description | Added\n--- | --- | ---\nbinary_quantize(vector) â†’ bit | binary quantize | 0.7.0\ncosine_distance(vector, vector) â†’ double precision | cosine distance |\ninner_product(vector, vector) â†’ double precision | inner product |\nl1_distance(vector, vector) â†’ double precision | taxicab distance | 0.5.0\nl2_distance(vector, vector) â†’ double precision | Euclidean distance |\nl2_normalize(vector) â†’ vector | Normalize with Euclidean norm | 0.7.0\nsubvector(vector, integer, integer) â†’ vector | subvector | 0.7.0\nvector_dims(vector) â†’ integer | number of dimensions |\nvector_norm(vector) â†’ double precision | Euclidean norm |\n\n### Vector Aggregate Functions\n\nFunction | Description | Added\n--- | --- | ---\navg(vector) â†’ vector | average |\nsum(vector) â†’ vector | sum | 0.5.0\n\n### Halfvec Type\n\nEach half vector takes `2 * dimensions + 8` bytes of storage. Each element is a half-precision floating-point number, and all elements must be finite (no `NaN`, `Infinity` or `-Infinity`). Half vectors can have up to 16,000 dimensions.\n\n### Halfvec Operators\n\nOperator | Description | Added\n--- | --- | ---\n\\+ | element-wise addition | 0.7.0\n\\- | element-wise subtraction | 0.7.0\n\\* | element-wise multiplication | 0.7.0\n\\|\\| | concatenate | 0.7.0\n<-> | Euclidean distance | 0.7.0\n<#> | negative inner product | 0.7.0\n<=> | cosine distance | 0.7.0\n<+> | taxicab distance | 0.7.0\n\n### Halfvec Functions\n\nFunction | Description | Added\n--- | --- | ---\nbinary_quantize(halfvec) â†’ bit | binary quantize | 0.7.0\ncosine_distance(halfvec, halfvec) â†’ double precision | cosine distance | 0.7.0\ninner_product(halfvec, halfvec) â†’ double precision | inner product | 0.7.0\nl1_distance(halfvec, halfvec) â†’ double precision | taxicab distance | 0.7.0\nl2_distance(halfvec, halfvec) â†’ double precision | Euclidean distance | 0.7.0\nl2_norm(halfvec) â†’ double precision | Euclidean norm | 0.7.0\nl2_normalize(halfvec) â†’ halfvec | Normalize with Euclidean norm | 0.7.0\nsubvector(halfvec, integer, integer) â†’ halfvec | subvector | 0.7.0\nvector_dims(halfvec) â†’ integer | number of dimensions | 0.7.0\n\n### Halfvec Aggregate Functions\n\nFunction | Description | Added\n--- | --- | ---\navg(halfvec) â†’ halfvec | average | 0.7.0\nsum(halfvec) â†’ halfvec | sum | 0.7.0\n\n### Bit Type\n\nEach bit vector takes `dimensions / 8 + 8` bytes of storage. See the [Postgres docs](https://www.postgresql.org/docs/current/datatype-bit.html) for more info.\n\n### Bit Operators\n\nOperator | Description | Added\n--- | --- | ---\n<~> | Hamming distance | 0.7.0\n<%> | Jaccard distance | 0.7.0\n\n### Bit Functions\n\nFunction | Description | Added\n--- | --- | ---\nhamming_distance(bit, bit) â†’ double precision | Hamming distance | 0.7.0\njaccard_distance(bit, bit) â†’ double precision | Jaccard distance | 0.7.0\n\n### Sparsevec Type\n\nEach sparse vector takes `8 * non-zero elements + 16` bytes of storage. Each element is a single-precision floating-point number, and all elements must be finite (no `NaN`, `Infinity` or `-Infinity`). Sparse vectors can have up to 16,000 non-zero elements.\n\n### Sparsevec Operators\n\nOperator | Description | Added\n--- | --- | ---\n<-> | Euclidean distance | 0.7.0\n<#> | negative inner product | 0.7.0\n<=> | cosine distance | 0.7.0\n<+> | taxicab distance | 0.7.0\n\n### Sparsevec Functions\n\nFunction | Description | Added\n--- | --- | ---\ncosine_distance(sparsevec, sparsevec) â†’ double precision | cosine distance | 0.7.0\ninner_product(sparsevec, sparsevec) â†’ double precision | inner product | 0.7.0\nl1_distance(sparsevec, sparsevec) â†’ double precision | taxicab distance | 0.7.0\nl2_distance(sparsevec, sparsevec) â†’ double precision | Euclidean distance | 0.7.0\nl2_norm(sparsevec) â†’ double precision | Euclidean norm | 0.7.0\nl2_normalize(sparsevec) â†’ sparsevec | Normalize with Euclidean norm | 0.7.0\n\n## Installation Notes - Linux and Mac\n\n### Postgres Location\n\nIf your machine has multiple Postgres installations, specify the path to [pg_config](https://www.postgresql.org/docs/current/app-pgconfig.html) with:\n\n```sh\nexport PG_CONFIG=/Library/PostgreSQL/18/bin/pg_config\n```\n\nThen re-run the installation instructions (run `make clean` before `make` if needed). If `sudo` is needed for `make install`, use:\n\n```sh\nsudo --preserve-env=PG_CONFIG make install\n```\n\nA few common paths on Mac are:\n\n- EDB installer - `/Library/PostgreSQL/18/bin/pg_config`\n- Homebrew (arm64) - `/opt/homebrew/opt/postgresql@18/bin/pg_config`\n- Homebrew (x86-64) - `/usr/local/opt/postgresql@18/bin/pg_config`\n\nNote: Replace `18` with your Postgres server version\n\n### Missing Header\n\nIf compilation fails with `fatal error: postgres.h: No such file or directory`, make sure Postgres development files are installed on the server.\n\nFor Ubuntu and Debian, use:\n\n```sh\nsudo apt install postgresql-server-dev-18\n```\n\nNote: Replace `18` with your Postgres server version\n\n### Missing SDK\n\nIf compilation fails and the output includes `warning: no such sysroot directory` on Mac, your Postgres installation points to a path that no longer exists.\n\n```sh\npg_config --cppflags\n```\n\nReinstall Postgres to fix this.\n\n### Portability\n\nBy default, pgvector compiles with `-march=native` on some platforms for best performance. However, this can lead to `Illegal instruction` errors if trying to run the compiled extension on a different machine.\n\nTo compile for portability, use:\n\n```sh\nmake OPTFLAGS=\"\"\n```\n\n## Installation Notes - Windows\n\n### Missing Header\n\nIf compilation fails with `Cannot open include file: 'postgres.h': No such file or directory`, make sure `PGROOT` is correct.\n\n### Mismatched Architecture\n\nIf compilation fails with `error C2196: case value '4' already used`, make sure youâ€™re using the `x64 Native Tools Command Prompt`. Then run `nmake /F Makefile.win clean` and re-run the installation instructions.\n\n### Missing Symbol\n\nIf linking fails with `unresolved external symbol float_to_shortest_decimal_bufn` with Postgres 17.0-17.2, upgrade to Postgres 17.3+.\n\n### Permissions\n\nIf installation fails with `Access is denied`, re-run the installation instructions as an administrator.\n\n## Additional Installation Methods\n\n### Docker\n\nGet the [Docker image](https://hub.docker.com/r/pgvector/pgvector) with:\n\n```sh\ndocker pull pgvector/pgvector:pg18-trixie\n```\n\nThis adds pgvector to the [Postgres image](https://hub.docker.com/_/postgres) (replace `18` with your Postgres server version, and run it the same way).\n\nSupported tags are:\n\n- `pg18-trixie`, `0.8.1-pg18-trixie`\n- `pg18-bookworm`, `0.8.1-pg18-bookworm`, `pg18`, `0.8.1-pg18`\n- `pg17-trixie`, `0.8.1-pg17-trixie`\n- `pg17-bookworm`, `0.8.1-pg17-bookworm`, `pg17`, `0.8.1-pg17`\n- `pg16-trixie`, `0.8.1-pg16-trixie`\n- `pg16-bookworm`, `0.8.1-pg16-bookworm`, `pg16`, `0.8.1-pg16`\n- `pg15-trixie`, `0.8.1-pg15-trixie`\n- `pg15-bookworm`, `0.8.1-pg15-bookworm`, `pg15`, `0.8.1-pg15`\n- `pg14-trixie`, `0.8.1-pg14-trixie`\n- `pg14-bookworm`, `0.8.1-pg14-bookworm`, `pg14`, `0.8.1-pg14`\n- `pg13-trixie`, `0.8.1-pg13-trixie`\n- `pg13-bookworm`, `0.8.1-pg13-bookworm`, `pg13`, `0.8.1-pg13`\n\nYou can also build the image manually:\n\n```sh\ngit clone --branch v0.8.1 https://github.com/pgvector/pgvector.git\ncd pgvector\ndocker build --pull --build-arg PG_MAJOR=18 -t myuser/pgvector .\n```\n\nIf you increase `maintenance_work_mem`, make sure `--shm-size` is at least that size to avoid an error with parallel HNSW index builds.\n\n```sh\ndocker run --shm-size=1g ...\n```\n\n### Homebrew\n\nWith Homebrew Postgres, you can use:\n\n```sh\nbrew install pgvector\n```\n\nNote: This only adds it to the `postgresql@18` and `postgresql@17` formulas\n\n### PGXN\n\nInstall from the [PostgreSQL Extension Network](https://pgxn.org/dist/vector) with:\n\n```sh\npgxn install vector\n```\n\n### APT\n\nDebian and Ubuntu packages are available from the [PostgreSQL APT Repository](https://wiki.postgresql.org/wiki/Apt). Follow the [setup instructions](https://wiki.postgresql.org/wiki/Apt#Quickstart) and run:\n\n```sh\nsudo apt install postgresql-18-pgvector\n```\n\nNote: Replace `18` with your Postgres server version\n\n### Yum\n\nRPM packages are available from the [PostgreSQL Yum Repository](https://yum.postgresql.org/). Follow the [setup instructions](https://www.postgresql.org/download/linux/redhat/) for your distribution and run:\n\n```sh\nsudo yum install pgvector_18\n# or\nsudo dnf install pgvector_18\n```\n\nNote: Replace `18` with your Postgres server version\n\n### pkg\n\nInstall the FreeBSD package with:\n\n```sh\npkg install postgresql17-pgvector\n```\n\nor the port with:\n\n```sh\ncd /usr/ports/databases/pgvector\nmake install\n```\n\n### APK\n\nInstall the Alpine package with:\n\n```sh\napk add postgresql-pgvector\n```\n\n### conda-forge\n\nWith Conda Postgres, install from [conda-forge](https://anaconda.org/conda-forge/pgvector) with:\n\n```sh\nconda install -c conda-forge pgvector\n```\n\nThis method is [community-maintained](https://github.com/conda-forge/pgvector-feedstock) by [@mmcauliffe](https://github.com/mmcauliffe)\n\n### Postgres.app\n\nDownload the [latest release](https://postgresapp.com/downloads.html) with Postgres 15+.\n\n## Hosted Postgres\n\npgvector is available on [these providers](https://github.com/pgvector/pgvector/issues/54).\n\n## Upgrading\n\n[Install](#installation) the latest version (use the same method as the original installation). Then in each database you want to upgrade, run:\n\n```sql\nALTER EXTENSION vector UPDATE;\n```\n\nYou can check the version in the current database with:\n\n```sql\nSELECT extversion FROM pg_extension WHERE extname = 'vector';\n```\n\n## Thanks\n\nThanks to:\n\n- [PASE: PostgreSQL Ultra-High-Dimensional Approximate Nearest Neighbor Search Extension](https://dl.acm.org/doi/pdf/10.1145/3318464.3386131)\n- [Faiss: A Library for Efficient Similarity Search and Clustering of Dense Vectors](https://github.com/facebookresearch/faiss)\n- [Using the Triangle Inequality to Accelerate k-means](https://cdn.aaai.org/ICML/2003/ICML03-022.pdf)\n- [k-means++: The Advantage of Careful Seeding](https://theory.stanford.edu/~sergei/papers/kMeansPP-soda.pdf)\n- [Concept Decompositions for Large Sparse Text Data using Clustering](https://www.cs.utexas.edu/users/inderjit/public_papers/concept_mlj.pdf)\n- [Efficient and Robust Approximate Nearest Neighbor Search using Hierarchical Navigable Small World Graphs](https://arxiv.org/ftp/arxiv/papers/1603/1603.09320.pdf)\n\n## History\n\nView the [changelog](https://github.com/pgvector/pgvector/blob/master/CHANGELOG.md)\n\n## Contributing\n\nEveryone is encouraged to help improve this project. Here are a few ways you can help:\n\n- [Report bugs](https://github.com/pgvector/pgvector/issues)\n- Fix bugs and [submit pull requests](https://github.com/pgvector/pgvector/pulls)\n- Write, clarify, or fix documentation\n- Suggest or add new features\n\nTo get started with development:\n\n```sh\ngit clone https://github.com/pgvector/pgvector.git\ncd pgvector\nmake\nmake install\n```\n\nTo run all tests:\n\n```sh\nmake installcheck        # regression tests\nmake prove_installcheck  # TAP tests\n```\n\nTo run single tests:\n\n```sh\nmake installcheck REGRESS=functions                            # regression test\nmake prove_installcheck PROVE_TESTS=test/t/001_ivfflat_wal.pl  # TAP test\n```\n\nTo enable assertions:\n\n```sh\nmake clean && PG_CFLAGS=\"-DUSE_ASSERT_CHECKING\" make && make install\n```\n\nTo enable benchmarking:\n\n```sh\nmake clean && PG_CFLAGS=\"-DIVFFLAT_BENCH\" make && make install\n```\n\nTo show memory usage:\n\n```sh\nmake clean && PG_CFLAGS=\"-DHNSW_MEMORY -DIVFFLAT_MEMORY\" make && make install\n```\n\nTo get k-means metrics:\n\n```sh\nmake clean && PG_CFLAGS=\"-DIVFFLAT_KMEANS_DEBUG\" make && make install\n```\n\nResources for contributors\n\n- [Extension Building Infrastructure](https://www.postgresql.org/docs/current/extend-pgxs.html)\n- [Index Access Method Interface Definition](https://www.postgresql.org/docs/current/indexam.html)\n- [Generic WAL Records](https://www.postgresql.org/docs/current/generic-wal.html)\n",
      "stars_today": 15
    },
    {
      "id": 24997096,
      "name": "luci",
      "full_name": "openwrt/luci",
      "description": "LuCI - OpenWrt Configuration Interface",
      "html_url": "https://github.com/openwrt/luci",
      "stars": 7404,
      "forks": 2766,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2014-10-09T16:02:20Z",
      "updated_at": "2026-01-24T23:56:32Z",
      "pushed_at": "2026-01-24T14:39:48Z",
      "open_issues": 305,
      "owner": {
        "login": "openwrt",
        "avatar_url": "https://avatars.githubusercontent.com/u/2528830?v=4"
      },
      "readme": "# OpenWrt luci feed\n\n[![Translation status](https://hosted.weblate.org/widgets/openwrt/-/svg-badge.svg)](https://hosted.weblate.org/engage/openwrt/?utm_source=widget)\n\n## Description\n\nThis is the OpenWrt \"luci\"-feed containing LuCI - OpenWrt Configuration Interface.\n\n## Usage\n\nThis feed is enabled by default. Your feeds.conf.default (or feeds.conf) should contain a line like:\n```\nsrc-git luci https://github.com/openwrt/luci.git\n```\n\nTo install all its package definitions, run:\n```\n./scripts/feeds update luci\n./scripts/feeds install -a -p luci\n```\n\n## API Reference\n\nYou can browse the generated API documentation directly on Github.\n\n - [Server side Lua APIs](http://openwrt.github.io/luci/api/index.html); Note: deprecated - Lua will be removed in future. Use ucode rpcd for server side operations.\n - [Client side JavaScript APIs](http://openwrt.github.io/luci/jsapi/index.html)\n\n## Development\n\nDocumentation for developing and extending LuCI can be found [in the Wiki](https://github.com/openwrt/luci/wiki)\n\n## License\n\nSee [LICENSE](LICENSE) file.\n \n## Package Guidelines\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) file.\n\n## Translation status\n\nUse [Weblate](https://hosted.weblate.org/engage/openwrt/?utm_source=widget) instead of direct editing of the `*.po` files.\n\n[![Translation status](https://hosted.weblate.org/widgets/openwrt/-/multi-auto.svg)](https://hosted.weblate.org/engage/openwrt/?utm_source=widget)\n",
      "stars_today": 15
    },
    {
      "id": 323673130,
      "name": "TwitchAdSolutions",
      "full_name": "pixeltris/TwitchAdSolutions",
      "description": null,
      "html_url": "https://github.com/pixeltris/TwitchAdSolutions",
      "stars": 10748,
      "forks": 571,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2020-12-22T16:08:18Z",
      "updated_at": "2026-01-25T01:59:21Z",
      "pushed_at": "2025-12-24T11:33:41Z",
      "open_issues": 8,
      "owner": {
        "login": "pixeltris",
        "avatar_url": "https://avatars.githubusercontent.com/u/6952411?v=4"
      },
      "readme": "# TwitchAdSolutions\n\nThis repo aims to provide multiple solutions for blocking Twitch ads.\n\n**Don't combine Twitch specific ad blockers.**\n\n## Recommendations\n\nProxies are the most reliable way of avoiding ads ([buffering / downtime info](full-list.md#proxy-issues)).\n\n- `TTV LOL PRO` - [chrome](https://chrome.google.com/webstore/detail/ttv-lol-pro/bpaoeijjlplfjbagceilcgbkcdjbomjd) / [firefox](https://addons.mozilla.org/addon/ttv-lol-pro/) / [code](https://github.com/younesaassila/ttv-lol-pro)\n\nAlternatively:\n\n- `Twitch Turbo` - https://www.twitch.tv/turbo\n- `Alternate Player for Twitch.tv` - [chrome](https://chrome.google.com/webstore/detail/alternate-player-for-twit/bhplkbgoehhhddaoolmakpocnenplmhf) / [firefox](https://addons.mozilla.org/en-US/firefox/addon/twitch_5/)\n- `Purple AdBlock` - [chrome](https://chrome.google.com/webstore/detail/purple-adblock/lkgcfobnmghhbhgekffaadadhmeoindg) / [firefox](https://addons.mozilla.org/en-US/firefox/addon/purpleadblock/) / [userscript](https://raw.githubusercontent.com/arthurbolsoni/Purple-adblock/refs/heads/main/platform/tampermonkey/dist/purpleadblocker.user.js) / [code](https://github.com/arthurbolsoni/Purple-adblock/)\n- `AdGuard Extra` - [chrome](https://chrome.google.com/webstore/detail/adguard-extra-beta/mglpocjcjbekdckiahfhagndealpkpbj) / [firefox](https://github.com/AdguardTeam/AdGuardExtra/#firefox) / [userscript](https://userscripts.adtidy.org/release/adguard-extra/1.0/adguard-extra.user.js)\n- `vaft` - see below\n\n[Read this for a full list and descriptions.](full-list.md)\n\n[Also see this list maintained by @zGato.](https://github.com/zGato/ScrewTwitchAds)\n\n## Scripts\n\n**There are better / easier to use methods in the above recommendations.**\n\n- vaft - [userscript](https://github.com/pixeltris/TwitchAdSolutions/raw/master/vaft/vaft.user.js) / [ublock](https://raw.githubusercontent.com/pixeltris/TwitchAdSolutions/master/vaft/vaft-ublock-origin.js) / [ublock (permalink)](https://raw.githubusercontent.com/pixeltris/TwitchAdSolutions/914f4ec6bd56b71e75b5da2d70646c825475c3bb/vaft/vaft-ublock-origin.js)\n  - Attempts to get a clean stream as fast as it can\n  - If it fails to get a clean stream it removes ad segments (no playback until ad-free stream is found)\n- video-swap-new - [userscript](https://github.com/pixeltris/TwitchAdSolutions/raw/master/video-swap-new/video-swap-new.user.js) / [ublock](https://raw.githubusercontent.com/pixeltris/TwitchAdSolutions/master/video-swap-new/video-swap-new-ublock-origin.js) / [ublock (permalink)](https://raw.githubusercontent.com/pixeltris/TwitchAdSolutions/914f4ec6bd56b71e75b5da2d70646c825475c3bb/video-swap-new/video-swap-new-ublock-origin.js)\n  - Attempts to get a clean stream\n  - If it fails to get a clean stream it removes ad segments (no playback until ad-free stream is found)\n  - Not recommended, `vaft` is a better script\n\n## Applying a script (uBlock Origin)\n\n- Navigate to the uBlock Origin Dashboard (the extension options)\n- Under the `My filters` tab add `twitch.tv##+js(twitch-videoad)`.\n- Under the `Settings` tab, enable `I am an advanced user`, then click the cog that appears. Modify the value of `userResourcesLocation` from `unset` to the full url of the solution you wish to use (if a url is already in use, add a space after the existing url). e.g. `userResourcesLocation https://raw.githubusercontent.com/pixeltris/TwitchAdSolutions/master/vaft/vaft-ublock-origin.js` \n- To ensure uBlock Origin loads the script I recommend that you disable/enable the uBlock Origin extension (or restart your browser).\n\nTo stop using a script remove the filter and make the url `unset`.\n\n*For the sake of security it's recommended to use a permalink when using uBlock Origin (permalinks do not auto update).*\n\n*The scripts __may randomly stop being applied by uBlock Origin__ for unknown reasons ([#200](https://github.com/pixeltris/TwitchAdSolutions/issues/200)). It's recommended to use the userscript versions instead.*\n\n## Applying a script (userscript)\n\nViewing one of the userscript files should prompt the given script to be added when you have a userscript manager installed.\n\nUserscript managers:\n\n- https://violentmonkey.github.io/\n- https://www.tampermonkey.net/\n- https://apps.apple.com/us/app/userscripts/id1463298887\n\n## Issues with the scripts\n\nIf the script doesn't work or you're experiencing freezing / buffering issues see [issues.md](issues.md)",
      "stars_today": 15
    },
    {
      "id": 764020969,
      "name": "vortex",
      "full_name": "vortex-data/vortex",
      "description": "An extensible, state of the art columnar file format. Formerly at @spiraldb, now an Incubation Stage project at LFAI&Data, part of the Linux Foundation.",
      "html_url": "https://github.com/vortex-data/vortex",
      "stars": 2540,
      "forks": 121,
      "language": "Rust",
      "topics": [
        "array",
        "arrow",
        "compression",
        "file",
        "multimodal",
        "python",
        "rust"
      ],
      "created_at": "2024-02-27T10:40:00Z",
      "updated_at": "2026-01-25T02:06:46Z",
      "pushed_at": "2026-01-25T00:50:11Z",
      "open_issues": 256,
      "owner": {
        "login": "vortex-data",
        "avatar_url": "https://avatars.githubusercontent.com/u/182635364?v=4"
      },
      "readme": "# ğŸŒªï¸ Vortex\n\n[![Build Status](https://github.com/vortex-data/vortex/actions/workflows/ci.yml/badge.svg)](https://github.com/vortex-data/vortex/actions)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10567/badge)](https://www.bestpractices.dev/projects/10567)\n[![Documentation](https://docs.rs/vortex/badge.svg)](https://docs.vortex.dev)\n[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/vortex-data/vortex)\n[![Crates.io](https://img.shields.io/crates/v/vortex.svg)](https://crates.io/crates/vortex)\n[![PyPI - Version](https://img.shields.io/pypi/v/vortex-data)](https://pypi.org/project/vortex-data/)\n[![Maven - Version](https://img.shields.io/maven-central/v/dev.vortex/vortex-spark)](https://central.sonatype.com/artifact/dev.vortex/vortex-spark)\n[![codecov](https://codecov.io/github/vortex-data/vortex/graph/badge.svg)](https://codecov.io/github/vortex-data/vortex)\n\n[Join the community on Slack!](https://vortex.dev/slack) | [Documentation](https://docs.vortex.dev/) | [Performance Benchmarks](https://bench.vortex.dev)\n\n## Overview\n\nVortex is a next-generation columnar file format and toolkit designed for high-performance data processing.\nIt is the fastest and most extensible format for building data systems backed by object storage. It provides:\n\n- **Blazing Fast Performance**\n  - 100x faster random access reads (vs. modern Apache Parquet)\n  - 10-20x faster scans\n  - 5x faster writes\n  - Similar compression ratios\n  - Efficient support for wide tables with zero-copy/zero-parse metadata\n\n- **Extensible Architecture**\n  - Modeled after Apache DataFusion's extensible approach\n  - Pluggable encoding system, type system, compression strategy, & layout strategy\n  - Zero-copy compatibility with Apache Arrow\n\n- **Open Source, Neutral Governance**\n  - A Linux Foundation (LF AI & Data) Project\n  - Apache-2.0 Licensed\n\n- **Integrations**\n  - Arrow, DataFusion, DuckDB, Spark, Pandas, Polars, & more\n  - Apache Iceberg (coming soon)\n\n> ğŸŸ¢ **Development Status**: Library APIs may change from version to version, but we now consider\n> the file format <ins>_stable_</ins>. From release 0.36.0, all future releases of Vortex should\n> maintain backwards compatibility of the file format (i.e., be able to read files written by\n> any earlier version >= 0.36.0).\n\n## Key Features\n\n### Core Capabilities\n\n- **Logical Types** - Clean separation between logical schema and physical layout\n- **Zero-Copy Arrow Integration** - Seamless conversion to/from Apache Arrow arrays\n- **Extensible Encodings** - Pluggable physical layouts with built-in optimizations\n- **Cascading Compression** - Support for nested encoding schemes\n- **High-Performance Computing** - Optimized compute kernels for encoded data\n- **Rich Statistics** - Lazy-loaded summary statistics for optimization\n\n### Technical Architecture\n\n#### Logical vs Physical Design\n\nVortex strictly separates logical and physical concerns:\n\n- **Logical Layer**: Defines data types and schema\n- **Physical Layer**: Handles encoding and storage implementation\n- **Built-in Encodings**: Compatible with Apache Arrow's memory format\n- **Extension Encodings**: Optimized compression schemes (RLE, dictionary, etc.)\n\n## Quick Start\n\n### Installation\n\n#### Rust Crate\n\nAll features are exported through the main `vortex` crate.\n\n```bash\ncargo add vortex\n```\n\n#### Python Package\n\n```bash\nuv add vortex-data\n```\n\n#### Command Line UI (vx)\n\nFor browsing the structure of Vortex files, you can use the `vx` command-line tool.\n\n```bash\n# Install latest release\ncargo install vortex-tui --locked\n\n# Or build from source\ncargo install --path vortex-tui --locked\n\n# Usage\nvx browse <file>\n```\n\n### Development Setup\n\n#### Prerequisites (macOS)\n\n```bash\n# Optional but recommended dependencies\nbrew install flatbuffers protobuf  # For .fbs and .proto files\nbrew install duckdb               # For benchmarks\n\n# Install Rust toolchain\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n# or\nbrew install rustup\n\n# Initialize submodules\ngit submodule update --init --recursive\n\n# Setup dependencies with uv\nuv sync --all-packages\n```\n\n### Benchmarking\n\nUse `vx-bench` to run benchmarks comparing engines (DataFusion, DuckDB) and formats (Parquet, Vortex):\n\n```bash\n# Install the benchmark orchestrator\nuv tool install \"bench_orchestrator @ ./bench-orchestrator/\"\n\n# Run TPC-H benchmarks\nvx-bench run tpch --engine datafusion,duckdb --format parquet,vortex\n\n# Compare results\nvx-bench compare --run latest\n```\n\nSee [bench-orchestrator/README.md](bench-orchestrator/README.md) for full documentation.\n\n### Performance Optimization\n\nFor optimal performance, we suggest using [MiMalloc](https://github.com/microsoft/mimalloc):\n\n```rust,ignore\n#[global_allocator]\nstatic GLOBAL_ALLOC: MiMalloc = MiMalloc;\n```\n\n## Project Information\n\n### License\n\nLicensed under the Apache License, Version 2.0.\n\n### Governance\n\nVortex is an independent open-source project and not controlled by any single company. The Vortex Project is a\nsub-project of the Linux Foundation Projects. The governance model is documented in\n[CONTRIBUTING.md](CONTRIBUTING.md) and is subject to the terms of\nthe [Technical Charter](https://vortex.dev/charter.pdf).\n\n### Contributing\n\nPlease **do** read [CONTRIBUTING.md](CONTRIBUTING.md) before you contribute.\n\n### Reporting Vulnerabilities\n\nIf you discover a security vulnerability, please email <vuln-report@vortex.dev>.\n\n### Trademarks\n\nCopyright Â© Vortex a Series of LF Projects, LLC.\nFor terms of use, trademark policy, and other project policies please see <https://lfprojects.org>\n\n## Acknowledgments\n\nThe Vortex project benefits enormously from groundbreaking work from the academic & open-source communities.\n\n### Research in Vortex\n\n- [BtrBlocks](https://www.cs.cit.tum.de/fileadmin/w00cfj/dis/papers/btrblocks.pdf) - Efficient columnar compression\n- [FastLanes](https://www.vldb.org/pvldb/vol16/p2132-afroozeh.pdf) & [FastLanes on GPU](https://dbdbd2023.ugent.be/abstracts/felius_fastlanes.pdf) - High-performance integer compression\n- [FSST](https://www.vldb.org/pvldb/vol13/p2649-boncz.pdf) - Fast random access string compression\n- [ALP](https://ir.cwi.nl/pub/33334/33334.pdf) & [G-ALP](https://dl.acm.org/doi/pdf/10.1145/3736227.3736242) - Adaptive lossless floating-point compression\n- [Procella](https://dl.acm.org/citation.cfm?id=3360438) - YouTube's unified data system\n- [Anyblob](https://www.durner.dev/app/media/papers/anyblob-vldb23.pdf) - High-performance access to object storage\n- [ClickHouse](https://www.vldb.org/pvldb/vol17/p3731-schulze.pdf) - Fast analytics for everyone\n- [MonetDB/X100](https://www.cidrdb.org/cidr2005/papers/P19.pdf) - Hyper-Pipelining Query Execution\n- [Morsel-Driven Parallelism](https://db.in.tum.de/~leis/papers/morsels.pdf): A NUMA-Aware Query Evaluation Format for the Many-Core Age\n- [The FastLanes File Format](https://github.com/cwida/FastLanes/blob/dev/docs/specification.pdf) - Expression Operators\n\n### Vortex in Research\n\n- [Anyblox](https://gienieczko.com/anyblox-paper) - A Framework for Self-Decoding Datasets\n- [F3](https://dl.acm.org/doi/pdf/10.1145/3749163) - Open-Source Data File Format for the Future\n\n### Open Source Inspiration\n\n- [Apache Arrow](https://arrow.apache.org)\n- [Apache DataFusion](https://github.com/apache/datafusion)\n- [parquet2](https://github.com/jorgecarleitao/parquet2) by Jorge Leitao\n- [DuckDB](https://github.com/duckdb/duckdb)\n- [Velox](https://github.com/facebookincubator/velox) & [Nimble](https://github.com/facebookincubator/nimble)\n\n#### Thanks to all contributors who have shared their knowledge and code with the community! ğŸš€\n",
      "stars_today": 15
    },
    {
      "id": 1036150999,
      "name": "CCometixLine",
      "full_name": "Haleclipse/CCometixLine",
      "description": "Claude Code statusline tool written in Rust",
      "html_url": "https://github.com/Haleclipse/CCometixLine",
      "stars": 1521,
      "forks": 92,
      "language": "Rust",
      "topics": [],
      "created_at": "2025-08-11T16:22:53Z",
      "updated_at": "2026-01-25T00:08:33Z",
      "pushed_at": "2026-01-23T21:05:12Z",
      "open_issues": 19,
      "owner": {
        "login": "Haleclipse",
        "avatar_url": "https://avatars.githubusercontent.com/u/15519695?v=4"
      },
      "readme": "# CCometixLine\n\n[English](README.md) | [ä¸­æ–‡](README.zh.md)\n\nA high-performance Claude Code statusline tool written in Rust with Git integration, usage tracking, interactive TUI configuration, and Claude Code enhancement utilities.\n\n![Language:Rust](https://img.shields.io/static/v1?label=Language&message=Rust&color=orange&style=flat-square)\n![License:MIT](https://img.shields.io/static/v1?label=License&message=MIT&color=blue&style=flat-square)\n\n## Screenshots\n\n![CCometixLine](assets/img1.png)\n\nThe statusline shows: Model | Directory | Git Branch Status | Context Window Information\n\n## Features\n\n### Core Functionality\n- **Git integration** with branch, status, and tracking info  \n- **Model display** with simplified Claude model names\n- **Usage tracking** based on transcript analysis\n- **Directory display** showing current workspace\n- **Minimal design** using Nerd Font icons\n\n### Interactive TUI Features\n- **Interactive main menu** when executed without input\n- **TUI configuration interface** with real-time preview\n- **Theme system** with multiple built-in presets\n- **Segment customization** with granular control\n- **Configuration management** (init, check, edit)\n\n### Claude Code Enhancement\n- **Context warning disabler** - Remove annoying \"Context low\" messages\n- **Verbose mode enabler** - Enhanced output detail\n- **Robust patcher** - Survives Claude Code version updates\n- **Automatic backups** - Safe modification with easy recovery\n\n## Installation\n\n### Quick Install (Recommended)\n\nInstall via npm (works on all platforms):\n\n```bash\n# Install globally\nnpm install -g @cometix/ccline\n\n# Or using yarn\nyarn global add @cometix/ccline\n\n# Or using pnpm\npnpm add -g @cometix/ccline\n```\n\nUse npm mirror for faster download:\n```bash\nnpm install -g @cometix/ccline --registry https://registry.npmmirror.com\n```\n\nAfter installation:\n- âœ… Global command `ccline` is available everywhere\n- âš™ï¸ Follow the configuration steps below to integrate with Claude Code\n- ğŸ¨ Run `ccline -c` to open configuration panel for theme selection\n\n### Claude Code Configuration\n\nAdd to your Claude Code `settings.json`:\n\n**Linux/macOS:**\n```json\n{\n  \"statusLine\": {\n    \"type\": \"command\", \n    \"command\": \"~/.claude/ccline/ccline\",\n    \"padding\": 0\n  }\n}\n```\n\n**Windows:**\n```json\n{\n  \"statusLine\": {\n    \"type\": \"command\", \n    \"command\": \"%USERPROFILE%\\\\.claude\\\\ccline\\\\ccline.exe\",\n    \"padding\": 0\n  }\n}\n```\n\n**Fallback (npm installation):**\n```json\n{\n  \"statusLine\": {\n    \"type\": \"command\", \n    \"command\": \"ccline\",\n    \"padding\": 0\n  }\n}\n```\n*Use this if npm global installation is available in PATH*\n\n### Update\n\n```bash\nnpm update -g @cometix/ccline\n```\n\n<details>\n<summary>Manual Installation (Click to expand)</summary>\n\nAlternatively, download from [Releases](https://github.com/Haleclipse/CCometixLine/releases):\n\n#### Linux\n\n#### Option 1: Dynamic Binary (Recommended)\n```bash\nmkdir -p ~/.claude/ccline\nwget https://github.com/Haleclipse/CCometixLine/releases/latest/download/ccline-linux-x64.tar.gz\ntar -xzf ccline-linux-x64.tar.gz\ncp ccline ~/.claude/ccline/\nchmod +x ~/.claude/ccline/ccline\n```\n*Requires: Ubuntu 22.04+, CentOS 9+, Debian 11+, RHEL 9+ (glibc 2.35+)*\n\n#### Option 2: Static Binary (Universal Compatibility)\n```bash\nmkdir -p ~/.claude/ccline\nwget https://github.com/Haleclipse/CCometixLine/releases/latest/download/ccline-linux-x64-static.tar.gz\ntar -xzf ccline-linux-x64-static.tar.gz\ncp ccline ~/.claude/ccline/\nchmod +x ~/.claude/ccline/ccline\n```\n*Works on any Linux distribution (static, no dependencies)*\n\n#### macOS (Intel)\n\n```bash  \nmkdir -p ~/.claude/ccline\nwget https://github.com/Haleclipse/CCometixLine/releases/latest/download/ccline-macos-x64.tar.gz\ntar -xzf ccline-macos-x64.tar.gz\ncp ccline ~/.claude/ccline/\nchmod +x ~/.claude/ccline/ccline\n```\n\n#### macOS (Apple Silicon)\n\n```bash\nmkdir -p ~/.claude/ccline  \nwget https://github.com/Haleclipse/CCometixLine/releases/latest/download/ccline-macos-arm64.tar.gz\ntar -xzf ccline-macos-arm64.tar.gz\ncp ccline ~/.claude/ccline/\nchmod +x ~/.claude/ccline/ccline\n```\n\n#### Windows\n\n```powershell\n# Create directory and download\nNew-Item -ItemType Directory -Force -Path \"$env:USERPROFILE\\.claude\\ccline\"\nInvoke-WebRequest -Uri \"https://github.com/Haleclipse/CCometixLine/releases/latest/download/ccline-windows-x64.zip\" -OutFile \"ccline-windows-x64.zip\"\nExpand-Archive -Path \"ccline-windows-x64.zip\" -DestinationPath \".\"\nMove-Item \"ccline.exe\" \"$env:USERPROFILE\\.claude\\ccline\\\"\n```\n\n</details>\n\n### Build from Source\n\n```bash\ngit clone https://github.com/Haleclipse/CCometixLine.git\ncd CCometixLine\ncargo build --release\n\n# Linux/macOS\nmkdir -p ~/.claude/ccline\ncp target/release/ccometixline ~/.claude/ccline/ccline\nchmod +x ~/.claude/ccline/ccline\n\n# Windows (PowerShell)\nNew-Item -ItemType Directory -Force -Path \"$env:USERPROFILE\\.claude\\ccline\"\ncopy target\\release\\ccometixline.exe \"$env:USERPROFILE\\.claude\\ccline\\ccline.exe\"\n```\n\n## Usage\n\n### Configuration Management\n\n```bash\n# Initialize configuration file\nccline --init\n\n# Check configuration validity  \nccline --check\n\n# Print current configuration\nccline --print\n\n# Enter TUI configuration mode\nccline --config\n```\n\n### Theme Override\n\n```bash\n# Temporarily use specific theme (overrides config file)\nccline --theme cometix\nccline --theme minimal\nccline --theme gruvbox\nccline --theme nord\nccline --theme powerline-dark\n\n# Or use custom theme files from ~/.claude/ccline/themes/\nccline --theme my-custom-theme\n```\n\n### Claude Code Enhancement\n\n```bash\n# Disable context warnings and enable verbose mode\nccline --patch /path/to/claude-code/cli.js\n\n# Example for common installation\nccline --patch ~/.local/share/fnm/node-versions/v24.4.1/installation/lib/node_modules/@anthropic-ai/claude-code/cli.js\n```\n\n## Default Segments\n\nDisplays: `Directory | Git Branch Status | Model | Context Window`\n\n### Git Status Indicators\n\n- Branch name with Nerd Font icon\n- Status: `âœ“` Clean, `â—` Dirty, `âš ` Conflicts  \n- Remote tracking: `â†‘n` Ahead, `â†“n` Behind\n\n### Model Display\n\nShows simplified Claude model names:\n- `claude-3-5-sonnet` â†’ `Sonnet 3.5`\n- `claude-4-sonnet` â†’ `Sonnet 4`\n\n### Context Window Display\n\nToken usage percentage based on transcript analysis with context limit tracking.\n\n## Configuration\n\nCCometixLine supports full configuration via TOML files and interactive TUI:\n\n- **Configuration file**: `~/.claude/ccline/config.toml`\n- **Interactive TUI**: `ccline --config` for real-time editing with preview\n- **Theme files**: `~/.claude/ccline/themes/*.toml` for custom themes\n- **Automatic initialization**: `ccline --init` creates default configuration\n\n### Available Segments\n\nAll segments are configurable with:\n- Enable/disable toggle\n- Custom separators and icons\n- Color customization\n- Format options\n\nSupported segments: Directory, Git, Model, Usage, Time, Cost, OutputStyle\n\n\n## Requirements\n\n- **Git**: Version 1.5+ (Git 2.22+ recommended for better branch detection)\n- **Terminal**: Must support Nerd Fonts for proper icon display\n  - Install a [Nerd Font](https://www.nerdfonts.com/) (e.g., FiraCode Nerd Font, JetBrains Mono Nerd Font)\n  - Configure your terminal to use the Nerd Font\n- **Claude Code**: For statusline integration\n\n## Development\n\n```bash\n# Build development version\ncargo build\n\n# Run tests\ncargo test\n\n# Build optimized release\ncargo build --release\n```\n\n## Roadmap\n\n- [x] TOML configuration file support\n- [x] TUI configuration interface\n- [x] Custom themes\n- [x] Interactive main menu\n- [x] Claude Code enhancement tools\n\n## Contributing\n\nContributions are welcome! Please feel free to submit issues or pull requests.\n\n## Related Projects\n\n- [tweakcc](https://github.com/Piebald-AI/tweakcc) - Command-line tool to customize your Claude Code themes, thinking verbs, and more.\n\n## License\n\nThis project is licensed under the [MIT License](LICENSE).\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Haleclipse/CCometixLine&type=Date)](https://star-history.com/#Haleclipse/CCometixLine&Date)\n",
      "stars_today": 15
    },
    {
      "id": 1075242574,
      "name": "Universal-ReVanced-Manager",
      "full_name": "Jman-Github/Universal-ReVanced-Manager",
      "description": "ğŸ’Š An Android application to use ReVanced on that has extra features the official manager doesn't have",
      "html_url": "https://github.com/Jman-Github/Universal-ReVanced-Manager",
      "stars": 511,
      "forks": 18,
      "language": "Kotlin",
      "topics": [
        "android",
        "kotlin",
        "revanced",
        "revanced-extended",
        "revanced-manager"
      ],
      "created_at": "2025-10-13T08:31:07Z",
      "updated_at": "2026-01-25T00:35:36Z",
      "pushed_at": "2026-01-24T18:34:11Z",
      "open_issues": 6,
      "owner": {
        "login": "Jman-Github",
        "avatar_url": "https://avatars.githubusercontent.com/u/128645077?v=4"
      },
      "readme": "<p align=\"center\">\r\n  <picture>\r\n    <source\r\n      width=\"256px\"\r\n      media=\"(prefers-color-scheme: dark)\"\r\n      srcset=\"assets/icons/icon-circle.png\"\r\n    >\r\n    <img\r\n      width=\"256px\"\r\n      src=\"assets/icons/icon-circle.png\"\r\n      alt=\"Universal ReVanced Manager icon\"\r\n    />\r\n  </picture>\r\n</p>\r\n\r\n# ğŸ’Š Universal ReVanced Manager\r\n\r\nApplication for using ReVanced on Android.\r\n\r\n<p align=\"center\">\r\n  <img src=\"https://img.shields.io/badge/License-GPL%20v3-yellow.svg\" alt=\"GPLv3 License\" />\r\n  &nbsp;\r\n  <a href=\"https://crowdin.com/project/universal-revanced-manager\" style=\"text-decoration:none;\"><img src=\"https://badges.crowdin.net/universal-revanced-manager/localized.svg\" alt=\"Crowdin\" /></a>\r\n  &nbsp;\r\n  <a href=\"https://crowdin.com/project/universal-revanced-manager\" style=\"text-decoration:none;\"><img src=\"https://img.shields.io/badge/Crowdin-Join-2E3340?logo=crowdin&logoColor=white\" alt=\"Crowdin\" /></a>\r\n  &nbsp;\r\n  <a href=\"https://t.me/urv_chat\" style=\"text-decoration:none;\"><img src=\"https://img.shields.io/badge/Telegram-Chat-2CA5E0?logo=telegram&logoColor=white\" alt=\"Telegram\" /></a>\r\n  &nbsp;\r\n  <a href=\"https://discord.gg/xZAqRHSp3V\" style=\"text-decoration:none;\"><img src=\"https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&logoColor=white\" alt=\"Discord\" /></a>\r\n</p>\r\n\r\n## ğŸ’ª Unique Features\r\n\r\nUniversal ReVanced Manager includes powerful features that the official ReVanced Manager does not:\r\n\r\n<details>\r\n<summary><strong>Patch Bundles & Customization</strong></summary>\r\n<ul>\r\n  <li><strong>Third-party patch support:</strong> Import any third-party API v4 patch bundle you want (including popular ones like inotia00's or anddea's), which the official ReVanced Manager does not support.</li>\r\n  <li><strong>Custom bundle names:</strong> Set a custom display name for any imported patch bundle so you can tell them apart at a glance.</li>\r\n  <li><strong>Smarter patch selection:</strong>\r\n    <ul>\r\n      <li>Global deselect all button</li>\r\n      <li>Per-bundle deselect all button</li>\r\n      <li>Per-bundle select all button</li>\r\n      <li>Global select all button</li>\r\n      <li>Patch profiles button to save patch selections and option states per app</li>\r\n      <li>Patch profiles can store a persistent APK path for one-tap patching</li>\r\n      <li>Patch confirmation screen showing selected bundles, patches, and sub-options</li>\r\n      <li>Export all patch selections at once</li>\r\n      <li>Latest patch bundle changelogs shown in bundle info</li>\r\n      <li>Undo and redo buttons</li>\r\n    </ul>\r\n  </li>\r\n  <li><strong>Bundle recommendation picker:</strong> Choose per-bundle suggested versions or override with any other supported version.</li>\r\n  <li><strong>Suggestion toggle on Select-App:</strong> Bundle suggestions are grouped behind a toggle with inline dialogs to view additional supported versions.</li>\r\n  <li><strong>Official bundle management:</strong> Delete the Official ReVanced patch bundle from the Patch Bundles tab and restore it from Advanced settings.</li>\r\n  <li><strong>Export filename templates:</strong> Configure a filename template for exported patched APKs with placeholders for app and patch metadata.</li>\r\n  <li><strong>Release link button:</strong> GitHub button on each bundle's info page opens the bundle repository's releases.</li>\r\n  <li><strong>Bundle timestamps:</strong> Cards show Created and Updated times; exports and imports preserve these timestamps.</li>\r\n  <li><strong>Organize bundles:</strong> \"Organize\" button to manually reorder bundles; exports and imports keep the custom order.</li>\r\n  <li><strong>Force bundle redownload:</strong> Long-press the update check button on a bundle to force a full redownload.</li>\r\n  <li><strong>Bundle discovery:</strong> Browse a patch bundle catalog and import external bundles directly from the app.</li>\r\n  <li><strong>Improved UI:</strong> Settings, the Patch Bundles tab, the Apps tab, the app selection page, and the patch selection page all have an improved UI design.</li>\r\n</ul>\r\n</details>\r\n\r\n<details>\r\n<summary><strong>App Patching Flow</strong></summary>\r\n<ul>\r\n  <li><strong>Morphe patch bundles support:</strong> Supports the <a href=\"https://github.com/MorpheApp/morphe-patcher\">Morphe Patcher</a> without needing a computer or another app.</li>\r\n  <li><strong>Downloaded app source:</strong> Added a \"Downloaded apps\" source in the select source screen when patching. If the manager has cached an APK from a downloader plugin, you can pick it directly from there. This option only appears when that app is available.</li>\r\n  <li><strong>Split APK support:</strong> .apkm, .apks, and .xapk file formats are automatically converted to the .apk format when patching. No need for outside tools.</li>\r\n  <li><strong>Split merge sub-steps:</strong> Expandable sub-steps for the \"Merging split APKs\" step, plus sub-steps for \"Writing patched APK\".</li>\r\n  <li><strong>Skip unused split modules:</strong> Optional Advanced setting that skips unnecessary split modules (like locale and density splits) when patching split APKs.</li>\r\n  <li><strong>Advanced native library stripping:</strong> Optional advanced setting to strip unused native libraries (unsupported ABIs) from patched APKs during patching, helping reduce size.</li>\r\n  <li><strong>Keystore support:</strong> Import and use JKS and PKCS12 keystores for signing patched APKs.</li>\r\n  <li><strong>Patcher logs export:</strong> Export patcher logs from the patcher screen as a .txt file.</li>\r\n  <li><strong>Export = auto-save:</strong> When you export a patched app to storage from the patching screen, the manager will now also automatically save that patched app under the \"Apps\" tab. Before, this only happened if you installed the patched app directly from that screen.</li>\r\n  <li><strong>Installer management:</strong> A full installer management system with installer metadata, and configurable primary and fallback that applies everywhere across the app.</li>\r\n  <li><strong>View applied patches:</strong> The \"Apps\" tab shows the applied patches for each saved patched APK and which patch bundle(s) were used.</li>\r\n  <li><strong>Organize apps & profiles:</strong> Reorder saved patched apps in the Apps tab and patch profiles in the Patch Profiles tab.</li>\r\n  <li><strong>Accidental exit protection:</strong> After patching, pressing the back button now shows a confirmation popup. It asks if you really want to leave and gives you the option to save the patched app for later (adds it to the \"Apps\" tab).</li>\r\n  <li><strong>Missing patch recovery:</strong> If a selected patch no longer exists, a detailed dialog explains the issue and returns you to patch selection with missing patches highlighted.</li>\r\n  <li><strong>Step auto-collapse:</strong> Completed patcher steps auto-collapse; toggle in Settings &gt; Advanced &gt; \"Auto-collapse completed patcher steps\".</li>\r\n  <li><strong>Saved apps toggle:</strong> Option to disable saving patched apps and hide saved app delete actions.</li>\r\n  <li><strong>Version tags:</strong> On the patch selection and app selection pages, each app or patch displays the versions it supports. Tapping a version chip opens a web search for that specific app and version.</li>\r\n</ul>\r\n</details>\r\n\r\n<details>\r\n<summary><strong>Patch Bundle Updates & Imports</strong></summary>\r\n<ul>\r\n  <li><strong>Progress with percentages:</strong> Progress bars with percentage for bundle updates, update checks, and imports.</li>\r\n  <li><strong>Background bundle updates:</strong> Auto-download bundles in the background with a single progress notification, plus update-available alerts for bundles set to manual updates.</li>\r\n  <li><strong>Installer management:</strong> Full installer management system covering app installs, saved app reinstalls, and manager updates.\r\n    <ul>\r\n      <li>Metadata display for each installer</li>\r\n      <li>Configurable primary and fallback installers</li>\r\n      <li>Shizuku installer option for silent installs when Shizuku or Sui is available</li>\r\n      <li>Advanced settings support saving custom installer packages with package-name lookup and autocomplete, plus dedicated management for third-party installers</li>\r\n      <li>App mounting support for rooted users (rooted mount installer)</li>\r\n    </ul>\r\n  </li>\r\n</ul>\r\n</details>\r\n\r\n<details>\r\n<summary><strong>Downloader & Storage Management</strong></summary>\r\n<ul>\r\n  <li><strong>Cached downloads management:</strong> The manager can now keep multiple downloaded apps (from downloader plugins) inside the downloader settings. You can also export any of these APKs to your device's storage whenever you want.</li>\r\n  <li><strong>Plugin cleanup:</strong> You can uninstall downloader plugins directly from inside the manager via the download settings page. No manual cleanup needed.</li>\r\n  <li><strong>File picker favorites:</strong> Favorite files or folders in the custom file picker for quick access.</li>\r\n</ul>\r\n</details>\r\n\r\n<details>\r\n<summary><strong>Appearance & Theming</strong></summary>\r\n<ul>\r\n  <li><strong>Enhanced theming:</strong> Appearance settings include an accent color picker, theme color picker, color HEX code support, presets, and a live preview widget so you can choose a custom theme color and customize the app to your liking.</li>\r\n  <li><strong>Monochrome app icons:</strong> Support for Android monochrome icons.</li>\r\n  <li><strong>Better long names:</strong> Long labels use horizontal swipe instead of auto-sliding or wrapping.</li>\r\n</ul>\r\n</details>\r\n\r\n<details>\r\n<summary><strong>Network & Updates</strong></summary>\r\n<ul>\r\n  <li><strong>Metered connection control:</strong> Toggle to allow updates on metered connections for both patch bundles and the manager itself, so you are not blocked on mobile data.</li>\r\n</ul>\r\n</details>\r\n\r\n<details>\r\n<summary><strong>Developer & Power Features</strong></summary>\r\n<ul>\r\n  <li><strong>Always-visible developer options:</strong> Developer options are always available in Settings by default. No hidden or secret unlock flow.</li>\r\n  <li><strong>Disable battery optimization banner:</strong> Developer option to hide the battery optimization warning banner.</li>\r\n  <li><strong>Robust import and export:</strong> Export and import your patch bundles, your patch profiles, and your app settings to and from JSON files for easy backup, sharing, or migration between devices.</li>\r\n</ul>\r\n</details>\r\n\r\n<details>\r\n<summary><strong>Settings & Navigation</strong></summary>\r\n<ul>\r\n  <li><strong>Settings search:</strong> Search across settings categories with jump-to highlighting.</li>\r\n  <li><strong>Tab search:</strong> Apps, Patch Bundles, and Patch Profiles tabs are searchable via a nav bar search button.</li>\r\n</ul>\r\n</details>\r\n\r\n<details>\r\n<summary><strong>Localization</strong></summary>\r\n<ul>\r\n  <li><strong>Chinese Simplified:</strong> User-selectable language option in settings.</li>\r\n  <li><strong>Vietnamese:</strong> User-selectable language option in settings.</li>\r\n  <li><strong>Korean:</strong> User-selectable language option in settings.</li>\r\n  <li><strong>Japanese:</strong> User-selectable language option in settings.</li>\r\n  <li><strong>Russian:</strong> User-selectable language option in settings.</li>\r\n  <li><strong>Ukrainian:</strong> User-selectable language option in settings.</li>\r\n  <li><strong>Brazilian Portuguese:</strong> User-selectable language option in settings.</li>\r\n  <li><strong>Indonesian:</strong> User-selectable language option in settings.</li>\r\n  <li><strong>Fillipino:</strong> User-selectable language option in settings.</li>\r\n  <li><strong>Hindi:</strong> User-selectable language option in settings.</li>\r\n  <li><strong>Gujarati:</strong> User-selectable language option in settings.</li>\r\n</ul>\r\n</details>\r\n\r\n## ğŸ”½ Download\r\n\r\nYou can download the most recent version of Universal ReVanced Manager from [GitHub releases](https://github.com/Jman-Github/universal-revanced-manager/releases/latest).\r\n\r\n## ğŸ“‹ Patch Bundles\r\n\r\nTo import patch bundles into Universal ReVanced Manager, use my [ReVanced Patch Bundles](https://github.com/Jman-Github/ReVanced-Patch-Bundles) repository. It includes a detailed [catalog](https://github.com/Jman-Github/ReVanced-Patch-Bundles/blob/bundles/patch-bundles/PATCH-LIST-CATALOG.md) of all patches across 20+ tracked bundles, as well as [bundle URLs](https://github.com/Jman-Github/ReVanced-Patch-Bundles#-patch-bundles-urls) you can paste directly into Universal ReVanced Manager to import them. Keep in mind that only the patch bundles labeled \"API v4\" can be imported into the manager. Bundles without this label cannot be imported into the app.\r\n\r\n## ğŸ”Œ Supported Downloader Plugins\r\n\r\n[Play Store Downloader](https://github.com/brosssh/revanced-manager-downloaders) âŒ  \r\n[ApkMirror Downloader](https://github.com/brosssh/revanced-manager-downloaders) âœ…  \r\n[APKPure Downloader](https://github.com/brosssh/revanced-manager-downloaders) âœ…  \r\n[APKCombo Downloader](https://github.com/brosssh/revanced-manager-downloaders) âœ…  \r\n\r\n## ğŸ¤ Contributors\r\n<table>\r\n  <tr>\r\n    <td style=\"vertical-align:middle;padding-right:8px;\">\r\n      <img src=\"https://images.weserv.nl/?url=github.com%2Fbrosssh.png&h=36&w=36&fit=cover&mask=circle\" alt=\"brosssh avatar\" width=\"36\" height=\"36\" />\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:24px;\">\r\n      <a href=\"https://github.com/brosssh\">brosssh</a><br />\r\n      Multiple PRs, top contributor\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:8px;\">\r\n      <img src=\"https://images.weserv.nl/?url=github.com%2FTanakaLun.png&h=36&w=36&fit=cover&mask=circle\" alt=\"TanakaLun avatar\" width=\"36\" height=\"36\" />\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:0;\">\r\n      <a href=\"https://github.com/TanakaLun\">TanakaLun</a><br />\r\n      Chinese localization\r\n    </td>\r\n  </tr>\r\n  <tr>\r\n    <td style=\"vertical-align:middle;padding-right:8px;\">\r\n      <img src=\"https://images.weserv.nl/?url=github.com%2Fann9cht.png&h=36&w=36&fit=cover&mask=circle\" alt=\"ann9cht avatar\" width=\"36\" height=\"36\" />\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:24px;\">\r\n      <a href=\"https://github.com/ann9cht\">ann9cht</a><br />\r\n      Vietnamese localization\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:8px;\">\r\n      <img src=\"https://images.weserv.nl/?url=github.com%2FKobeW50.png&h=36&w=36&fit=cover&mask=circle\" alt=\"KobeW50 avatar\" width=\"36\" height=\"36\" />\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:0;\">\r\n      <a href=\"https://github.com/KobeW50\">KobeW50</a><br />\r\n      Proofreading strings & wording\r\n    </td>\r\n  </tr>\r\n  <tr>\r\n    <td style=\"vertical-align:middle;padding-right:8px;\">\r\n      <img src=\"https://images.weserv.nl/?url=github.com/BlackGold8282.png&h=36&w=36&fit=cover&mask=circle\" alt=\"BlackGold8282 avatar\" width=\"36\" height=\"36\" />\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:24px;\">\r\n      <a href=\"https://github.com/BlackGold8282\">BlackGold8282</a><br />\r\n      Korean localization\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:8px;\">\r\n      <img src=\"https://images.weserv.nl/?url=github.com%2FYuzuMikan404.png&h=36&w=36&fit=cover&mask=circle\" alt=\"YuzuMikan404 avatar\" width=\"36\" height=\"36\" />\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:0;\">\r\n      <a href=\"https://github.com/YuzuMikan404\">YuzuMikan404</a><br />\r\n      Japanese localization\r\n    </td>\r\n  </tr>\r\n  <tr>\r\n    <td style=\"vertical-align:middle;padding-right:8px;\">\r\n      <img src=\"https://images.weserv.nl/?url=github.com%2Fvippium.png&h=36&w=36&fit=cover&mask=circle\" alt=\"vippium avatar\" width=\"36\" height=\"36\" />\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:24px;\">\r\n      <a href=\"https://github.com/vippium\">vippium</a><br />\r\n      Monochrome icon improvements\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:8px;\">\r\n      <img src=\"https://images.weserv.nl/?url=github.com%2FVertuhai.png&h=36&w=36&fit=cover&mask=circle\" alt=\"Vertuhai avatar\" width=\"36\" height=\"36\" />\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:0;\">\r\n      <a href=\"https://github.com/Vertuhai\">Vertuhai</a><br />\r\n      Russian and Ukrainian localization\r\n    </td>\r\n  </tr>\r\n  <tr>\r\n    <td style=\"vertical-align:middle;padding-right:8px;\">\r\n      <img src=\"https://images.weserv.nl/?url=github.com%2Fr7reiz.png&h=36&w=36&fit=cover&mask=circle\" alt=\"r7reiz avatar\" width=\"36\" height=\"36\" />\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:24px;\">\r\n      <a href=\"https://github.com/r7reiz\">r7reiz</a><br />\r\n      Brazilian Portuguese localization\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:8px;\">\r\n      <img src=\"https://images.weserv.nl/?url=crowdin-static.cf-downloads.crowdin.com/avatar/13430318/large/73204ec2b41cc713d81dc88824059dea.jpg&h=36&w=36&fit=cover&mask=circle\" alt=\"naokoshoto avatar\" width=\"36\" height=\"36\" />\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:0;\">\r\n      <a href=\"https://crowdin.com/profile/naokoshoto\">naokoshoto</a><br />\r\n      Indonesian localization\r\n    </td>\r\n  </tr>\r\n  <tr>\r\n    <td style=\"vertical-align:middle;padding-right:8px;\">\r\n      <img src=\"https://images.weserv.nl/?url=crowdin-static.cf-downloads.crowdin.com/avatar/16366724/large/e0afadb935d2fa9b972ca1697169c806.png&h=36&w=36&fit=cover&mask=circle\" alt=\"mesazane avatar\" width=\"36\" height=\"36\" />\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:24px;\">\r\n      <a href=\"https://crowdin.com/profile/mesazane\">Mesazane</a><br />\r\n      Indonesian localization\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:8px;\">\r\n      <img src=\"https://images.weserv.nl/?url=crowdin-static.cf-downloads.crowdin.com/avatar/17524508/large/b5f2c910b17aae07cdfc69bcd973fe31.png&h=36&w=36&fit=cover&mask=circle\" alt=\"fielph avatar\" width=\"36\" height=\"36\" />\r\n    </td>\r\n    <td style=\"vertical-align:middle;padding-right:0;\">\r\n      <a href=\"https://crowdin.com/profile/fielph\">fielph</a><br />\r\n      Fillipino localization\r\n    </td>\r\n  </tr>\r\n</table>\r\n\r\n## â­ Star History\r\n\r\n[![Star History Chart](https://api.star-history.com/svg?repos=Jman-Github/Universal-ReVanced-Manager&type=date&legend=top-left)](https://www.star-history.com/#Jman-Github/Universal-ReVanced-Manager&type=date&legend=top-left)\r\n\r\n## âš–ï¸ License\r\n\r\nUniversal ReVanced Manager is licensed under the GPLv3 license. Please see the [license file](https://github.com/Jman-Github/universal-revanced-manager/blob/main/LICENSE) for more information.\r\n[tl;dr](https://www.tldrlegal.com/license/gnu-general-public-license-v3-gpl-3) you may copy, distribute and modify Universal ReVanced Manager as long as you track changes/dates in source files.\r\nAny modifications to Universal ReVanced Manager must also be made available under the GPL, along with build & install instructions.\r\n",
      "stars_today": 15
    },
    {
      "id": 15111821,
      "name": "grafana",
      "full_name": "grafana/grafana",
      "description": "The open and composable observability and data visualization platform. Visualize metrics, logs, and traces from multiple sources like Prometheus, Loki, Elasticsearch, InfluxDB, Postgres and many more. ",
      "html_url": "https://github.com/grafana/grafana",
      "stars": 71872,
      "forks": 13395,
      "language": "TypeScript",
      "topics": [
        "alerting",
        "analytics",
        "business-intelligence",
        "dashboard",
        "data-visualization",
        "elasticsearch",
        "go",
        "grafana",
        "hacktoberfest",
        "influxdb",
        "metrics",
        "monitoring",
        "mysql",
        "postgres",
        "prometheus"
      ],
      "created_at": "2013-12-11T15:59:56Z",
      "updated_at": "2026-01-25T02:02:17Z",
      "pushed_at": "2026-01-25T00:45:59Z",
      "open_issues": 3607,
      "owner": {
        "login": "grafana",
        "avatar_url": "https://avatars.githubusercontent.com/u/7195757?v=4"
      },
      "readme": "![Grafana Logo (Light)](docs/logo-horizontal.png#gh-light-mode-only)\n![Grafana Logo (Dark)](docs/logo-horizontal-dark.png#gh-dark-mode-only)\n\nThe open-source platform for monitoring and observability\n\n[![License](https://img.shields.io/github/license/grafana/grafana)](LICENSE)\n[![Go Report Card](https://goreportcard.com/badge/github.com/grafana/grafana)](https://goreportcard.com/report/github.com/grafana/grafana)\n\nGrafana allows you to query, visualize, alert on and understand your metrics no matter where they are stored. Create, explore, and share dashboards with your team and foster a data-driven culture:\n\n- **Visualizations:** Fast and flexible client side graphs with a multitude of options. Panel plugins offer many different ways to visualize metrics and logs.\n- **Dynamic Dashboards:** Create dynamic & reusable dashboards with template variables that appear as dropdowns at the top of the dashboard.\n- **Explore Metrics:** Explore your data through ad-hoc queries and dynamic drilldown. Split view and compare different time ranges, queries and data sources side by side.\n- **Explore Logs:** Experience the magic of switching from metrics to logs with preserved label filters. Quickly search through all your logs or streaming them live.\n- **Alerting:** Visually define alert rules for your most important metrics. Grafana will continuously evaluate and send notifications to systems like Slack, PagerDuty, VictorOps, OpsGenie.\n- **Mixed Data Sources:** Mix different data sources in the same graph! You can specify a data source on a per-query basis. This works for even custom datasources.\n\n## Get started\n\n- [Get Grafana](https://grafana.com/get)\n- [Installation guides](https://grafana.com/docs/grafana/latest/setup-grafana/installation/)\n\nUnsure if Grafana is for you? Watch Grafana in action on [play.grafana.org](https://play.grafana.org/)!\n\n## Documentation\n\nThe Grafana documentation is available at [grafana.com/docs](https://grafana.com/docs/).\n\n## Contributing\n\nIf you're interested in contributing to the Grafana project:\n\n- Start by reading the [Contributing guide](https://github.com/grafana/grafana/blob/HEAD/CONTRIBUTING.md).\n- Learn how to set up your local environment, in our [Developer guide](https://github.com/grafana/grafana/blob/HEAD/contribute/developer-guide.md).\n- Explore our [beginner-friendly issues](https://github.com/grafana/grafana/issues?q=is%3Aopen+is%3Aissue+label%3A%22beginner+friendly%22).\n- Look through our [style guide and Storybook](https://developers.grafana.com/ui/latest/index.html).\n\n> Share your contributor experience in our [feedback survey](https://gra.fan/ome) to help us improve.\n\n## Get involved\n\n- Follow [@grafana on X (formerly Twitter)](https://x.com/grafana/).\n- Read and subscribe to the [Grafana blog](https://grafana.com/blog/).\n- If you have a specific question, check out our [discussion forums](https://community.grafana.com/).\n- For general discussions, join us on the [official Slack](https://slack.grafana.com) team.\n\nThis project is tested with [BrowserStack](https://www.browserstack.com/).\n\n## License\n\nGrafana is distributed under [AGPL-3.0-only](LICENSE). For Apache-2.0 exceptions, see [LICENSING.md](https://github.com/grafana/grafana/blob/HEAD/LICENSING.md).\n",
      "stars_today": 14
    },
    {
      "id": 130464961,
      "name": "bat",
      "full_name": "sharkdp/bat",
      "description": "A cat(1) clone with wings.",
      "html_url": "https://github.com/sharkdp/bat",
      "stars": 56794,
      "forks": 1441,
      "language": "Rust",
      "topics": [
        "cli",
        "command-line",
        "git",
        "hacktoberfest",
        "rust",
        "syntax-highlighting",
        "terminal",
        "tool"
      ],
      "created_at": "2018-04-21T10:52:23Z",
      "updated_at": "2026-01-25T01:48:38Z",
      "pushed_at": "2026-01-15T20:13:42Z",
      "open_issues": 339,
      "owner": {
        "login": "sharkdp",
        "avatar_url": "https://avatars.githubusercontent.com/u/4209276?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src=\"doc/logo-header.svg\" alt=\"bat - a cat clone with wings\"><br>\n  <a href=\"https://github.com/sharkdp/bat/actions?query=workflow%3ACICD\"><img src=\"https://github.com/sharkdp/bat/workflows/CICD/badge.svg\" alt=\"Build Status\"></a>\n  <img src=\"https://img.shields.io/crates/l/bat.svg\" alt=\"license\">\n  <a href=\"https://crates.io/crates/bat\"><img src=\"https://img.shields.io/crates/v/bat.svg?colorB=319e8c\" alt=\"Version info\"></a><br>\n  A <i>cat(1)</i> clone with syntax highlighting and Git integration.\n</p>\n\n<p align=\"center\">\n  <a href=\"#syntax-highlighting\">Key Features</a> â€¢\n  <a href=\"#how-to-use\">How To Use</a> â€¢\n  <a href=\"#installation\">Installation</a> â€¢\n  <a href=\"#customization\">Customization</a> â€¢\n  <a href=\"#project-goals-and-alternatives\">Project goals, alternatives</a><br>\n  [English]\n  [<a href=\"doc/README-zh.md\">ä¸­æ–‡</a>]\n  [<a href=\"doc/README-ja.md\">æ—¥æœ¬èª</a>]\n  [<a href=\"doc/README-ko.md\">í•œêµ­ì–´</a>]\n  [<a href=\"doc/README-ru.md\">Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>]\n</p>\n\n### Sponsors\n\nA special *thank you* goes to our biggest <a href=\"doc/sponsors.md\">sponsors</a>:<br>\n\n<p>\n<a href=\"https://www.warp.dev/bat\">\n  <img src=\"doc/sponsors/warp-logo.png\" width=\"200\" alt=\"Warp\">\n  <br>\n  <strong>Warp, the intelligent terminal</strong>\n  <br>\n  <sub>Available on MacOS, Linux, Windows</sub>\n</a>\n</p>\n\n### Syntax highlighting\n\n`bat` supports syntax highlighting for a large number of programming and markup\nlanguages:\n\n![Syntax highlighting example](https://imgur.com/rGsdnDe.png)\n\n### Git integration\n\n`bat` communicates with `git` to show modifications with respect to the index\n(see left side bar):\n\n![Git integration example](https://i.imgur.com/2lSW4RE.png)\n\n### Show non-printable characters\n\nYou can use the `-A`/`--show-all` option to show and highlight non-printable\ncharacters:\n\n![Non-printable character example](https://i.imgur.com/WndGp9H.png)\n\n### Automatic paging\n\nBy default, `bat` pipes its own output to a pager (e.g. `less`) if the output is too large for one screen.\nIf you would rather `bat` work like `cat` all the time (never page output), you can set `--paging=never` as an option, either on the command line or in your configuration file.\nIf you intend to alias `cat` to `bat` in your shell configuration, you can use `alias cat='bat --paging=never'` to preserve the default behavior.\n\n#### File concatenation\n\nEven with a pager set, you can still use `bat` to concatenate files :wink:.\nWhenever `bat` detects a non-interactive terminal (i.e. when you pipe into another process or into a file), `bat` will act as a drop-in replacement for `cat` and fall back to printing the plain file contents, regardless of the `--pager` option's value.\n\n## How to use\n\nDisplay a single file on the terminal\n\n```bash\nbat README.md\n```\n\nDisplay multiple files at once\n\n```bash\nbat src/*.rs\n```\n\nRead from stdin, determine the syntax automatically (note, highlighting will\nonly work if the syntax can be determined from the first line of the file,\nusually through a shebang such as `#!/bin/sh`)\n\n```bash\ncurl -s https://sh.rustup.rs | bat\n```\n\nRead from stdin, specify the language explicitly\n\n```bash\nyaml2json .travis.yml | json_pp | bat -l json\n```\n\nShow and highlight non-printable characters:\n```bash\nbat -A /etc/hosts\n```\n\nUse it as a `cat` replacement:\n\n```bash\nbat > note.md  # quickly create a new file\n\nbat header.md content.md footer.md > document.md\n\nbat -n main.rs  # show line numbers (only)\n\nbat f - g  # output 'f', then stdin, then 'g'.\n```\n\n### Integration with other tools\n\n#### `fzf`\n\nYou can use `bat` as a previewer for [`fzf`](https://github.com/junegunn/fzf). To do this,\nuse `bat`'s `--color=always` option to force colorized output. You can also use `--line-range`\noption to restrict the load times for long files:\n\n```bash\nfzf --preview \"bat --color=always --style=numbers --line-range=:500 {}\"\n```\n\nFor more information, see [`fzf`'s `README`](https://github.com/junegunn/fzf#preview-window).\n\n#### `find` or `fd`\n\nYou can use the `-exec` option of `find` to preview all search results with `bat`:\n\n```bash\nfind â€¦ -exec bat {} +\n```\n\nIf you happen to use [`fd`](https://github.com/sharkdp/fd), you can use the `-X`/`--exec-batch` option to do the same:\n\n```bash\nfd â€¦ -X bat\n```\n\n#### `ripgrep`\n\nWith [`batgrep`](https://github.com/eth-p/bat-extras/blob/master/doc/batgrep.md), `bat` can be used as the printer for [`ripgrep`](https://github.com/BurntSushi/ripgrep) search results.\n\n```bash\nbatgrep needle src/\n```\n\n#### `tail -f`\n\n`bat` can be combined with `tail -f` to continuously monitor a given file with syntax highlighting.\n\n```bash\ntail -f /var/log/pacman.log | bat --paging=never -l log\n```\n\nNote that we have to switch off paging in order for this to work. We have also specified the syntax\nexplicitly (`-l log`), as it can not be auto-detected in this case.\n\n#### `git`\n\nYou can combine `bat` with `git show` to view an older version of a given file with proper syntax\nhighlighting:\n\n```bash\ngit show v0.6.0:src/main.rs | bat -l rs\n```\n\n#### `git diff`\n\nYou can combine `bat` with `git diff` to view lines around code changes with proper syntax\nhighlighting:\n```bash\nbatdiff() {\n    git diff --name-only --relative --diff-filter=d -z | xargs -0 bat --diff\n}\n```\nIf you prefer to use this as a separate tool, check out `batdiff` in [`bat-extras`](https://github.com/eth-p/bat-extras).\n\nIf you are looking for more support for git and diff operations, check out [`delta`](https://github.com/dandavison/delta).\n\n#### `xclip`\n\nThe line numbers and Git modification markers in the output of `bat` can make it hard to copy\nthe contents of a file. To prevent this, you can call `bat` with the `-p`/`--plain` option or\nsimply pipe the output into `xclip`:\n```bash\nbat main.cpp | xclip\n```\n`bat` will detect that the output is being redirected and print the plain file contents.\n\n#### `man`\n\n`bat` can be used as a colorizing pager for `man`, by setting the\n`MANPAGER` environment variable:\n\n```bash\nexport MANPAGER=\"bat -plman\"\nman 2 select\n```\n(replace `bat` with `batcat` if you are on Debian or Ubuntu)\n\nIf you prefer to have this bundled in a new command, you can also use [`batman`](https://github.com/eth-p/bat-extras/blob/master/doc/batman.md).\n\nNote that the [Manpage syntax](assets/syntaxes/02_Extra/Manpage.sublime-syntax) is developed in this repository and still needs some work.\n\n#### `prettier` / `shfmt` / `rustfmt`\n\nThe [`prettybat`](https://github.com/eth-p/bat-extras/blob/master/doc/prettybat.md) script is a wrapper that will format code and print it with `bat`.\n\n#### `Warp`\n\n<a href=\"https://app.warp.dev/drive/folder/-Bat-Warp-Pack-lxhe7HrEwgwpG17mvrFSz1\">\n  <img src=\"doc/sponsors/warp-pack-header.png\" alt=\"Warp\">\n</a>\n\n#### Highlighting `--help` messages\n\nYou can use `bat` to colorize help text: `$ cp --help | bat -plhelp`\n\nYou can also use a wrapper around this:\n\n```bash\n# in your .bashrc/.zshrc/*rc\nalias bathelp='bat --plain --language=help'\nhelp() {\n    \"$@\" --help 2>&1 | bathelp\n}\n```\n\nThen you can do `$ help cp` or `$ help git commit`.\n\nWhen you are using `zsh`, you can also use global aliases to override `-h` and `--help` entirely:\n\n```bash\nalias -g -- -h='-h 2>&1 | bat --language=help --style=plain'\nalias -g -- --help='--help 2>&1 | bat --language=help --style=plain'\n```\n\nFor `fish`, you can use abbreviations:\n\n```fish\nabbr -a --position anywhere -- --help '--help | bat -plhelp'\nabbr -a --position anywhere -- -h '-h | bat -plhelp'\n```\n\nThis way, you can keep on using `cp --help`, but get colorized help pages.\n\nBe aware that in some cases, `-h` may not be a shorthand of `--help` (for example with `ls`). In cases where you need to use `-h` \nas a command argument you can prepend `\\` to the argument (eg. `ls \\-h`) to escape the aliasing defined above. \n\nPlease report any issues with the help syntax in [this repository](https://github.com/victor-gp/cmd-help-sublime-syntax).\n\n\n## Installation\n\n<!--\n\nInstallation instructions need to:\n* be for widely used systems\n* be non-obvious\n* be from somewhat official sources\n\n-->\n\n[![Packaging status](https://repology.org/badge/vertical-allrepos/bat-cat.svg?columns=3&exclude_unsupported=1)](https://repology.org/project/bat-cat/versions)\n\n### On Ubuntu (using `apt`)\n*... and other Debian-based Linux distributions.*\n\n`bat` is available on [Ubuntu since 20.04 (\"Focal\")](https://packages.ubuntu.com/search?keywords=bat&exact=1) and [Debian since August 2021 (Debian 11 - \"Bullseye\")](https://packages.debian.org/bullseye/bat).\n\nIf your Ubuntu/Debian installation is new enough you can simply run:\n\n```bash\nsudo apt install bat\n```\n\n**Important**: If you install `bat` this way, please note that the executable may be installed as `batcat` instead of `bat` (due to [a name\nclash with another package](https://github.com/sharkdp/bat/issues/982)). You can set up a `bat -> batcat` symlink or alias to prevent any issues that may come up because of this and to be consistent with other distributions:\n``` bash\nmkdir -p ~/.local/bin\nln -s /usr/bin/batcat ~/.local/bin/bat\n```\n\nan example alias for `batcat` as `bat`:\n```bash\nalias bat=\"batcat\"\n```\n\n### On Ubuntu (using most recent `.deb` packages)\n*... and other Debian-based Linux distributions.*\n\nIf the package has not yet been promoted to your Ubuntu/Debian installation, or you want\nthe most recent release of `bat`, download the latest `.deb` package from the\n[release page](https://github.com/sharkdp/bat/releases) and install it via:\n\n```bash\nsudo dpkg -i bat_0.18.3_amd64.deb  # adapt version number and architecture\n```\n\n### On Alpine Linux\n\nYou can install [the `bat` package](https://pkgs.alpinelinux.org/packages?name=bat)\nfrom the official sources, provided you have the appropriate repository enabled:\n\n```bash\napk add bat\n```\n\n### On Arch Linux\n\nYou can install [the `bat` package](https://www.archlinux.org/packages/extra/x86_64/bat/)\nfrom the official sources:\n\n```bash\npacman -S bat\n```\n\n### On Fedora\n\nYou can install [the `bat` package](https://koji.fedoraproject.org/koji/packageinfo?packageID=27506) from the official [Fedora Modular](https://docs.fedoraproject.org/en-US/modularity/using-modules/) repository.\n\n```bash\ndnf install bat\n```\n\n### On Gentoo Linux\n\nYou can install [the `bat` package](https://packages.gentoo.org/packages/sys-apps/bat)\nfrom the official sources:\n\n```bash\nemerge sys-apps/bat\n```\n\n### On FreeBSD\n\nYou can install a precompiled [`bat` package](https://www.freshports.org/textproc/bat) with pkg:\n\n```bash\npkg install bat\n```\n\nor build it on your own from the FreeBSD ports:\n\n```bash\ncd /usr/ports/textproc/bat\nmake install\n```\n\n### On OpenBSD\n\nYou can install `bat` package using [`pkg_add(1)`](https://man.openbsd.org/pkg_add.1):\n\n```bash\npkg_add bat\n```\n\n### Via nix\n\nYou can install `bat` using the [nix package manager](https://nixos.org/nix):\n\n```bash\nnix-env -i bat\n```\n\n### On openSUSE\n\nYou can install `bat` with zypper:\n\n```bash\nzypper install bat\n```\n\n### Via snap package\n\nThere is currently no recommended snap package available.\nExisting packages may be available, but are not officially supported and may contain [issues](https://github.com/sharkdp/bat/issues/1519).\n\n### On macOS (or Linux) via Homebrew\n\nYou can install `bat` with [Homebrew](https://formulae.brew.sh/formula/bat):\n\n```bash\nbrew install bat\n```\n\n### On macOS via MacPorts\n\nOr install `bat` with [MacPorts](https://ports.macports.org/port/bat/summary):\n\n```bash\nport install bat\n```\n\n### On Windows\n\nThere are a few options to install `bat` on Windows. Once you have installed `bat`,\ntake a look at the [\"Using `bat` on Windows\"](#using-bat-on-windows) section.\n\n#### Prerequisites\n\nYou will need to install the [Visual C++ Redistributable](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist#latest-microsoft-visual-c-redistributable-version)\n\n#### With WinGet\n\nYou can install `bat` via [WinGet](https://learn.microsoft.com/en-us/windows/package-manager/winget):\n\n```bash\nwinget install sharkdp.bat\n```\n\n#### With Chocolatey\n\nYou can install `bat` via [Chocolatey](https://chocolatey.org/packages/Bat):\n```bash\nchoco install bat\n```\n\n#### With Scoop\n\nYou can install `bat` via [scoop](https://scoop.sh/):\n```bash\nscoop install bat\n```\n\n#### From prebuilt binaries:\n\nYou can download prebuilt binaries from the [Release page](https://github.com/sharkdp/bat/releases),\n\nYou will need to install the [Visual C++ Redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) package.\n\n### From binaries\n\nCheck out the [Release page](https://github.com/sharkdp/bat/releases) for\nprebuilt versions of `bat` for many different architectures. Statically-linked\nbinaries are also available: look for archives with `musl` in the file name.\n\n### From source\n\nIf you want to build `bat` from source, you need Rust 1.79.0 or\nhigher. You can then use `cargo` to build everything:\n\n#### From local source\n```bash\ncargo install --path . --locked\n```\n> [!NOTE]\n> The `--path .` above specifies the directory of the source code and NOT where `bat` will be installed.\n> For more information see the docs for [`cargo install`](https://doc.rust-lang.org/cargo/commands/cargo-install.html).\n\n#### From `crates.io`\n```bash\ncargo install --locked bat\n```\n\nNote that additional files like the man page or shell completion\nfiles can not be installed automatically in both these ways.\nIf installing from a local source, they will be generated by `cargo`\nand should be available in the cargo target folder under `build`.\n\nFurthermore, shell completions are also available by running:\n```bash\nbat --completion <shell>\n# see --help for supported shells\n```\n\n## Customization\n\n### Highlighting theme\n\nUse `bat --list-themes` to get a list of all available themes for syntax\nhighlighting. By default, `bat` uses `Monokai Extended` or `Monokai Extended Light`\nfor dark and light themes respectively. To select the `TwoDark` theme, call `bat`\nwith the `--theme=TwoDark` option or set the `BAT_THEME` environment variable to\n`TwoDark`. Use `export BAT_THEME=\"TwoDark\"` in your shell's startup file to\nmake the change permanent. Alternatively, use `bat`'s\n[configuration file](#configuration-file).\n\nIf you want to preview the different themes on a custom file, you can use\nthe following command (you need [`fzf`](https://github.com/junegunn/fzf) for this):\n```bash\nbat --list-themes | fzf --preview=\"bat --theme={} --color=always /path/to/file\"\n```\n\n`bat` automatically picks a fitting theme depending on your terminal's background color.\nYou can use the `--theme-dark` / `--theme-light` options or the `BAT_THEME_DARK` / `BAT_THEME_LIGHT` environment variables\nto customize the themes used. This is especially useful if you frequently switch between dark and light mode.\n\nYou can also use a custom theme by following the\n['Adding new themes' section below](#adding-new-themes).\n\n### 8-bit themes\n\n`bat` has three themes that always use [8-bit colors](https://en.wikipedia.org/wiki/ANSI_escape_code#Colors),\neven when truecolor support is available:\n\n- `ansi` looks decent on any terminal. It uses 3-bit colors: black, red, green,\n  yellow, blue, magenta, cyan, and white.\n- `base16` is designed for [base16](https://github.com/tinted-theming/home) terminal themes. It uses\n  4-bit colors (3-bit colors plus bright variants) in accordance with the\n  [base16 styling guidelines](https://github.com/tinted-theming/home/blob/main/styling.md).\n- `base16-256` is designed for [tinted-shell](https://github.com/tinted-theming/tinted-shell).\n  It replaces certain bright colors with 8-bit colors from 16 to 21. **Do not** use this simply\n  because you have a 256-color terminal but are not using tinted-shell.\n\nAlthough these themes are more restricted, they have three advantages over truecolor themes. They:\n\n- Enjoy maximum compatibility. Some terminal utilities do not support more than 3-bit colors.\n- Adapt to terminal theme changes. Even for already printed output.\n- Visually harmonize better with other terminal software.\n\n### Output style\n\nYou can use the `--style` option to control the appearance of `bat`'s output.\nYou can use `--style=numbers,changes`, for example, to show only Git changes\nand line numbers but no grid and no file header. Set the `BAT_STYLE` environment\nvariable to make these changes permanent or use `bat`'s\n[configuration file](#configuration-file).\n\n>[!tip]\n> If you specify a default style in `bat`'s config file, you can change which components\n> are displayed during a single run of `bat` using the `--style` command-line argument.\n> By prefixing a component with `+` or `-`, it can be added or removed from the current style.\n>\n> For example, if your config contains `--style=full,-snip`, you can run bat with\n> `--style=-grid,+snip` to remove the grid and add back the `snip` component.\n> Or, if you want to override the styles completely, you use `--style=numbers` to\n> only show the line numbers.\n\n### Decorations\n\nBy default, `bat` only shows decorations (such as line numbers, file headers, grid borders, etc.) when outputting to an interactive terminal. You can control this behavior with the `--decorations` option. Use `--decorations=always` to show decorations even when piping output to another command, or `--decorations=never` to disable them entirely. Possible values are `auto` (default), `never`, and `always`.\n\nThere is also the `--force-colorization` option, which is an alias for `--decorations=always --color=always`. This is useful if you want to keep colorization and decorations when piping `bat`'s output to another program.\n\n### Adding new syntaxes / language definitions\n\nShould you find that a particular syntax is not available within `bat`, you can follow these\ninstructions to easily add new syntaxes to your current `bat` installation.\n\n`bat` uses the excellent [`syntect`](https://github.com/trishume/syntect/)\nlibrary for syntax highlighting. `syntect` can read any\n[Sublime Text `.sublime-syntax` file](https://www.sublimetext.com/docs/3/syntax.html)\nand theme.\n\nA good resource for finding Sublime Syntax packages is [Package Control](https://packagecontrol.io/). Once you found a\nsyntax:\n\n1. Create a folder with syntax definition files:\n\n   ```bash\n   mkdir -p \"$(bat --config-dir)/syntaxes\"\n   cd \"$(bat --config-dir)/syntaxes\"\n\n   # Put new '.sublime-syntax' language definition files\n   # in this folder (or its subdirectories), for example:\n   git clone https://github.com/tellnobody1/sublime-purescript-syntax\n   ```\n\n2. Now use the following command to parse these files into a binary cache:\n\n   ```bash\n   bat cache --build\n   ```\n\n3. Finally, use `bat --list-languages` to check if the new languages are available.\n\n   If you ever want to go back to the default settings, call:\n\n   ```bash\n   bat cache --clear\n   ```\n\n4. If you think that a specific syntax should be included in `bat` by default, please\n   consider opening a \"syntax request\" ticket after reading the policies and\n   instructions [here](doc/assets.md): [Open Syntax Request](https://github.com/sharkdp/bat/issues/new?labels=syntax-request&template=syntax_request.md).\n\n### Adding new themes\n\nThis works very similar to how we add new syntax definitions.\n> [!NOTE]\n> Themes are stored in [`.tmTheme` files](https://www.sublimetext.com/docs/color_schemes_tmtheme.html).\n\nFirst, create a folder with the new syntax highlighting themes:\n```bash\nmkdir -p \"$(bat --config-dir)/themes\"\ncd \"$(bat --config-dir)/themes\"\n\n# Download a theme in '.tmTheme' format, for example:\ngit clone https://github.com/greggb/sublime-snazzy\n\n# Update the binary cache\nbat cache --build\n```\n\nFinally, use `bat --list-themes` to check if the new themes are available.\n> [!NOTE]\n> `bat` uses the name of the `.tmTheme` file for the theme's name. \n\n### Adding or changing file type associations\n\nYou can add new (or change existing) file name patterns using the `--map-syntax`\ncommand line option. The option takes an argument of the form `pattern:syntax` where\n`pattern` is a glob pattern that is matched against the file name and\nthe absolute file path. The `syntax` part is the full name of a supported language\n(use `bat --list-languages` for an overview).\n\n**Note:** You probably want to use this option as [an entry in `bat`'s configuration file](#configuration-file)\nfor persistence instead of passing it on the command line as a one-off. Generally\nyou'd just use `-l` if you want to manually specify a language for a file.\n\nExample: To use \"INI\" syntax highlighting for all files with a `.conf` file extension, use\n```bash\n--map-syntax='*.conf:INI'\n```\n\nExample: To open all files called `.ignore` (exact match) with the \"Git Ignore\" syntax, use:\n```bash\n--map-syntax='.ignore:Git Ignore'\n```\n\nExample: To open all `.conf` files in subfolders of `/etc/apache2` with the \"Apache Conf\"\nsyntax, use (this mapping is already built in):\n```bash\n--map-syntax='/etc/apache2/**/*.conf:Apache Conf'\n```\n\n### Using a different pager\n\n`bat` uses the pager that is specified in the `PAGER` environment variable. If this variable is not\nset, `less` is used by default. You can also use bat's built-in pager with `--pager=builtin` or\nby setting the `BAT_PAGER` environment variable to \"builtin\".\n\nIf you want to use a different pager, you can either modify the `PAGER` variable or set the\n`BAT_PAGER` environment variable to override what is specified in `PAGER`.\n\n>[!NOTE]\n> If `PAGER` is `more` or `most`, `bat` will silently use `less` instead to ensure support for colors.\n\nIf you want to pass command-line arguments to the pager, you can also set them via the\n`PAGER`/`BAT_PAGER` variables:\n\n```bash\nexport BAT_PAGER=\"less -RFK\"\n```\n\nInstead of using environment variables, you can also use `bat`'s [configuration file](#configuration-file) to configure the pager (`--pager` option).\n\n\n### Using `less` as a pager\n\nWhen using `less` as a pager, `bat` will automatically pass extra options along to `less`\nto improve the experience. Specifically, `-R`/`--RAW-CONTROL-CHARS`, `-F`/`--quit-if-one-screen`,\n`-K`/`--quit-on-intr` and under certain conditions, `-X`/`--no-init` and/or `-S`/`--chop-long-lines`.\n\n>[!IMPORTANT]\n> These options will not be added if:\n> - The pager is not named `less`.\n> - The `--pager` argument contains any command-line arguments (e.g. `--pager=\"less -R\"`).\n> - The `BAT_PAGER` environment variable contains any command-line arguments (e.g. `export BAT_PAGER=\"less -R\"`)\n>\n> The `--quit-if-one-screen` option will not be added when:\n> - The `--paging=always` argument is used.\n> - The `BAT_PAGING` environment is set to `always`.\n\nThe `-R`/`--RAW-CONTROL-CHARS` option is needed to interpret ANSI colors correctly.\n\nThe `-F`/`--quit-if-one-screen` option instructs `less` to exit immediately if the output size is smaller than\nthe vertical size of the terminal. This is convenient for small files because you do not\nhave to press `q` to quit the pager.\n\nThe `-K`/`--quit-on-intr` option instructs `less` to exit immediately when an interrupt signal is received.\nThis is useful to ensure that `less` quits together with `bat` on SIGINT.\n\nThe `-X`/`--no-init` option is added to versions of `less` older than version 530 (older than 558 on Windows) to\nfix a bug with the `-F`/`--quit-if-one-screen` feature. Unfortunately, it also breaks mouse-wheel support in `less`.\nIf you want to enable mouse-wheel scrolling on older versions of `less` and do not mind losing\nthe quit-if-one-screen feature, you can set the pager (via `--pager` or `BAT_PAGER`) to `less -R`.\nFor `less` 530 or newer, it should work out of the box.\n\nThe `-S`/`--chop-long-lines` option is added when `bat`'s `-S`/`--chop-long-lines` option is used. This tells `less`\nto truncate any lines larger than the terminal width.\n\n### Indentation\n\n`bat` expands tabs to 4 spaces by itself, not relying on the pager. To change this, simply add the\n`--tabs` argument with the number of spaces you want to be displayed.\n\n**Note**: Defining tab stops for the pager (via the `--pager` argument by `bat`, or via the `LESS`\nenvironment variable for `less`) won't be taken into account because the pager will already get\nexpanded spaces instead of tabs. This behaviour is added to avoid indentation issues caused by the\nsidebar. Calling `bat` with `--tabs=0` will override it and let tabs be consumed by the pager.\n\n### Dark mode\n\nIf you make use of the dark mode feature in **macOS**, you might want to configure `bat` to use a different\ntheme based on the OS theme. The following snippet uses the `default` theme when in the _dark mode_\nand the `GitHub` theme when in the _light mode_.\n\n```bash\nalias cat=\"bat --theme auto:system --theme-dark default --theme-light GitHub\"\n```\n\nThe same dark mode feature is now available in **GNOME** and affects the `org.gnome.desktop.interface color-scheme` setting. The following code converts the above to use said setting.\n\n```bash\n# .bashrc\nsys_color_scheme_is_dark() {\n    condition=$(gsettings get org.gnome.desktop.interface color-scheme)\n    condition=$(echo \"$condition\" | tr -d \"[:space:]'\")\n    if [ $condition == \"prefer-dark\" ]; then\n        return 0\n    else\n        return 1\n    fi\n}\n\nbat_alias_wrapper() {\n    #get color scheme\n    sys_color_scheme_is_dark\n    if [[ $? -eq 0 ]]; then\n        # bat command with dark color scheme\n        bat --theme=default \"$@\"\n    else\n        # bat command with light color scheme\n        bat --theme=GitHub \"$@\"\n    fi\n}\nalias cat='bat_alias_wrapper'\n```\n\n\n## Configuration file\n\n`bat` can also be customized with a configuration file. The location of the file is dependent\non your operating system. To get the default path for your system, call\n```bash\nbat --config-file\n```\n\nAlternatively, you can use `BAT_CONFIG_PATH` or `BAT_CONFIG_DIR` environment variables to point `bat`\nto a non-default location of the configuration file or the configuration directory respectively:\n```bash\nexport BAT_CONFIG_PATH=\"/path/to/bat/bat.conf\"\nexport BAT_CONFIG_DIR=\"/path/to/bat\"\n```\n\nA default configuration file can be created with the `--generate-config-file` option.\n```bash\nbat --generate-config-file\n```\n\nThere is also now a systemwide configuration file, which is located under `/etc/bat/config` on\nLinux and Mac OS and `C:\\ProgramData\\bat\\config` on windows. If the system wide configuration\nfile is present, the content of the user configuration will simply be appended to it.\n\n### Format\n\nThe configuration file is a simple list of command line arguments. Use `bat --help` to see a full list of possible options and values. In addition, you can add comments by prepending a line with the `#` character.\n\nExample configuration file:\n```bash\n# Set the theme to \"TwoDark\"\n--theme=\"TwoDark\"\n\n# Show line numbers, Git modifications and file header (but no grid)\n--style=\"numbers,changes,header\"\n\n# Use italic text on the terminal (not supported on all terminals)\n--italic-text=always\n\n# Use C++ syntax for Arduino .ino files\n--map-syntax \"*.ino:C++\"\n```\n\n## Using `bat` on Windows\n\n`bat` mostly works out-of-the-box on Windows, but a few features may need extra configuration.\n\n### Prerequisites\n\nYou will need to install the [Visual C++ Redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) package.\n\n### Paging\n\nWindows only includes a very limited pager in the form of `more`. You can download a Windows binary\nfor `less` [from its homepage](http://www.greenwoodsoftware.com/less/download.html) or [through\nChocolatey](https://chocolatey.org/packages/Less). To use it, place the binary in a directory in\nyour `PATH` or [define an environment variable](#using-a-different-pager). The [Chocolatey package](#on-windows) installs `less` automatically.\n\n### Colors\n\nWindows 10 natively supports colors in both `conhost.exe` (Command Prompt) and PowerShell since\n[v1511](https://en.wikipedia.org/wiki/Windows_10_version_history#Version_1511_(November_Update)), as\nwell as in newer versions of bash. On earlier versions of Windows, you can use\n[Cmder](http://cmder.app/), which includes [ConEmu](https://conemu.github.io/).\n\n**Note:** Old versions of `less` do not correctly interpret colors on Windows. To fix this, you can add the optional Unix tools to your PATH when installing Git. If you donâ€™t have any other pagers installed, you can disable paging entirely by passing `--paging=never` or by setting `BAT_PAGER` to an empty string.\n\n### Cygwin\n\n`bat` on Windows does not natively support Cygwin's unix-style paths (`/cygdrive/*`). When passed an absolute cygwin path as an argument, `bat` will encounter the following error: `The system cannot find the path specified. (os error 3)`\n\nThis can be solved by creating a wrapper or adding the following function to your `.bash_profile` file:\n\n```bash\nbat() {\n    local index\n    local args=(\"$@\")\n    for index in $(seq 0 ${#args[@]}) ; do\n        case \"${args[index]}\" in\n        -*) continue;;\n        *)  [ -e \"${args[index]}\" ] && args[index]=\"$(cygpath --windows \"${args[index]}\")\";;\n        esac\n    done\n    command bat \"${args[@]}\"\n}\n```\n\n## Troubleshooting\n\n### Garbled output\n\nIf an input file contains color codes or other ANSI escape sequences or control characters, `bat` will have problems\nperforming syntax highlighting and text wrapping, and thus the output can become garbled.\n\nIf your version of `bat` supports the `--strip-ansi=auto` option, it can be used to remove such sequences\nbefore syntax highlighting. Alternatively, you may disable both syntax highlighting and wrapping by\npassing the `--color=never --wrap=never` options to `bat`.\n\n> [!NOTE]\n> The `auto` option of `--strip-ansi` avoids removing escape sequences when the syntax is plain text.\n\n### Terminals & colors\n\n`bat` handles terminals *with* and *without* truecolor support. However, the colors in most syntax\nhighlighting themes are not optimized for 8-bit colors. It is therefore strongly recommended\nthat you use a terminal with 24-bit truecolor support (`terminator`, `konsole`, `iTerm2`, ...),\nor use one of the basic [8-bit themes](#8-bit-themes) designed for a restricted set of colors.\nSee [this article](https://gist.github.com/XVilka/8346728) for more details and a full list of\nterminals with truecolor support.\n\nMake sure that your truecolor terminal sets the `COLORTERM` variable to either `truecolor` or\n`24bit`. Otherwise, `bat` will not be able to determine whether or not 24-bit escape sequences\nare supported (and fall back to 8-bit colors).\n\n### Line numbers and grid are hardly visible\n\nPlease try a different theme (see `bat --list-themes` for a list). The `OneHalfDark` and\n`OneHalfLight` themes provide grid and line colors that are brighter.\n\n### File encodings\n\n`bat` natively supports UTF-8 as well as UTF-16. For every other file encoding, you may need to\nconvert to UTF-8 first because the encodings can typically not be auto-detected. You can `iconv`\nto do so.\nExample: if you have a PHP file in Latin-1 (ISO-8859-1) encoding, you can call:\n``` bash\niconv -f ISO-8859-1 -t UTF-8 my-file.php | bat\n```\nNote: you might have to use the `-l`/`--language` option if the syntax can not be auto-detected\nby `bat`.\n\n## Development\n\n```bash\n# Recursive clone to retrieve all submodules\ngit clone --recursive https://github.com/sharkdp/bat\n\n# Build (debug version)\ncd bat\ncargo build --bins\n\n# Run unit tests and integration tests\ncargo test\n\n# Install (release version)\ncargo install --path . --locked\n\n# Build a bat binary with modified syntaxes and themes\nbash assets/create.sh\ncargo install --path . --locked --force\n```\n\nIf you want to build an application that uses `bat`'s pretty-printing\nfeatures as a library, check out the [the API documentation](https://docs.rs/bat/).\nNote that you have to use either `regex-onig` or `regex-fancy` as a feature\nwhen you depend on `bat` as a library.\n\n## Contributing\n\nTake a look at the [`CONTRIBUTING.md`](CONTRIBUTING.md) guide.\n\n## Maintainers\n\n- [sharkdp](https://github.com/sharkdp)\n- [eth-p](https://github.com/eth-p)\n- [keith-hall](https://github.com/keith-hall)\n- [Enselic](https://github.com/Enselic)\n\n## Security vulnerabilities\n\nSee [`SECURITY.md`](SECURITY.md).\n\n## Project goals and alternatives\n\n`bat` tries to achieve the following goals:\n\n- Provide beautiful, advanced syntax highlighting\n- Integrate with Git to show file modifications\n- Be a drop-in replacement for (POSIX) `cat`\n- Offer a user-friendly command-line interface\n\nThere are a lot of alternatives, if you are looking for similar programs. See\n[this document](doc/alternatives.md) for a comparison.\n\n## License\nCopyright (c) 2018-2025 [bat-developers](https://github.com/sharkdp/bat).\n\n`bat` is made available under the terms of either the MIT License or the Apache License 2.0, at your option.\n\nSee the [LICENSE-APACHE](LICENSE-APACHE) and [LICENSE-MIT](LICENSE-MIT) files for license details.\n",
      "stars_today": 14
    },
    {
      "id": 75277003,
      "name": "thingsboard",
      "full_name": "thingsboard/thingsboard",
      "description": "Open-source IoT Platform - Device management, data collection, processing and visualization.",
      "html_url": "https://github.com/thingsboard/thingsboard",
      "stars": 20991,
      "forks": 6062,
      "language": "Java",
      "topics": [
        "cloud",
        "coap",
        "dashboard",
        "iot",
        "iot-analytics",
        "iot-platform",
        "iot-solutions",
        "java",
        "kafka",
        "lwm2m",
        "microservices",
        "middleware",
        "mqtt",
        "netty",
        "platform",
        "snmp",
        "thingsboard",
        "visualization",
        "websockets",
        "widgets"
      ],
      "created_at": "2016-12-01T09:33:30Z",
      "updated_at": "2026-01-24T19:13:59Z",
      "pushed_at": "2026-01-24T09:57:07Z",
      "open_issues": 167,
      "owner": {
        "login": "thingsboard",
        "avatar_url": "https://avatars.githubusercontent.com/u/24291394?v=4"
      },
      "readme": "![banner](https://github.com/user-attachments/assets/3584b592-33dd-4fb4-91d4-47b62b34806c)\n\n<div align=\"center\">\n\n# Open-source IoT platform for data collection, processing, visualization, and device management.\n\n</div>\n<br>\n<div align=\"center\">\n \nğŸ’¡ [Get started](https://thingsboard.io/docs/getting-started-guides/helloworld/)&ensp;â€¢&ensp;ğŸŒ [Website](https://thingsboard.io/)&ensp;â€¢&ensp;ğŸ“š [Documentation](https://thingsboard.io/docs/)&ensp;â€¢&ensp;ğŸ“” [Blog](https://thingsboard.io/blog/)&ensp;â€¢&ensp;â–¶ï¸ [Live demo](https://demo.thingsboard.io/signup)&ensp;â€¢&ensp;ğŸ”— [LinkedIn](https://www.linkedin.com/company/thingsboard/posts/?feedView=all)\n\n</div>\n\n## ğŸš€ Installation options\n\n* Install ThingsBoard [On-premise](https://thingsboard.io/docs/user-guide/install/installation-options/?ceInstallType=onPremise)\n* Try [ThingsBoard Cloud](https://thingsboard.io/installations/)\n* or [Use our Live demo](https://demo.thingsboard.io/signup)\n\n## ğŸ’¡ Getting started with ThingsBoard\n\nCheck out our [Getting Started guide](https://thingsboard.io/docs/getting-started-guides/helloworld/) or [watch the video](https://www.youtube.com/watch?v=80L0ubQLXsc) to learn the basics of ThingsBoard and create your first dashboard! You will learn to:\n\n* Connect devices to ThingsBoard\n* Push data from devices to ThingsBoard\n* Build real-time dashboards\n* Create a Customer and assign the dashboard with them.\n* Define thresholds and trigger alarms\n* Set up notifications via email, SMS, mobile apps, or integrate with third-party services.\n\n## âœ¨ Features\n\n<table>\n  <tr>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/255cca4f-b111-44e8-99ea-0af55f8e3681\" alt=\"Provision and manage devices and assets\" width=\"378\" />\n        <h3>Provision and manage <br> devices and assets</h3>\n      </div>\n      <div align=\"center\">\n        <p>Provision, monitor and control your IoT entities in secure way using rich server-side APIs. Define relations between your devices, assets, customers or any other entities.</p>\n      </div>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/docs/user-guide/entities-and-relations/\">Read more âœ</a>\n      </div>\n      <br>\n    </td>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/24b41d10-150a-42dd-ab1a-32ac9b5978c1\" alt=\"Collect and visualize your data\" width=\"378\" />\n        <h3>Collect and visualize <br> your data</h3>\n      </div>\n      <div align=\"center\">\n        <p>Collect and store telemetry data in scalable and fault-tolerant way. Visualize your data with built-in or custom widgets and flexible dashboards. Share dashboards with your customers.</p>\n      </div>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/iot-data-visualization/\">Read more âœ</a>\n      </div>\n      <br>\n    </td>\n  </tr>\n  <tr>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/6f2a6dd2-7b33-4d17-8b92-d1f995adda2c\" alt=\"SCADA Dashboards\" width=\"378\" />\n        <h3>SCADA Dashboards</h3>\n      </div>\n      <div align=\"center\">\n        <p>Monitor and control your industrial processes in real time with SCADA. Use SCADA symbols on dashboards to create and manage any workflow, offering full flexibility to design and oversee operations according to your requirements.</p>\n      </div>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/use-cases/scada/\">Read more âœ</a>\n      </div>\n      <br>\n    </td>\n    <td width=\"50%\" valign=\"top\">\n      <br>\n      <div align=\"center\">\n        <img src=\"https://github.com/user-attachments/assets/c23dcc9b-aeba-40ef-9973-49b953fc1257\" alt=\"Process and React\" width=\"378\" />\n        <h3>Process and React</h3>\n      </div>\n      <div align=\"center\">\n        <p>Define data processing rule chains. Transform and normalize your device data. Raise alarms on incoming telemetry events, attribute updates, device inactivity and user actions.<br></p>\n      </div>\n      <br>\n      <br>\n      <div align=\"center\">\n        <a href=\"https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/\">Read more âœ</a>\n      </div>\n      <br>\n    </td>\n  </tr>\n</table>\n\n## âš™ï¸ Powerful IoT Rule Engine\n\nThingsBoard allows you to create complex [Rule Chains](https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/) to process data from your devices and match your application specific use cases.\n\n[![IoT Rule Engine](https://github.com/user-attachments/assets/43d21dc9-0e18-4f1b-8f9a-b72004e12f07 \"IoT Rule Engine\")](https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/)\n\n<div align=\"center\">\n\n[**Read more about Rule Engine âœ**](https://thingsboard.io/docs/user-guide/rule-engine-2-0/re-getting-started/)\n\n</div>\n\n## ğŸ“¦ Real-Time IoT Dashboards\n\nThingsBoard is a scalable, user-friendly, and device-agnostic IoT platform that speeds up time-to-market with powerful built-in solution templates. It enables data collection and analysis from any devices, saving resources on routine tasks and letting you focus on your solutionâ€™s unique aspects. See more our Use Cases [here](https://thingsboard.io/iot-use-cases/).\n\n[**Smart energy**](https://thingsboard.io/use-cases/smart-energy/)\n\n[![Smart energy](https://github.com/user-attachments/assets/2a0abf13-6dc5-4f5e-9c30-1aea1d39af1e \"Smart energy\")](https://thingsboard.io/use-cases/smart-energy/)\n\n[**SCADA swimming pool**](https://thingsboard.io/use-cases/scada/)\n\n[![SCADA Swimming pool](https://github.com/user-attachments/assets/68fd9e29-99f1-4c16-8c4c-476f4ccb20c0 \"SCADA Swimming pool\")](https://thingsboard.io/use-cases/scada/)\n\n[**Site fleet tracking**](https://thingsboard.io/use-cases/site-fleet-tracking/)\n\n[![Site fleet tracking](https://github.com/user-attachments/assets/d6ce0766-b138-4a42-86aa-7112a543026c \"Site fleet tracking\")](https://thingsboard.io/use-cases/site-fleet-tracking/)\n\n[**Smart farming**](https://thingsboard.io/use-cases/smart-farming/)\n\n[![Smart farming](https://github.com/user-attachments/assets/56b84c99-ef24-44e5-a903-b925b7f9d142 \"Smart farming\")](https://thingsboard.io/use-cases/smart-farming/)\n\n[**Smart metering**](https://thingsboard.io/smart-metering/)\n\n[![Smart metering](https://github.com/user-attachments/assets/adc05e3d-397c-48ef-bed6-535bbd698455 \"Smart metering\")](https://thingsboard.io/smart-metering/)\n\n<div align=\"center\">\n\n[**Check more of our use cases âœ**](https://thingsboard.io/iot-use-cases/)\n\n</div>\n\n## ğŸ«¶ Support\n\nTo get support, please visit our [GitHub issues page](https://github.com/thingsboard/thingsboard/issues)\n\n## ğŸ“„ Licenses\n\nThis project is released under [Apache 2.0 License](./LICENSE)\n",
      "stars_today": 14
    },
    {
      "id": 1058017661,
      "name": "LaunchNext",
      "full_name": "RoversX/LaunchNext",
      "description": "Bring your Launchpad back in MacOS26+ ,highly customizable, powerful, free.",
      "html_url": "https://github.com/RoversX/LaunchNext",
      "stars": 2039,
      "forks": 104,
      "language": "Swift",
      "topics": [],
      "created_at": "2025-09-16T14:08:59Z",
      "updated_at": "2026-01-24T19:42:46Z",
      "pushed_at": "2026-01-16T15:36:39Z",
      "open_issues": 124,
      "owner": {
        "login": "RoversX",
        "avatar_url": "https://avatars.githubusercontent.com/u/85817538?v=4"
      },
      "readme": "# LaunchNext\n\n**Languages**: [English](README.md) | [ä¸­æ–‡](i18n/README.zh.md) | [æ—¥æœ¬èª](i18n/README.ja.md) | [í•œêµ­ì–´](i18n/README.ko.md) | [FranÃ§ais](i18n/README.fr.md) | [EspaÃ±ol](i18n/README.es.md) | [Deutsch](i18n/README.de.md) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](i18n/README.ru.md) | [à¤¹à¤¿à¤¨à¥à¤¦à¥€](i18n/README.hi.md) | [Tiáº¿ng Viá»‡t](i18n/README.vi.md) | [Italiano](i18n/README.it.md) | [ÄŒeÅ¡tina](i18n/README.cs.md)\n\n## ğŸ“¥ Download\n\n**[Download here](https://github.com/RoversX/LaunchNext/releases/latest)** - Get the latest release\n\nâ­ Consider starring [LaunchNext](https://github.com/RoversX/LaunchNext) and especially [LaunchNow](https://github.com/ggkevinnnn/LaunchNow)!\n\n| | |\n|:---:|:---:|\n| ![](./public/banner.webp) | ![](./public/setting1.webp) |\n| ![](./public/setting2.webp) | ![](./public/setting3.webp) |\n\nMacOS Tahoe removed launchpad,and it's so hard to use, it's doesn't use your Bio GPU, please apple, at least give people an option to switch back. Before that, here is LaunchNext\n\n*Built upon [LaunchNow](https://github.com/ggkevinnnn/LaunchNow) by ggkevinnnn - huge thanks to the original project! I hope this enhanced version can be merged back to the original repository*\n\n*LaunchNow has chosen the GPL 3 license. LaunchNext follows the same licensing terms.*\n\nâš ï¸ **If macOS blocks the app, run this in Terminal:**\n```bash\nsudo xattr -r -d com.apple.quarantine /Applications/LaunchNext.app\n```\n**Why**: I can't afford Apple's developer certificate ($99/year), so macOS blocks unsigned apps. This command removes the quarantine flag to let it run. **Only use this command on apps you trust.**\n\n### What LaunchNext Delivers\n- âœ… **One-click import from old system Launchpad** - directly reads your native Launchpad SQLite database (`/private$(getconf DARWIN_USER_DIR)com.apple.dock.launchpad/db/db`) to perfectly recreate your existing folders, app positions, and layout\n- âœ… **Classic Launchpad experience** - works exactly like the beloved original interface\n- âœ… **Multi-language support** - full internationalization with English, Chinese, Japanese, French, Spanish, German, and Russian\n- âœ… **Hide icon labels** - clean, minimalist view when you don't need app names\n- âœ… **Custom icon sizes** - adjust icon dimensions to fit your preferences\n- âœ… **Smart folder management** - create and organize folders just like before\n- âœ… **Instant search and keyboard navigation** - find apps quickly\n\n### What We Lost in macOS Tahoe\n- âŒ No custom app organization\n- âŒ No user-created folders\n- âŒ No drag-and-drop customization\n- âŒ No visual app management\n- âŒ Forced categorical grouping\n\n\n### Data Storage\nApplication data is safely stored in:\n```\n~/Library/Application Support/LaunchNext/Data.store\n```\n\n### Native Launchpad Integration\nReads directly from the system Launchpad database:\n```bash\n/private$(getconf DARWIN_USER_DIR)com.apple.dock.launchpad/db/db\n```\n\n## Installation\n\n### Requirements\n- macOS 26 (Tahoe) or later\n- Apple Silicon or Intel processor\n- Xcode 26 (for building from source)\n\n### Build from Source\n\n1. **Clone the repository**\n   ```bash\n   git clone https://github.com/yourusername/LaunchNext.git\n   cd LaunchNext\n   ```\n\n2. **Open in Xcode**\n   ```bash\n   open LaunchNext.xcodeproj\n   ```\n\n3. **Build and run**\n   - Select your target device\n   - Press `âŒ˜+R` to build and run\n   - Or `âŒ˜+B` to build only\n\n### Command Line Build\n\n**Regular Build:**\n```bash\nxcodebuild -project LaunchNext.xcodeproj -scheme LaunchNext -configuration Release\n```\n\n**Universal Binary Build (Intel + Apple Silicon):**\n```bash\nxcodebuild -project LaunchNext.xcodeproj -scheme LaunchNext -configuration Release ARCHS=\"arm64 x86_64\" ONLY_ACTIVE_ARCH=NO clean build\n```\n\n## Usage\n\n### Getting Started\n1. **First Launch**: LaunchNext automatically scans all installed applications\n2. **Select**: Click to select apps, double-click to launch\n3. **Search**: Type to instantly filter applications\n4. **Organize**: Drag apps to create folders and custom layouts\n\n### Import Your Launchpad\n1. Open Settings (gear icon)\n2. Click **\"Import Launchpad\"**\n3. Your existing layout and folders are automatically imported\n\n\n### Display Modes\n- **Windowed**: Floating window with rounded corners\n- **Fullscreen**: Full-screen mode for maximum visibility\n- Switch modes in Settings\n\n## Advanced Features\n\n### Smart Background Interaction\n- Intelligent click detection prevents accidental dismissal\n- Context-aware gesture handling\n- Search field protection\n\n### Performance Optimization\n- **Icon Caching**: Intelligent image caching for smooth scrolling\n- **Lazy Loading**: Efficient memory usage\n- **Background Scanning**: Non-blocking app discovery\n\n### Multi-Display Support\n- Automatic screen detection\n- Per-display positioning\n- Seamless multi-monitor workflows\n\n## Troubleshooting\n\n### Common Issues\n\n**Q: App won't start?**\nA: Ensure macOS 26.0+ and check system permissions.\n\n## Contributing\n\nWe welcome contributions! Please:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit changes (`git commit -m 'Add amazing feature'`)\n4. Push to branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n### Development Guidelines\n- Follow Swift style conventions\n- Add meaningful comments for complex logic\n- Test on multiple macOS versions\n- Maintain backward compatibility\n\n## The Future of App Management\n\nAs Apple moves away from customizable interfaces, LaunchNext represents the community's commitment to user control and personalization. I hope apple cound bring launchpad back.\n\n**LaunchNext** isn't just a Launchpad replacementâ€”it's a statement that user choice matters.\n\n\n---\n\n**LaunchNext** - Reclaim Your App Launcher ğŸš€\n\n*Built for macOS users who refuse to compromise on customization.*\n\n## Development Tools\n\n- Claude Code \n- Cursor \n- OpenAI Codex Cli\n- Perplexity\n- Google\n\n\n![GitHub downloads](https://img.shields.io/github/downloads/RoversX/LaunchNext/total)\n",
      "stars_today": 14
    },
    {
      "id": 999686447,
      "name": "vscode-copilot-chat",
      "full_name": "microsoft/vscode-copilot-chat",
      "description": "Copilot Chat extension for VS Code",
      "html_url": "https://github.com/microsoft/vscode-copilot-chat",
      "stars": 9333,
      "forks": 1605,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2025-06-10T16:21:19Z",
      "updated_at": "2026-01-25T00:43:07Z",
      "pushed_at": "2026-01-25T00:43:05Z",
      "open_issues": 138,
      "owner": {
        "login": "microsoft",
        "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
      },
      "readme": "# GitHub Copilot - Your AI peer programmer\n\n**[GitHub Copilot](https://code.visualstudio.com/docs/copilot/overview)** is an AI peer programming tool that helps you write code faster and smarter.\n\nGitHub Copilot adapts to your unique needs allowing you to select the best model for your project, customize chat responses with custom instructions, and utilize agent mode for AI-powered, seamlessly integrated peer programming sessions.\n\n**Sign up for [GitHub Copilot Free](https://github.com/settings/copilot?utm_source=vscode-chat-readme&utm_medium=first&utm_campaign=2025mar-em-MSFT-signup)!**\n\n![Working with GitHub Copilot agent mode to make edits to code in your workspace](https://github.com/microsoft/vscode-copilot-release/blob/main/images/hero-dark.png?raw=true)\n\nWhen you install Copilot in Visual Studio Code, you get two extensions:\n* **[GitHub Copilot](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot)** - Provides inline coding suggestions as you type.\n* **[GitHub Copilot Chat](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-chat)** (this extension) - A companion extension that provides conversational AI assistance.\n\n## Getting access to GitHub Copilot\n\nSign up for [GitHub Copilot Free](https://github.com/settings/copilot?utm_source=vscode-chat-readme&utm_medium=second&utm_campaign=2025mar-em-MSFT-signup), or request access from your enterprise admin.\n\nTo access GitHub Copilot, an active GitHub Copilot subscription is required. You can read more about our business and individual offerings at [github.com/features/copilot](https://github.com/features/copilot?utm_source=vscode-chat&utm_medium=readme&utm_campaign=2025mar-em-MSFT-signup).\n\n## AI-powered coding sessions\n\n**Start an AI-powered coding session tailored to your workflow**. Copilot Edits allows you to quickly iterate on code changes directly in the editor, across multiple files using natural language. For a more autonomous peer programmer experience,\n[agent mode](https://aka.ms/vscode-copilot-agent) performs multi-step coding tasks at your command. It automatically handles compile and lint errors, monitors terminal and test output, and iterates until the task is complete. [Edit mode](https://aka.ms/vscode-copilot-edit) offers a conversational, step-by-step coding experience. Engage in multi-turn chat conversations while Copilot applies edits directly to your codebase, allowing you to review changes in context and maintain full control.\n\n![Agent mode in Copilot Chat creating a new Vue application](https://github.com/microsoft/vscode-copilot-release/blob/main/images/agent-mode-readme.gif?raw=true)\n\n## Inline suggestions in the editor\n\n**Automatically receive inline suggestions in the editor** from [ghost text suggestions](https://aka.ms/vscode-completions) and [next edit suggestions](https://aka.ms/vscode-nes) to help you write code faster. Ghost text suggestions provide suggestions at the current location, tailored to your coding style and your existing code. Copilot next edit suggestions (Copilot NES) takes it a step further and predicts what and where your next logical code change will be. Use the Tab key to navigate and accept changes in quick succession.\n\n![Copilot next edit suggestions](https://code.visualstudio.com/assets/docs/copilot/inline-suggestions/nes-point.gif)\n\n## Ask and learn about your code with chat\n\n**Ask Copilot for help with any task or question** in the [Chat view](https://aka.ms/vscode-chat), bringing in code from your current files. Rather than giving you a generic answer, it can give answers that are relevant for your codebase using information provided by [participants](https://aka.ms/vscode-chat-participants), [variables](https://aka.ms/vscode-chat-variables), and [slash commands](https://aka.ms/vscode-chat-commands).\n\n![Using the workspace chat participant](https://github.com/microsoft/vscode-copilot-release/blob/main/images/participants-workspace.gif?raw=true)\n\n**Apply Copilot's AI suggestions directly to your code** using [Inline chat](https://aka.ms/vscode-inline-chat), staying in the flow. Need help with refactoring a method, adding error handling, or explaining a complex algorithm - just launch Copilot in the editor!\n\n![Inline chat in VS Code](https://code.visualstudio.com/assets/docs/copilot/copilot-chat/inline-chat-question-example.png)\n\n### Supported languages and frameworks\n\nGitHub Copilot works on any language, including Java, PHP, Python, JavaScript, Ruby, Go, C#, or C++. Because itâ€™s been trained on languages in public repositories, it works for most popular languages, libraries and frameworks.\n\n### Version compatibility\n\nAs Copilot Chat releases in lockstep with VS Code due to its deep UI integration, every new version of Copilot Chat is only compatible with the latest and newest release of VS Code. This means that if you are using an older version of VS Code, you will not be able to use the latest Copilot Chat.\n\nOnly the latest Copilot Chat versions will use the latest models provided by the Copilot service, as even minor model upgrades require prompt changes and fixes in the extension.\n\n### Privacy and preview terms\n\nBy using Copilot Chat you agree to [GitHub Copilot chat preview terms](https://docs.github.com/en/early-access/copilot/github-copilot-chat-technical-preview-license-terms). Review the [transparency note](https://aka.ms/CopilotChatTransparencyNote) to understand about usage, limitations and ways to improve Copilot Chat during the technical preview.\n\nYour code is yours. We follow responsible practices in accordance with our [Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement) to ensure that your code snippets will not be used as suggested code for other users of GitHub Copilot.\n\nTo get the latest security fixes, please use the latest version of the Copilot extension and VS Code.\n\n### Resources & next steps\n* **Sign up for [GitHub Copilot Free](https://github.com/settings/copilot?utm_source=vscode-chat-readme&utm_medium=third&utm_campaign=2025mar-em-MSFT-signup)**\n    * If you're using Copilot for your business, check out [Copilot Business](https://docs.github.com/en/copilot/copilot-business/about-github-copilot-business) and [Copilot Enterprise](https://docs.github.com/en/copilot/github-copilot-enterprise/overview/about-github-copilot-enterprise)\n* **[Get started with Copilot in VS Code tutorial](https://code.visualstudio.com/docs/copilot/getting-started)**\n* **[Copilot Chat quickstart video](https://www.youtube.com/watch?v=3surPGP7_4o)** to learn Copilot Chat in less than 4 minutes\n* **[VS Code Copilot Series on YouTube](https://www.youtube.com/playlist?list=PLj6YeMhvp2S5_hvBl2SE-7YCHYlLQ0bPt)**\n* **[FAQ](https://code.visualstudio.com/docs/copilot/faq)**\n* **[Feedback](https://github.com/microsoft/vscode-copilot-release/issues)**: We'd love to get your help in making GitHub Copilot better!\n\n## Data and telemetry\n\nThe GitHub Copilot Extension for Visual Studio Code collects usage data and sends it to Microsoft to help improve our products and services. Read our [privacy statement](https://privacy.microsoft.com/privacystatement) to learn more. This extension respects the `telemetry.telemetryLevel` setting which you can learn more about at https://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.\n\n## License\n\nCopyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the [MIT](LICENSE.txt) license.\n",
      "stars_today": 13
    },
    {
      "id": 59522149,
      "name": "terragrunt",
      "full_name": "gruntwork-io/terragrunt",
      "description": "Terragrunt is a flexible orchestration tool that allows Infrastructure as Code written in OpenTofu/Terraform to scale.",
      "html_url": "https://github.com/gruntwork-io/terragrunt",
      "stars": 9233,
      "forks": 1135,
      "language": "Go",
      "topics": [
        "aws",
        "cli",
        "developer-tools",
        "devops",
        "opentofu",
        "terraform"
      ],
      "created_at": "2016-05-23T22:17:48Z",
      "updated_at": "2026-01-24T22:30:38Z",
      "pushed_at": "2026-01-25T00:21:19Z",
      "open_issues": 242,
      "owner": {
        "login": "gruntwork-io",
        "avatar_url": "https://avatars.githubusercontent.com/u/17118990?v=4"
      },
      "readme": "# Terragrunt\n\n[![Maintained by Gruntwork.io](https://img.shields.io/badge/maintained%20by-gruntwork.io-%235849a6.svg)](https://gruntwork.io/?ref=repo_terragrunt)\n[![Go Report Card](https://goreportcard.com/badge/github.com/gruntwork-io/terragrunt)](https://goreportcard.com/report/github.com/gruntwork-io/terragrunt)\n[![GoDoc](https://godoc.org/github.com/gruntwork-io/terragrunt?status.svg)](https://godoc.org/github.com/gruntwork-io/terragrunt)\n![OpenTofu Version](https://img.shields.io/badge/tofu-%3E%3D1.6.0-blue.svg)\n![Terraform Version](https://img.shields.io/badge/tf-%3E%3D0.12.0-blue.svg)\n\nTerragrunt is a flexible orchestration tool that allows Infrastructure as Code written in [OpenTofu](https://opentofu.org)/[Terraform](https://www.terraform.io) to scale.\n\nPlease see the following for more info, including install instructions and complete documentation:\n\n* [Terragrunt Website](https://terragrunt.gruntwork.io)\n* [Getting started with Terragrunt](https://terragrunt.gruntwork.io/docs/getting-started/quick-start/)\n* [Terragrunt Documentation](https://terragrunt.gruntwork.io/docs)\n* [Contributing to Terragrunt](https://terragrunt.gruntwork.io/docs/community/contributing)\n* [Commercial Support](https://gruntwork.io/support/)\n\n## Join the Discord!\n\nJoin [our community](https://discord.gg/vBCsJQRb) for discussions, support, and contributions:\n\n[![](https://dcbadge.limes.pink/api/server/https://discord.gg/YENaT9h8jh)](https://discord.gg/YENaT9h8jh)\n\n## License\n\nThis code is released under the MIT License. See [LICENSE.txt](LICENSE.txt).\n\n",
      "stars_today": 13
    },
    {
      "id": 45717250,
      "name": "tensorflow",
      "full_name": "tensorflow/tensorflow",
      "description": "An Open Source Machine Learning Framework for Everyone",
      "html_url": "https://github.com/tensorflow/tensorflow",
      "stars": 193473,
      "forks": 75205,
      "language": "C++",
      "topics": [
        "deep-learning",
        "deep-neural-networks",
        "distributed",
        "machine-learning",
        "ml",
        "neural-network",
        "python",
        "tensorflow"
      ],
      "created_at": "2015-11-07T01:19:20Z",
      "updated_at": "2026-01-25T01:38:07Z",
      "pushed_at": "2026-01-25T01:33:50Z",
      "open_issues": 2733,
      "owner": {
        "login": "tensorflow",
        "avatar_url": "https://avatars.githubusercontent.com/u/15658638?v=4"
      },
      "readme": "<div align=\"center\">\n  <img src=\"https://www.tensorflow.org/images/tf_logo_horizontal.png\">\n</div>\n\n[![Python](https://img.shields.io/pypi/pyversions/tensorflow.svg)](https://badge.fury.io/py/tensorflow)\n[![PyPI](https://badge.fury.io/py/tensorflow.svg)](https://badge.fury.io/py/tensorflow)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4724125.svg)](https://doi.org/10.5281/zenodo.4724125)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1486/badge)](https://bestpractices.coreinfrastructure.org/projects/1486)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/tensorflow/tensorflow/badge)](https://securityscorecards.dev/viewer/?uri=github.com/tensorflow/tensorflow)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/tensorflow.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:tensorflow)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/tensorflow-py.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:tensorflow-py)\n[![OSSRank](https://shields.io/endpoint?url=https://ossrank.com/shield/44)](https://ossrank.com/p/44)\n[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-v1.4%20adopted-ff69b4.svg)](CODE_OF_CONDUCT.md)\n\n**`Documentation`** |\n------------------- |\n[![Documentation](https://img.shields.io/badge/api-reference-blue.svg)](https://www.tensorflow.org/api_docs/) |\n\n[TensorFlow](https://www.tensorflow.org/) is an end-to-end open source platform\nfor machine learning. It has a comprehensive, flexible ecosystem of\n[tools](https://www.tensorflow.org/resources/tools),\n[libraries](https://www.tensorflow.org/resources/libraries-extensions), and\n[community](https://www.tensorflow.org/community) resources that lets\nresearchers push the state-of-the-art in ML and developers easily build and\ndeploy ML-powered applications.\n\nTensorFlow was originally developed by researchers and engineers working within\nthe Machine Intelligence team at Google Brain to conduct research in machine\nlearning and neural networks. However, the framework is versatile enough to be\nused in other areas as well.\n\nTensorFlow provides stable [Python](https://www.tensorflow.org/api_docs/python)\nand [C++](https://www.tensorflow.org/api_docs/cc) APIs, as well as a\nnon-guaranteed backward compatible API for\n[other languages](https://www.tensorflow.org/api_docs).\n\nKeep up-to-date with release announcements and security updates by subscribing\nto\n[announce@tensorflow.org](https://groups.google.com/a/tensorflow.org/forum/#!forum/announce).\nSee all the [mailing lists](https://www.tensorflow.org/community/forums).\n\n## Install\n\nSee the [TensorFlow install guide](https://www.tensorflow.org/install) for the\n[pip package](https://www.tensorflow.org/install/pip), to\n[enable GPU support](https://www.tensorflow.org/install/gpu), use a\n[Docker container](https://www.tensorflow.org/install/docker), and\n[build from source](https://www.tensorflow.org/install/source).\n\nTo install the current release, which includes support for\n[CUDA-enabled GPU cards](https://www.tensorflow.org/install/gpu) *(Ubuntu and\nWindows)*:\n\n```\n$ pip install tensorflow\n```\n\nOther devices (DirectX and MacOS-metal) are supported using\n[Device Plugins](https://www.tensorflow.org/install/gpu_plugins#available_devices).\n\nA smaller CPU-only package is also available:\n\n```\n$ pip install tensorflow-cpu\n```\n\nTo update TensorFlow to the latest version, add `--upgrade` flag to the above\ncommands.\n\n*Nightly binaries are available for testing using the\n[tf-nightly](https://pypi.python.org/pypi/tf-nightly) and\n[tf-nightly-cpu](https://pypi.python.org/pypi/tf-nightly-cpu) packages on PyPI.*\n\n#### *Try your first TensorFlow program*\n\n```shell\n$ python\n```\n\n```python\n>>> import tensorflow as tf\n>>> tf.add(1, 2).numpy()\n3\n>>> hello = tf.constant('Hello, TensorFlow!')\n>>> hello.numpy()\nb'Hello, TensorFlow!'\n```\n\nFor more examples, see the\n[TensorFlow Tutorials](https://www.tensorflow.org/tutorials/).\n\n## Contribution guidelines\n\n**If you want to contribute to TensorFlow, be sure to review the\n[Contribution Guidelines](CONTRIBUTING.md). This project adheres to TensorFlow's\n[Code of Conduct](CODE_OF_CONDUCT.md). By participating, you are expected to\nuphold this code.**\n\n**We use [GitHub Issues](https://github.com/tensorflow/tensorflow/issues) for\ntracking requests and bugs, please see\n[TensorFlow Forum](https://discuss.tensorflow.org/) for general questions and\ndiscussion, and please direct specific questions to\n[Stack Overflow](https://stackoverflow.com/questions/tagged/tensorflow).**\n\nThe TensorFlow project strives to abide by generally accepted best practices in\nopen-source software development.\n\n## Patching guidelines\n\nFollow these steps to patch a specific version of TensorFlow, for example, to\napply fixes to bugs or security vulnerabilities:\n\n*   Clone the TensorFlow repository and switch to the appropriate branch for\n    your desired versionâ€”for example, `r2.8` for version 2.8.\n*   Apply the desired changes (i.e., cherry-pick them) and resolve any code\n    conflicts.\n*   Run TensorFlow tests and ensure they pass.\n*   [Build](https://www.tensorflow.org/install/source) the TensorFlow pip\n    package from source.\n\n## Continuous build status\n\nYou can find more community-supported platforms and configurations in the\n[TensorFlow SIG Build Community Builds Table](https://github.com/tensorflow/build#community-supported-tensorflow-builds).\n\n### Official Builds\n\nBuild Type                    | Status                                                                                                                                                                           | Artifacts\n----------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------\n**Linux CPU**                 | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-cc.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-cc.html)           | [PyPI](https://pypi.org/project/tf-nightly/)\n**Linux GPU**                 | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-gpu-py3.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-gpu-py3.html) | [PyPI](https://pypi.org/project/tf-nightly-gpu/)\n**Linux XLA**                 | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-xla.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-xla.html)         | TBA\n**macOS**                     | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/macos-py2-cc.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/macos-py2-cc.html)     | [PyPI](https://pypi.org/project/tf-nightly/)\n**Windows CPU**               | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-cpu.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-cpu.html)       | [PyPI](https://pypi.org/project/tf-nightly/)\n**Windows GPU**               | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-gpu.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-gpu.html)       | [PyPI](https://pypi.org/project/tf-nightly-gpu/)\n**Android**                   | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/android.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/android.html)               | [Download](https://bintray.com/google/tensorflow/tensorflow/_latestVersion)\n**Raspberry Pi 0 and 1**      | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi01-py3.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi01-py3.html)           | [Py3](https://storage.googleapis.com/tensorflow-nightly/tensorflow-1.10.0-cp34-none-linux_armv6l.whl)\n**Raspberry Pi 2 and 3**      | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi23-py3.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi23-py3.html)           | [Py3](https://storage.googleapis.com/tensorflow-nightly/tensorflow-1.10.0-cp34-none-linux_armv7l.whl)\n**Libtensorflow MacOS CPU**   | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/macos/latest/macos_cpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n**Libtensorflow Linux CPU**   | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/ubuntu_16/latest/cpu/ubuntu_cpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n**Libtensorflow Linux GPU**   | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/ubuntu_16/latest/gpu/ubuntu_gpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n**Libtensorflow Windows CPU** | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/windows/latest/cpu/windows_cpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n**Libtensorflow Windows GPU** | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/windows/latest/gpu/windows_gpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n\n## Resources\n\n*   [TensorFlow.org](https://www.tensorflow.org)\n*   [TensorFlow Tutorials](https://www.tensorflow.org/tutorials/)\n*   [TensorFlow Official Models](https://github.com/tensorflow/models/tree/master/official)\n*   [TensorFlow Examples](https://github.com/tensorflow/examples)\n*   [TensorFlow Codelabs](https://codelabs.developers.google.com/?cat=TensorFlow)\n*   [TensorFlow Blog](https://blog.tensorflow.org)\n*   [Learn ML with TensorFlow](https://www.tensorflow.org/resources/learn-ml)\n*   [TensorFlow Twitter](https://twitter.com/tensorflow)\n*   [TensorFlow YouTube](https://www.youtube.com/channel/UC0rqucBdTuFTjJiefW5t-IQ)\n*   [TensorFlow model optimization roadmap](https://www.tensorflow.org/model_optimization/guide/roadmap)\n*   [TensorFlow White Papers](https://www.tensorflow.org/about/bib)\n*   [TensorBoard Visualization Toolkit](https://github.com/tensorflow/tensorboard)\n*   [TensorFlow Code Search](https://cs.opensource.google/tensorflow/tensorflow)\n\nLearn more about the\n[TensorFlow Community](https://www.tensorflow.org/community) and how to\n[Contribute](https://www.tensorflow.org/community/contribute).\n\n## Courses\n\n* [Coursera](https://www.coursera.org/search?query=TensorFlow)\n* [Udacity](https://www.udacity.com/courses/all?search=TensorFlow)\n* [Edx](https://www.edx.org/search?q=TensorFlow)\n\n## License\n\n[Apache License 2.0](LICENSE)\n",
      "stars_today": 12
    },
    {
      "id": 9384267,
      "name": "electron",
      "full_name": "electron/electron",
      "description": ":electron: Build cross-platform desktop apps with JavaScript, HTML, and CSS",
      "html_url": "https://github.com/electron/electron",
      "stars": 119881,
      "forks": 16947,
      "language": "C++",
      "topics": [
        "c-plus-plus",
        "chrome",
        "css",
        "electron",
        "html",
        "javascript",
        "nodejs",
        "v8",
        "works-with-codespaces"
      ],
      "created_at": "2013-04-12T01:47:36Z",
      "updated_at": "2026-01-25T00:18:32Z",
      "pushed_at": "2026-01-24T22:50:49Z",
      "open_issues": 911,
      "owner": {
        "login": "electron",
        "avatar_url": "https://avatars.githubusercontent.com/u/13409222?v=4"
      },
      "readme": "[![Electron Logo](https://electronjs.org/images/electron-logo.svg)](https://electronjs.org)\n\n[![GitHub Actions Build Status](https://github.com/electron/electron/actions/workflows/build.yml/badge.svg)](https://github.com/electron/electron/actions/workflows/build.yml)\n[![Electron Discord Invite](https://img.shields.io/discord/745037351163527189?color=%237289DA&label=chat&logo=discord&logoColor=white)](https://discord.gg/electronjs)\n\n:memo: Available Translations: ğŸ‡¨ğŸ‡³ ğŸ‡§ğŸ‡· ğŸ‡ªğŸ‡¸ ğŸ‡¯ğŸ‡µ ğŸ‡·ğŸ‡º ğŸ‡«ğŸ‡· ğŸ‡ºğŸ‡¸ ğŸ‡©ğŸ‡ª.\nView these docs in other languages on our [Crowdin](https://crowdin.com/project/electron) project.\n\nThe Electron framework lets you write cross-platform desktop applications\nusing JavaScript, HTML and CSS. It is based on [Node.js](https://nodejs.org/) and\n[Chromium](https://www.chromium.org) and is used by the\n[Visual Studio Code](https://github.com/Microsoft/vscode/) and many other [apps](https://electronjs.org/apps).\n\nFollow [@electronjs](https://twitter.com/electronjs) on Twitter for important\nannouncements.\n\nThis project adheres to the Contributor Covenant\n[code of conduct](https://github.com/electron/electron/tree/main/CODE_OF_CONDUCT.md).\nBy participating, you are expected to uphold this code. Please report unacceptable\nbehavior to [coc@electronjs.org](mailto:coc@electronjs.org).\n\n## Installation\n\nTo install prebuilt Electron binaries, use [`npm`](https://docs.npmjs.com/).\nThe preferred method is to install Electron as a development dependency in your\napp:\n\n```sh\nnpm install electron --save-dev\n```\n\nFor more installation options and troubleshooting tips, see\n[installation](docs/tutorial/installation.md). For info on how to manage Electron versions in your apps, see\n[Electron versioning](docs/tutorial/electron-versioning.md).\n\n## Platform support\n\nEach Electron release provides binaries for macOS, Windows, and Linux.\n\n* macOS (Monterey and up): Electron provides 64-bit Intel and Apple Silicon / ARM binaries for macOS.\n* Windows (Windows 10 and up): Electron provides `ia32` (`x86`), `x64` (`amd64`), and `arm64` binaries for Windows. Windows on ARM support was added in Electron 5.0.8. Support for Windows 7, 8 and 8.1 was [removed in Electron 23, in line with Chromium's Windows deprecation policy](https://www.electronjs.org/blog/windows-7-to-8-1-deprecation-notice).\n* Linux: The prebuilt binaries of Electron are built on Ubuntu 22.04. They have also been verified to work on:\n  * Ubuntu 18.04 and newer\n  * Fedora 32 and newer\n  * Debian 10 and newer\n\n## Electron Fiddle\n\nUse [`Electron Fiddle`](https://github.com/electron/fiddle)\nto build, run, and package small Electron experiments, to see code examples for all of Electron's APIs, and\nto try out different versions of Electron. It's designed to make the start of your journey with\nElectron easier.\n\n## Resources for learning Electron\n\n* [electronjs.org/docs](https://electronjs.org/docs) - All of Electron's documentation\n* [electron/fiddle](https://github.com/electron/fiddle) - A tool to build, run, and package small Electron experiments\n* [electronjs.org/community#boilerplates](https://electronjs.org/community#boilerplates) - Sample starter apps created by the community\n\n## Programmatic usage\n\nMost people use Electron from the command line, but if you require `electron` inside\nyour **Node app** (not your Electron app) it will return the file path to the\nbinary. Use this to spawn Electron from Node scripts:\n\n```javascript\nconst electron = require('electron')\nconst proc = require('node:child_process')\n\n// will print something similar to /Users/maf/.../Electron\nconsole.log(electron)\n\n// spawn Electron\nconst child = proc.spawn(electron)\n```\n\n### Mirrors\n\n* [China](https://npmmirror.com/mirrors/electron/)\n\nSee the [Advanced Installation Instructions](https://www.electronjs.org/docs/latest/tutorial/installation#mirror) to learn how to use a custom mirror.\n\n## Documentation translations\n\nWe crowdsource translations for our documentation via [Crowdin](https://crowdin.com/project/electron).\nWe currently accept translations for Chinese (Simplified), French, German, Japanese, Portuguese,\nRussian, and Spanish.\n\n## Contributing\n\nIf you are interested in reporting/fixing issues and contributing directly to the code base, please see [CONTRIBUTING.md](CONTRIBUTING.md) for more information on what we're looking for and how to get started.\n\n## Community\n\nInfo on reporting bugs, getting help, finding third-party tools and sample apps,\nand more can be found on the [Community page](https://www.electronjs.org/community).\n\n## License\n\n[MIT](https://github.com/electron/electron/blob/main/LICENSE)\n\nWhen using Electron logos, make sure to follow [OpenJS Foundation Trademark Policy](https://trademark-policy.openjsf.org/).\n",
      "stars_today": 12
    },
    {
      "id": 11171548,
      "name": "json",
      "full_name": "nlohmann/json",
      "description": "JSON for Modern C++",
      "html_url": "https://github.com/nlohmann/json",
      "stars": 48656,
      "forks": 7303,
      "language": "C++",
      "topics": [
        "bson",
        "cbor",
        "header-only",
        "json",
        "json-diff",
        "json-merge-patch",
        "json-parser",
        "json-patch",
        "json-pointer",
        "json-serialization",
        "messagepack",
        "msgpack",
        "rfc-6901",
        "rfc-6902",
        "rfc-7049",
        "rfc-7159",
        "rfc-8259",
        "stl-containers",
        "ubjson"
      ],
      "created_at": "2013-07-04T08:47:49Z",
      "updated_at": "2026-01-25T01:31:26Z",
      "pushed_at": "2026-01-23T15:52:41Z",
      "open_issues": 100,
      "owner": {
        "login": "nlohmann",
        "avatar_url": "https://avatars.githubusercontent.com/u/159488?v=4"
      },
      "readme": "[![JSON for Modern C++](docs/mkdocs/docs/images/json.gif)](https://github.com/nlohmann/json/releases)\n\n[![Build Status](https://ci.appveyor.com/api/projects/status/1acb366xfyg3qybk/branch/develop?svg=true)](https://ci.appveyor.com/project/nlohmann/json)\n[![Ubuntu](https://github.com/nlohmann/json/workflows/Ubuntu/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AUbuntu)\n[![macOS](https://github.com/nlohmann/json/workflows/macOS/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AmacOS)\n[![Windows](https://github.com/nlohmann/json/workflows/Windows/badge.svg)](https://github.com/nlohmann/json/actions?query=workflow%3AWindows)\n[![Coverage Status](https://coveralls.io/repos/github/nlohmann/json/badge.svg?branch=develop)](https://coveralls.io/github/nlohmann/json?branch=develop)\n[![Coverity Scan Build Status](https://scan.coverity.com/projects/5550/badge.svg)](https://scan.coverity.com/projects/nlohmann-json)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/e0d1a9d5d6fd46fcb655c4cb930bb3e8)](https://app.codacy.com/gh/nlohmann/json/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)\n[![Cirrus CI](https://api.cirrus-ci.com/github/nlohmann/json.svg)](https://cirrus-ci.com/github/nlohmann/json)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/json.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:json)\n[![Try online](https://img.shields.io/badge/try-online-blue.svg)](https://wandbox.org/permlink/1mp10JbaANo6FUc7)\n[![Documentation](https://img.shields.io/badge/docs-mkdocs-blue.svg)](https://json.nlohmann.me)\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/nlohmann/json/master/LICENSE.MIT)\n[![GitHub Releases](https://img.shields.io/github/release/nlohmann/json.svg)](https://github.com/nlohmann/json/releases)\n[![Packaging status](https://repology.org/badge/tiny-repos/nlohmann-json.svg)](https://repology.org/project/nlohmann-json/versions)\n[![GitHub Downloads](https://img.shields.io/github/downloads/nlohmann/json/total)](https://github.com/nlohmann/json/releases)\n[![GitHub Issues](https://img.shields.io/github/issues/nlohmann/json.svg)](https://github.com/nlohmann/json/issues)\n[![Average time to resolve an issue](https://isitmaintained.com/badge/resolution/nlohmann/json.svg)](https://isitmaintained.com/project/nlohmann/json \"Average time to resolve an issue\")\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/289/badge)](https://bestpractices.coreinfrastructure.org/projects/289)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/nlohmann/json/badge)](https://scorecard.dev/viewer/?uri=github.com/nlohmann/json)\n[![Backup Status](https://app.cloudback.it/badge/nlohmann/json)](https://cloudback.it)\n[![GitHub Sponsors](https://img.shields.io/badge/GitHub-Sponsors-ff69b4)](https://github.com/sponsors/nlohmann)\n[![REUSE status](https://api.reuse.software/badge/github.com/nlohmann/json)](https://api.reuse.software/info/github.com/nlohmann/json)\n[![Discord](https://img.shields.io/discord/1003743314341793913)](https://discord.gg/6mrGXKvX7y)\n\n- [Design goals](#design-goals)\n- [Sponsors](#sponsors)\n- [Support](#support) ([documentation](https://json.nlohmann.me), [FAQ](https://json.nlohmann.me/home/faq/), [discussions](https://github.com/nlohmann/json/discussions), [API](https://json.nlohmann.me/api/basic_json/), [bug issues](https://github.com/nlohmann/json/issues))\n- [Quick reference](#quick-reference)\n- [Examples](#examples)\n  - [Read JSON from a file](#read-json-from-a-file)\n  - [Creating `json` objects from JSON literals](#creating-json-objects-from-json-literals)\n  - [JSON as a first-class data type](#json-as-a-first-class-data-type)\n  - [Serialization / Deserialization](#serialization--deserialization)\n  - [STL-like access](#stl-like-access)\n  - [Conversion from STL containers](#conversion-from-stl-containers)\n  - [JSON Pointer and JSON Patch](#json-pointer-and-json-patch)\n  - [JSON Merge Patch](#json-merge-patch)\n  - [Implicit conversions](#implicit-conversions)\n  - [Conversions to/from arbitrary types](#arbitrary-types-conversions)\n  - [Specializing enum conversion](#specializing-enum-conversion)\n  - [Binary formats (BSON, CBOR, MessagePack, UBJSON, and BJData)](#binary-formats-bson-cbor-messagepack-ubjson-and-bjdata)\n- [Customers](#customers)\n- [Supported compilers](#supported-compilers)\n- [Integration](#integration)\n  - [CMake](#cmake)\n  - [Package Managers](#package-managers)\n  - [Pkg-config](#pkg-config)\n- [License](#license)\n- [Contact](#contact)\n- [Thanks](#thanks)\n- [Used third-party tools](#used-third-party-tools)\n- [Notes](#notes)\n- [Execute unit tests](#execute-unit-tests)\n\n## Design goals\n\nThere are myriads of [JSON](https://json.org) libraries out there, and each may even have its reason to exist. Our class had these design goals:\n\n- **Intuitive syntax**. In languages such as Python, JSON feels like a first-class data type. We used all the operator magic of modern C++ to achieve the same feeling in your code. Check out the [examples below](#examples) and you'll know what I mean.\n\n- **Trivial integration**. Our whole code consists of a single header file [`json.hpp`](https://github.com/nlohmann/json/blob/develop/single_include/nlohmann/json.hpp). That's it. No library, no subproject, no dependencies, no complex build system. The class is written in vanilla C++11. All in all, everything should require no adjustment of your compiler flags or project settings. The library is also included in all popular [package managers](https://json.nlohmann.me/integration/package_managers/).\n\n- **Serious testing**. Our code is heavily [unit-tested](https://github.com/nlohmann/json/tree/develop/tests/src) and covers [100%](https://coveralls.io/r/nlohmann/json) of the code, including all exceptional behavior. Furthermore, we checked with [Valgrind](https://valgrind.org) and the [Clang Sanitizers](https://clang.llvm.org/docs/index.html) that there are no memory leaks. [Google OSS-Fuzz](https://github.com/google/oss-fuzz/tree/master/projects/json) additionally runs fuzz tests against all parsers 24/7, effectively executing billions of tests so far. To maintain high quality, the project is following the [Core Infrastructure Initiative (CII) best practices](https://bestpractices.coreinfrastructure.org/projects/289). See the [quality assurance](https://json.nlohmann.me/community/quality_assurance) overview documentation.\n\nOther aspects were not so important to us:\n\n- **Memory efficiency**. Each JSON object has an overhead of one pointer (the maximal size of a union) and one enumeration element (1 byte). The default generalization uses the following C++ data types: `std::string` for strings, `int64_t`, `uint64_t` or `double` for numbers, `std::map` for objects, `std::vector` for arrays, and `bool` for Booleans. However, you can template the generalized class `basic_json` to your needs.\n\n- **Speed**. There are certainly [faster JSON libraries](https://github.com/miloyip/nativejson-benchmark#parsing-time) out there. However, if your goal is to speed up your development by adding JSON support with a single header, then this library is the way to go. If you know how to use a `std::vector` or `std::map`, you are already set.\n\nSee the [contribution guidelines](https://github.com/nlohmann/json/blob/master/.github/CONTRIBUTING.md#please-dont) for more information.\n\n## Sponsors\n\nYou can sponsor this library at [GitHub Sponsors](https://github.com/sponsors/nlohmann).\n\n### :raising_hand: Priority Sponsor\n\n- [Martti Laine](https://github.com/codeclown)\n- [Paul Harrington](https://github.com/phrrngtn)\n\n### :label: Named Sponsors\n\n- [Michael Hartmann](https://github.com/reFX-Mike)\n- [Stefan Hagen](https://github.com/sthagen)\n- [Steve Sperandeo](https://github.com/homer6)\n- [Robert Jefe LindstÃ¤dt](https://github.com/eljefedelrodeodeljefe)\n- [Steve Wagner](https://github.com/ciroque)\n- [Lion Yang](https://github.com/LionNatsu)\n\n### Further support\n\nThe development of the library is further supported by JetBrains by providing free access to their IDE tools.\n\n[![JetBrains logo.](https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg)](https://jb.gg/OpenSourceSupport)\n\nThanks everyone!\n\n## Support\n\n:question: If you have a **question**, please check if it is already answered in the [**FAQ**](https://json.nlohmann.me/home/faq/) or the [**Q&A**](https://github.com/nlohmann/json/discussions/categories/q-a) section. If not, please [**ask a new question**](https://github.com/nlohmann/json/discussions/new) there.\n\n:books: If you want to **learn more** about how to use the library, check out the rest of the [**README**](#examples), have a look at [**code examples**](https://github.com/nlohmann/json/tree/develop/docs/mkdocs/docs/examples), or browse through the [**help pages**](https://json.nlohmann.me).\n\n:construction: If you want to understand the **API** better, check out the [**API Reference**](https://json.nlohmann.me/api/basic_json/) or have a look at the [quick reference](#quick-reference) below.\n\n:bug: If you found a **bug**, please check the [**FAQ**](https://json.nlohmann.me/home/faq/) if it is a known issue or the result of a design decision. Please also have a look at the [**issue list**](https://github.com/nlohmann/json/issues) before you [**create a new issue**](https://github.com/nlohmann/json/issues/new/choose). Please provide as much information as possible to help us understand and reproduce your issue.\n\nThere is also a [**docset**](https://github.com/Kapeli/Dash-User-Contributions/tree/master/docsets/JSON_for_Modern_C%2B%2B) for the documentation browsers [Dash](https://kapeli.com/dash), [Velocity](https://velocity.silverlakesoftware.com), and [Zeal](https://zealdocs.org) that contains the full [documentation](https://json.nlohmann.me) as an offline resource.\n\n## Quick reference\n\n- **Constructors** [basic_json](https://json.nlohmann.me/api/basic_json/basic_json), [array](https://json.nlohmann.me/api/basic_json/array), [binary](https://json.nlohmann.me/api/basic_json/binary), [object](https://json.nlohmann.me/api/basic_json/object)\n- **Object inspection**: [type](https://json.nlohmann.me/api/basic_json/type), [operator value_t](https://json.nlohmann.me/api/basic_json/operator_value_t), [type_name](https://json.nlohmann.me/api/basic_json/type_name), [is_primitive](https://json.nlohmann.me/api/basic_json/is_primitive), [is_structured](https://json.nlohmann.me/api/basic_json/is_structured), [is_null](https://json.nlohmann.me/api/basic_json/is_null), [is_boolean](https://json.nlohmann.me/api/basic_json/is_boolean), [is_number](https://json.nlohmann.me/api/basic_json/is_number), [is_number_integer](https://json.nlohmann.me/api/basic_json/is_number_integer), [is_number_unsigned](https://json.nlohmann.me/api/basic_json/is_number_unsigned), [is_number_float](https://json.nlohmann.me/api/basic_json/is_number_float), [is_object](https://json.nlohmann.me/api/basic_json/is_object), [is_array](https://json.nlohmann.me/api/basic_json/is_array), [is_string](https://json.nlohmann.me/api/basic_json/is_string), [is_binary](https://json.nlohmann.me/api/basic_json/is_binary), [is_discarded](https://json.nlohmann.me/api/basic_json/is_discarded)\n- **Value access**; [get](https://json.nlohmann.me/api/basic_json/get), [get_to](https://json.nlohmann.me/api/basic_json/get_to), [get_ptr](https://json.nlohmann.me/api/basic_json/get_ptr), [get_ref](https://json.nlohmann.me/api/basic_json/get_ref), [operator ValueType](https://json.nlohmann.me/api/basic_json/operator_ValueType), [get_binary](https://json.nlohmann.me/api/basic_json/get_binary)\n- **Element access**: [at](https://json.nlohmann.me/api/basic_json/at), [operator[]](https://json.nlohmann.me/api/basic_json/operator[]), [value](https://json.nlohmann.me/api/basic_json/value), [front](https://json.nlohmann.me/api/basic_json/front), [back](https://json.nlohmann.me/api/basic_json/back)\n- **Lookup**: [find](https://json.nlohmann.me/api/basic_json/find), [count](https://json.nlohmann.me/api/basic_json/count), [contains](https://json.nlohmann.me/api/basic_json/contains)\n- **Iterators**: [begin](https://json.nlohmann.me/api/basic_json/begin), [cbegin](https://json.nlohmann.me/api/basic_json/cbegin), [end](https://json.nlohmann.me/api/basic_json/end), [cend](https://json.nlohmann.me/api/basic_json/cend), [rbegin](https://json.nlohmann.me/api/basic_json/rbegin), [rend](https://json.nlohmann.me/api/basic_json/rend), [crbegin](https://json.nlohmann.me/api/basic_json/crbegin), [crend](https://json.nlohmann.me/api/basic_json/crend), [items](https://json.nlohmann.me/api/basic_json/items)\n- **Capacity**: [empty](https://json.nlohmann.me/api/basic_json/empty), [size](https://json.nlohmann.me/api/basic_json/size), [max_size](https://json.nlohmann.me/api/basic_json/max_size)\n- **Modifiers**: [clear](https://json.nlohmann.me/api/basic_json/clear), [push_back](https://json.nlohmann.me/api/basic_json/push_back), [operator+=](https://json.nlohmann.me/api/basic_json/operator+=), [emplace_back](https://json.nlohmann.me/api/basic_json/emplace_back), [emplace](https://json.nlohmann.me/api/basic_json/emplace), [erase](https://json.nlohmann.me/api/basic_json/erase), [insert](https://json.nlohmann.me/api/basic_json/insert), [update](https://json.nlohmann.me/api/basic_json/update), [swap](https://json.nlohmann.me/api/basic_json/swap)\n- **Lexicographical comparison operators**: [operator==](https://json.nlohmann.me/api/basic_json/operator_eq), [operator!=](https://json.nlohmann.me/api/basic_json/operator_ne), [operator<](https://json.nlohmann.me/api/basic_json/operator_lt), [operator>](https://json.nlohmann.me/api/basic_json/operator_gt), [operator<=](https://json.nlohmann.me/api/basic_json/operator_le), [operator>=](https://json.nlohmann.me/api/basic_json/operator_ge), [operator<=>](https://json.nlohmann.me/api/basic_json/operator_spaceship)\n- **Serialization / Dumping**: [dump](https://json.nlohmann.me/api/basic_json/dump)\n- **Deserialization / Parsing**: [parse](https://json.nlohmann.me/api/basic_json/parse), [accept](https://json.nlohmann.me/api/basic_json/accept), [sax_parse](https://json.nlohmann.me/api/basic_json/sax_parse)\n- **JSON Pointer functions**: [flatten](https://json.nlohmann.me/api/basic_json/flatten), [unflatten](https://json.nlohmann.me/api/basic_json/unflatten)\n- **JSON Patch functions**: [patch](https://json.nlohmann.me/api/basic_json/patch), [patch_inplace](https://json.nlohmann.me/api/basic_json/patch_inplace), [diff](https://json.nlohmann.me/api/basic_json/diff), [merge_patch](https://json.nlohmann.me/api/basic_json/merge_patch)\n- **Static functions**: [meta](https://json.nlohmann.me/api/basic_json/meta), [get_allocator](https://json.nlohmann.me/api/basic_json/get_allocator)\n- **Binary formats**: [from_bjdata](https://json.nlohmann.me/api/basic_json/from_bjdata), [from_bson](https://json.nlohmann.me/api/basic_json/from_bson), [from_cbor](https://json.nlohmann.me/api/basic_json/from_cbor), [from_msgpack](https://json.nlohmann.me/api/basic_json/from_msgpack), [from_ubjson](https://json.nlohmann.me/api/basic_json/from_ubjson), [to_bjdata](https://json.nlohmann.me/api/basic_json/to_bjdata), [to_bson](https://json.nlohmann.me/api/basic_json/to_bson), [to_cbor](https://json.nlohmann.me/api/basic_json/to_cbor), [to_msgpack](https://json.nlohmann.me/api/basic_json/to_msgpack), [to_ubjson](https://json.nlohmann.me/api/basic_json/to_ubjson)\n- **Non-member functions**: [operator<<](https://json.nlohmann.me/api/operator_ltlt/), [operator>>](https://json.nlohmann.me/api/operator_gtgt/), [to_string](https://json.nlohmann.me/api/basic_json/to_string)\n- **Literals**: [operator\"\"_json](https://json.nlohmann.me/api/operator_literal_json)\n- **Helper classes**: [std::hash&lt;basic_json&gt;](https://json.nlohmann.me/api/basic_json/std_hash), [std::swap&lt;basic_json&gt;](https://json.nlohmann.me/api/basic_json/std_swap)\n\n[**Full API documentation**](https://json.nlohmann.me/api/basic_json/)\n\n## Examples\n\nHere are some examples to give you an idea how to use the class.\n\nBesides the examples below, you may want to:\n\nâ†’ Check the [documentation](https://json.nlohmann.me/)\\\nâ†’ Browse the [standalone example files](https://github.com/nlohmann/json/tree/develop/docs/mkdocs/docs/examples)\\\nâ†’ Read the full [API Documentation](https://json.nlohmann.me/api/basic_json/) with self-contained examples for every function\n\n### Read JSON from a file\n\nThe `json` class provides an API for manipulating a JSON value. To create a `json` object by reading a JSON file:\n\n```cpp\n#include <fstream>\n#include <nlohmann/json.hpp>\nusing json = nlohmann::json;\n\n// ...\n\nstd::ifstream f(\"example.json\");\njson data = json::parse(f);\n```\n\nIf using modules (enabled with `NLOHMANN_JSON_BUILD_MODULES`), this example becomes:\n```cpp\nimport std;\nimport nlohmann.json;\n\nusing json = nlohmann::json;\n\n// ...\n\nstd::ifstream f(\"example.json\");\njson data = json::parse(f);\n```\n\n### Creating `json` objects from JSON literals\n\nAssume you want to create hard-code this literal JSON value in a file, as a `json` object:\n\n```json\n{\n  \"pi\": 3.141,\n  \"happy\": true\n}\n```\n\nThere are various options:\n\n```cpp\n// Using (raw) string literals and json::parse\njson ex1 = json::parse(R\"(\n  {\n    \"pi\": 3.141,\n    \"happy\": true\n  }\n)\");\n\n// Using user-defined (raw) string literals\nusing namespace nlohmann::literals;\njson ex2 = R\"(\n  {\n    \"pi\": 3.141,\n    \"happy\": true\n  }\n)\"_json;\n\n// Using initializer lists\njson ex3 = {\n  {\"happy\", true},\n  {\"pi\", 3.141},\n};\n```\n\n### JSON as a first-class data type\n\nHere are some examples to give you an idea how to use the class.\n\nAssume you want to create the JSON object\n\n```json\n{\n  \"pi\": 3.141,\n  \"happy\": true,\n  \"name\": \"Niels\",\n  \"nothing\": null,\n  \"answer\": {\n    \"everything\": 42\n  },\n  \"list\": [1, 0, 2],\n  \"object\": {\n    \"currency\": \"USD\",\n    \"value\": 42.99\n  }\n}\n```\n\nWith this library, you could write:\n\n```cpp\n// create an empty structure (null)\njson j;\n\n// add a number stored as double (note the implicit conversion of j to an object)\nj[\"pi\"] = 3.141;\n\n// add a Boolean stored as bool\nj[\"happy\"] = true;\n\n// add a string stored as std::string\nj[\"name\"] = \"Niels\";\n\n// add another null object by passing nullptr\nj[\"nothing\"] = nullptr;\n\n// add an object inside the object\nj[\"answer\"][\"everything\"] = 42;\n\n// add an array stored as std::vector (using an initializer list)\nj[\"list\"] = { 1, 0, 2 };\n\n// add another object (using an initializer list of pairs)\nj[\"object\"] = { {\"currency\", \"USD\"}, {\"value\", 42.99} };\n\n// instead, you could also write (which looks very similar to the JSON above)\njson j2 = {\n  {\"pi\", 3.141},\n  {\"happy\", true},\n  {\"name\", \"Niels\"},\n  {\"nothing\", nullptr},\n  {\"answer\", {\n    {\"everything\", 42}\n  }},\n  {\"list\", {1, 0, 2}},\n  {\"object\", {\n    {\"currency\", \"USD\"},\n    {\"value\", 42.99}\n  }}\n};\n```\n\nNote that in all these cases, you never need to \"tell\" the compiler which JSON value type you want to use. If you want to be explicit or express some edge cases, the functions [`json::array()`](https://json.nlohmann.me/api/basic_json/array/) and [`json::object()`](https://json.nlohmann.me/api/basic_json/object/) will help:\n\n```cpp\n// a way to express the empty array []\njson empty_array_explicit = json::array();\n\n// ways to express the empty object {}\njson empty_object_implicit = json({});\njson empty_object_explicit = json::object();\n\n// a way to express an _array_ of key/value pairs [[\"currency\", \"USD\"], [\"value\", 42.99]]\njson array_not_object = json::array({ {\"currency\", \"USD\"}, {\"value\", 42.99} });\n```\n\n### Serialization / Deserialization\n\n#### To/from strings\n\nYou can create a JSON value (deserialization) by appending `_json` to a string literal:\n\n```cpp\n// create object from string literal\njson j = \"{ \\\"happy\\\": true, \\\"pi\\\": 3.141 }\"_json;\n\n// or even nicer with a raw string literal\nauto j2 = R\"(\n  {\n    \"happy\": true,\n    \"pi\": 3.141\n  }\n)\"_json;\n```\n\nNote that without appending the `_json` suffix, the passed string literal is not parsed, but just used as JSON string\nvalue. That is, `json j = \"{ \\\"happy\\\": true, \\\"pi\\\": 3.141 }\"` would just store the string\n`\"{ \"happy\": true, \"pi\": 3.141 }\"` rather than parsing the actual object.\n\nThe string literal should be brought into scope with `using namespace nlohmann::literals;`\n(see [`json::parse()`](https://json.nlohmann.me/api/operator_literal_json/)).\n\nThe above example can also be expressed explicitly using [`json::parse()`](https://json.nlohmann.me/api/basic_json/parse/):\n\n```cpp\n// parse explicitly\nauto j3 = json::parse(R\"({\"happy\": true, \"pi\": 3.141})\");\n```\n\nYou can also get a string representation of a JSON value (serialize):\n\n```cpp\n// explicit conversion to string\nstd::string s = j.dump();    // {\"happy\":true,\"pi\":3.141}\n\n// serialization with pretty printing\n// pass in the amount of spaces to indent\nstd::cout << j.dump(4) << std::endl;\n// {\n//     \"happy\": true,\n//     \"pi\": 3.141\n// }\n```\n\nNote the difference between serialization and assignment:\n\n```cpp\n// store a string in a JSON value\njson j_string = \"this is a string\";\n\n// retrieve the string value\nauto cpp_string = j_string.get<std::string>();\n// retrieve the string value (alternative when a variable already exists)\nstd::string cpp_string2;\nj_string.get_to(cpp_string2);\n\n// retrieve the serialized value (explicit JSON serialization)\nstd::string serialized_string = j_string.dump();\n\n// output of original string\nstd::cout << cpp_string << \" == \" << cpp_string2 << \" == \" << j_string.get<std::string>() << '\\n';\n// output of serialized value\nstd::cout << j_string << \" == \" << serialized_string << std::endl;\n```\n\n[`.dump()`](https://json.nlohmann.me/api/basic_json/dump/) returns the originally stored string value.\n\nNote the library only supports UTF-8. When you store strings with different encodings in the library, calling [`dump()`](https://json.nlohmann.me/api/basic_json/dump/) may throw an exception unless `json::error_handler_t::replace` or `json::error_handler_t::ignore` are used as error handlers.\n\n#### To/from streams (e.g., files, string streams)\n\nYou can also use streams to serialize and deserialize:\n\n```cpp\n// deserialize from standard input\njson j;\nstd::cin >> j;\n\n// serialize to standard output\nstd::cout << j;\n\n// the setw manipulator was overloaded to set the indentation for pretty printing\nstd::cout << std::setw(4) << j << std::endl;\n```\n\nThese operators work for any subclasses of `std::istream` or `std::ostream`. Here is the same example with files:\n\n```cpp\n// read a JSON file\nstd::ifstream i(\"file.json\");\njson j;\ni >> j;\n\n// write prettified JSON to another file\nstd::ofstream o(\"pretty.json\");\no << std::setw(4) << j << std::endl;\n```\n\nPlease note that setting the exception bit for `failbit` is inappropriate for this use case. It will result in program termination due to the `noexcept` specifier in use.\n\n#### Read from iterator range\n\nYou can also parse JSON from an iterator range; that is, from any container accessible by iterators whose `value_type` is an integral type of 1, 2, or 4 bytes, which will be interpreted as UTF-8, UTF-16, and UTF-32 respectively. For instance, a `std::vector<std::uint8_t>`, or a `std::list<std::uint16_t>`:\n\n```cpp\nstd::vector<std::uint8_t> v = {'t', 'r', 'u', 'e'};\njson j = json::parse(v.begin(), v.end());\n```\n\nYou may leave the iterators for the range [begin, end):\n\n```cpp\nstd::vector<std::uint8_t> v = {'t', 'r', 'u', 'e'};\njson j = json::parse(v);\n```\n\n#### Custom data source\n\nSince the parse function accepts arbitrary iterator ranges, you can provide your own data sources by implementing the `LegacyInputIterator` concept.\n\n```cpp\nstruct MyContainer {\n  void advance();\n  const char& get_current();\n};\n\nstruct MyIterator {\n    using difference_type = std::ptrdiff_t;\n    using value_type = char;\n    using pointer = const char*;\n    using reference = const char&;\n    using iterator_category = std::input_iterator_tag;\n\n    MyIterator& operator++() {\n        target->advance();\n        return *this;\n    }\n\n    bool operator!=(const MyIterator& rhs) const {\n        return rhs.target != target;\n    }\n\n    reference operator*() const {\n        return target->get_current();\n    }\n\n    MyContainer* target = nullptr;\n};\n\nMyIterator begin(MyContainer& tgt) {\n    return MyIterator{&tgt};\n}\n\nMyIterator end(const MyContainer&) {\n    return {};\n}\n\nvoid foo() {\n    MyContainer c;\n    json j = json::parse(c);\n}\n```\n\n#### SAX interface\n\nThe library uses a SAX-like interface with the following functions:\n\n```cpp\n// called when null is parsed\nbool null();\n\n// called when a boolean is parsed; value is passed\nbool boolean(bool val);\n\n// called when a signed or unsigned integer number is parsed; value is passed\nbool number_integer(number_integer_t val);\nbool number_unsigned(number_unsigned_t val);\n\n// called when a floating-point number is parsed; value and original string is passed\nbool number_float(number_float_t val, const string_t& s);\n\n// called when a string is parsed; value is passed and can be safely moved away\nbool string(string_t& val);\n// called when a binary value is parsed; value is passed and can be safely moved away\nbool binary(binary_t& val);\n\n// called when an object or array begins or ends, resp. The number of elements is passed (or -1 if not known)\nbool start_object(std::size_t elements);\nbool end_object();\nbool start_array(std::size_t elements);\nbool end_array();\n// called when an object key is parsed; value is passed and can be safely moved away\nbool key(string_t& val);\n\n// called when a parse error occurs; byte position, the last token, and an exception is passed\nbool parse_error(std::size_t position, const std::string& last_token, const detail::exception& ex);\n```\n\nThe return value of each function determines whether parsing should proceed.\n\nTo implement your own SAX handler, proceed as follows:\n\n1. Implement the SAX interface in a class. You can use class `nlohmann::json_sax<json>` as base class, but you can also use any class where the functions described above are implemented and public.\n2. Create an object of your SAX interface class, e.g. `my_sax`.\n3. Call `bool json::sax_parse(input, &my_sax)`; where the first parameter can be any input like a string or an input stream and the second parameter is a pointer to your SAX interface.\n\nNote the `sax_parse` function only returns a `bool` indicating the result of the last executed SAX event. It does not return a  `json` value - it is up to you to decide what to do with the SAX events. Furthermore, no exceptions are thrown in case of a parse error -- it is up to you what to do with the exception object passed to your `parse_error` implementation. Internally, the SAX interface is used for the DOM parser (class `json_sax_dom_parser`) as well as the acceptor (`json_sax_acceptor`), see file [`json_sax.hpp`](https://github.com/nlohmann/json/blob/develop/include/nlohmann/detail/input/json_sax.hpp).\n\n### STL-like access\n\nWe designed the JSON class to behave just like an STL container. In fact, it satisfies the [**ReversibleContainer**](https://en.cppreference.com/w/cpp/named_req/ReversibleContainer) requirement.\n\n```cpp\n// create an array using push_back\njson j;\nj.push_back(\"foo\");\nj.push_back(1);\nj.push_back(true);\n\n// also use emplace_back\nj.emplace_back(1.78);\n\n// iterate the array\nfor (json::iterator it = j.begin(); it != j.end(); ++it) {\n  std::cout << *it << '\\n';\n}\n\n// range-based for\nfor (auto& element : j) {\n  std::cout << element << '\\n';\n}\n\n// getter/setter\nconst auto tmp = j[0].get<std::string>();\nj[1] = 42;\nbool foo = j.at(2);\n\n// comparison\nj == R\"([\"foo\", 1, true, 1.78])\"_json;  // true\n\n// other stuff\nj.size();     // 4 entries\nj.empty();    // false\nj.type();     // json::value_t::array\nj.clear();    // the array is empty again\n\n// convenience type checkers\nj.is_null();\nj.is_boolean();\nj.is_number();\nj.is_object();\nj.is_array();\nj.is_string();\n\n// create an object\njson o;\no[\"foo\"] = 23;\no[\"bar\"] = false;\no[\"baz\"] = 3.141;\n\n// also use emplace\no.emplace(\"weather\", \"sunny\");\n\n// special iterator member functions for objects\nfor (json::iterator it = o.begin(); it != o.end(); ++it) {\n  std::cout << it.key() << \" : \" << it.value() << \"\\n\";\n}\n\n// the same code as range for\nfor (auto& el : o.items()) {\n  std::cout << el.key() << \" : \" << el.value() << \"\\n\";\n}\n\n// even easier with structured bindings (C++17)\nfor (auto& [key, value] : o.items()) {\n  std::cout << key << \" : \" << value << \"\\n\";\n}\n\n// find an entry\nif (o.contains(\"foo\")) {\n  // there is an entry with key \"foo\"\n}\n\n// or via find and an iterator\nif (o.find(\"foo\") != o.end()) {\n  // there is an entry with key \"foo\"\n}\n\n// or simpler using count()\nint foo_present = o.count(\"foo\"); // 1\nint fob_present = o.count(\"fob\"); // 0\n\n// delete an entry\no.erase(\"foo\");\n```\n\n### Conversion from STL containers\n\nAny sequence container (`std::array`, `std::vector`, `std::deque`, `std::forward_list`, `std::list`) whose values can be used to construct JSON values (e.g., integers, floating point numbers, Booleans, string types, or again STL containers described in this section) can be used to create a JSON array. The same holds for similar associative containers (`std::set`, `std::multiset`, `std::unordered_set`, `std::unordered_multiset`), but in these cases the order of the elements of the array depends on how the elements are ordered in the respective STL container.\n\n```cpp\nstd::vector<int> c_vector {1, 2, 3, 4};\njson j_vec(c_vector);\n// [1, 2, 3, 4]\n\nstd::deque<double> c_deque {1.2, 2.3, 3.4, 5.6};\njson j_deque(c_deque);\n// [1.2, 2.3, 3.4, 5.6]\n\nstd::list<bool> c_list {true, true, false, true};\njson j_list(c_list);\n// [true, true, false, true]\n\nstd::forward_list<int64_t> c_flist {12345678909876, 23456789098765, 34567890987654, 45678909876543};\njson j_flist(c_flist);\n// [12345678909876, 23456789098765, 34567890987654, 45678909876543]\n\nstd::array<unsigned long, 4> c_array {{1, 2, 3, 4}};\njson j_array(c_array);\n// [1, 2, 3, 4]\n\nstd::set<std::string> c_set {\"one\", \"two\", \"three\", \"four\", \"one\"};\njson j_set(c_set); // only one entry for \"one\" is used\n// [\"four\", \"one\", \"three\", \"two\"]\n\nstd::unordered_set<std::string> c_uset {\"one\", \"two\", \"three\", \"four\", \"one\"};\njson j_uset(c_uset); // only one entry for \"one\" is used\n// maybe [\"two\", \"three\", \"four\", \"one\"]\n\nstd::multiset<std::string> c_mset {\"one\", \"two\", \"one\", \"four\"};\njson j_mset(c_mset); // both entries for \"one\" are used\n// maybe [\"one\", \"two\", \"one\", \"four\"]\n\nstd::unordered_multiset<std::string> c_umset {\"one\", \"two\", \"one\", \"four\"};\njson j_umset(c_umset); // both entries for \"one\" are used\n// maybe [\"one\", \"two\", \"one\", \"four\"]\n```\n\nLikewise, any associative key-value containers (`std::map`, `std::multimap`, `std::unordered_map`, `std::unordered_multimap`) whose keys can construct an `std::string` and whose values can be used to construct JSON values (see examples above) can be used to create a JSON object. Note that in case of multimaps, only one key is used in the JSON object and the value depends on the internal order of the STL container.\n\n```cpp\nstd::map<std::string, int> c_map { {\"one\", 1}, {\"two\", 2}, {\"three\", 3} };\njson j_map(c_map);\n// {\"one\": 1, \"three\": 3, \"two\": 2 }\n\nstd::unordered_map<const char*, double> c_umap { {\"one\", 1.2}, {\"two\", 2.3}, {\"three\", 3.4} };\njson j_umap(c_umap);\n// {\"one\": 1.2, \"two\": 2.3, \"three\": 3.4}\n\nstd::multimap<std::string, bool> c_mmap { {\"one\", true}, {\"two\", true}, {\"three\", false}, {\"three\", true} };\njson j_mmap(c_mmap); // only one entry for key \"three\" is used\n// maybe {\"one\": true, \"two\": true, \"three\": true}\n\nstd::unordered_multimap<std::string, bool> c_ummap { {\"one\", true}, {\"two\", true}, {\"three\", false}, {\"three\", true} };\njson j_ummap(c_ummap); // only one entry for key \"three\" is used\n// maybe {\"one\": true, \"two\": true, \"three\": true}\n```\n\n### JSON Pointer and JSON Patch\n\nThe library supports **JSON Pointer** ([RFC 6901](https://tools.ietf.org/html/rfc6901)) as an alternative means to address structured values. On top of this, **JSON Patch** ([RFC 6902](https://tools.ietf.org/html/rfc6902)) allows describing differences between two JSON values -- effectively allowing patch and diff operations known from Unix.\n\n```cpp\n// a JSON value\njson j_original = R\"({\n  \"baz\": [\"one\", \"two\", \"three\"],\n  \"foo\": \"bar\"\n})\"_json;\n\n// access members with a JSON pointer (RFC 6901)\nj_original[\"/baz/1\"_json_pointer];\n// \"two\"\n\n// a JSON patch (RFC 6902)\njson j_patch = R\"([\n  { \"op\": \"replace\", \"path\": \"/baz\", \"value\": \"boo\" },\n  { \"op\": \"add\", \"path\": \"/hello\", \"value\": [\"world\"] },\n  { \"op\": \"remove\", \"path\": \"/foo\"}\n])\"_json;\n\n// apply the patch\njson j_result = j_original.patch(j_patch);\n// {\n//    \"baz\": \"boo\",\n//    \"hello\": [\"world\"]\n// }\n\n// calculate a JSON patch from two JSON values\njson::diff(j_result, j_original);\n// [\n//   { \"op\":\" replace\", \"path\": \"/baz\", \"value\": [\"one\", \"two\", \"three\"] },\n//   { \"op\": \"remove\",\"path\": \"/hello\" },\n//   { \"op\": \"add\", \"path\": \"/foo\", \"value\": \"bar\" }\n// ]\n```\n\n### JSON Merge Patch\n\nThe library supports **JSON Merge Patch** ([RFC 7386](https://tools.ietf.org/html/rfc7386)) as a patch format. Instead of using JSON Pointer (see above) to specify values to be manipulated, it describes the changes using a syntax that closely mimics the document being modified.\n\n```cpp\n// a JSON value\njson j_document = R\"({\n  \"a\": \"b\",\n  \"c\": {\n    \"d\": \"e\",\n    \"f\": \"g\"\n  }\n})\"_json;\n\n// a patch\njson j_patch = R\"({\n  \"a\":\"z\",\n  \"c\": {\n    \"f\": null\n  }\n})\"_json;\n\n// apply the patch\nj_document.merge_patch(j_patch);\n// {\n//  \"a\": \"z\",\n//  \"c\": {\n//    \"d\": \"e\"\n//  }\n// }\n```\n\n### Implicit conversions\n\nSupported types can be implicitly converted to JSON values.\n\nIt is recommended to **NOT USE** implicit conversions **FROM** a JSON value.\nYou can find more details about this recommendation [here](https://www.github.com/nlohmann/json/issues/958).\nYou can switch off implicit conversions by defining `JSON_USE_IMPLICIT_CONVERSIONS` to `0` before including the `json.hpp` header. When using CMake, you can also achieve this by setting the option `JSON_ImplicitConversions` to `OFF`.\n\n```cpp\n// strings\nstd::string s1 = \"Hello, world!\";\njson js = s1;\nauto s2 = js.get<std::string>();\n// NOT RECOMMENDED\nstd::string s3 = js;\nstd::string s4;\ns4 = js;\n\n// Booleans\nbool b1 = true;\njson jb = b1;\nauto b2 = jb.get<bool>();\n// NOT RECOMMENDED\nbool b3 = jb;\nbool b4;\nb4 = jb;\n\n// numbers\nint i = 42;\njson jn = i;\nauto f = jn.get<double>();\n// NOT RECOMMENDED\ndouble f2 = jb;\ndouble f3;\nf3 = jb;\n\n// etc.\n```\n\nNote that `char` types are not automatically converted to JSON strings, but to integer numbers. A conversion to a string must be specified explicitly:\n\n```cpp\nchar ch = 'A';                       // ASCII value 65\njson j_default = ch;                 // stores integer number 65\njson j_string = std::string(1, ch);  // stores string \"A\"\n```\n\n### Arbitrary types conversions\n\nEvery type can be serialized in JSON, not just STL containers and scalar types. Usually, you would do something along those lines:\n\n```cpp\nnamespace ns {\n    // a simple struct to model a person\n    struct person {\n        std::string name;\n        std::string address;\n        int age;\n    };\n}\n\nns::person p = {\"Ned Flanders\", \"744 Evergreen Terrace\", 60};\n\n// convert to JSON: copy each value into the JSON object\njson j;\nj[\"name\"] = p.name;\nj[\"address\"] = p.address;\nj[\"age\"] = p.age;\n\n// ...\n\n// convert from JSON: copy each value from the JSON object\nns::person p {\n    j[\"name\"].get<std::string>(),\n    j[\"address\"].get<std::string>(),\n    j[\"age\"].get<int>()\n};\n```\n\nIt works, but that's quite a lot of boilerplate... Fortunately, there's a better way:\n\n```cpp\n// create a person\nns::person p {\"Ned Flanders\", \"744 Evergreen Terrace\", 60};\n\n// conversion: person -> json\njson j = p;\n\nstd::cout << j << std::endl;\n// {\"address\":\"744 Evergreen Terrace\",\"age\":60,\"name\":\"Ned Flanders\"}\n\n// conversion: json -> person\nauto p2 = j.get<ns::person>();\n\n// that's it\nassert(p == p2);\n```\n\n#### Basic usage\n\nTo make this work with one of your types, you only need to provide two functions:\n\n```cpp\nusing json = nlohmann::json;\n\nnamespace ns {\n    void to_json(json& j, const person& p) {\n        j = json{{\"name\", p.name}, {\"address\", p.address}, {\"age\", p.age}};\n    }\n\n    void from_json(const json& j, person& p) {\n        j.at(\"name\").get_to(p.name);\n        j.at(\"address\").get_to(p.address);\n        j.at(\"age\").get_to(p.age);\n    }\n} // namespace ns\n```\n\nThat's all! When calling the `json` constructor with your type, your custom `to_json` method will be automatically called.\nLikewise, when calling `get<your_type>()` or `get_to(your_type&)`, the `from_json` method will be called.\n\nSome important things:\n\n- Those methods **MUST** be in your type's namespace (which can be the global namespace), or the library will not be able to locate them (in this example, they are in namespace `ns`, where `person` is defined).\n- Those methods **MUST** be available (e.g., proper headers must be included) everywhere you use these conversions. Look at [issue 1108](https://github.com/nlohmann/json/issues/1108) for errors that may occur otherwise.\n- When using `get<your_type>()`, `your_type` **MUST** be [DefaultConstructible](https://en.cppreference.com/w/cpp/named_req/DefaultConstructible). (There is a way to bypass this requirement described later.)\n- In function `from_json`, use function [`at()`](https://json.nlohmann.me/api/basic_json/at/) to access the object values rather than `operator[]`. In case a key does not exist, `at` throws an exception that you can handle, whereas `operator[]` exhibits undefined behavior.\n- You do not need to add serializers or deserializers for STL types like `std::vector`: the library already implements these.\n\n#### Simplify your life with macros\n\nIf you just want to serialize/deserialize some structs, the `to_json`/`from_json` functions can be a lot of boilerplate. There are [**several macros**](https://json.nlohmann.me/features/arbitrary_types/#simplify-your-life-with-macros) to make your life easier as long as you (1) want to use a JSON object as serialization and (2) want to use the member variable names as object keys in that object.\n\nWhich macro to choose depends on whether private member variables need to be accessed, a deserialization is needed, missing values should yield an error or should be replaced by default values, and if derived classes are used. See [this overview to choose the right one for your use case](https://json.nlohmann.me/api/macros/#serializationdeserialization-macros).\n\n##### Example usage of macros\n\nThe `to_json`/`from_json` functions for the `person` struct above can be created with [`NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`](https://json.nlohmann.me/api/macros/nlohmann_define_type_non_intrusive/). In all macros, the first parameter is the name of the class/struct, and all remaining parameters name the members.\n\n```cpp\nnamespace ns {\n    NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE(person, name, address, age)\n}\n```\n\nHere is another example with private members, where [`NLOHMANN_DEFINE_TYPE_INTRUSIVE`](https://json.nlohmann.me/api/macros/nlohmann_define_type_intrusive/) is needed:\n\n```cpp\nnamespace ns {\n    class address {\n      private:\n        std::string street;\n        int housenumber;\n        int postcode;\n  \n      public:\n        NLOHMANN_DEFINE_TYPE_INTRUSIVE(address, street, housenumber, postcode)\n    };\n}\n```\n\n#### How do I convert third-party types?\n\nThis requires a bit more advanced technique. But first, let's see how this conversion mechanism works:\n\nThe library uses **JSON Serializers** to convert types to JSON.\nThe default serializer for `nlohmann::json` is `nlohmann::adl_serializer` (ADL means [Argument-Dependent Lookup](https://en.cppreference.com/w/cpp/language/adl)).\n\nIt is implemented like this (simplified):\n\n```cpp\ntemplate <typename T>\nstruct adl_serializer {\n    static void to_json(json& j, const T& value) {\n        // calls the \"to_json\" method in T's namespace\n    }\n\n    static void from_json(const json& j, T& value) {\n        // same thing, but with the \"from_json\" method\n    }\n};\n```\n\nThis serializer works fine when you have control over the type's namespace. However, what about `boost::optional` or `std::filesystem::path` (C++17)? Hijacking the `boost` namespace is pretty bad, and it's illegal to add something other than template specializations to `std`...\n\nTo solve this, you need to add a specialization of `adl_serializer` to the `nlohmann` namespace, here's an example:\n\n```cpp\n// partial specialization (full specialization works too)\nnamespace nlohmann {\n    template <typename T>\n    struct adl_serializer<boost::optional<T>> {\n        static void to_json(json& j, const boost::optional<T>& opt) {\n            if (opt == boost::none) {\n                j = nullptr;\n            } else {\n              j = *opt; // this will call adl_serializer<T>::to_json which will\n                        // find the free function to_json in T's namespace!\n            }\n        }\n\n        static void from_json(const json& j, boost::optional<T>& opt) {\n            if (j.is_null()) {\n                opt = boost::none;\n            } else {\n                opt = j.get<T>(); // same as above, but with\n                                  // adl_serializer<T>::from_json\n            }\n        }\n    };\n}\n```\n\n#### How can I use `get()` for non-default constructible/non-copyable types?\n\nThere is a way if your type is [MoveConstructible](https://en.cppreference.com/w/cpp/named_req/MoveConstructible). You will need to specialize the `adl_serializer` as well, but with a special `from_json` overload:\n\n```cpp\nstruct move_only_type {\n    move_only_type() = delete;\n    move_only_type(int ii): i(ii) {}\n    move_only_type(const move_only_type&) = delete;\n    move_only_type(move_only_type&&) = default;\n\n    int i;\n};\n\nnamespace nlohmann {\n    template <>\n    struct adl_serializer<move_only_type> {\n        // note: the return type is no longer 'void', and the method only takes\n        // one argument\n        static move_only_type from_json(const json& j) {\n            return {j.get<int>()};\n        }\n\n        // Here's the catch! You must provide a to_json method! Otherwise, you\n        // will not be able to convert move_only_type to json, since you fully\n        // specialized adl_serializer on that type\n        static void to_json(json& j, move_only_type t) {\n            j = t.i;\n        }\n    };\n}\n```\n\n#### Can I write my own serializer? (Advanced use)\n\nYes. You might want to take a look at [`unit-udt.cpp`](https://github.com/nlohmann/json/blob/develop/tests/src/unit-udt.cpp) in the test suite, to see a few examples.\n\nIf you write your own serializer, you'll need to do a few things:\n\n- use a different `basic_json` alias than `nlohmann::json` (the last template parameter of `basic_json` is the `JSONSerializer`)\n- use your `basic_json` alias (or a template parameter) in all your `to_json`/`from_json` methods\n- use `nlohmann::to_json` and `nlohmann::from_json` when you need ADL\n\nHere is an example, without simplifications, that only accepts types with a size <= 32, and uses ADL.\n\n```cpp\n// You should use void as a second template argument\n// if you don't need compile-time checks on T\ntemplate<typename T, typename SFINAE = typename std::enable_if<sizeof(T) <= 32>::type>\nstruct less_than_32_serializer {\n    template <typename BasicJsonType>\n    static void to_json(BasicJsonType& j, T value) {\n        // we want to use ADL, and call the correct to_json overload\n        using nlohmann::to_json; // this method is called by adl_serializer,\n                                 // this is where the magic happens\n        to_json(j, value);\n    }\n\n    template <typename BasicJsonType>\n    static void from_json(const BasicJsonType& j, T& value) {\n        // same thing here\n        using nlohmann::from_json;\n        from_json(j, value);\n    }\n};\n```\n\nBe **very** careful when reimplementing your serializer, you can stack overflow if you don't pay attention:\n\n```cpp\ntemplate <typename T, void>\nstruct bad_serializer\n{\n    template <typename BasicJsonType>\n    static void to_json(BasicJsonType& j, const T& value) {\n      // this calls BasicJsonType::json_serializer<T>::to_json(j, value)\n      // if BasicJsonType::json_serializer == bad_serializer ... oops!\n      j = value;\n    }\n\n    template <typename BasicJsonType>\n    static void to_json(const BasicJsonType& j, T& value) {\n      // this calls BasicJsonType::json_serializer<T>::from_json(j, value)\n      // if BasicJsonType::json_serializer == bad_serializer ... oops!\n      value = j.get<T>(); // oops!\n    }\n};\n```\n\n### Specializing enum conversion\n\nBy default, enum values are serialized to JSON as integers. In some cases, this could result in undesired behavior. If an enum is modified or re-ordered after data has been serialized to JSON, the later deserialized JSON data may be undefined or a different enum value than was originally intended.\n\nIt is possible to more precisely specify how a given enum is mapped to and from JSON as shown below:\n\n```cpp\n// example enum type declaration\nenum TaskState {\n    TS_STOPPED,\n    TS_RUNNING,\n    TS_COMPLETED,\n    TS_INVALID=-1,\n};\n\n// map TaskState values to JSON as strings\nNLOHMANN_JSON_SERIALIZE_ENUM( TaskState, {\n    {TS_INVALID, nullptr},\n    {TS_STOPPED, \"stopped\"},\n    {TS_RUNNING, \"running\"},\n    {TS_COMPLETED, \"completed\"},\n})\n```\n\nThe `NLOHMANN_JSON_SERIALIZE_ENUM()` macro declares a set of `to_json()` / `from_json()` functions for type `TaskState` while avoiding repetition and boilerplate serialization code.\n\n**Usage:**\n\n```cpp\n// enum to JSON as string\njson j = TS_STOPPED;\nassert(j == \"stopped\");\n\n// json string to enum\njson j3 = \"running\";\nassert(j3.get<TaskState>() == TS_RUNNING);\n\n// undefined json value to enum (where the first map entry above is the default)\njson jPi = 3.14;\nassert(jPi.get<TaskState>() == TS_INVALID);\n```\n\nJust as in [Arbitrary Type Conversions](#arbitrary-types-conversions) above,\n\n- `NLOHMANN_JSON_SERIALIZE_ENUM()` MUST be declared in your enum type's namespace (which can be the global namespace), or the library will not be able to locate it, and it will default to integer serialization.\n- It MUST be available (e.g., proper headers must be included) everywhere you use the conversions.\n\nOther Important points:\n\n- When using `get<ENUM_TYPE>()`, undefined JSON values will default to the first pair specified in your map. Select this default pair carefully.\n- If an enum or JSON value is specified more than once in your map, the first matching occurrence from the top of the map will be returned when converting to or from JSON.\n\n### Binary formats (BSON, CBOR, MessagePack, UBJSON, and BJData)\n\nThough JSON is a ubiquitous data format, it is not a very compact format suitable for data exchange, for instance over a network. Hence, the library supports [BSON](https://bsonspec.org) (Binary JSON), [CBOR](https://cbor.io) (Concise Binary Object Representation), [MessagePack](https://msgpack.org), [UBJSON](https://ubjson.org) (Universal Binary JSON Specification) and [BJData](https://neurojson.org/bjdata) (Binary JData) to efficiently encode JSON values to byte vectors and to decode such vectors.\n\n```cpp\n// create a JSON value\njson j = R\"({\"compact\": true, \"schema\": 0})\"_json;\n\n// serialize to BSON\nstd::vector<std::uint8_t> v_bson = json::to_bson(j);\n\n// 0x1B, 0x00, 0x00, 0x00, 0x08, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0x00, 0x01, 0x10, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n\n// roundtrip\njson j_from_bson = json::from_bson(v_bson);\n\n// serialize to CBOR\nstd::vector<std::uint8_t> v_cbor = json::to_cbor(j);\n\n// 0xA2, 0x67, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0xF5, 0x66, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00\n\n// roundtrip\njson j_from_cbor = json::from_cbor(v_cbor);\n\n// serialize to MessagePack\nstd::vector<std::uint8_t> v_msgpack = json::to_msgpack(j);\n\n// 0x82, 0xA7, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0xC3, 0xA6, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x00\n\n// roundtrip\njson j_from_msgpack = json::from_msgpack(v_msgpack);\n\n// serialize to UBJSON\nstd::vector<std::uint8_t> v_ubjson = json::to_ubjson(j);\n\n// 0x7B, 0x69, 0x07, 0x63, 0x6F, 0x6D, 0x70, 0x61, 0x63, 0x74, 0x54, 0x69, 0x06, 0x73, 0x63, 0x68, 0x65, 0x6D, 0x61, 0x69, 0x00, 0x7D\n\n// roundtrip\njson j_from_ubjson = json::from_ubjson(v_ubjson);\n```\n\nThe library also supports binary types from BSON, CBOR (byte strings), and MessagePack (bin, ext, fixext). They are stored by default as `std::vector<std::uint8_t>` to be processed outside the library.\n\n```cpp\n// CBOR byte string with payload 0xCAFE\nstd::vector<std::uint8_t> v = {0x42, 0xCA, 0xFE};\n\n// read value\njson j = json::from_cbor(v);\n\n// the JSON value has type binary\nj.is_binary(); // true\n\n// get reference to stored binary value\nauto& binary = j.get_binary();\n\n// the binary value has no subtype (CBOR has no binary subtypes)\nbinary.has_subtype(); // false\n\n// access std::vector<std::uint8_t> member functions\nbinary.size(); // 2\nbinary[0]; // 0xCA\nbinary[1]; // 0xFE\n\n// set subtype to 0x10\nbinary.set_subtype(0x10);\n\n// serialize to MessagePack\nauto cbor = json::to_msgpack(j); // 0xD5 (fixext2), 0x10, 0xCA, 0xFE\n```\n\n## Customers\n\nThe library is used in multiple projects, applications, operating systems, etc. The list below is not exhaustive, but the result of an internet search. If you know further customers of the library, please let me know, see [contact](#contact).\n\n[![logos of customers using the library](docs/mkdocs/docs/images/customers.png)](https://json.nlohmann.me/home/customers/)\n\n## Supported compilers\n\nThough it's 2026 already, the support for C++11 is still a bit sparse. Currently, the following compilers are known to work:\n\n- GCC 4.8 - 14.2 (and possibly later)\n- Clang 3.4 - 21.0 (and possibly later)\n- Apple Clang 9.1 - 16.0 (and possibly later)\n- Intel C++ Compiler 17.0.2 (and possibly later)\n- Nvidia CUDA Compiler 11.0.221 (and possibly later)\n- Microsoft Visual C++ 2015 / Build Tools 14.0.25123.0 (and possibly later)\n- Microsoft Visual C++ 2017 / Build Tools 15.5.180.51428 (and possibly later)\n- Microsoft Visual C++ 2019 / Build Tools 16.3.1+1def00d3d (and possibly later)\n- Microsoft Visual C++ 2022 / Build Tools 19.30.30709.0 (and possibly later)\n\nI would be happy to learn about other compilers/versions.\n\nPlease note:\n\n- GCC 4.8 has a bug [57824](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=57824): multiline raw strings cannot be the arguments to macros. Don't use multiline raw strings directly in macros with this compiler.\n- Android defaults to using very old compilers and C++ libraries. To fix this, add the following to your `Application.mk`. This will switch to the LLVM C++ library, the Clang compiler, and enable C++11 and other features disabled by default.\n\n    ```makefile\n    APP_STL := c++_shared\n    NDK_TOOLCHAIN_VERSION := clang3.6\n    APP_CPPFLAGS += -frtti -fexceptions\n    ```\n\n    The code compiles successfully with [Android NDK](https://developer.android.com/ndk/index.html?hl=ml), Revision 9 - 11 (and possibly later) and [CrystaX's Android NDK](https://www.crystax.net/en/android/ndk) version 10.\n\n- For GCC running on MinGW or Android SDK, the error `'to_string' is not a member of 'std'` (or similarly, for `strtod` or `strtof`) may occur. Note this is not an issue with the code, but rather with the compiler itself. On Android, see above to build with a newer environment.  For MinGW, please refer to [this site](https://tehsausage.com/mingw-to-string) and [this discussion](https://github.com/nlohmann/json/issues/136) for information on how to fix this bug. For Android NDK using `APP_STL := gnustl_static`, please refer to [this discussion](https://github.com/nlohmann/json/issues/219).\n\n- Unsupported versions of GCC and Clang are rejected by `#error` directives. This can be switched off by defining `JSON_SKIP_UNSUPPORTED_COMPILER_CHECK`. Note that you can expect no support in this case.\n\nSee the page [quality assurance](https://json.nlohmann.me/community/quality_assurance) on the compilers used to check the library in the CI.\n\n## Integration\n\n[`json.hpp`](https://github.com/nlohmann/json/blob/develop/single_include/nlohmann/json.hpp) is the single required file in `single_include/nlohmann` or [released here](https://github.com/nlohmann/json/releases). You need to add\n\n```cpp\n#include <nlohmann/json.hpp>\n\n// for convenience\nusing json = nlohmann::json;\n```\n\nto the files you want to process JSON and set the necessary switches to enable C++11 (e.g., `-std=c++11` for GCC and Clang).\n\nYou can further use file [`include/nlohmann/json_fwd.hpp`](https://github.com/nlohmann/json/blob/develop/include/nlohmann/json_fwd.hpp) for forward-declarations. The installation of `json_fwd.hpp` (as part of cmake's install step) can be achieved by setting `-DJSON_MultipleHeaders=ON`.\n\n### CMake\n\nYou can also use the `nlohmann_json::nlohmann_json` interface target in CMake.  This target populates the appropriate usage requirements for `INTERFACE_INCLUDE_DIRECTORIES` to point to the appropriate include directories and `INTERFACE_COMPILE_FEATURES` for the necessary C++11 flags.\n\n#### External\n\nTo use this library from a CMake project, you can locate it directly with `find_package()` and use the namespaced imported target from the generated package configuration:\n\n```cmake\n# CMakeLists.txt\nfind_package(nlohmann_json 3.12.0 REQUIRED)\n...\nadd_library(foo ...)\n...\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\nThe package configuration file, `nlohmann_jsonConfig.cmake`, can be used either from an install tree or directly out of the build tree.\n\n#### Embedded\n\nTo embed the library directly into an existing CMake project, place the entire source tree in a subdirectory and call `add_subdirectory()` in your `CMakeLists.txt` file:\n\n```cmake\n# Typically you don't care so much for a third party library's tests to be\n# run from your own project's code.\nset(JSON_BuildTests OFF CACHE INTERNAL \"\")\n\n# If you only include this third party in PRIVATE source files, you do not\n# need to install it when your main project gets installed.\n# set(JSON_Install OFF CACHE INTERNAL \"\")\n\n# Don't use include(nlohmann_json/CMakeLists.txt) since that carries with it\n# unintended consequences that will break the build.  It's generally\n# discouraged (although not necessarily well documented as such) to use\n# include(...) for pulling in other CMake projects anyways.\nadd_subdirectory(nlohmann_json)\n...\nadd_library(foo ...)\n...\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n##### Embedded (FetchContent)\n\nSince CMake v3.11,\n[FetchContent](https://cmake.org/cmake/help/v3.11/module/FetchContent.html) can\nbe used to automatically download a release as a dependency at configure time.\n\nExample:\n\n```cmake\ninclude(FetchContent)\n\nFetchContent_Declare(json URL https://github.com/nlohmann/json/releases/download/v3.12.0/json.tar.xz)\nFetchContent_MakeAvailable(json)\n\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n**Note**: It is recommended to use the URL approach described above, which is supported as of version 3.10.0. See\n<https://json.nlohmann.me/integration/cmake/#fetchcontent> for more information.\n\n#### Supporting Both\n\nTo allow your project to support either an externally supplied or an embedded JSON library, you can use a pattern akin to the following:\n\n``` cmake\n# Top level CMakeLists.txt\nproject(FOO)\n...\noption(FOO_USE_EXTERNAL_JSON \"Use an external JSON library\" OFF)\n...\nadd_subdirectory(thirdparty)\n...\nadd_library(foo ...)\n...\n# Note that the namespaced target will always be available regardless of the\n# import method\ntarget_link_libraries(foo PRIVATE nlohmann_json::nlohmann_json)\n```\n\n```cmake\n# thirdparty/CMakeLists.txt\n...\nif(FOO_USE_EXTERNAL_JSON)\n  find_package(nlohmann_json 3.12.0 REQUIRED)\nelse()\n  set(JSON_BuildTests OFF CACHE INTERNAL \"\")\n  add_subdirectory(nlohmann_json)\nendif()\n...\n```\n\n`thirdparty/nlohmann_json` is then a complete copy of this source tree.\n\n### Package Managers\n\nUse your favorite [**package manager**](https://json.nlohmann.me/integration/package_managers/) to use the library.\n\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/homebrew.svg\" height=\"20\">&nbsp;[**Homebrew**](https://json.nlohmann.me/integration/package_managers/#homebrew) `nlohmann-json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/meson.svg\" height=\"20\">&nbsp;[**Meson**](https://json.nlohmann.me/integration/package_managers/#meson) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/bazel.svg\" height=\"20\">&nbsp;[**Bazel**](https://json.nlohmann.me/integration/package_managers/#bazel) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/conan.svg\" height=\"20\">&nbsp;[**Conan**](https://json.nlohmann.me/integration/package_managers/#conan) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/spack.svg\" height=\"20\">&nbsp;[**Spack**](https://json.nlohmann.me/integration/package_managers/#spack) `nlohmann-json`\n- [**Hunter**](https://json.nlohmann.me/integration/package_managers/#hunter) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/vcpkg.png\" height=\"20\">&nbsp;[**vcpkg**](https://json.nlohmann.me/integration/package_managers/#vcpkg) `nlohmann-json`\n- [**cget**](https://json.nlohmann.me/integration/package_managers/#cget) `nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/swift.svg\" height=\"20\">&nbsp;[**Swift Package Manager**](https://json.nlohmann.me/integration/package_managers/#swift-package-manager) `nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/nuget.svg\" height=\"20\">&nbsp;[**Nuget**](https://json.nlohmann.me/integration/package_managers/#nuget) `nlohmann.json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/conda.svg\" height=\"20\">&nbsp;[**Conda**](https://json.nlohmann.me/integration/package_managers/#conda) `nlohmann_json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/macports.svg\" height=\"20\">&nbsp;[**MacPorts**](https://json.nlohmann.me/integration/package_managers/#macports) `nlohmann-json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/CPM.png\" height=\"20\">&nbsp;[**cpm.cmake**](https://json.nlohmann.me/integration/package_managers/#cpmcmake) `gh:nlohmann/json`\n- <img src=\"https://raw.githubusercontent.com/nlohmann/json/refs/heads/develop/docs/mkdocs/docs/images/package_managers/xmake.svg\" height=\"20\">&nbsp;[**xmake**](https://json.nlohmann.me/integration/package_managers/#xmake) `nlohmann_json`\n\nThe library is part of many package managers. See the [**documentation**](https://json.nlohmann.me/integration/package_managers/) for detailed descriptions and examples.\n\n### Pkg-config\n\nIf you are using bare Makefiles, you can use `pkg-config` to generate the include flags that point to where the library is installed:\n\n```sh\npkg-config nlohmann_json --cflags\n```\n\n## License\n\n<img align=\"right\" src=\"https://149753425.v2.pressablecdn.com/wp-content/uploads/2009/06/OSIApproved_100X125.png\" alt=\"OSI approved license\">\n\nThe class is licensed under the [MIT License](https://opensource.org/licenses/MIT):\n\nCopyright &copy; 2013-2026 [Niels Lohmann](https://nlohmann.me)\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the â€œSoftwareâ€), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED â€œAS ISâ€, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n* * *\n\n- The class contains the UTF-8 Decoder from Bjoern Hoehrmann which is licensed under the [MIT License](https://opensource.org/licenses/MIT) (see above). Copyright &copy; 2008-2009 [BjÃ¶rn Hoehrmann](https://bjoern.hoehrmann.de/) <bjoern@hoehrmann.de>\n- The class contains a slightly modified version of the Grisu2 algorithm from Florian Loitsch which is licensed under the [MIT License](https://opensource.org/licenses/MIT) (see above). Copyright &copy; 2009 [Florian Loitsch](https://florian.loitsch.com/)\n- The class contains a copy of [Hedley](https://nemequ.github.io/hedley/) from Evan Nemerson which is licensed as [CC0-1.0](https://creativecommons.org/publicdomain/zero/1.0/).\n- The class contains parts of [Google Abseil](https://github.com/abseil/abseil-cpp) which is licensed under the [Apache 2.0 License](https://opensource.org/licenses/Apache-2.0).\n\n<img align=\"right\" src=\"https://git.fsfe.org/reuse/reuse-ci/raw/branch/master/reuse-horizontal.png\" alt=\"REUSE Software\">\n\nThe library is compliant to version 3.3 of the [**REUSE specification**](https://reuse.software):\n\n- Every source file contains an SPDX copyright header.\n- The full text of all licenses used in the repository can be found in the `LICENSES` folder.\n- File `.reuse/dep5` contains an overview of all files' copyrights and licenses.\n- Run `pipx run reuse lint` to verify the project's REUSE compliance and `pipx run reuse spdx` to generate a SPDX SBOM.\n\n## Contact\n\nIf you have questions regarding the library, I would like to invite you to [open an issue at GitHub](https://github.com/nlohmann/json/issues/new/choose). Please describe your request, problem, or question as detailed as possible, and also mention the version of the library you are using as well as the version of your compiler and operating system. Opening an issue at GitHub allows other users and contributors to this library to collaborate. For instance, I have little experience with MSVC, and most issues in this regard have been solved by a growing community. If you have a look at the [closed issues](https://github.com/nlohmann/json/issues?q=is%3Aissue+is%3Aclosed), you will see that we react quite timely in most cases.\n\nOnly if your request would contain confidential information, please [send me an email](mailto:mail@nlohmann.me). For encrypted messages, please use [this key](https://keybase.io/nlohmann/pgp_keys.asc).\n\n## Security\n\n[Commits by Niels Lohmann](https://github.com/nlohmann/json/commits) and [releases](https://github.com/nlohmann/json/releases) are signed with this [PGP Key](https://keybase.io/nlohmann/pgp_keys.asc?fingerprint=797167ae41c0a6d9232e48457f3cea63ae251b69).\n\n## Thanks\n\nI deeply appreciate the help of the following people.\n\n<img src=\"https://raw.githubusercontent.com/nlohmann/json/develop/docs/avatars.png\" align=\"right\" alt=\"GitHub avatars of the contributors\">\n\n1. [Teemperor](https://github.com/Teemperor) implemented CMake support and lcov integration, realized escape and Unicode handling in the string parser, and fixed the JSON serialization.\n2. [elliotgoodrich](https://github.com/elliotgoodrich) fixed an issue with double deletion in the iterator classes.\n3. [kirkshoop](https://github.com/kirkshoop) made the iterators of the class composable to other libraries.\n4. [wancw](https://github.com/wanwc) fixed a bug that hindered the class to compile with Clang.\n5. Tomas Ã…blad found a bug in the iterator implementation.\n6. [Joshua C. Randall](https://github.com/jrandall) fixed a bug in the floating-point serialization.\n7. [Aaron Burghardt](https://github.com/aburgh) implemented code to parse streams incrementally. Furthermore, he greatly improved the parser class by allowing the definition of a filter function to discard undesired elements while parsing.\n8. [Daniel KopeÄek](https://github.com/dkopecek) fixed a bug in the compilation with GCC 5.0.\n9. [Florian Weber](https://github.com/Florianjw) fixed a bug in and improved the performance of the comparison operators.\n10. [Eric Cornelius](https://github.com/EricMCornelius) pointed out a bug in the handling with NaN and infinity values. He also improved the performance of the string escaping.\n11. [æ˜“æ€é¾™](https://github.com/likebeta) implemented a conversion from anonymous enums.\n12. [kepkin](https://github.com/kepkin) patiently pushed forward the support for Microsoft Visual Studio.\n13. [gregmarr](https://github.com/gregmarr) simplified the implementation of reverse iterators and helped with numerous hints and improvements. In particular, he pushed forward the implementation of user-defined types.\n14. [Caio Luppi](https://github.com/caiovlp) fixed a bug in the Unicode handling.\n15. [dariomt](https://github.com/dariomt) fixed some typos in the examples.\n16. [Daniel Frey](https://github.com/d-frey) cleaned up some pointers and implemented exception-safe memory allocation.\n17. [Colin Hirsch](https://github.com/ColinH) took care of a small namespace issue.\n18. [Huu Nguyen](https://github.com/whoshuu) corrected a variable name in the documentation.\n19. [Silverweed](https://github.com/silverweed) overloaded `parse()` to accept an rvalue reference.\n20. [dariomt](https://github.com/dariomt) fixed a subtlety in MSVC type support and implemented the `get_ref()` function to get a reference to stored values.\n21. [ZahlGraf](https://github.com/ZahlGraf) added a workaround that allows compilation using Android NDK.\n22. [whackashoe](https://github.com/whackashoe) replaced a function that was marked as unsafe by Visual Studio.\n23. [406345](https://github.com/406345) fixed two small warnings.\n24. [Glen Fernandes](https://github.com/glenfe) noted a potential portability problem in the `has_mapped_type` function.\n25. [Corbin Hughes](https://github.com/nibroc) fixed some typos in the contribution guidelines.\n26. [twelsby](https://github.com/twelsby) fixed the array subscript operator, an issue that failed the MSVC build, and floating-point parsing/dumping. He further added support for unsigned integer numbers and implemented better roundtrip support for parsed numbers.\n27. [Volker Diels-Grabsch](https://github.com/vog) fixed a link in the README file.\n28. [msm-](https://github.com/msm-) added support for American Fuzzy Lop.\n29. [Annihil](https://github.com/Annihil) fixed an example in the README file.\n30. [Themercee](https://github.com/Themercee) noted a wrong URL in the README file.\n31. [Lv Zheng](https://github.com/lv-zheng) fixed a namespace issue with `int64_t` and `uint64_t`.\n32. [abc100m](https://github.com/abc100m) analyzed the issues with GCC 4.8 and proposed a [partial solution](https://github.com/nlohmann/json/pull/212).\n33. [zewt](https://github.com/zewt) added useful notes to the README file about Android.\n34. [RÃ³bert MÃ¡rki](https://github.com/robertmrk) added a fix to use move iterators and improved the integration via CMake.\n35. [Chris Kitching](https://github.com/ChrisKitching) cleaned up the CMake files.\n36. [Tom Needham](https://github.com/06needhamt) fixed a subtle bug with MSVC 2015 which was also proposed by [Michael K.](https://github.com/Epidal).\n37. [MÃ¡rio Feroldi](https://github.com/thelostt) fixed a small typo.\n38. [duncanwerner](https://github.com/duncanwerner) found a really embarrassing performance regression in the 2.0.0 release.\n39. [Damien](https://github.com/dtoma) fixed one of the last conversion warnings.\n40. [Thomas Braun](https://github.com/t-b) fixed a warning in a test case and adjusted MSVC calls in the CI.\n41. [ThÃ©o DELRIEU](https://github.com/theodelrieu) patiently and constructively oversaw the long way toward [iterator-range parsing](https://github.com/nlohmann/json/issues/290). He also implemented the magic behind the serialization/deserialization of user-defined types and split the single header file into smaller chunks.\n42. [Stefan](https://github.com/5tefan) fixed a minor issue in the documentation.\n43. [Vasil Dimov](https://github.com/vasild) fixed the documentation regarding conversions from `std::multiset`.\n44. [ChristophJud](https://github.com/ChristophJud) overworked the CMake files to ease project inclusion.\n45. [Vladimir Petrigo](https://github.com/vpetrigo) made a SFINAE hack more readable and added Visual Studio 17 to the build matrix.\n46. [Denis Andrejew](https://github.com/seeekr) fixed a grammar issue in the README file.\n47. [Pierre-Antoine Lacaze](https://github.com/palacaze) found a subtle bug in the `dump()` function.\n48. [TurpentineDistillery](https://github.com/TurpentineDistillery) pointed to [`std::locale::classic()`](https://en.cppreference.com/w/cpp/locale/locale/classic) to avoid too much locale joggling, found some nice performance improvements in the parser, improved the benchmarking code, and realized locale-independent number parsing and printing.\n49. [cgzones](https://github.com/cgzones) had an idea how to fix the Coverity scan.\n50. [Jared Grubb](https://github.com/jaredgrubb) silenced a nasty documentation warning.\n51. [Yixin Zhang](https://github.com/qwename) fixed an integer overflow check.\n52. [Bosswestfalen](https://github.com/Bosswestfalen) merged two iterator classes into a smaller one.\n53. [Daniel599](https://github.com/Daniel599) helped to get Travis to execute the tests with Clang's sanitizers.\n54. [Jonathan Lee](https://github.com/vjon) fixed an example in the README file.\n55. [gnzlbg](https://github.com/gnzlbg) supported the implementation of user-defined types.\n56. [Alexej Harm](https://github.com/qis) helped to get the user-defined types working with Visual Studio.\n57. [Jared Grubb](https://github.com/jaredgrubb) supported the implementation of user-defined types.\n58. [EnricoBilla](https://github.com/EnricoBilla) noted a typo in an example.\n59. [Martin HoÅ™eÅˆovskÃ½](https://github.com/horenmar) found a way for a 2x speedup for the compilation time of the test suite.\n60. [ukhegg](https://github.com/ukhegg) found proposed an improvement for the examples section.\n61. [rswanson-ihi](https://github.com/rswanson-ihi) noted a typo in the README.\n62. [Mihai Stan](https://github.com/stanmihai4) fixed a bug in the comparison with `nullptr`s.\n63. [Tushar Maheshwari](https://github.com/tusharpm) added [cotire](https://github.com/sakra/cotire) support to speed up the compilation.\n64. [TedLyngmo](https://github.com/TedLyngmo) noted a typo in the README, removed unnecessary bit arithmetic, and fixed some `-Weffc++` warnings.\n65. [Krzysztof WoÅ›](https://github.com/krzysztofwos) made exceptions more visible.\n66. [ftillier](https://github.com/ftillier) fixed a compiler warning.\n67. [tinloaf](https://github.com/tinloaf) made sure all pushed warnings are properly popped.\n68. [Fytch](https://github.com/Fytch) found a bug in the documentation.\n69. [Jay Sistar](https://github.com/Type1J) implemented a Meson build description.\n70. [Henry Lee](https://github.com/HenryRLee) fixed a warning in ICC and improved the iterator implementation.\n71. [Vincent Thiery](https://github.com/vthiery) maintains a package for the Conan package manager.\n72. [Steffen](https://github.com/koemeet) fixed a potential issue with MSVC and `std::min`.\n73. [Mike Tzou](https://github.com/Chocobo1) fixed some typos.\n74. [amrcode](https://github.com/amrcode) noted misleading documentation about comparison of floats.\n75. [Oleg Endo](https://github.com/olegendo) reduced the memory consumption by replacing `<iostream>` with `<iosfwd>`.\n76. [dan-42](https://github.com/dan-42) cleaned up the CMake files to simplify including/reusing of the library.\n77. [Nikita Ofitserov](https://github.com/himikof) allowed for moving values from initializer lists.\n78. [Greg Hurrell](https://github.com/wincent) fixed a typo.\n79. [Dmitry Kukovinets](https://github.com/DmitryKuk) fixed a typo.\n80. [kbthomp1](https://github.com/kbthomp1) fixed an issue related to the Intel OSX compiler.\n81. [Markus Werle](https://github.com/daixtrose) fixed a typo.\n82. [WebProdPP](https://github.com/WebProdPP) fixed a subtle error in a precondition check.\n83. [Alex](https://github.com/leha-bot) noted an error in a code sample.\n84. [Tom de Geus](https://github.com/tdegeus) reported some warnings with ICC and helped to fix them.\n85. [Perry Kundert](https://github.com/pjkundert) simplified reading from input streams.\n86. [Sonu Lohani](https://github.com/sonulohani) fixed a small compilation error.\n87. [Jamie Seward](https://github.com/jseward) fixed all MSVC warnings.\n88. [Nate Vargas](https://github.com/eld00d) added a Doxygen tag file.\n89. [pvleuven](https://github.com/pvleuven) helped to fix a warning in ICC.\n90. [Pavel](https://github.com/crea7or) helped to fix some warnings in MSVC.\n91. [Jamie Seward](https://github.com/jseward) avoided unnecessary string copies in `find()` and `count()`.\n92. [Mitja](https://github.com/Itja) fixed some typos.\n93. [Jorrit Wronski](https://github.com/jowr) updated the Hunter package links.\n94. [Matthias MÃ¶ller](https://github.com/TinyTinni) added a `.natvis` for the MSVC debug view.\n95. [bogemic](https://github.com/bogemic) fixed some C++17 deprecation warnings.\n96. [Eren Okka](https://github.com/erengy) fixed some MSVC warnings.\n97. [abolz](https://github.com/abolz) integrated the Grisu2 algorithm for proper floating-point formatting, allowing more roundtrip checks to succeed.\n98. [Vadim Evard](https://github.com/Pipeliner) fixed a Markdown issue in the README.\n99. [zerodefect](https://github.com/zerodefect) fixed a compiler warning.\n100. [Kert](https://github.com/kaidokert) allowed to template the string type in the serialization and added the possibility to override the exceptional behavior.\n101. [mark-99](https://github.com/mark-99) helped fix an ICC error.\n102. [Patrik Huber](https://github.com/patrikhuber) fixed links in the README file.\n103. [johnfb](https://github.com/johnfb) found a bug in the implementation of CBOR's indefinite length strings.\n104. [Paul Fultz II](https://github.com/pfultz2) added a note on the cget package manager.\n105. [Wilson Lin](https://github.com/wla80) made the integration section of the README more concise.\n106. [RalfBielig](https://github.com/ralfbielig) detected and fixed a memory leak in the parser callback.\n107. [agrianius](https://github.com/agrianius) allowed dumping JSON to an alternative string type.\n108. [Kevin Tonon](https://github.com/ktonon) overworked the C++11 compiler checks in CMake.\n109. [Axel Huebl](https://github.com/ax3l) simplified a CMake check and added support for the [Spack package manager](https://spack.io).\n110. [Carlos O'Ryan](https://github.com/coryan) fixed a typo.\n111. [James Upjohn](https://github.com/jammehcow) fixed a version number in the compilers section.\n112. [Chuck Atkins](https://github.com/chuckatkins) adjusted the CMake files to the CMake packaging guidelines and provided documentation for the CMake integration.\n113. [Jan SchÃ¶ppach](https://github.com/dns13) fixed a typo.\n114. [martin-mfg](https://github.com/martin-mfg) fixed a typo.\n115. [Matthias MÃ¶ller](https://github.com/TinyTinni) removed the dependency from `std::stringstream`.\n116. [agrianius](https://github.com/agrianius) added code to use alternative string implementations.\n117. [Daniel599](https://github.com/Daniel599) allowed to use more algorithms with the `items()` function.\n118. [Julius Rakow](https://github.com/jrakow) fixed the Meson include directory and fixed the links to [cppreference.com](https://cppreference.com).\n119. [Sonu Lohani](https://github.com/sonulohani) fixed the compilation with MSVC 2015 in debug mode.\n120. [grembo](https://github.com/grembo) fixed the test suite and re-enabled several test cases.\n121. [Hyeon Kim](https://github.com/simnalamburt) introduced the macro `JSON_INTERNAL_CATCH` to control the exception handling inside the library.\n122. [thyu](https://github.com/thyu) fixed a compiler warning.\n123. [David Guthrie](https://github.com/LEgregius) fixed a subtle compilation error with Clang 3.4.2.\n124. [Dennis Fischer](https://github.com/dennisfischer) allowed to call `find_package` without installing the library.\n125. [Hyeon Kim](https://github.com/simnalamburt) fixed an issue with a double macro definition.\n126. [Ben Berman](https://github.com/rivertam) made some error messages more understandable.\n127. [zakalibit](https://github.com/zakalibit) fixed a compilation problem with the Intel C++ compiler.\n128. [mandreyel](https://github.com/mandreyel) fixed a compilation problem.\n129. [Kostiantyn Ponomarenko](https://github.com/koponomarenko) added version and license information to the Meson build file.\n130. [Henry Schreiner](https://github.com/henryiii) added support for GCC 4.8.\n131. [knilch](https://github.com/knilch0r) made sure the test suite does not stall when run in the wrong directory.\n132. [Antonio Borondo](https://github.com/antonioborondo) fixed an MSVC 2017 warning.\n133. [Dan Gendreau](https://github.com/dgendreau) implemented the `NLOHMANN_JSON_SERIALIZE_ENUM` macro to quickly define an enum/JSON mapping.\n134. [efp](https://github.com/efp) added line and column information to parse errors.\n135. [julian-becker](https://github.com/julian-becker) added BSON support.\n136. [Pratik Chowdhury](https://github.com/pratikpc) added support for structured bindings.\n137. [David Avedissian](https://github.com/davedissian) added support for Clang 5.0.1 (PS4 version).\n138. [Jonathan Dumaresq](https://github.com/dumarjo) implemented an input adapter to read from `FILE*`.\n139. [kjpus](https://github.com/kjpus) fixed a link in the documentation.\n140. [Manvendra Singh](https://github.com/manu-chroma) fixed a typo in the documentation.\n141. [ziggurat29](https://github.com/ziggurat29) fixed an MSVC warning.\n142. [Sylvain Corlay](https://github.com/SylvainCorlay) added code to avoid an issue with MSVC.\n143. [mefyl](https://github.com/mefyl) fixed a bug when JSON was parsed from an input stream.\n144. [Millian Poquet](https://github.com/mpoquet) allowed to install the library via Meson.\n145. [Michael Behrns-Miller](https://github.com/moodboom) found an issue with a missing namespace.\n146. [Nasztanovics Ferenc](https://github.com/naszta) fixed a compilation issue with libc 2.12.\n147. [Andreas Schwab](https://github.com/andreas-schwab) fixed the endian conversion.\n148. [Mark-Dunning](https://github.com/Mark-Dunning) fixed a warning in MSVC.\n149. [Gareth Sylvester-Bradley](https://github.com/garethsb-sony) added `operator/` for JSON Pointers.\n150. [John-Mark](https://github.com/johnmarkwayve) noted a missing header.\n151. [Vitaly Zaitsev](https://github.com/xvitaly) fixed compilation with GCC 9.0.\n152. [Laurent Stacul](https://github.com/stac47) fixed compilation with GCC 9.0.\n153. [Ivor Wanders](https://github.com/iwanders) helped to reduce the CMake requirement to version 3.1.\n154. [njlr](https://github.com/njlr) updated the Buckaroo instructions.\n155. [Lion](https://github.com/lieff) fixed a compilation issue with GCC 7 on CentOS.\n156. [Isaac Nickaein](https://github.com/nickaein) improved the integer serialization performance and implemented the `contains()` function.\n157. [past-due](https://github.com/past-due) suppressed an unfixable warning.\n158. [Elvis Oric](https://github.com/elvisoric) improved Meson support.\n159. [MatÄ›j Plch](https://github.com/Afforix) fixed an example in the README.\n160. [Mark Beckwith](https://github.com/wythe) fixed a typo.\n161. [scinart](https://github.com/scinart) fixed a bug in the serializer.\n162. [Patrick Boettcher](https://github.com/pboettch) implemented `push_back()` and `pop_back()` for JSON Pointers.\n163. [Bruno Oliveira](https://github.com/nicoddemus) added support for Conda.\n164. [Michele Caini](https://github.com/skypjack) fixed links in the README.\n165. [Hani](https://github.com/hnkb) documented how to install the library with NuGet.\n166. [Mark Beckwith](https://github.com/wythe) fixed a typo.\n167. [yann-morin-1998](https://github.com/yann-morin-1998) helped to reduce the CMake requirement to version 3.1.\n168. [Konstantin Podsvirov](https://github.com/podsvirov) maintains a package for the MSYS2 software distro.\n169. [remyabel](https://github.com/remyabel) added GNUInstallDirs to the CMake files.\n170. [Taylor Howard](https://github.com/taylorhoward92) fixed a unit test.\n171. [Gabe Ron](https://github.com/Macr0Nerd) implemented the `to_string` method.\n172. [Watal M. Iwasaki](https://github.com/heavywatal) fixed a Clang warning.\n173. [Viktor Kirilov](https://github.com/onqtam) switched the unit tests from [Catch](https://github.com/philsquared/Catch) to [doctest](https://github.com/onqtam/doctest)\n174. [Juncheng E](https://github.com/ejcjason) fixed a typo.\n175. [tete17](https://github.com/tete17) fixed a bug in the `contains` function.\n176. [Xav83](https://github.com/Xav83) fixed some cppcheck warnings.\n177. [0xflotus](https://github.com/0xflotus) fixed some typos.\n178. [Christian Deneke](https://github.com/chris0x44) added a const version of `json_pointer::back`.\n179. [Julien Hamaide](https://github.com/crazyjul) made the `items()` function work with custom string types.\n180. [Evan Nemerson](https://github.com/nemequ) updated fixed a bug in Hedley and updated this library accordingly.\n181. [Florian Pigorsch](https://github.com/flopp) fixed a lot of typos.\n182. [Camille BÃ©guÃ©](https://github.com/cbegue) fixed an issue in the conversion from  `std::pair` and `std::tuple` to `json`.\n183. [Anthony VH](https://github.com/AnthonyVH) fixed a compile error in an enum deserialization.\n184. [Yuriy Vountesmery](https://github.com/ua-code-dragon) noted a subtle bug in a preprocessor check.\n185. [Chen](https://github.com/dota17) fixed numerous issues in the library.\n186. [Antony Kellermann](https://github.com/aokellermann) added a CI step for GCC 10.1.\n187. [Alex](https://github.com/gistrec) fixed an MSVC warning.\n188. [Rainer](https://github.com/rvjr) proposed an improvement in the floating-point serialization in CBOR.\n189. [Francois Chabot](https://github.com/FrancoisChabot) made performance improvements in the input adapters.\n190. [Arthur Sonzogni](https://github.com/ArthurSonzogni) documented how the library can be included via `FetchContent`.\n191. [Rimas MiseviÄius](https://github.com/rmisev) fixed an error message.\n192. [Alexander Myasnikov](https://github.com/alexandermyasnikov) fixed some examples and a link in the README.\n193. [Hubert Chathi](https://github.com/uhoreg) made CMake's version config file architecture-independent.\n194. [OmnipotentEntity](https://github.com/OmnipotentEntity) implemented the binary values for CBOR, MessagePack, BSON, and UBJSON.\n195. [ArtemSarmini](https://github.com/ArtemSarmini) fixed a compilation issue with GCC 10 and fixed a leak.\n196. [Evgenii Sopov](https://github.com/sea-kg) integrated the library to the wsjcpp package manager.\n197. [Sergey Linev](https://github.com/linev) fixed a compiler warning.\n198. [Miguel MagalhÃ£es](https://github.com/magamig) fixed the year in the copyright.\n199. [Gareth Sylvester-Bradley](https://github.com/garethsb-sony) fixed a compilation issue with MSVC.\n200. [Alexander â€œweejâ€ Jones](https://github.com/alex-weej) fixed an example in the README.\n201. [Antoine CÅ“ur](https://github.com/Coeur) fixed some typos in the documentation.\n202. [jothepro](https://github.com/jothepro) updated links to the Hunter package.\n203. [Dave Lee](https://github.com/kastiglione) fixed a link in the README.\n204. [JoÃ«l Lamotte](https://github.com/Klaim) added instruction for using Build2's package manager.\n205. [Paul Jurczak](https://github.com/pauljurczak) fixed an example in the README.\n206. [Sonu Lohani](https://github.com/sonulohani) fixed a warning.\n207. [Carlos Gomes Martinho](https://github.com/gocarlos) updated the Conan package source.\n208. [Konstantin Podsvirov](https://github.com/podsvirov) fixed the MSYS2 package documentation.\n209. [Tridacnid](https://github.com/Tridacnid) improved the CMake tests.\n210. [Michael](https://github.com/MBalszun) fixed MSVC warnings.\n211. [Quentin Barbarat](https://github.com/quentin-dev) fixed an example in the documentation.\n212. [XyFreak](https://github.com/XyFreak) fixed a compiler warning.\n213. [TotalCaesar659](https://github.com/TotalCaesar659) fixed links in the README.\n214. [Tanuj Garg](https://github.com/tanuj208) improved the fuzzer coverage for UBSAN input.\n215. [AODQ](https://github.com/AODQ) fixed a compiler warning.\n216. [jwittbrodt](https://github.com/jwittbrodt) made `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE` inline.\n217. [pfeatherstone](https://github.com/pfeatherstone) improved the upper bound of arguments of the `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`/`NLOHMANN_DEFINE_TYPE_INTRUSIVE` macros.\n218. [Jan ProchÃ¡zka](https://github.com/jprochazk) fixed a bug in the CBOR parser for binary and string values.\n219. [T0b1-iOS](https://github.com/T0b1-iOS) fixed a bug in the new hash implementation.\n220. [Matthew Bauer](https://github.com/matthewbauer) adjusted the CBOR writer to create tags for binary subtypes.\n221. [gatopeich](https://github.com/gatopeich) implemented an ordered map container for `nlohmann::ordered_json`.\n222. [Ã‰rico Nogueira Rolim](https://github.com/ericonr) added support for pkg-config.\n223. [KonanM](https://github.com/KonanM) proposed an implementation for the `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE`/`NLOHMANN_DEFINE_TYPE_INTRUSIVE` macros.\n224. [Guillaume Racicot](https://github.com/gracicot) implemented `string_view` support and allowed C++20 support.\n225. [Alex Reinking](https://github.com/alexreinking) improved CMake support for `FetchContent`.\n226. [Hannes Domani](https://github.com/ssbssa) provided a GDB pretty printer.\n227. Lars Wirzenius reviewed the README file.\n228. [Jun Jie](https://github.com/ongjunjie) fixed a compiler path in the CMake scripts.\n229. [Ronak Buch](https://github.com/rbuch) fixed typos in the documentation.\n230. [Alexander Karzhenkov](https://github.com/karzhenkov) fixed a move constructor and the Travis builds.\n231. [Leonardo Lima](https://github.com/leozz37) added CPM.Cmake support.\n232. [Joseph Blackman](https://github.com/jbzdarkid) fixed a warning.\n233. [Yaroslav](https://github.com/YarikTH) updated doctest and implemented unit tests.\n234. [Martin Stump](https://github.com/globberwops) fixed a bug in the CMake files.\n235. [Jaakko Moisio](https://github.com/jasujm) fixed a bug in the input adapters.\n236. [bl-ue](https://github.com/bl-ue) fixed some Markdown issues in the README file.\n237. [William A. Wieselquist](https://github.com/wawiesel) fixed an example from the README.\n238. [abbaswasim](https://github.com/abbaswasim) fixed an example from the README.\n239. [Remy Jette](https://github.com/remyjette) fixed a warning.\n240. [Fraser](https://github.com/frasermarlow) fixed the documentation.\n241. [Ben Beasley](https://github.com/musicinmybrain) updated doctest.\n242. [Doron Behar](https://github.com/doronbehar) fixed pkg-config.pc.\n243. [raduteo](https://github.com/raduteo) fixed a warning.\n244. [David Pfahler](https://github.com/theShmoo) added the possibility to compile the library without I/O support.\n245. [Morten Fyhn Amundsen](https://github.com/mortenfyhn) fixed a typo.\n246. [jpl-mac](https://github.com/jpl-mac) allowed treating the library as a system header in CMake.\n247. [Jason Dsouza](https://github.com/jasmcaus) fixed the indentation of the CMake file.\n248. [offa](https://github.com/offa) added a link to Conan Center to the documentation.\n249. [TotalCaesar659](https://github.com/TotalCaesar659) updated the links in the documentation to use HTTPS.\n250. [Rafail Giavrimis](https://github.com/grafail) fixed the Google Benchmark default branch.\n251. [Louis Dionne](https://github.com/ldionne) fixed a conversion operator.\n252. [justanotheranonymoususer](https://github.com/justanotheranonymoususer) made the examples in the README more consistent.\n253. [Finkman](https://github.com/Finkman) suppressed some `-Wfloat-equal` warnings.\n254. [Ferry Huberts](https://github.com/fhuberts) fixed `-Wswitch-enum` warnings.\n255. [Arseniy Terekhin](https://github.com/senyai) made the GDB pretty-printer robust against unset variable names.\n256. [Amir Masoud Abdol](https://github.com/amirmasoudabdol) updated the Homebrew command as nlohmann/json is now in homebrew-core.\n257. [Hallot](https://github.com/Hallot) fixed some `-Wextra-semi-stmt warnings`.\n258. [Giovanni Cerretani](https://github.com/gcerretani) fixed `-Wunused` warnings on `JSON_DIAGNOSTICS`.\n259. [Bogdan Popescu](https://github.com/Kapeli) hosts the [docset](https://github.com/Kapeli/Dash-User-Contributions/tree/master/docsets/JSON_for_Modern_C%2B%2B) for offline documentation viewers.\n260. [Carl Smedstad](https://github.com/carlsmedstad) fixed an assertion error when using `JSON_DIAGNOSTICS`.\n261. [miikka75](https://github.com/miikka75) provided an important fix to compile C++17 code with Clang 9.\n262. [Maarten Becker](https://github.com/kernie) fixed a warning for shadowed variables.\n263. [Cristi VÃ®jdea](https://github.com/axnsan12) fixed typos in the `operator[]` documentation.\n264. [Alex Beregszaszi](https://github.com/axic) fixed spelling mistakes in comments.\n265. [Dirk Stolle](https://github.com/striezel) fixed typos in documentation.\n266. [Daniel Albuschat](https://github.com/daniel-kun) corrected the parameter name in the `parse` documentation.\n267. [Prince Mendiratta](https://github.com/Prince-Mendiratta) fixed a link to the FAQ.\n268. [Florian Albrechtskirchinger](https://github.com/falbrechtskirchinger) implemented `std::string_view` support for object keys and made dozens of other improvements.\n269. [Qianqian Fang](https://github.com/fangq) implemented the Binary JData (BJData) format.\n270. [pketelsen](https://github.com/pketelsen) added macros `NLOHMANN_DEFINE_TYPE_INTRUSIVE_WITH_DEFAULT` and `NLOHMANN_DEFINE_TYPE_NON_INTRUSIVE_WITH_DEFAULT`.\n271. [DarkZeros](https://github.com/DarkZeros) adjusted to code to not clash with Arduino defines.\n272. [flagarde](https://github.com/flagarde) fixed the output of `meta()` for MSVC.\n273. [Giovanni Cerretani](https://github.com/gcerretani) fixed a check for `std::filesystem`.\n274. [Dimitris Apostolou](https://github.com/rex4539) fixed a typo.\n275. [Ferry Huberts](https://github.com/fhuberts) fixed a typo.\n276. [Michael Nosthoff](https://github.com/heinemml) fixed a typo.\n277. [JungHoon Lee](https://github.com/jhnlee) fixed a typo.\n278. [Faruk D.](https://github.com/fdiblen) fixed the CITATION.CFF file.\n279. [Andrea Cocito](https://github.com/puffetto) added a clarification on macro usage to the documentation.\n280. [Krzysiek Karbowiak](https://github.com/kkarbowiak) refactored the tests to use `CHECK_THROWS_WITH_AS`.\n281. [Chaoqi Zhang](https://github.com/prncoprs) fixed a typo.\n282. [ivanovmp](https://github.com/ivanovmp) fixed a whitespace error.\n283. [KsaNL](https://github.com/KsaNL) fixed a build error when including `<windows.h>`.\n284. [Andrea Pappacoda](https://github.com/Tachi107) moved `.pc` and `.cmake` files to `share` directory.\n285. [Wolf Vollprecht](https://github.com/wolfv) added the `patch_inplace` function.\n286. [Jake Zimmerman](https://github.com/jez) highlighted common usage patterns in the README file.\n287. [NN](https://github.com/NN---) added the Visual Studio output directory to `.gitignore`.\n288. [Romain Reignier](https://github.com/romainreignier) improved the performance of the vector output adapter.\n289. [Mike](https://github.com/Mike-Leo-Smith) fixed the `std::iterator_traits`.\n290. [Richard HozÃ¡k](https://github.com/zxey) added macro `JSON_NO_ENUM` to disable default enum conversions.\n291. [vakokako](https://github.com/vakokako) fixed tests when compiling with C++20.\n292. [Alexander â€œweejâ€ Jones](https://github.com/alexweej) fixed an example in the README.\n293. [Eli Schwartz](https://github.com/eli-schwartz) added more files to the `include.zip` archive.\n294. [Kevin Lu](https://github.com/kevinlul) fixed a compilation issue when typedefs with certain names were present.\n295. [Trevor Hickey](https://github.com/luxe) improved the description of an example.\n296. [Jef LeCompte](https://github.com/jef) updated the year in the README file.\n297. [Alexandre Hamez](https://github.com/ahamez) fixed a warning.\n298. [Maninderpal Badhan](https://github.com/mbadhan) fixed a typo.\n299. [kevin--](https://github.com/kevin--) added a note to an example in the README file.\n300. [I](https://github.com/wx257osn2) fixed a typo.\n301. [Gregorio Litenstein](https://github.com/Lord-Kamina) fixed the Clang detection.\n302. [Andreas Smas](https://github.com/andoma) added a Doozer badge.\n303. [WanCW](https://github.com/wancw) fixed the string conversion with Clang.\n304. [zhaohuaxishi](https://github.com/zhaohuaxishi) fixed a Doxygen error.\n305. [emvivre](https://github.com/emvivre) removed an invalid parameter from CMake.\n306. [Tobias Hermann](https://github.com/Dobiasd) fixed a link in the README file.\n307. [Michael](https://github.com/traits) fixed a warning.\n308. [Ryan Mulder](https://github.com/ryanjmulder) added `ensure_ascii` to the `dump` function.\n309. [Muri Nicanor](https://github.com/murinicanor) fixed the `sed` discovery in the Makefile.\n310. [David Avedissian](https://github.com/dgavedissian) implemented SFINAE-friendly `iterator_traits`.\n311. [AQNOUCH Mohammed](https://github.com/aqnouch) fixed a typo in the README.\n312. [Gareth Sylvester-Bradley](https://github.com/garethsb) added `operator/=` and `operator/` to construct JSON pointers.\n313. [Michael Macnair](https://github.com/mykter) added support for afl-fuzz testing.\n314. [Berkus Decker](https://github.com/berkus) fixed a typo in the README.\n315. [Illia Polishchuk](https://github.com/effolkronium) improved the CMake testing.\n316. [Ikko Ashimine](https://github.com/eltociear) fixed a typo.\n317. [Raphael Grimm](https://github.com/barcode) added the possibility to define a custom base class.\n318. [tocic](https://github.com/tocic) fixed typos in the documentation.\n319. [Vertexwahn](https://github.com/Vertexwahn) added Bazel build support.\n320. [Dirk Stolle](https://github.com/striezel) fixed typos in the documentation.\n321. [DavidKorczynski](https://github.com/DavidKorczynski) added a CIFuzz CI GitHub action.\n322. [Finkman](https://github.com/Finkman) fixed the debug pretty-printer.\n323. [Florian Segginger](https://github.com/floriansegginger) bumped the years in the README.\n324. [haadfida](https://github.com/haadfida) cleaned up the badges of used services.\n325. [Arsen ArsenoviÄ‡](https://github.com/ArsenArsen) fixed a build error.\n326. [theevilone45](https://github.com/theevilone45) fixed a typo in a CMake file.\n327. [Sergei Trofimovich](https://github.com/trofi) fixed the custom allocator support.\n328. [Joyce](https://github.com/joycebrum) fixed some security issues in the GitHub workflows.\n329. [Nicolas Jakob](https://github.com/njakob) add vcpkg version badge.\n330. [Tomerkm](https://github.com/Tomerkm) added tests.\n331. [No.](https://github.com/tusooa) fixed the use of `get<>` calls.\n332. [taro](https://github.com/tarolling) fixed a typo in the `CODEOWNERS` file.\n333. [Ikko Eltociear Ashimine](https://github.com/eltociear) fixed a typo.\n334. [Felix Yan](https://github.com/felixonmars) fixed a typo in the README.\n335. [HO-COOH](https://github.com/HO-COOH) fixed a parenthesis in the documentation.\n336. [Ivor Wanders](https://github.com/iwanders) fixed the examples to catch exception by `const&`.\n337. [miny1233](https://github.com/miny1233) fixed a parenthesis in the documentation.\n338. [tomalakgeretkal](https://github.com/tomalakgeretkal) fixed a compilation error.\n339. [alferov](https://github.com/ALF-ONE) fixed a compilation error.\n340. [Craig Scott](https://github.com/craigscott-crascit) fixed a deprecation warning in CMake.\n341. [Vyacheslav Zhdanovskiy](https://github.com/ZeronSix) added macros for serialization-only types.\n342. [Mathieu Westphal](https://github.com/mwestphal) fixed typos.\n343. [scribam](https://github.com/scribam) fixed the MinGW workflow.\n344. [Aleksei Sapitskii](https://github.com/aleksproger) added support for Apple's Swift Package Manager.\n345. [Benjamin Buch](https://github.com/bebuch) fixed the installation path in CMake.\n346. [Colby Haskell](https://github.com/colbychaskell) clarified the parse error message in case a file cannot be opened.\n347. [Juan Carlos Arevalo Baeza](https://github.com/TheJCAB) fixed the enum conversion.\n348. [alferov](https://github.com/ALF-ONE) fixed a version in the documentation.\n349. [ss](https://github.com/serge-s) fixed the amalgamation call.\n350. [AniketDhemare](https://github.com/AniketDhemare) fixed a version in the documentation.\n351. [Philip MÃ¼ller](https://github.com/philip-paul-mueller) fixed an example.\n352. [Leila Shcheglova](https://github.com/LeilaShcheglova) fixed a warning in a test.\n353. [Alex Prabhat Bara](https://github.com/alexprabhat99) fixed a function name in the documentation.\n354. [laterlaugh](https://github.com/laterlaugh) fixed some typos.\n355. [Yuanhao Jia](https://github.com/MrJia1997) fixed the GDB pretty printer.\n356. [Fallen_Breath](https://github.com/Fallen-Breath) fixed an example for JSON Pointer.\n357. [Nikhil Idiculla](https://github.com/tsnl) fixed some typos.\n358. [Griffin Myers](https://github.com/gmyers18) updated the Natvis file.\n359. [thetimr](https://github.com/thetimr) fixed a typo in the documentation.\n360. [Balazs Erseki](https://github.com/zerocukor287) fixed a URL in the contribution guidelines.\n361. [NiccolÃ² Iardella](https://github.com/rotolof) added `NLOHMANN_DEFINE_DERIVED_TYPE_*` macros.\n362. [Borislav Stanimirov](https://github.com/iboB) allowed overriding the CMake target name.\n363. [Captain Crutches](https://github.com/captaincrutches) made `iterator_proxy_value` a `std::forward_iterator`.\n364. [Fredrik Sandhei](https://github.com/fsandhei) added type conversion support for `std::optional`.\n365. [jh96](https://github.com/jordan-hoang) added exceptions when `nullptr` is passed to `parse`.\n366. [Stuart Gorman](https://github.com/StuartGorman) fixed number parsing when `EINTR` set in `errno`.\n367. [Dylan Baker](https://github.com/dcbaker) generated a pkg-config file that follows the pkg-config conventions.\n368. [Tianyi Chen](https://github.com/TianyiChen) optimized the binary `get_number` implementation.\n369. [peng-wang-cn](https://github.com/peng-wang-cn) added type conversion support for multidimensional arrays.\n370. [Einars Netlis-Galejs](https://github.com/EinarsNG) added `ONLY_SERIALIZE` for `NLOHMANN_DEFINE_DERIVED_TYPE_*` macros.\n371. [Marcel](https://github.com/mering) removed `alwayslink=True` Bazel flag.\n372. [Harinath Nampally](https://github.com/hnampally) added diagnostic positions to exceptions.\n373. [Nissim Armand Ben Danan](https://github.com/NissimBendanan) fixed `NLOHMANN_DEFINE_TYPE_INTRUSIVE_WITH_DEFAULT` with an empty JSON instance.\n374. [Michael Valladolid](https://github.com/codenut) added support for BSON uint64 serialization/deserialization.\n375. [Nikhil](https://github.com/nikhilreddydev) updated the documentation.\n376. [NebojÅ¡a CvetkoviÄ‡](https://github.com/nebkat) added support for BJDATA optimized binary array type.\n377. [Sushrut Shringarputale](https://github.com/sushshring) added support for diagnostic positions. \n378. [kimci86](https://github.com/kimci86) templated to `NLOHMANN_DEFINE_TYPE` macros to also support `ordered_json`.\n379. [Richard Topchii](https://github.com/richardtop) added support for VisionOS in the Swift Package Manager.\n380. [Robert Chisholm](https://github.com/Robadob) fixed a typo.\n381. [zjyhjqs](https://github.com/zjyhjqs) added CPack support.\n382. [bitFiedler](https://github.com/bitFiedler) made GDB pretty printer work with Python 3.8.\n383. [Gianfranco Costamagna](https://github.com/LocutusOfBorg) fixed a compiler warning.\n384. [risa2000](https://github.com/risa2000) made `std::filesystem::path` conversion to/from UTF-8 encoded string explicit.\n\nThanks a lot for helping out! Please [let me know](mailto:mail@nlohmann.me) if I forgot someone.\n\n## Used third-party tools\n\nThe library itself consists of a single header file licensed under the MIT license. However, it is built, tested, documented, and whatnot using a lot of third-party tools and services. Thanks a lot!\n\n- [**amalgamate.py - Amalgamate C source and header files**](https://github.com/edlund/amalgamate) to create a single header file\n- [**American fuzzy lop**](https://lcamtuf.coredump.cx/afl/) for fuzz testing\n- [**AppVeyor**](https://www.appveyor.com) for [continuous integration](https://ci.appveyor.com/project/nlohmann/json) on Windows\n- [**Artistic Style**](http://astyle.sourceforge.net) for automatic source code indentation\n- [**Clang**](https://clang.llvm.org) for compilation with code sanitizers\n- [**CMake**](https://cmake.org) for build automation\n- [**Codacy**](https://www.codacy.com) for further [code analysis](https://app.codacy.com/gh/nlohmann/json/dashboard)\n- [**Coveralls**](https://coveralls.io) to measure [code coverage](https://coveralls.io/github/nlohmann/json)\n- [**Coverity Scan**](https://scan.coverity.com) for [static analysis](https://scan.coverity.com/projects/nlohmann-json)\n- [**cppcheck**](http://cppcheck.sourceforge.net) for static analysis\n- [**doctest**](https://github.com/onqtam/doctest) for the unit tests\n- [**GitHub Changelog Generator**](https://github.com/skywinder/github-changelog-generator) to generate the [ChangeLog](https://github.com/nlohmann/json/blob/develop/ChangeLog.md)\n- [**Google Benchmark**](https://github.com/google/benchmark) to implement the benchmarks\n- [**Hedley**](https://nemequ.github.io/hedley/) to avoid re-inventing several compiler-agnostic feature macros\n- [**lcov**](https://github.com/linux-test-project/lcov) to process coverage information and create an HTML view\n- [**libFuzzer**](https://llvm.org/docs/LibFuzzer.html) to implement fuzz testing for OSS-Fuzz\n- [**Material for MkDocs**](https://squidfunk.github.io/mkdocs-material/) for the style of the documentation site\n- [**MkDocs**](https://www.mkdocs.org) for the documentation site\n- [**OSS-Fuzz**](https://github.com/google/oss-fuzz) for continuous fuzz testing of the library ([project repository](https://github.com/google/oss-fuzz/tree/master/projects/json))\n- [**Probot**](https://probot.github.io) for automating maintainer tasks such as closing stale issues, requesting missing information, or detecting toxic comments.\n- [**Valgrind**](https://valgrind.org) to check for correct memory management\n\n## Notes\n\n### Character encoding\n\nThe library supports **Unicode input** as follows:\n\n- Only **UTF-8** encoded input is supported, which is the default encoding for JSON according to [RFC 8259](https://tools.ietf.org/html/rfc8259.html#section-8.1).\n- `std::u16string` and `std::u32string` can be parsed, assuming UTF-16 and UTF-32 encoding, respectively. These encodings are not supported when reading from files or other input containers.\n- Other encodings such as Latin-1 or ISO 8859-1 are **not** supported and will yield parse or serialization errors.\n- [Unicode noncharacters](https://www.unicode.org/faq/private_use.html#nonchar1) will not be replaced by the library.\n- Invalid surrogates (e.g., incomplete pairs such as `\\uDEAD`) will yield parse errors.\n- The strings stored in the library are UTF-8 encoded. When using the default string type (`std::string`), note that its length/size functions return the number of stored bytes rather than the number of characters or glyphs.\n- When you store strings with different encodings in the library, calling [`dump()`](https://json.nlohmann.me/api/basic_json/dump/) may throw an exception unless `json::error_handler_t::replace` or `json::error_handler_t::ignore` are used as error handlers.\n- To store wide strings (e.g., `std::wstring`), you need to convert them to a UTF-8 encoded `std::string` before, see [an example](https://json.nlohmann.me/home/faq/#wide-string-handling).\n\n### Comments in JSON\n\nThis library does not support comments by default. It does so for three reasons:\n\n1. Comments are not part of the [JSON specification](https://tools.ietf.org/html/rfc8259). You may argue that `//` or `/* */` are allowed in JavaScript, but JSON is not JavaScript.\n2. This was not an oversight: Douglas Crockford [wrote on this](https://plus.google.com/118095276221607585885/posts/RK8qyGVaGSr) in May 2012:\n  \n    > I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability.  I know that the lack of comments makes some people sad, but it shouldn't.\n    >\n    > Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.\n  \n3. It is dangerous for interoperability if some libraries would add comment support while others don't. Please check [The Harmful Consequences of the Robustness Principle](https://tools.ietf.org/html/draft-iab-protocol-maintenance-01) on this.\n\nHowever, you can set set parameter `ignore_comments` to true in the `parse` function to ignore `//` or `/* */` comments. Comments will then be treated as whitespace.\n\n### Trailing commas\n\nThe JSON specification does not allow trailing commas in arrays and objects, and hence this library is treating them as parsing errors by default.\n\nLike comments, you can set parameter `ignore_trailing_commas` to true in the `parse` function to ignore trailing commas in arrays and objects. Note that a single comma as the only content of the array or object (`[,]` or `{,}`) is not allowed, and multiple trailing commas (`[1,,]`) are not allowed either.\n\nThis library does not add trailing commas when serializing JSON data.\n\nFor more information, see [JSON With Commas and Comments (JWCC)](https://nigeltao.github.io/blog/2021/json-with-commas-comments.html).\n\n### Order of object keys\n\nBy default, the library does not preserve the **insertion order of object elements**. This is standards-compliant, as the [JSON standard](https://tools.ietf.org/html/rfc8259.html) defines objects as \"an unordered collection of zero or more name/value pairs\".\n\nIf you do want to preserve the insertion order, you can try the type [`nlohmann::ordered_json`](https://github.com/nlohmann/json/issues/2179). Alternatively, you can use a more sophisticated ordered map like [`tsl::ordered_map`](https://github.com/Tessil/ordered-map) ([integration](https://github.com/nlohmann/json/issues/546#issuecomment-304447518)) or [`nlohmann::fifo_map`](https://github.com/nlohmann/fifo_map) ([integration](https://github.com/nlohmann/json/issues/485#issuecomment-333652309)).\n\nSee the [**documentation on object order**](https://json.nlohmann.me/features/object_order/) for more information.\n\n### Memory Release\n\nWe checked with Valgrind and the Address Sanitizer (ASAN) that there are no memory leaks.\n\nIf you find that a parsing program with this library does not release memory, please consider the following case, and it may be unrelated to this library.\n\n**Your program is compiled with glibc.** There is a tunable threshold that glibc uses to decide whether to actually return memory to the system or whether to cache it for later reuse. If in your program you make lots of small allocations and those small allocations are not a contiguous block and are presumably below the threshold, then they will not get returned to the OS.\nHere is a related issue [#1924](https://github.com/nlohmann/json/issues/1924).\n\n### Further notes\n\n- The code contains numerous debug **assertions** which can be switched off by defining the preprocessor macro `NDEBUG`, see the [documentation of `assert`](https://en.cppreference.com/w/cpp/error/assert). In particular, note [`operator[]`](https://json.nlohmann.me/api/basic_json/operator%5B%5D/) implements **unchecked access** for const objects: If the given key is not present, the behavior is undefined (think of a dereferenced null pointer) and yields an [assertion failure](https://github.com/nlohmann/json/issues/289) if assertions are switched on. If you are not sure whether an element in an object exists, use checked access with the [`at()` function](https://json.nlohmann.me/api/basic_json/at/). Furthermore, you can define `JSON_ASSERT(x)` to replace calls to `assert(x)`. See the [**documentation on runtime assertions**](https://json.nlohmann.me/features/assertions/) for more information.\n- As the exact number type is not defined in the [JSON specification](https://tools.ietf.org/html/rfc8259.html), this library tries to choose the best fitting C++ number type automatically. As a result, the type `double` may be used to store numbers which may yield [**floating-point exceptions**](https://github.com/nlohmann/json/issues/181) in certain rare situations if floating-point exceptions have been unmasked in the calling code. These exceptions are not caused by the library and need to be fixed in the calling code, such as by re-masking the exceptions prior to calling library functions.\n- The code can be compiled without C++ **runtime type identification** features; that is, you can use the `-fno-rtti` compiler flag.\n- **Exceptions** are used widely within the library. They can, however, be switched off with either using the compiler flag `-fno-exceptions` or by defining the symbol `JSON_NOEXCEPTION`. In this case, exceptions are replaced by `abort()` calls. You can further control this behavior by defining `JSON_THROW_USER` (overriding `throw`), `JSON_TRY_USER` (overriding `try`), and `JSON_CATCH_USER` (overriding `catch`). Note that `JSON_THROW_USER` should leave the current scope (e.g., by throwing or aborting), as continuing after it may yield undefined behavior. Note the explanatory [`what()`](https://en.cppreference.com/w/cpp/error/exception/what) string of exceptions is not available for MSVC if exceptions are disabled, see [#2824](https://github.com/nlohmann/json/discussions/2824). See the [**documentation of exceptions**](https://json.nlohmann.me/home/exceptions/) for more information.\n\n## Execute unit tests\n\nTo compile and run the tests, you need to execute\n\n```shell\nmkdir build\ncd build\ncmake .. -DJSON_BuildTests=On\ncmake --build .\nctest --output-on-failure\n```\n\nNote that during the `ctest` stage, several JSON test files are downloaded from an [external repository](https://github.com/nlohmann/json_test_data). If policies forbid downloading artifacts during testing, you can download the files yourself and pass the directory with the test files via `-DJSON_TestDataDirectory=path` to CMake. Then, no Internet connectivity is required. See [issue #2189](https://github.com/nlohmann/json/issues/2189) for more information.\n\nIf the testdata is not found, several test suites will fail like this:\n\n```\n===============================================================================\njson/tests/src/make_test_data_available.hpp:21:\nTEST CASE:  check test suite is downloaded\n\njson/tests/src/make_test_data_available.hpp:23: FATAL ERROR: REQUIRE( utils::check_testsuite_downloaded() ) is NOT correct!\n  values: REQUIRE( false )\n  logged: Test data not found in 'json/cmake-build-debug/json_test_data'.\n          Please execute target 'download_test_data' before running this test suite.\n          See <https://github.com/nlohmann/json#execute-unit-tests> for more information.\n\n===============================================================================\n```\n\nIn case you have downloaded the library rather than checked out the code via Git, test `cmake_fetch_content_configure` will fail. Please execute `ctest -LE git_required` to skip these tests. See [issue #2189](https://github.com/nlohmann/json/issues/2189) for more information.\n\nSome tests are requiring network to be properly execute. They are labeled as `git_required`. Please execute `ctest -LE git_required` to skip these tests. See [issue #4851](https://github.com/nlohmann/json/issues/4851) for more information.\n\nSome tests change the installed files and hence make the whole process not reproducible. Please execute `ctest -LE not_reproducible` to skip these tests. See [issue #2324](https://github.com/nlohmann/json/issues/2324) for more information. Furthermore, assertions must be switched off to ensure reproducible builds (see [discussion 4494](https://github.com/nlohmann/json/discussions/4494)).\n\nNote you need to call `cmake -LE \"not_reproducible|git_required\"` to exclude both labels. See [issue #2596](https://github.com/nlohmann/json/issues/2596) for more information.\n\nAs Intel compilers use unsafe floating point optimization by default, the unit tests may fail. Use flag [`/fp:precise`](https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/2021-8/fp-model-fp.html) then.\n",
      "stars_today": 12
    },
    {
      "id": 311683390,
      "name": "ImHex",
      "full_name": "WerWolv/ImHex",
      "description": "ğŸ” A Hex Editor for Reverse Engineers, Programmers and people who value their retinas when working at 3 AM.",
      "html_url": "https://github.com/WerWolv/ImHex",
      "stars": 52394,
      "forks": 2329,
      "language": "C++",
      "topics": [
        "analyzer",
        "binary-analysis",
        "c-plus-plus",
        "cpp",
        "cybersecurity",
        "dark-mode",
        "dear-imgui",
        "disassembler",
        "forensics",
        "hacking",
        "hacktoberfest",
        "hex-editor",
        "ips",
        "multi-platform",
        "pattern-language",
        "reverse-engineering",
        "static-analysis",
        "windows"
      ],
      "created_at": "2020-11-10T14:27:00Z",
      "updated_at": "2026-01-25T00:40:23Z",
      "pushed_at": "2026-01-25T00:42:52Z",
      "open_issues": 311,
      "owner": {
        "login": "WerWolv",
        "avatar_url": "https://avatars.githubusercontent.com/u/10835354?v=4"
      },
      "readme": "<a href=\"https://imhex.werwolv.net\">\n  <h1 align=\"center\">\n    <picture>\n      <img height=\"300px\" style=\"margin: 0; padding: 0\" src=\"./resources/dist/common/logo/ImHexLogoSVGBG.svg\">\n    </picture>\n  </h1>\n</a>\n\n<p align=\"center\">\n    A Hex Editor for Reverse Engineers, Programmers and people who value their retinas when working at 3 AM.\n    <br>\n    <a href=\"https://itinerarium.github.io/phoneme-synthesis/?w=/'ËˆÉªmhÉ›ks/\"><strong>/ËˆÉªmhÉ›ks/</strong></a>\n</p>\n<p align=\"center\">\n  <a title=\"'Build' workflow Status\" href=\"https://github.com/WerWolv/ImHex/actions?query=workflow%3ABuild\"><img alt=\"'Build' workflow Status\" src=\"https://img.shields.io/github/actions/workflow/status/WerWolv/ImHex/build.yml?longCache=true&style=for-the-badge&label=Build&logoColor=fff&logo=GitHub%20Actions&branch=master\"></a>\n  <a title=\"Discord Server\" href=\"https://discord.gg/X63jZ36xBY\"><img alt=\"Discord Server\" src=\"https://img.shields.io/discord/789833418631675954?label=Discord&logo=Discord&logoColor=fff&style=for-the-badge\"></a>\n  <a title=\"Total Downloads\" href=\"https://github.com/WerWolv/ImHex/releases/latest\"><img alt=\"Total Downloads\" src=\"https://img.shields.io/github/downloads/WerWolv/ImHex/total?longCache=true&style=for-the-badge&label=Downloads&logoColor=fff&logo=GitHub\"></a>\n  <a title=\"Code Quality\" href=\"https://www.codefactor.io/repository/github/werwolv/imhex\"><img alt=\"Code Quality\" src=\"https://img.shields.io/codefactor/grade/github/WerWolv/ImHex?longCache=true&style=for-the-badge&label=Code%20Quality&logoColor=fff&logo=CodeFactor&branch=master\"></a>\n  <a title=\"Translation\" href=\"https://weblate.werwolv.net/projects/imhex/\"><img alt=\"Translation\" src=\"https://img.shields.io/weblate/progress/imhex?logo=weblate&logoColor=%23FFFFFF&server=https%3A%2F%2Fweblate.werwolv.net&style=for-the-badge\"></a>\n  <a title=\"Plugins\" href=\"https://github.com/WerWolv/ImHex/blob/master/PLUGINS.md\"><img alt=\"Plugins\" src=\"https://img.shields.io/badge/Plugins-Supported-brightgreen?logo=stackedit&logoColor=%23FFFFFF&style=for-the-badge\"></a>\n</p>\n\n<p align=\"center\">\n  <a title=\"Download the latest version of ImHex\" href=\"https://imhex.download\"><img alt=\"Download the latest version of ImHex!\" src=\"resources/dist/common/get_release_banner.png\"></a>\n  <a title=\"Download the latest nightly pre-release version of ImHex\" href=\"https://imhex.download/#nightly\"><img alt=\"Download the latest nightly pre-release version of ImHex\" src=\"resources/dist/common/get_nightly_banner.png\"></a>\n  <a title=\"Use the Web version of ImHex right in your browser!\" href=\"https://web.imhex.werwolv.net\"><img alt=\"Use the Web version of ImHex right in your browser!\" src=\"resources/dist/common/try_online_banner.png\"></a>\n  <a title=\"Read the documentation of ImHex!\" href=\"https://docs.werwolv.net\"><img alt=\"Read the documentation of ImHex!\" src=\"resources/dist/common/read_docs_banner.png\"></a>\n</p>\n\n## Supporting\n\nIf you like my work, please consider supporting me on GitHub Sponsors, Ko-Fi or PayPal. Thanks a lot!\n\n<p align=\"center\">\n<a href=\"https://github.com/sponsors/WerWolv\"><img src=\"https://werwolv.net/assets/github_banner.png\" alt=\"GitHub donate button\" /></a>\n<a href=\"https://ko-fi.com/WerWolv\"><img src=\"https://werwolv.net/assets/kofi_banner.png\" alt=\"Ko-Fi donate button\" /></a>\n<a href=\"https://werwolv.net/donate\"><img src=\"https://werwolv.net/assets/paypal_banner.png\" alt=\"PayPal donate button\" /></a>\n</p>\n\n### Notable Sponsors\n|                                                                                                     |                                                                                   |\n|:---------------------------------------------------------------------------------------------------:|-----------------------------------------------------------------------------------|\n| [![JetBrains logo](https://avatars.githubusercontent.com/u/878437?s=48)](https://www.jetbrains.com) | JetBrains, providing us with free All Products Pack licenses for development      |\n|   [![SignPath logo](https://avatars.githubusercontent.com/u/34448643?s=48)](https://signpath.io/)   | SignPath, providing us with free Code Signing Certificates for our Windows builds |\n|     [![AWS logo](https://avatars.githubusercontent.com/u/2232217?s=48)](https://aws.amazon.com)     | Amazon, providing us with free AWS Cloud Credits for our CI                       |\n\nWould you like to appear here as well? Contact us at [imhex@werwolv.net](mailto:imhex@werwolv.net)!\n\n## Screenshots\n![Hex editor, patterns and data information](https://github.com/user-attachments/assets/902a7c4c-410d-490f-999e-14c856fec027)\n![Bookmarks, data information, find view and data processor](https://github.com/user-attachments/assets/58eefa1f-31c9-4bb8-a1c1-8cdd8ddbd29f)\n\n<details>\n<summary><strong>More Screenshots</strong></summary>\n\n![Data Processor decrypting some data and displaying it as an image](https://github.com/WerWolv/ImHex/assets/10835354/d0623081-3094-4840-a8a8-647b38724db8)\n![STL Parser written in the Pattern Language visualizing a 3D model](https://github.com/WerWolv/ImHex/assets/10835354/62cbcd18-1c3f-4dd6-a877-2bf2bf4bb2a5)\n![Data Information view displaying various stats about the file](https://github.com/WerWolv/ImHex/assets/10835354/d4706c01-c258-45c9-80b8-fe7a10d5a1de)\n\n</details>\n\n## Features\n\n<details>\n  <summary><strong>Featureful hex view</strong></summary>\n\n  - Byte patching\n  - Patch management\n  - Infinite Undo/Redo\n  - \"Copy bytes as...\"\n    - Bytes\n    - Hex string\n    - C, C++, C#, Rust, Python, Java & JavaScript array\n    - ASCII-Art hex view\n    - HTML self-contained div\n  - Simple string and hex search\n  - Goto from start, end and current cursor position\n  - Colorful highlighting\n    - Configurable foreground highlighting rules\n    - Background highlighting using patterns, find results and bookmarks\n  - Displaying data as a list of many different types\n    - Hexadecimal integers (8, 16, 32, 64 bit)\n    - Signed and unsigned decimal integers (8, 16, 32, 64 bit)\n    - Floats (16, 32, 64 bit)\n    - RGBA8 Colors\n    - HexII\n    - Binary\n  - Decoding data as ASCII and custom encodings\n    - Built-in support for UTF-8, UTF-16, ShiftJIS, most Windows encodings and many more\n  - Paged data view\n</details>\n<details>\n  <summary><strong>Custom C++-like pattern language for parsing highlighting a file's content</strong></summary>\n  \n  - Automatic loading based on MIME types and magic values\n  - Arrays, pointers, structs, unions, enums, bitfields, namespaces, little and big endian support, conditionals and much more!\n  - Useful error messages, syntax highlighting and error marking\n  - Support for visualizing many different types of data\n    - Images\n    - Audio\n    - 3D Models\n    - Coordinates\n    - Time stamps\n</details>\n<details>\n  <summary><strong>Theming support</strong></summary>\n\n  - Doesn't burn out your retinas when used in late-night sessions\n    - Dark mode by default, but a light mode is available as well\n  - Customizable colors and styles for all UI elements through shareable theme files\n  - Support for custom fonts\n</details>\n<details>\n  <summary><strong>Importing and Exporting data</strong></summary>\n  \n  - Base64 files\n  - IPS and IPS32 patches\n  - Markdown reports\n  - Binary arrays for various programming languages\n</details>\n<details>\n  <summary><strong>Data Inspector</strong></summary>\n\n  - Interpreting data as many different types with endianness, decimal, hexadecimal and octal support and bit inversion\n    - Unsigned and signed integers (8, 16, 24, 32, 48, 64 bit)\n    - Floats (16, 32, 64 bit)\n    - Signed and Unsigned LEB128\n    - ASCII, Wide and UTF-8 characters and strings\n    - time32_t, time64_t, DOS date and time\n    - GUIDs\n    - RGBA8 and RGB65 Colors\n  - Copying and modifying bytes through the inspector\n  - Adding new data types through the pattern language\n  - Support for hiding rows that aren't used\n</details>\n<details>\n  <summary><strong>Node-based data pre-processor</strong></summary>\n\n  - Modify, decrypt and decode data before it's being displayed in the hex editor\n  - Modify data without touching the underlying source\n  - Support for adding custom nodes\n</details>\n<details>\n  <summary><strong>Loading data from many different data sources</strong></summary>\n\n  - Local Files\n    - Support for huge files with fast and efficient loading\n  - Raw Disks\n    - Loading data from raw disks and partitions\n  - GDB Server\n    - Access the RAM of a running process or embedded devices through GDB\n  - Intel Hex and Motorola SREC data\n  - Base64 encoded data\n  - UDP Packets\n    - Support for displaying raw data received over UDP\n  - Process Memory\n    - Inspect the entire address space of a running process\n  - Remote Files over SSH with SFTP\n    - Support for loading files from remote servers using SSH and SFTP\n</details>\n<details>\n  <summary><strong>Data searching</strong></summary>\n  \n  - Support for searching the entire file or only a selection\n  - String extraction\n    - Option to specify minimum length and character set (lower case, upper case, digits, symbols)\n    - Option to specify encoding (ASCII, UTF-8, UTF-16 big and little endian)\n  - Sequence search\n    - Search for a sequence of bytes or characters\n    - Option to ignore character case\n  - Regex search\n    - Search for strings using regular expressions\n  - Binary Pattern\n    - Search for sequences of bytes with optional wildcards\n  - Numeric Value search\n    - Search for signed/unsigned integers and floats\n    - Search for ranges of values\n    - Option to specify size and endianness\n    - Option to ignore unaligned values\n</details>\n<details>\n  <summary><strong>Data hashing support</strong></summary>\n\n  - Many different algorithms available\n    - CRC8, CRC16 and CRC32 with custom initial values and polynomials\n      - Many default polynomials available\n    - MD5\n    - SHA-1, SHA-224, SHA-256, SHA-384, SHA-512\n    - Adler32\n    - AP\n    - BKDR\n    - Bernstein, Bernstein1\n    - DEK, DJB, ELF, FNV1, FNV1a, JS, PJW, RS, SDBM\n    - OneAtTime, Rotating, ShiftAndXor, SuperFast\n    - Murmur2_32, MurmurHash3_x86_32, MurmurHash3_x86_128, MurmurHash3_x64_128\n    - SipHash64, SipHash128\n    - XXHash32, XXHash64\n    - Tiger, Tiger2\n    - Blake2B, Blake2S\n  - Hashing of specific regions of the loaded data\n  - Hashing of arbitrary strings\n</details>\n<details>\n  <summary><strong>Diffing support</strong></summary>\n\n  - Compare data of different data sources\n  - Difference highlighting\n  - Table view of differences\n</details>\n<details>\n  <summary><strong>Integrated disassembler</strong></summary>\n  \n  - Support for all architectures supported by Capstone\n    - ARM32 (ARM, Thumb, Cortex-M, AArch32)\n    - ARM64\n    - MIPS (MIPS32, MIPS64, MIPS32R6, Micro)\n    - x86 (16-bit, 32-bit, 64-bit)\n    - PowerPC (32-bit, 64-bit)\n    - SPARC\n    - IBM SystemZ\n    - xCORE\n    - M68K\n    - TMS320C64X\n    - M680X\n    - Ethereum\n    - RISC-V\n    - WebAssembly\n    - MOS65XX\n    - Berkeley Packet Filter\n  - Support for writing custom disassemblers for your own architectures\n</details>\n<details>\n  <summary><strong>Bookmarks</strong></summary>\n\n  - Support for bookmarks with custom names and colors\n  - Highlighting of bookmarked region in the hex editor\n  - Jump to bookmarks\n  - Open content of bookmark in a new tab\n  - Add comments to bookmarks\n</details>\n<details>\n  <summary><strong>Featureful data analyzer and visualizer</strong></summary>\n\n  - File magic-based file parser and MIME type database\n  - Byte type distribution graph\n  - Entropy graph\n  - Highest and average entropy\n  - Encrypted / Compressed file detection\n  - Digram and Layered distribution graphs\n</details>\n<details>\n  <summary><strong>YARA Rule support</strong></summary>\n\n  - Scan a file for vulnerabilities with official yara rules\n  - Highlight matches in the hex editor\n  - Jump to matches\n  - Apply multiple rules at once\n</details>\n<details>\n  <summary><strong>Helpful tools</strong></summary>\n\n  - Itanium, MSVC, Rust and D-Lang demangler based on LLVM\n  - ASCII table\n  - Regex replacer\n  - Mathematical expression evaluator (Calculator)\n  - Graphing calculator\n  - Hexadecimal Color picker with support for many different formats\n  - Base converter\n  - Byte swapper\n  - UNIX Permissions calculator\n  - Wikipedia term definition finder\n  - File utilities\n    - File splitter\n    - File combiner\n    - File shredder\n  - IEEE754 Float visualizer\n  - Division by invariant multiplication calculator\n  - TCP Client/Server\n  - Euclidean algorithm calculator\n  - HTTP Requests\n</details>\n<details>\n  <summary><strong>Built-in Content updater</strong></summary>\n\n  - Download all files found in the database directly from within ImHex\n    - Pattern files for decoding various file formats\n    - Libraries for the pattern language\n    - Magic files for file type detection\n    - Custom data processor nodes\n    - Custom encodings\n    - Custom themes\n    - Yara rules\n</details>\n<details>\n  <summary><strong>Modern Interface</strong></summary>\n\n  - Support for multiple workspaces\n  - Support for custom layouts\n  - Detachable windows\n</details>\n<details>\n  <summary><strong>Easy to get started</strong></summary>\n\n  - Support for many different languages\n  - Simplified mode for beginners\n  - Extensive documentation\n  - Many example files available on [the Database](https://github.com/WerWolv/ImHex-Patterns)\n  - Achievements guiding you through the features of ImHex\n  - Interactive tutorials\n</details>\n\n## Pattern Language\n\nThe Pattern Language is the completely custom programming language developed for ImHex.\nIt allows you to define structures and data types in a C-like syntax and then use them to parse and highlight a file's content.\n\n- Source Code: [Link](https://github.com/WerWolv/PatternLanguage/)\n- Documentation: [Link](https://docs.werwolv.net/pattern-language/)\n\n## Database\n\nFor format patterns, libraries, magic and constant files, check out the [ImHex-Patterns](https://github.com/WerWolv/ImHex-Patterns) repository. \n\n**Feel free to PR your own files there as well!**\n\n## Requirements\n\nTo use ImHex, the following minimal system requirements need to be met.\n\n> [!IMPORTANT]\n> ImHex requires a GPU with OpenGL 3.0 support in general.\n> There are releases available (with the `-NoGPU` suffix) that are software rendered and don't require a GPU, however these can be a lot slower than the GPU accelerated versions.\n> \n> If possible at all, make ImHex use the dedicated GPU on your system instead of the integrated one.\n> ImHex will usually run fine with integrated GPUs as well but certain Intel HD GPU drivers on Windows are known to cause graphical artifacts.\n\n- **OS**: \n  - **Windows**: Windows 7 or higher (Windows 10/11 recommended)\n  - **macOS**: macOS 15 (Sequoia) or higher, \n    - Lower versions should still work too, but you'll need to compile ImHex yourself. The release binaries will NOT work due to GitHub not having any macOS 15 or lower CI runners available.\n    - The macOS build is not signed and will require you to manually allow them in the Security & Privacy settings.\n  - **Linux**: \"Modern\" Linux. The following distributions have official releases available. Other distros are supported through the AppImage, Flatpak and Snap releases.\n    - Ubuntu and Debian\n    - Fedora\n    - RHEL/AlmaLinux\n    - Arch Linux\n    - Basically any other distro will work as well when compiling ImHex from sources.\n  - **FreeBSD**: Tested on FreeBSD 14.3\n    - Other versions will most likely work too but are untested\n- **CPU**: Officially supported are x86, AMD64 and ARM64, though any Little Endian CPU should work.\n- **GPU**: OpenGL 3.0 or higher \n  - Integrated Intel HD iGPUs are supported, however certain drivers are known to cause various graphical artifacts, especially on Windows. Use at your own risk.\n  - In case you don't have a GPU available, there are software rendered releases available for Windows and macOS\n- **RAM**: ~50MiB, more is required for more complex analysis\n- **Storage**: ~100MiB\n\n## Installing\n\nInformation on how to install ImHex can be found in the [Install](/INSTALL.md) guide\n\n## Compiling\n\nTo compile ImHex on any platform, GCC (or Clang) is required with a version that supports C++23 or higher. \nWindows and Linux releases are being built using latest available GCC.\nMacOS releases are being built using latest available LLVM Clang.\n\nImportant to note is, the MSVC and AppleClang compilers are both **NOT** supported since they're both generally severely outdated and lack features GCC and LLVM Clang have.\n\n> [!NOTE]\n> Many dependencies are bundled into the repository using submodules so make sure to clone it using the `--recurse-submodules` option.\n> All dependencies that aren't bundled, can be installed using the dependency installer scripts found in the `/dist` folder.\n\nFor more information, check out the [Compiling](/dist/compiling) guide.\n\n## Contributing\nSee [Contributing](/CONTRIBUTING.md)\n\n\n## Plugin development\nTo develop plugins for ImHex, use the following template project to get started. You then have access to the entirety of libimhex as well as the ImHex API and the Content Registry to interact with ImHex or to add new content.\nTo build a plugin, you will need to use our SDK\n\n### Getting the SDK locally\nYou can build the SDK by compiling ImHex like this:\n- `cmake -G Ninja -DIMHEX_BUNDLE_PLUGIN_SDK=ON -B build`\n- `cd build`\n- `DESTDIR=install ninja install`\nThe SDK will then be available at `install/usr/local/share/imhex/sdk`. You will need to set the variable `IMHEX_SDK_PATH` to that (absolute) path.\n\n### Getting the SDK in a Github Actions CI\nYou can use [this action](https://github.com/WerWolv/imhex-download-sdk) to automatically download the SDK to your Github Runner\n- [ImHex Plugin Template](https://github.com/WerWolv/ImHex-Plugin-Template)\n\n\n## Credits\n\n### Contributors\n\n- [AxCut](https://github.com/paxcut) for a gigantic amount of contributions to the Pattern Text Editor and tons of other parts of ImHex\n- [iTrooz](https://github.com/iTrooz) for getting ImHex onto the Web as well as hundreds of contributions in every part of the project\n- [jumanji144](https://github.com/jumanji144) for huge contributions to the Pattern Language and ImHex's infrastructure\n- [Mary](https://github.com/marysaka) for her immense help porting ImHex to macOS and help during development\n- [Roblabla](https://github.com/Roblabla) for adding MSI Installer support to ImHex\n- [Mailaender](https://github.com/Mailaender) for getting ImHex onto Flathub\n- Everybody else who has reported issues on Discord or GitHub that I had great conversations with :)\n\n### Dependencies\n\n- Thanks a lot to ocornut for their amazing [Dear ImGui](https://github.com/ocornut/imgui) which is used for building the entire interface\n  - Thanks to epezent for [ImPlot](https://github.com/epezent/implot) used to plot data in various places\n  - Thanks to Nelarius for [ImNodes](https://github.com/Nelarius/imnodes) used as base for the data processor \n  - Thanks to BalazsJako for [ImGuiColorTextEdit](https://github.com/BalazsJako/ImGuiColorTextEdit) used for the pattern language syntax highlighting\n- Thanks to nlohmann for their [json](https://github.com/nlohmann/json) library used for configuration files\n- Thanks to vitaut for their [libfmt](https://github.com/fmtlib/fmt) library which makes formatting and logging so much better\n- Thanks to btzy for [nativefiledialog-extended](https://github.com/btzy/nativefiledialog-extended) and their great support, used for handling file dialogs on all platforms\n- Thanks to danyspin97 for [xdgpp](https://sr.ht/~danyspin97/xdgpp) used to handle folder paths on Linux\n- Thanks to aquynh for [capstone](https://github.com/aquynh/capstone) which is the base of the disassembly window\n- Thanks to rxi for [microtar](https://github.com/rxi/microtar) used for extracting downloaded store assets \n- Thanks to VirusTotal for [Yara](https://github.com/VirusTotal/yara) used by the Yara plugin\n- Thanks to Martinsos for [edlib](https://github.com/Martinsos/edlib) used for sequence searching in the diffing view\n- Thanks to ron4fun for [HashLibPlus](https://github.com/ron4fun/HashLibPlus) which implements every hashing algorithm under the sun\n- Thanks to mackron for [miniaudio](https://github.com/mackron/miniaudio) used to play audio files\n- Thanks to all other groups and organizations whose libraries are used in ImHex\n\n### License\n\nThe biggest part of ImHex is under the GPLv2-only license. \nNotable exceptions to this are the following parts which are under the LGPLv2.1 license:\n- **/lib/libimhex**: The library that allows Plugins to interact with ImHex.\n- **/plugins/ui**: The UI plugin library that contains some common UI elements that can be used by other plugins\n\nThe reason for this is to allow for proprietary plugins to be developed for ImHex.\n\n### Code Signing Policy\n\nFree code signing provided by [SignPath.io](https://about.signpath.io/),\ncertificate by [SignPath Foundation](https://signpath.org/).\n\nThis program will not transfer any information to other networked systems\nunless specifically requested by the user or the person installing or\noperating it.\n\n#### People with direct push access\n- [WerWolv](https://github.com/WerWolv)\n- [iTrooz](https://github.com/iTrooz)\n- [jumanji144](https://github.com/jumanji144)\n- [AxCut](https://github.com/paxcut)\n",
      "stars_today": 12
    },
    {
      "id": 133134007,
      "name": "openapi-generator",
      "full_name": "OpenAPITools/openapi-generator",
      "description": "OpenAPI Generator allows generation of API client libraries (SDK generation), server stubs, documentation and configuration automatically given an OpenAPI Spec (v2, v3)",
      "html_url": "https://github.com/OpenAPITools/openapi-generator",
      "stars": 25675,
      "forks": 7367,
      "language": "Java",
      "topics": [
        "api",
        "api-client",
        "api-server",
        "generator",
        "hacktoberfest",
        "openapi",
        "openapi-generator",
        "openapi3",
        "rest",
        "rest-api",
        "rest-client",
        "restful-api",
        "sdk"
      ],
      "created_at": "2018-05-12T09:57:56Z",
      "updated_at": "2026-01-25T00:18:44Z",
      "pushed_at": "2026-01-25T00:18:39Z",
      "open_issues": 5572,
      "owner": {
        "login": "OpenAPITools",
        "avatar_url": "https://avatars.githubusercontent.com/u/37325267?v=4"
      },
      "readme": "<h1 align=\"center\">OpenAPI Generator</h1>\n\n\n<div align=\"center\">\n\n[![Stable releases in Maven Central](https://img.shields.io/maven-metadata/v/https/repo1.maven.org/maven2/org/openapitools/openapi-generator/maven-metadata.xml.svg)](http://search.maven.org/#search%7Cgav%7C1%7Cg%3A%22org.openapitools%22%20AND%20a%3A%22openapi-generator%22)\n[![Apache 2.0 License](https://img.shields.io/badge/License-Apache%202.0-orange)](./LICENSE)\n[![Open Collective backers](https://img.shields.io/opencollective/backers/openapi_generator?color=orange&label=OpenCollective%20Backers)](https://opencollective.com/openapi_generator)\n[![Join the Slack chat room](https://img.shields.io/badge/Slack-Join%20the%20chat%20room-orange)](https://join.slack.com/t/openapi-generator/shared_invite/zt-36ucx4ybl-jYrN6euoYn6zxXNZdldoZA)\n[![Follow OpenAPI Generator Twitter account to get the latest update](https://img.shields.io/twitter/follow/oas_generator.svg?style=social&label=Follow)](https://twitter.com/oas_generator)\n[![Contribute with Gitpod](https://img.shields.io/badge/Contribute%20with-Gitpod-908a85?logo=gitpod)](https://gitpod.io/#https://github.com/OpenAPITools/openapi-generator)\n[![Conan Center](https://shields.io/conan/v/openapi-generator)](https://conan.io/center/recipes/openapi-generator)\n[![Revved up by Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A)](https://ge.openapi-generator.tech/scans)\n</div>\n\n<div align=\"center\">\n\n[Master](https://github.com/OpenAPITools/openapi-generator/tree/master) (`7.20.0`):\n[![Integration Test2](https://circleci.com/gh/OpenAPITools/openapi-generator.svg?style=shield)](https://circleci.com/gh/OpenAPITools/openapi-generator)\n[![Bitrise](https://img.shields.io/bitrise/4a2b10a819d12b67/master?label=bitrise%3A%20Swift+4,5&token=859FMDR8QHwabCzwvZK6vQ)](https://app.bitrise.io/app/4a2b10a819d12b67)\n\n</div>\n\n<div align=\"center\">\n\n:star::star::star: If you would like to contribute, please refer to [guidelines](CONTRIBUTING.md) and a list of [open tasks](https://github.com/openapitools/openapi-generator/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22). :star::star::star:\n\n:bangbang: To migrate from Swagger Codegen to OpenAPI Generator, please refer to the [migration guide](docs/migration-from-swagger-codegen.md) :bangbang:\n\n:notebook_with_decorative_cover: For more information, please refer to the [Wiki page](https://github.com/openapitools/openapi-generator/wiki) and [FAQ](https://github.com/openapitools/openapi-generator/wiki/FAQ) :notebook_with_decorative_cover:\n\n:notebook_with_decorative_cover: The eBook [A Beginner's Guide to Code Generation for REST APIs](https://gum.co/openapi_generator_ebook) is a good starting point for beginners :notebook_with_decorative_cover:\n\n:warning: If the OpenAPI spec, templates or any input (e.g. options, environment variables) is obtained from an untrusted source or environment, please make sure you've reviewed these inputs before using OpenAPI Generator to generate the API client, server stub or documentation to avoid potential security issues (e.g. [code injection](https://en.wikipedia.org/wiki/Code_injection)). For security vulnerabilities, please contact [team@openapitools.org](mailto:team@openapitools.org). :warning:\n\n:bangbang: Both \"OpenAPI Tools\" (https://OpenAPITools.org - the parent organization of OpenAPI Generator) and \"OpenAPI Generator\" are not affiliated with OpenAPI Initiative (OAI) :bangbang:\n\n</div>\n\n## Sponsors\n\nIf you find OpenAPI Generator useful for work, please consider asking your company to support this Open Source project by [becoming a sponsor](https://opencollective.com/openapi_generator). You can also individually sponsor the project by [becoming a backer](https://opencollective.com/openapi_generator).\n\n#### Thank you to our bronze sponsors!\n\n[![NamSor](https://openapi-generator.tech/img/companies/namsor.png)](https://www.namsor.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[![LightBow](https://openapi-generator.tech/img/companies/lightbow.png)](https://www.lightbow.net/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/docspring.png\" width=\"128\" height=\"128\">](https://docspring.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/datadog.png\" width=\"128\" height=\"128\">](https://datadoghq.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/thales.jpg\" width=\"128\" height=\"128\">](https://cpl.thalesgroup.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/apideck.jpg\" width=\"128\" height=\"128\">](https://www.apideck.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/pexa.png\" width=\"128\" height=\"128\">](https://www.pexa.com.au/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/numary.png\" width=\"128\" height=\"128\">](https://www.numary.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/onesignal.png\" width=\"128\" height=\"128\">](https://www.onesignal.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/virtualansoftware.png\" width=\"128\" height=\"128\">](https://www.virtualansoftware.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/mergedev.jpeg\" width=\"128\" height=\"128\">](https://www.merge.dev/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/burkert.jpg\" width=\"128\" height=\"128\">](https://www.burkert.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/finbourne.png\" width=\"128\" height=\"128\">](https://www.finbourne.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/bumpsh.png\" width=\"128\" height=\"128\">](https://bump.sh/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/bileto.png\" width=\"128\" height=\"128\">](https://www.bileto.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/bairesdev.png\" width=\"128\" height=\"128\">](https://www.bairesdev.com/sponsoring-open-source-projects/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/dmtech.jpeg\" width=\"128\" height=\"128\">](https://www.dmtech.de/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/adyen.png\" width=\"128\" height=\"128\">](https://adyen.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/fornex.png\" width=\"128\" height=\"128\">](https://fornex.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/alloyautomation.png\" width=\"128\" height=\"128\">](https://runalloy.com/signup?utm_source=github&utm_medium=referral&utm_campaign=1524_openapigenerator)\n[<img src=\"https://openapi-generator.tech/img/companies/ssstwitter.png\" width=\"128\" height=\"128\">](https://ssstwitter.com/?utm_source=github&utm_medium=referral&utm_campaign=sponsor)\n[<img src=\"https://openapi-generator.tech/img/companies/svix.png\" width=\"128\" height=\"128\">](https://www.svix.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/litslink.png\" width=\"128\" height=\"128\">](https://litslink.com/services/artificial-intelligence?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/designli.jpg\" width=\"128\" height=\"128\">](https://designli.co?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/itm.png\" width=\"128\" height=\"128\">](https://opensource.muenchen.de?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/kong.png\" width=\"128\" height=\"128\">](https://konghq.com/products/kong-konnect?utm_medium=referral&utm_source=github&utm_campaign=platform&utm_content=openapi-generator)\n[<img src=\"https://openapi-generator.tech/img/companies/route4me.png\" width=\"128\" height=\"128\">](https://route4me.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/dm.png\" width=\"128\" height=\"128\">](https://www.dotcom-monitor.com/sponsoring-open-source-projects/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/clickit.jpg\" width=\"128\" height=\"128\">](https://www.clickittech.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/unified_to.jpg\" width=\"128\" height=\"128\">](https://unified.to/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/savetwt.jpg\" width=\"128\" height=\"128\">](https://savetwt.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n[<img src=\"https://openapi-generator.tech/img/companies/serpapi.png\" width=\"128\" height=\"128\">](https://serpapi.com/?utm_source=openapi-generator&utm_medium=sponsorship&utm_campaign=oss-sponsorship)\n\n#### Thank you GoDaddy for sponsoring the domain names, Linode for sponsoring the VPS, Checkly for sponsoring the API monitoring and Gradle for sponsoring Develocity\n\n[<img src=\"https://openapi-generator.tech/img/companies/godaddy.png\" width=\"150\">](https://www.godaddy.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[![Linode](https://www.linode.com/media/images/logos/standard/light/linode-logo_standard_light_small.png)](https://www.linode.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRAhEYadUyZYzGUotZiSdXkVMqqLGuohyixLl4eUpUV6pAbUULL\" width=\"150\">](https://checklyhq.com/?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n[<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Gradle_logo.png/320px-Gradle_logo.png\" width=\"150\">](https://gradle.org?utm_source=openapi_generator&utm_medium=github_webpage&utm_campaign=sponsor)\n\n## Overview\n\nOpenAPI Generator allows generation of API client libraries (SDK generation), server stubs,  documentation and configuration automatically given an [OpenAPI Spec](https://github.com/OAI/OpenAPI-Specification) (both 2.0 and 3.0 are supported). Currently, the following languages/frameworks are supported:\n\n|                                  | Languages/Frameworks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n| -------------------------------- |--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **API clients**                  | **ActionScript**, **Ada**, **Apex**, **Bash**, **C**, **C#** (.net 2.0, 3.5 or later, .NET Standard 1.3 - 2.1, .NET Core 3.1, .NET 5.0. Libraries: RestSharp, GenericHost, HttpClient), **C++** (Arduino, cpp-restsdk, Qt5, Tizen, Unreal Engine 4), **Clojure**, **Crystal**, **Dart**, **Elixir**, **Elm**, **Eiffel**, **Erlang**, **Go**, **Groovy**, **Haskell** (http-client, Servant), **Java** (Apache HttpClient 4.x, Apache HttpClient 5.x, Jersey2.x, OkHttp, Retrofit1.x, Retrofit2.x, Feign, RestTemplate, RESTEasy, Vertx, Google API Client Library for Java, Rest-assured, Spring 5 Web Client, Spring 6 RestClient, MicroProfile Rest Client, Helidon), **Jetbrains HTTP Client**, **Julia**, **k6**, **Kotlin**, **Lua**, **N4JS**, **Nim**, **Node.js/JavaScript** (ES5, ES6, AngularJS with Google Closure Compiler annotations, Flow types, Apollo GraphQL DataStore), **Objective-C**, **OCaml**, **Perl**, **PHP**, **PowerShell**, **Python**, **R**, **Ruby**, **Rust** (hyper, reqwest, rust-server), **Scala** (akka, http4s, scalaz, sttp, swagger-async-httpclient, pekko), **Swift** (2.x, 3.x, 4.x, 5.x, 6.x), **Typescript** (AngularJS, Angular (9.x - 19.x), Aurelia, Axios, Fetch, Inversify, jQuery, Nestjs, Node, redux-query, Rxjs), **XoJo**, **Zapier** |\n| **Server stubs**                 | **Ada**, **C#** (ASP.NET Core, Azure Functions), **C++** (Oat++, Pistache, Restbed, Qt5 QHTTPEngine), **Erlang**, **F#** (Giraffe), **Go** (net/http, Gin, Echo), **Haskell** (Servant, Yesod), **Java** (MSF4J, Spring, Undertow, JAX-RS: CDI, CXF, Inflector, Jersey, RestEasy, Play Framework, [PKMST](https://github.com/ProKarma-Inc/pkmst-getting-started-examples), [Vert.x](https://vertx.io/), [Apache Camel](https://camel.apache.org/), [Helidon](https://helidon.io/)), **Julia**, **Kotlin** (Spring Boot, [Ktor](https://github.com/ktorio/ktor), [Vert.x](https://vertx.io/)), **PHP** ([Flight](https://docs.flightphp.com/), Laravel, Lumen, [Mezzio (fka Zend Expressive)](https://github.com/mezzio/mezzio), Slim, Silex, [Symfony](https://symfony.com/)), **Python** (FastAPI, Flask), **NodeJS**, **Ruby** (Sinatra, Rails5), **Rust** ([rust-server](https://openapi-generator.tech/docs/generators/rust-server/)), **Scala** (Akka, [Finch](https://github.com/finagle/finch), [Lagom](https://github.com/lagom/lagom), [Play](https://www.playframework.com/), [Cask](https://github.com/com-lihaoyi/cask), Scalatra)                                                                                                                                                    |\n| **API documentation generators** | **HTML**, **Confluence Wiki**, **Asciidoc**, **Markdown**, **PlantUML**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n| **Configuration files**          | [**Apache2**](https://httpd.apache.org/)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n| **Others**                       | **GraphQL**, **JMeter**, **Ktorm**, **MySQL Schema**, **Postman Collection**, **Protocol Buffer**, **WSDL**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n\n## Table of contents\n\n- [Sponsors](#sponsors)\n    - [Thank you to our bronze sponsors!](#thank-you-to-our-bronze-sponsors)\n    - [Thank you GoDaddy for sponsoring the domain names, Linode for sponsoring the VPS, Checkly for sponsoring the API monitoring and Gradle for sponsoring Develocity](#thank-you-godaddy-for-sponsoring-the-domain-names-linode-for-sponsoring-the-vps-checkly-for-sponsoring-the-api-monitoring-and-gradle-for-sponsoring-develocity)\n- [Overview](#overview)\n- [Table of contents](#table-of-contents)\n- [1 - Installation](#1---installation)\n  - [1.1 - Compatibility](#11---compatibility)\n- [1.2 - Artifacts on Maven Central](#12---artifacts-on-maven-central)\n  - [1.3 - Download JAR](#13---download-jar)\n  - [Launcher Script](#launcher-script)\n  - [1.4 - Build Projects](#14---build-projects)\n    - [Nix users](#nix-users)\n  - [1.5 - Homebrew](#15---homebrew)\n  - [1.6 - Docker](#16---docker)\n    - [Public Pre-built Docker images](#public-pre-built-docker-images)\n    - [OpenAPI Generator CLI Docker Image](#openapi-generator-cli-docker-image)\n    - [OpenAPI Generator Online Docker Image](#openapi-generator-online-docker-image)\n    - [Development in docker](#development-in-docker)\n      - [Troubleshooting](#troubleshooting)\n    - [Run Docker in Vagrant](#run-docker-in-vagrant)\n  - [1.7 - NPM](#17---npm)\n  - [1.8 - pip](#18---pip)\n- [2 - Getting Started](#2---getting-started)\n- [3 - Usage](#3---usage)\n  - [To generate a sample client library](#to-generate-a-sample-client-library)\n  - [3.1 - Customization](#31---customization)\n  - [3.2 - Workflow Integration (Maven, Gradle, Github, CI/CD)](#32---workflow-integration-maven-gradle-github-cicd)\n  - [3.3 - Online OpenAPI generator](#33---online-openapi-generator)\n  - [3.4 - License information on Generated Code](#34---license-information-on-generated-code)\n  - [3.5 - IDE Integration](#35---ide-integration)\n- [4 - Companies/Projects using OpenAPI Generator](#4---companiesprojects-using-openapi-generator)\n- [5 - Presentations/Videos/Tutorials/Books](#5---presentationsvideostutorialsbooks)\n- [6 - About Us](#6---about-us)\n  - [6.1 - OpenAPI Generator Core Team](#61---openapi-generator-core-team)\n    - [Core Team Members](#core-team-members)\n    - [Template Creator](#template-creator)\n    - [How to join the core team](#how-to-join-the-core-team)\n  - [6.2 - OpenAPI Generator Technical Committee](#62---openapi-generator-technical-committee)\n    - [Members of Technical Committee](#members-of-technical-committee)\n  - [6.3 - History of OpenAPI Generator](#63---history-of-openapi-generator)\n    - [Founding Members (alphabetical order):](#founding-members-alphabetical-order)\n- [7 - License](#7---license)\n\n## [1 - Installation](#table-of-contents)\n\n### [1.1 - Compatibility](#table-of-contents)\n\nThe OpenAPI Specification has undergone 3 revisions since initial creation in 2010.  The openapi-generator project has the following compatibilities with the OpenAPI Specification:\n\n| OpenAPI Generator Version                                                                                                                                 | Release Date | Notes                                             |\n| --------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------ | ------------------------------------------------- |\n| 7.20.0 (upcoming minor release) [SNAPSHOT](https://github.com/OpenAPITools/openapi-generator/wiki/FAQ#how-to-test-with-the-latest-master-of-openapi-generator) | 20.02.2026   | Minor release with breaking changes (with fallback) |\n| [7.19.0](https://github.com/OpenAPITools/openapi-generator/releases/tag/v7.19.0) (latest stable release)                                                    | 20.01.2026   | Minor release with breaking changes (with fallback) |\n| [6.6.0](https://github.com/OpenAPITools/openapi-generator/releases/tag/v6.6.0)                                                    | 11.05.2023   | Minor release with breaking changes (with fallback) |\n| [5.4.0](https://github.com/OpenAPITools/openapi-generator/releases/tag/v5.4.0)                                                    | 31.01.2022   | Minor release with breaking changes (with fallback) |\n| [4.3.1](https://github.com/OpenAPITools/openapi-generator/releases/tag/v4.3.1)                                                    | 06.05.2020   | Patch release (enhancements, bug fixes, etc)                       |\n\nOpenAPI Spec compatibility: 1.0, 1.1, 1.2, 2.0, 3.0, 3.1 (beta support)\n\n(We do not publish daily/nightly build. Please use SNAPSHOT instead)\n\nFor old releases, please refer to the [**Release**](https://github.com/OpenAPITools/openapi-generator/releases) page.\n\nFor decommissioned generators/libraries/frameworks, please refer to [the \"Decommission\" label](https://github.com/OpenAPITools/openapi-generator/issues?q=label%3ADecommission+is%3Amerged+) in the pull request page.\n\n## [1.2 - Artifacts on Maven Central](#table-of-contents)\n\nYou can find our released artifacts on maven central:\n\n**Core:**\n```xml\n<dependency>\n    <groupId>org.openapitools</groupId>\n    <artifactId>openapi-generator</artifactId>\n    <version>${openapi-generator-version}</version>\n</dependency>\n```\nSee the different versions of the [openapi-generator](https://search.maven.org/artifact/org.openapitools/openapi-generator) artifact available on maven central.\n\n**Cli:**\n```xml\n<dependency>\n    <groupId>org.openapitools</groupId>\n    <artifactId>openapi-generator-cli</artifactId>\n    <version>${openapi-generator-version}</version>\n</dependency>\n```\nSee the different versions of the [openapi-generator-cli](https://search.maven.org/artifact/org.openapitools/openapi-generator-cli) artifact available on maven central.\n\n**Maven plugin:**\n```xml\n<dependency>\n    <groupId>org.openapitools</groupId>\n    <artifactId>openapi-generator-maven-plugin</artifactId>\n    <version>${openapi-generator-version}</version>\n</dependency>\n```\n* See the different versions of the [openapi-generator-maven-plugin](https://search.maven.org/artifact/org.openapitools/openapi-generator-maven-plugin) artifact available on maven central.\n* [Readme](https://github.com/OpenAPITools/openapi-generator/blob/master/modules/openapi-generator-maven-plugin/README.md)\n\n**Gradle plugin:**\n```xml\n<dependency>\n    <groupId>org.openapitools</groupId>\n    <artifactId>openapi-generator-gradle-plugin</artifactId>\n    <version>${openapi-generator-version}</version>\n</dependency>\n```\n* See the different versions of the [openapi-generator-gradle-plugin](https://search.maven.org/artifact/org.openapitools/openapi-generator-gradle-plugin) artifact available on maven central.\n* [Readme](https://github.com/OpenAPITools/openapi-generator/blob/master/modules/openapi-generator-gradle-plugin/README.adoc)\n\n### [1.3 - Download JAR](#table-of-contents)\n<!-- RELEASE_VERSION -->\nIf you're looking for the latest stable version, you can grab it directly from Maven.org (Java 11 runtime at a minimum):\n\nJAR location: `https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/7.19.0/openapi-generator-cli-7.19.0.jar`\n\nFor **Mac/Linux** users:\n```sh\nwget https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/7.19.0/openapi-generator-cli-7.19.0.jar -O openapi-generator-cli.jar\n```\n\nFor **Windows** users, you will need to install [wget](http://gnuwin32.sourceforge.net/packages/wget.htm) or you can use Invoke-WebRequest in PowerShell (3.0+), e.g.\n```\nInvoke-WebRequest -OutFile openapi-generator-cli.jar https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/7.19.0/openapi-generator-cli-7.19.0.jar\n```\n\nAfter downloading the JAR, run `java -jar openapi-generator-cli.jar help` to show the usage.\n\nFor Mac users, please make sure Java 11 is installed (Tips: run `java -version` to check the version), and export `JAVA_HOME` in order to use the supported Java version:\n```sh\nexport JAVA_HOME=`/usr/libexec/java_home -v 1.11`\nexport PATH=${JAVA_HOME}/bin:$PATH\n```\n\n<!-- /RELEASE_VERSION -->\n### Launcher Script\n\nOne downside to manual jar downloads is that you don't keep up-to-date with the latest released version. We have a Bash launcher script at [bin/utils/openapi-generator.cli.sh](./bin/utils/openapi-generator-cli.sh) which resolves this issue.\n\nTo install the launcher script, copy the contents of the script to a location on your path and make the script executable.\n\nAn example of setting this up (NOTE: Always evaluate scripts curled from external systems before executing them).\n\n```\nmkdir -p ~/bin/openapitools\ncurl https://raw.githubusercontent.com/OpenAPITools/openapi-generator/master/bin/utils/openapi-generator-cli.sh > ~/bin/openapitools/openapi-generator-cli\nchmod u+x ~/bin/openapitools/openapi-generator-cli\nexport PATH=$PATH:~/bin/openapitools/\n```\n\nNow, `openapi-generator-cli` is \"installed\". On invocation, it will query the GitHub repository for the most recently released version. If this matches the last downloaded jar,\nit will execute as normal. If a newer version is found, the script will download the latest release and execute it.\n\nIf you need to invoke an older version of the generator, you can define the variable `OPENAPI_GENERATOR_VERSION` either ad hoc or globally. You can export this variable if you'd like to persist a specific release version.\n\nExamples:\n\n```\n# Execute latest released openapi-generator-cli\nopenapi-generator-cli version\n\n# Execute version 4.1.0 for the current invocation, regardless of the latest released version\nOPENAPI_GENERATOR_VERSION=4.1.0 openapi-generator-cli version\n\n# Execute version 4.1.0-SNAPSHOT for the current invocation\nOPENAPI_GENERATOR_VERSION=4.1.0-SNAPSHOT openapi-generator-cli version\n\n# Execute version 4.0.2 for every invocation in the current shell session\nexport OPENAPI_GENERATOR_VERSION=4.0.2\nopenapi-generator-cli version # is 4.0.2\nopenapi-generator-cli version # is also 4.0.2\n\n# To \"install\" a specific version, set the variable in .bashrc/.bash_profile\necho \"export OPENAPI_GENERATOR_VERSION=4.0.2\" >> ~/.bashrc\nsource ~/.bashrc\nopenapi-generator-cli version # is always 4.0.2, unless any of the above overrides are done ad hoc\n```\n\n### [1.4 - Build Projects](#table-of-contents)\n\nTo build from source, you need the following installed and available in your `$PATH:`\n\n* [Java 11](https://adoptium.net/)\n\n* [Apache Maven 3.8.8 or greater](https://maven.apache.org/) (optional)\n\nAfter cloning the project, you can build it from source using [maven wrapper](https://maven.apache.org/wrapper/):\n\n- Linux: `./mvnw clean install`\n- Windows: `mvnw.cmd clean install`\n\n#### Nix users\n\nIf you're a nix user, you can enter OpenAPI Generator shell, by typing:\n```sh\nnix develop\n```\nIt will enter a shell with Java 11 installed.\n\nDirenv supports automatically loading of the nix developer shell, so if you're using direnv too, type:\n```sh\ndirenv allow\n```\nand have `java` and `mvn` set up with correct versions each time you enter project directory.\n\nThe default build contains minimal static analysis (via CheckStyle). To run your build with PMD and Spotbugs, use the `static-analysis` profile:\n\n- Linux: `./mvnw -Pstatic-analysis clean install`\n- Windows: `mvnw.cmd -Pstatic-analysis clean install`\n\n### [1.5 - Homebrew](#table-of-contents)\n\nTo install, run `brew install openapi-generator`\n\nHere is an example usage to generate a Ruby client:\n```sh\nopenapi-generator generate -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml -g ruby -o /tmp/test/\n```\n\nTo reinstall with the latest master, run `brew uninstall openapi-generator && brew install --HEAD openapi-generator`\n\nTo install OpenJDK (pre-requisites), please run\n```sh\nbrew tap AdoptOpenJDK/openjdk\nbrew install --cask adoptopenjdk11\nexport JAVA_HOME=`/usr/libexec/java_home -v 1.11`\n```\n\nor download installer via https://adoptium.net/\n\nTo install Maven (optional), please run\n```sh\nbrew install maven\n```\n\n### [1.6 - Docker](#table-of-contents)\n\n#### Public Pre-built Docker images\n\n - [https://hub.docker.com/r/openapitools/openapi-generator-cli/](https://hub.docker.com/r/openapitools/openapi-generator-cli/) (official CLI)\n - [https://hub.docker.com/r/openapitools/openapi-generator-online/](https://hub.docker.com/r/openapitools/openapi-generator-online/) (official web service)\n\n\n#### OpenAPI Generator CLI Docker Image\n\nThe OpenAPI Generator image acts as a standalone executable. It can be used as an alternative to installing via homebrew, or for developers who are unable to install Java or upgrade the installed version.\n\nTo generate code with this image, you'll need to mount a local location as a volume.\n\nExample:\n\n```sh\ndocker run --rm -v \"${PWD}:/local\" openapitools/openapi-generator-cli generate \\\n    -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml \\\n    -g go \\\n    -o /local/out/go\n```\n\nThe generated code will be located under `./out/go` in the current directory.\n\n#### OpenAPI Generator Online Docker Image\n\nThe openapi-generator-online image can act as a self-hosted web application and API for generating code. This container can be incorporated into a CI pipeline, and requires at least two HTTP requests and some docker orchestration to access generated code.\n\nExample usage:\n\n```sh\n# Start container at port 8888 and save the container id\n> CID=$(docker run -d -p 8888:8080 openapitools/openapi-generator-online)\n\n# allow for startup\n> sleep 10\n\n# Get the IP of the running container (optional)\nGEN_IP=$(docker inspect --format '{{.NetworkSettings.IPAddress}}'  $CID)\n\n# Execute an HTTP request to generate a Ruby client\n> curl -X POST --header 'Content-Type: application/json' --header 'Accept: application/json' \\\n-d '{\"openAPIUrl\": \"https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml\"}' \\\n'http://localhost:8888/api/gen/clients/ruby'\n\n{\"code\":\"c2d483.3.4672-40e9-91df-b9ffd18d22b8\",\"link\":\"http://localhost:8888/api/gen/download/c2d483.3.4672-40e9-91df-b9ffd18d22b8\"}\n\n# Download the generated zip file\n> wget http://localhost:8888/api/gen/download/c2d483.3.4672-40e9-91df-b9ffd18d22b8\n\n# Unzip the file\n> unzip c2d483.3.4672-40e9-91df-b9ffd18d22b8\n\n# Shutdown the openapi generator image\n> docker stop $CID && docker rm $CID\n```\n\n#### Development in docker\n\nYou can use `run-in-docker.sh` to do all development. This script maps your local repository to `/gen`\nin the docker container. It also maps `~/.m2/repository` to the appropriate container location.\n\nTo execute `mvn package`:\n\n```sh\ngit clone https://github.com/openapitools/openapi-generator\ncd openapi-generator\n./run-in-docker.sh mvn package\n```\n\nBuild artifacts are now accessible in your working directory.\n\nOnce built, `run-in-docker.sh` will act as an executable for openapi-generator-cli. To generate code, you'll need to output to a directory under `/gen` (e.g. `/gen/out`). For example:\n\n```sh\n./run-in-docker.sh help # Executes 'help' command for openapi-generator-cli\n./run-in-docker.sh list # Executes 'list' command for openapi-generator-cli\n./run-in-docker.sh generate -i modules/openapi-generator/src/test/resources/3_0/petstore.yaml \\\n    -g go -o /gen/out/go-petstore -p packageName=petstore # generates go client, outputs locally to ./out/go-petstore\n```\n\n##### Troubleshooting\n\nIf an error like this occurs, just execute the **./mvnw clean install -U** command:\n\n> org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project openapi-generator: A type incompatibility occurred while executing org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test: java.lang.ExceptionInInitializerError cannot be cast to java.io.IOException\n\n```sh\n./run-in-docker.sh ./mvnw clean install -U\n```\n\n> Failed to execute goal org.fortasoft:gradle-maven-plugin:1.0.8:invoke (default) on project openapi-generator-gradle-plugin-mvn-wrapper: org.gradle.tooling.BuildException: Could not execute build using Gradle distribution 'https://services.gradle.org/distributions/gradle-4.7-bin.zip'\n\nRight now: no solution for this one :|\n\n#### Run Docker in Vagrant\nPrerequisite: install [Vagrant](https://www.vagrantup.com/downloads.html) and [VirtualBox](https://www.virtualbox.org/wiki/Downloads).\n ```sh\ngit clone https://github.com/openapitools/openapi-generator.git\ncd openapi-generator\nvagrant up\nvagrant ssh\ncd /vagrant\n./run-in-docker.sh ./mvnw package\n```\n\n### [1.7 - NPM](#table-of-contents)\n\nThere is also an [NPM package wrapper](https://www.npmjs.com/package/@openapitools/openapi-generator-cli) available for different platforms (e.g. Linux, Mac, Windows). (JVM is still required)\nPlease see the [project's README](https://github.com/openapitools/openapi-generator-cli) there for more information.\n\nInstall it globally to get the CLI available on the command line:\n\n```sh\nnpm install @openapitools/openapi-generator-cli -g\nopenapi-generator-cli version\n```\n\n<!-- RELEASE_VERSION -->\nTo use a specific version of \"openapi-generator-cli\"\n\n```sh\nopenapi-generator-cli version-manager set 7.19.0\n```\n\nOr install it as dev-dependency:\n\n```sh\nnpm install @openapitools/openapi-generator-cli -D\n```\n<!-- /RELEASE_VERSION -->\n\nYou can use [locally built JARs](https://github.com/OpenAPITools/openapi-generator-cli?tab=readme-ov-file#use-locally-built-jar) or [`SNAPSHOT` versions](https://github.com/OpenAPITools/openapi-generator-cli?tab=readme-ov-file#use-nightly-snapshot-build) as well.\n\n### [1.8 - pip](#table-of-contents)\n\n\n> **Platform(s)**: Linux, macOS, Windows\n**Install** via [PyPI](https://pypi.org/) (`java` executable is needed to run):\n\n```\npip install openapi-generator-cli\n```\n\nTo install a specific version\n```\npip install openapi-generator-cli==7.19.0\n```\n\nYou can also install with [jdk4py](https://github.com/activeviam/jdk4py) instead of java binary. (python>=3.10 is required)\n\n```\npip install openapi-generator-cli[jdk4py]\n```\n\nRef: https://github.com/openAPITools/openapi-generator-pip\n\n## [2 - Getting Started](#table-of-contents)\n\nTo generate a PHP client for [petstore.yaml](https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml), please run the following\n```sh\ngit clone https://github.com/openapitools/openapi-generator\ncd openapi-generator\n./mvnw clean package\njava -jar modules/openapi-generator-cli/target/openapi-generator-cli.jar generate \\\n   -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml \\\n   -g php \\\n   -o /var/tmp/php_api_client\n```\n(if you're on Windows, replace the last command with `java -jar modules\\openapi-generator-cli\\target\\openapi-generator-cli.jar generate -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml -g php -o c:\\temp\\php_api_client`)\n\n<!-- RELEASE_VERSION -->\nYou can also download the JAR (latest release) directly from [maven.org](https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/7.19.0/openapi-generator-cli-7.19.0.jar)\n<!-- /RELEASE_VERSION -->\n\nTo get a list of **general** options available, please run `java -jar modules/openapi-generator-cli/target/openapi-generator-cli.jar help generate`\n\nTo get a list of PHP specified options (which can be passed to the generator with a config file via the `-c` option), please run `java -jar modules/openapi-generator-cli/target/openapi-generator-cli.jar config-help -g php`\n\n## [3 - Usage](#table-of-contents)\n\n### To generate a sample client library\nYou can build a client against the [Petstore API](https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml) as follows:\n\n```sh\n./bin/generate-samples.sh ./bin/configs/java-okhttp-gson.yaml\n```\n\n(On Windows, please install [GIT Bash for Windows](https://gitforwindows.org/) to run the command above)\n\nThis script uses the default library, which is `okhttp-gson`. It will run the generator with this command:\n\n```sh\njava -jar modules/openapi-generator-cli/target/openapi-generator-cli.jar generate \\\n  -i https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml \\\n  -g java \\\n  -t modules/openapi-generator/src/main/resources/Java \\\n  --additional-properties artifactId=petstore-okhttp-gson,hideGenerationTimestamp=true \\\n  -o samples/client/petstore/java/okhttp-gson\n```\n\nwith a number of options. [The java options are documented here.](docs/generators/java.md)\n\nYou can also get the options with the `help generate` command (below only shows partial results):\n\n```\nNAME\n        openapi-generator-cli generate - Generate code with the specified\n        generator.\n\nSYNOPSIS\n        openapi-generator-cli generate\n                [(-a <authorization> | --auth <authorization>)]\n                [--api-name-suffix <api name suffix>] [--api-package <api package>]\n                [--artifact-id <artifact id>] [--artifact-version <artifact version>]\n                [(-c <configuration file> | --config <configuration file>)] [--dry-run]\n                [(-e <templating engine> | --engine <templating engine>)]\n                [--enable-post-process-file]\n                [(-g <generator name> | --generator-name <generator name>)]\n                [--generate-alias-as-model] [--git-host <git host>]\n                [--git-repo-id <git repo id>] [--git-user-id <git user id>]\n                [--global-property <global properties>...] [--group-id <group id>]\n                [--http-user-agent <http user agent>]\n                [(-i <spec file> | --input-spec <spec file>)]\n                [--ignore-file-override <ignore file override location>]\n                [--import-mappings <import mappings>...]\n                [--instantiation-types <instantiation types>...]\n                [--invoker-package <invoker package>]\n                [--language-specific-primitives <language specific primitives>...]\n                [--legacy-discriminator-behavior] [--library <library>]\n                [--log-to-stderr] [--minimal-update]\n                [--model-name-prefix <model name prefix>]\n                [--model-name-suffix <model name suffix>]\n                [--model-package <model package>]\n                [(-o <output directory> | --output <output directory>)] [(-p <additional properties> | --additional-properties <additional properties>)...]\n                [--package-name <package name>] [--release-note <release note>]\n                [--remove-operation-id-prefix]\n                [--reserved-words-mappings <reserved word mappings>...]\n                [(-s | --skip-overwrite)] [--server-variables <server variables>...]\n                [--skip-validate-spec] [--strict-spec <true/false strict behavior>]\n                [(-t <template directory> | --template-dir <template directory>)]\n                [--type-mappings <type mappings>...] [(-v | --verbose)]\n\nOPTIONS\n        -a <authorization>, --auth <authorization>\n            adds authorization headers when fetching the OpenAPI definitions\n            remotely. Pass in a URL-encoded string of name:header with a comma\n            separating multiple values\n\n...... (results omitted)\n\n        -v, --verbose\n            verbose mode\n\n```\n\nYou can then compile and run the client, as well as unit tests against it:\n\n```sh\ncd samples/client/petstore/java/okhttp-gson\nmvn package\n```\n\nOther generators have [samples](https://github.com/OpenAPITools/openapi-generator/tree/master/samples) too.\n\n### [3.1 - Customization](#table-of-contents)\n\nPlease refer to [customization.md](docs/customization.md) on how to customize the output (e.g. package name, version)\n\n### [3.2 - Workflow Integration (Maven, Gradle, Github, CI/CD)](#table-of-contents)\n\nPlease refer to [integration.md](docs/integration.md) on how to integrate OpenAPI generator with Maven, Gradle, sbt, Bazel, Github and CI/CD.\n\n### [3.3 - Online OpenAPI generator](#table-of-contents)\n\nHere are the public online services:\n\n- latest stable version: https://api.openapi-generator.tech\n- latest master: https://api-latest-master.openapi-generator.tech (updated with latest master every hour)\n\nThe server is sponsored by [Linode](https://www.linode.com/) [![Linode Logo](https://www.linode.com/media/images/logos/standard/light/linode-logo_standard_light_small.png)](https://www.linode.com/)\n\n(These services are beta and do not have any guarantee on service level)\n\nPlease refer to [online.md](docs/online.md) on how to run and use the `openapi-generator-online` - a web service for `openapi-generator`.\n\n### [3.4 - License information on Generated Code](#table-of-contents)\n\nThe OpenAPI Generator project is intended as a benefit for users of the Open API Specification.  The project itself has the [License](#7---license) as specified. In addition, please understand the following points:\n\n* The templates included with this project are subject to the [License](#7---license).\n* Generated code is intentionally _not_ subject to the parent project license\n\nWhen code is generated from this project, it shall be considered **AS IS** and owned by the user of the software.  There are no warranties--expressed or implied--for generated code.  You can do what you wish with it, and once generated, the code is your responsibility and subject to the licensing terms that you deem appropriate.\n\n### [3.5 - IDE Integration](#table-of-contents)\n\nHere is a list of community-contributed IDE plug-ins that integrate with OpenAPI Generator:\n\n- Eclipse: [Codewind OpenAPI Tools for Eclipse](https://www.eclipse.org/codewind/open-api-tools-for-eclipse.html) by [IBM](https://www.ibm.com)\n- IntelliJ IDEA: [OpenAPI Generator](https://plugins.jetbrains.com/plugin/8433-openapi-generator) by [Jim Schubert](https://jimschubert.us/#/)\n- IntelliJ IDEA: [Senya Editor](https://plugins.jetbrains.com/plugin/10690-senya-editor) by [senya.io](https://senya.io)\n- [RepreZen API Studio](https://www.reprezen.com/)\n- Visual Studio: [REST API Client Code Generator](https://marketplace.visualstudio.com/items?itemName=ChristianResmaHelle.ApiClientCodeGenerator) by [Christian Resma Helle](https://christian-helle.blogspot.com/)\n- Visual Studio Code: [Codewind OpenAPI Tools](https://marketplace.visualstudio.com/items?itemName=IBM.codewind-openapi-tools) by [IBM](https://marketplace.visualstudio.com/publishers/IBM)\n\n\n## [4 - Companies/Projects using OpenAPI Generator](#table-of-contents)\nHere are some companies/projects (alphabetical order) using OpenAPI Generator in production. To add your company/project to the list, please visit [README.md](README.md) and click on the icon to edit the page.\n\n- [Aalborg University](https://www.aau.dk)\n- [act coding](https://github.com/actcoding)\n- [Adaptant Solutions AG](https://www.adaptant.io/)\n- [adesso SE](https://www.adesso.de/)\n- [adorsys GmbH & Co.KG](https://adorsys.com/)\n- [Adyen](https://www.adyen.com/)\n- [Agoda](https://www.agoda.com/)\n- [Airthings](https://www.airthings.com/)\n- [Aleri Solutions Gmbh](https://www.aleri.de/)\n- [Allianz](https://www.allianz.com)\n- [Angular.Schule](https://angular.schule/)\n- [Aqovia](https://aqovia.com/)\n- [Australia and New Zealand Banking Group (ANZ)](http://www.anz.com/)\n- [Arduino](https://www.arduino.cc/)\n- [ASKUL](https://www.askul.co.jp)\n- [Amazon Web Services (AWS)](https://aws.amazon.com/)\n- [b<>com](https://b-com.com/en)\n- [ç™¾åº¦è¥é”€](https://e.baidu.com)\n- [Bandwidth](https://dev.bandwidth.com)\n- [Banzai Cloud](https://banzaicloud.com)\n- [BIMData.io](https://bimdata.io)\n- [Bithost GmbH](https://www.bithost.ch)\n- [Bosch Connected Industry](https://www.bosch-connected-industry.com)\n- [Boxever](https://www.boxever.com/)\n- [Brevy](https://www.brevy.com)\n- [Bunker Holding Group](https://www.bunker-holding.com/)\n- [California State University, Northridge](https://www.csun.edu)\n- [CAM](https://www.cam-inc.co.jp/)\n- [Camptocamp](https://www.camptocamp.com/en)\n- [Carlsberg Group](https://www.carlsberggroup.com/)\n- [CERN](https://home.cern/)\n- [Christopher Queen Consulting](https://www.christopherqueenconsulting.com/)\n- [Cisco](https://www.cisco.com/)\n- [codecentric AG](https://www.codecentric.de/)\n- [CoinAPI](https://www.coinapi.io/)\n- [Commencis](https://www.commencis.com/)\n- [ConfigCat](https://configcat.com/)\n- [cronn GmbH](https://www.cronn.de/)\n- [Crossover Health](https://crossoverhealth.com/)\n- [Cupix](https://www.cupix.com/)\n- [Datadog](https://www.datadoghq.com)\n- [DB Systel](https://www.dbsystel.de)\n- [Deeporute.ai](https://www.deeproute.ai/)\n- [Devsupply](https://www.devsupply.com/)\n- [dmTECH GmbH](https://www.dmTECH.de)\n- [DocSpring](https://docspring.com/)\n- [dwango](https://dwango.co.jp/)\n- [Edge Impulse](https://www.edgeimpulse.com/)\n- [Element AI](https://www.elementai.com/)\n- [Embotics](https://www.embotics.com/)\n- [emineo](https://www.emineo.ch)\n- [fastly](https://www.fastly.com/)\n- [Fenergo](https://www.fenergo.com/)\n- [freee](https://corp.freee.co.jp/en/)\n- [FreshCells](https://www.freshcells.de/)\n- [Fuse](https://www.fuse.no/)\n- [Gantner](https://www.gantner.com)\n- [GenFlow](https://github.com/RepreZen/GenFlow)\n- [GetYourGuide](https://www.getyourguide.com/)\n- [Glovo](https://glovoapp.com/)\n- [GMO Pepabo](https://pepabo.com/en/)\n- [GoDaddy](https://godaddy.com)\n- [Gumtree](https://gumtree.com)\n- [Here](https://developer.here.com/)\n- [IBM](https://www.ibm.com/)\n- [Instana](https://www.instana.com)\n- [Interxion](https://www.interxion.com)\n- [Inquisico](https://inquisico.com)\n- [JustStar](https://www.juststarinfo.com)\n- [k6.io](https://k6.io/)\n- [Klarna](https://www.klarna.com/)\n- [Kronsoft Development](https://www.kronsoft.ro/home/)\n- [Kubernetes](https://kubernetes.io)\n- [Landeshauptstadt MÃ¼nchen - it@M](https://muenchen.digital/it-at-m/)\n- [Linode](https://www.linode.com/)\n- [Logicdrop](https://www.logicdrop.com)\n- [Lumeris](https://www.lumeris.com)\n- [LVM Versicherungen](https://www.lvm.de)\n- [MailSlurp](https://www.mailslurp.com)\n- [Manticore Search](https://manticoresearch.com)\n- [Mastercard](https://developers.mastercard.com)\n- [MÃ©diavision](https://www.mediavision.fr/)\n- [Metaswitch](https://www.metaswitch.com/)\n- [MoonVision](https://www.moonvision.io/)\n- [Myworkout](https://myworkout.com)\n- [NamSor](https://www.namsor.com/)\n- [Neverfail](https://www.neverfail.com/)\n- [NeuerEnergy](https://neuerenergy.com)\n- [Nokia](https://www.nokia.com/)\n- [OneSignal](https://www.onesignal.com/)\n- [Options Clearing Corporation (OCC)](https://www.theocc.com/)\n- [Openet](https://www.openet.com/)\n- [openVALIDATION](https://openvalidation.io/)\n- [Oracle](https://www.oracle.com/)\n- [Paxos](https://www.paxos.com)\n- [Plaid](https://plaid.com)\n- [PLAID, Inc.](https://plaid.co.jp/)\n- [Pinterest](https://www.pinterest.com)\n- [Ponicode](https://ponicode.dev/)\n- [Pricefx](https://www.pricefx.com/)\n- [PrintNanny](https://www.print-nanny.com/)\n- [Prometheus/Alertmanager](https://github.com/prometheus/alertmanager)\n- [Qavar](https://www.qavar.com)\n- [QEDIT](https://qed-it.com)\n- [Qovery](https://qovery.com)\n- [Qulix Systems](https://www.qulix.com)\n- [Raksul](https://corp.raksul.com)\n- [Raiffeisen Schweiz Genossenschaft](https://www.raiffeisen.ch)\n- [RedHat](https://www.redhat.com)\n- [RepreZen API Studio](https://www.reprezen.com/swagger-openapi-code-generation-api-first-microservices-enterprise-development)\n- [REST United](https://restunited.com)\n- [Robocorp](https://www.robocorp.com)\n- [Robotinfra](https://www.robotinfra.com)\n- [Sarvika Technologies Pvt. Ltd.](https://www.sarvika.com)\n- [SearchApi](https://www.searchapi.io/)\n- [SmartHR](https://smarthr.co.jp/)\n- [Sony Interactive Entertainment](https://www.sie.com/en/index.html)\n- [Splitit](https://www.splitit.com/)\n- [Stingray](http://www.stingray.com)\n- [Suva](https://www.suva.ch/)\n- [Svix](https://www.svix.com/)\n- [Telstra](https://dev.telstra.com)\n- [Tencent](https://www.tencent.com)\n- [The University of Aizu](https://www.u-aizu.ac.jp/en/)\n- [TINQIN](https://www.tinqin.com/)\n- [Translucent ApS](https://www.translucent.dk)\n- [TravelTime platform](https://www.traveltimeplatform.com/)\n- [TribalScale](https://www.tribalscale.com)\n- [Trifork](https://trifork.com)\n- [TUI InfoTec GmbH](http://www.tui-infotec.com/)\n- [Twilio](https://www.twilio.com/)\n- [Twitter](https://twitter.com)\n- [unblu inc.](https://www.unblu.com/)\n- [Veamly](https://www.veamly.com/)\n- [VMWare](https://www.vmware.com/)\n- [wbt-solutions](https://www.wbt-solutions.de/)\n- [Woleet](https://www.woleet.io/)\n- [WSO2](https://wso2.com/)\n- [Vouchery.io](https://vouchery.io)\n- [Xero](https://www.xero.com/)\n- [Yahoo Japan](https://www.yahoo.co.jp/)\n- [viadee](https://www.viadee.de/)\n- [Vonage](https://vonage.com)\n- [YITU Technology](https://www.yitutech.com/)\n- [Yelp](https://www.yelp.com/)\n- [Zalando](https://www.zalando.com)\n- [3DS Outscale](https://www.outscale.com/)\n\n## [5 - Presentations/Videos/Tutorials/Books](#table-of-contents)\n\n- 2018/05/12 - [OpenAPI Generator - community drivenã§æˆé•·ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿](https://ackintosh.github.io/blog/2018/05/12/openapi-generator/) by [ä¸­é‡æšäºº](https://github.com/ackintosh)\n- 2018/05/15 - [Starting a new open-source project](http://jmini.github.io/blog/2018/2018-05-15_new-open-source-project.html) by [Jeremie Bresson](https://github.com/jmini)\n- 2018/05/15 - [REST APIä»•æ§˜ã‹ã‚‰APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚„ã‚¹ã‚¿ãƒ–ã‚µãƒ¼ãƒã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã€ŒOpenAPI Generatorã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹ã€‚Swagger Codegenã‹ã‚‰ã®ãƒ•ã‚©ãƒ¼ã‚¯](https://www.publickey1.jp/blog/18/rest_apiapiopenapi_generatorswagger_generator.html) by [Publickey](https://www.publickey1.jp)\n- 2018/06/08 - [Swagger Codegen is now OpenAPI Generator](https://angular.schule/blog/2018-06-swagger-codegen-is-now-openapi-generator) by [JohannesHoppe](https://github.com/JohannesHoppe)\n- 2018/06/21 - [Connect your JHipster apps to the world of APIs with OpenAPI and gRPC](https://fr.slideshare.net/chbornet/jhipster-conf-2018-connect-your-jhipster-apps-to-the-world-of-apis-with-openapi-and-grpc) by [Christophe Bornet](https://github.com/cbornet) at [JHipster Conf 2018](https://jhipster-conf.github.io/)\n- 2018/06/22 - [OpenAPI Generator ã§ Gatling Client ã‚’ç”Ÿæˆã—ã¦ã¿ãŸ](https://rohki.hatenablog.com/entry/2018/06/22/073000) at [ã‚½ãƒ¢ã‚µãƒ³](https://rohki.hatenablog.com/)\n- 2018/06/27 - [Lessons Learned from Leading an Open-Source Project Supporting 30+ Programming Languages](https://speakerdeck.com/wing328/lessons-learned-from-leading-an-open-source-project-supporting-30-plus-programming-languages) - [William Cheng](https://github.com/wing328) at [LinuxCon + ContainerCon + CloudOpen China 2018](http://bit.ly/2waDKKX)\n- 2018/07/19 - [OpenAPI Generator Contribution Quickstart - RingCentral Go SDK](https://medium.com/ringcentral-developers/openapi-generator-for-go-contribution-quickstart-8cc72bf37b53) by [John Wang](https://github.com/grokify)\n- 2018/08/22 - [OpenAPI Generatorã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆãªã©ã®ãƒ¡ãƒ¢](https://yinm.info/20180822/) by [Yusuke Iinuma](https://github.com/yinm)\n- 2018/09/12 - [RepreZen and OpenAPI 3.0: Now is the Time](https://www.reprezen.com/blog/reprezen-openapi-3.0-upgrade-now-is-the-time) by [Miles Daffin](https://www.reprezen.com/blog/author/miles-daffin)\n- 2018/10/31 - [A node package wrapper for openapi-generator](https://github.com/HarmoWatch/openapi-generator-cli)\n- 2018/11/03 - [OpenAPI Generator + golang + Flutter ã§ã‚¢ãƒ—ãƒªé–‹ç™º](http://ryuichi111std.hatenablog.com/entry/2018/11/03/214005) by [Ryuichi Daigo](https://github.com/ryuichi111)\n- 2018/11/15 - [åŸºäºopenapi3.0çš„yamlæ–‡ä»¶ç”Ÿæˆjavaä»£ç çš„ä¸€æ¬¡å®è·µ](https://blog.csdn.net/yzy199391/article/details/84023982) by [ç„±é­”ç‹](https://me.csdn.net/yzy199391)\n- 2018/11/18 - [Generating PHP library code from OpenAPI](https://lornajane.net/posts/2018/generating-php-library-code-from-openapi) by [Lorna Jane](https://lornajane.net/) at [LORNAJANE Blog](https://lornajane.net/blog)\n- 2018/11/19 - [OpenAPIs are everywhere](https://youtu.be/-lDot4Yn7Dg) by [Jeremie Bresson (Unblu)](https://github.com/jmini) at [EclipseCon Europe 2018](https://www.eclipsecon.org/europe2018)\n- 2018/12/09 - [openapi-generator ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹æ–¹æ³•](https://qiita.com/watiko/items/0961287c02eac9211572) by [@watiko](https://qiita.com/watiko)\n- 2019/01/03 - [Calling a Swagger service from Apex using openapi-generator](https://lekkimworld.com/2019/01/03/calling-a-swagger-service-from-apex-using-openapi-generator/) by [Mikkel Flindt Heisterberg](https://lekkimworld.com)\n- 2019/01/13 - [OpenAPI Generatorã§RESTful APIã®å®šç¾©æ›¸ã‹ã‚‰è‰²ã€…è‡ªå‹•ç”Ÿæˆã™ã‚‹](https://ky-yk-d.hatenablog.com/entry/2019/01/13/234108) by [@ky_yk_d](https://twitter.com/ky_yk_d)\n- 2019/01/20 - [Contract-First API Development with OpenAPI Generator and Connexion](https://medium.com/commencis/contract-first-api-development-with-openapi-generator-and-connexion-b21bbf2f9244) by [Anil Can Aydin](https://github.com/anlcnydn)\n- 2019/01/30 - [Rapid Application Development With API First Approach Using Open-API Generator](https://dzone.com/articles/rapid-api-development-using-open-api-generator) by [Milan Sonkar](https://dzone.com/users/828329/milan_sonkar.html)\n- 2019/02/02 - [å¹³é™ã‚’ä¿ã¡ã€ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã›ã‚ˆ ã€œ OpenAPI Generatorèª•ç”Ÿã®èƒŒæ™¯ã¨è»Œè·¡ ã€œ](https://speakerdeck.com/akihito_nakano/gunmaweb34) by [ä¸­é‡æšäºº](https://github.com/ackintosh) at [Gunma.web #34 ã‚¹ã‚­ãƒ¼ãƒé§†å‹•é–‹ç™º](https://gunmaweb.connpass.com/event/113974/)\n- 2019/02/20 - [An adventure in OpenAPI V3 code generation](https://mux.com/blog/an-adventure-in-openapi-v3-api-code-generation/) by [Phil Cluff](https://mux.com/blog/author/philc/)\n- 2019/02/26 - [Building API Services: A Beginnerâ€™s Guide](https://medium.com/google-cloud/building-api-services-a-beginners-guide-7274ae4c547f) by [Ratros Y.](https://medium.com/@ratrosy) in [Google Cloud Platform Blog](https://medium.com/google-cloud)\n- 2019/02/26 - [Building APIs with OpenAPI: Continued](https://medium.com/@ratrosy/building-apis-with-openapi-continued-5d0faaed32eb) by [Ratros Y.](https://medium.com/@ratrosy) in [Google Cloud Platform Blog](https://medium.com/google-cloud)\n- 2019-03-07 - [OpenAPI Generator ã§ Spring Boot ã¨ Angular ã‚’ã‚¿ã‚¤ãƒ—ã‚»ãƒ¼ãƒ•ã«ç¹‹ã](https://qiita.com/chibato/items/e4a748db12409b40c02f) by [Tomofumi Chiba](https://github.com/chibat)\n- 2019-03-16 - [A Quick introduction to manual OpenAPI V3](https://vadosware.io/post/quick-intro-to-manual-openapi-v3/) by [vados](https://github.com/t3hmrman) at [VADOSWARE](https://vadosware.io)\n- 2019-03-25 - [Access any REST service with the SAP S/4HANA Cloud SDK](https://blogs.sap.com/2019/03/25/integrate-sap-s4hana-cloud-sdk-with-open-api/) by [Alexander Duemont](https://people.sap.com/alexander.duemont)\n- 2019-03-25 - [OpenAPI generatorã‚’è©¦ã—ã¦ã¿ã‚‹](https://qiita.com/amuyikam/items/e8a45daae59c68be0fc8) by [@amuyikam](https://twitter.com/amuyikam)\n- 2019-03-27 - [OpenAPI3ã‚’ä½¿ã£ã¦ã¿ã‚ˆã†ï¼Goè¨€èªã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚¹ã‚¿ãƒ–ã®è‡ªå‹•ç”Ÿæˆã¾ã§ï¼](https://techblog.zozo.com/entry/openapi3/go) by [@gold_kou](https://twitter.com/gold_kou)\n- 2019-04-17 - [OpenAPIã«ã‚ˆã‚‹ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆé–‹ç™ºã®å®Ÿæ–½ã‚µãƒ³ãƒ—ãƒ«ã¨Cloud Runã«ã¤ã„ã¦](https://tech-blog.optim.co.jp/entry/2019/04/17/174000) by [@yukey1031](https://twitter.com/yukey1031)\n- 2019-04-18 - [How to use OpenAPI3 for API developer (RubyKaigi 2019)](https://speakerdeck.com/ota42y/how-to-use-openapi3-for-api-developer) by [@ota42y](https://twitter.com/ota42y) at [RubyKaigi 2019](https://rubykaigi.org/2019)\n- 2019-04-29 - [A Beginner's Guide to Code Generation for REST APIs (OpenAPI Generator)](https://gum.co/openapi_generator_ebook) by [William Cheng](https://twitter.com/wing328)\n- 2019-05-01 - [Design and generate a REST API from Swagger / OpenAPI in Java, Python, C# and more](https://simply-how.com/design-and-generate-api-code-from-openapi) by [Simply How](https://simply-how.com/)\n- 2019-05-17 - [Generate Spring Boot REST API using Swagger/OpenAPI](https://www.47northlabs.com/knowledge-base/generate-spring-boot-rest-api-using-swagger-openapi/) by [Antonie Zafirov](https://www.47northlabs.com/author/antonie-zafirov/)\n- 2019-05-22 - [REST APIsä»£ç ç”ŸæˆæŒ‡å—(OpenAPI Generator)](https://gum.co/openapi_generator_ebook_gb) by [William Cheng](https://twitter.com/wing328), [Xin Meng](https://github.com/xmeng1)\n- 2019-05-24 - [REST API ä»£ç¢¼ç”ŸæˆæŒ‡å— (OpenAPI Generator)](https://gum.co/openapi_generator_ebook_big5) by [William Cheng](https://twitter.com/wing328)\n- 2019-06-24 - [Kubernetes Clients and OpenAPI Generator](https://speakerdeck.com/wing328/kubernetes-clients-and-openapi-generator) by [William Cheng](https://twitter.com/wing328) at [Kubernetes Contributor Summits Shanghai 2019](https://www.lfasiallc.com/events/contributors-summit-china-2019/)\n- 2019-06-28 [Codewind OpenAPI Tools](https://marketplace.eclipse.org/content/codewind-openapi-tools) in [Eclipse Marketplace](https://marketplace.eclipse.org/) by IBM\n- 2019-06-29 [Codewind OpenAPI Tools](https://marketplace.visualstudio.com/items?itemName=IBM.codewind-openapi-tools) in [Visual Studio Marketplace](https://marketplace.visualstudio.com/) by IBM\n- 2019-07-04 - [REST API ã®ãŸã‚ã®ã‚³ãƒ¼ãƒˆã‚™ç”Ÿæˆå…¥é–€ (OpenAPI Generator)](https://gum.co/openapi_generator_ebook_big5) by [William Cheng](https://twitter.com/wing328), [ä¸­é‡æšäºº](https://github.com/ackintosh), [å’Œç”°æ‹“æœ—](https://github.com/taxpon)\n- 2019-07-08 - [OpenAPI Generator ã«ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆã—ãŸã‚‰ç¤¾åãŒè¼‰ã£ãŸè©±ã€‚(CAM) - CAM TECH BLOG](https://tech.cam-inc.co.jp/entry/2019/07/08/140000) by [CAM, Inc.](https://www.cam-inc.co.jp/)\n- 2019-07-14 - [OpenAPI Generatorã§Pythonã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½œæˆã—ãŸ](https://qiita.com/yuji38kwmt/items/dfb929316a1335a161c0) by [yuji38kwmt](https://qiita.com/yuji38kwmt)\n- 2019-07-19 - [Developer Experience (DX) for Open-Source Projects: How to Engage Developers and Build a Growing Developer Community](https://speakerdeck.com/wing328/developer-experience-dx-for-open-source-projects-english-japanese) by [William Cheng](https://twitter.com/wing328), [ä¸­é‡æšäºº](https://github.com/ackintosh) at [Open Source Summit Japan 2019](https://events.linuxfoundation.org/events/open-source-summit-japan-2019/)\n- 2019-08-14 - [Our OpenAPI journey with Standardizing SDKs](https://bitmovin.com/our-openapi-journey-with-standardizing-sdks/) by [Sebastian Burgstaller](https://bitmovin.com/author/sburgstaller/) at [Bitmovin](https://www.bitmovin.com)\n- 2019-08-15 - [APIã®ã‚³ãƒ¼ãƒ‰ã‚’è‡ªå‹•ç”Ÿæˆã•ã›ãŸã„ã ã‘ãªã‚‰gRPCã§ãªãã¦ã‚‚ã‚ˆããªã„?](https://www.m3tech.blog/entry/2019/08/15/110000) by [M3, Inc.](https://corporate.m3.com/)\n- 2019-08-22 - [ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã«ãŠã‘ã‚‹Web APIã‚¹ã‚­ãƒ¼ãƒã®ç®¡ç†â”€ GraphQLã€gRPCã€OpenAPIã®ç‰¹å¾´ã¨ä½¿ã„ã©ã“ã‚](https://employment.en-japan.com/engineerhub/entry/2019/08/22/103000) by [@ota42y](https://twitter.com/ota42y)\n- 2019-08-24 - [Swaggerãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰OpenAPI Generatorã‚’ä½¿ã£ã¦ãƒ¢ãƒƒã‚¯ã‚µãƒ¼ãƒãƒ¼ä½œæˆ](https://qiita.com/masayoshi0222/items/4845e4c715d04587c104) by [å‚æœ¬æ­£ç¾©](https://qiita.com/masayoshi0222)\n- 2019-08-29 - [OpenAPIåˆæ¢](https://cloud.tencent.com/developer/article/1495986) by [peakxie](https://cloud.tencent.com/developer/user/1113152) at [è…¾è®¯äº‘ç¤¾åŒº](https://cloud.tencent.com/developer)\n- 2019-08-29 - [å…¨é¢è¿›åŒ–ï¼šKubernetes CRD 1.16 GAå‰ç»](https://www.servicemesher.com/blog/kubernetes-1.16-crd-ga-preview/) by [Min Kim](https://github.com/yue9944882) at [ServiceMesher Blog](https://www.servicemesher.com/blog/)\n- 2019-09-01 - [Creating a PHP-Slim server using OpenAPI (Youtube video)](https://www.youtube.com/watch?v=5cJtbIrsYkg) by [Daniel Persson](https://www.youtube.com/channel/UCnG-TN23lswO6QbvWhMtxpA)\n- 2019-09-06 - [Vert.x and OpenAPI](https://wissel.net/blog/2019/09/vertx-and-openapi.html) by [Stephan H Wissel](https://twitter.com/notessensei) at [wissel.net blog](https://wissel.net)\n- 2019-09-09 - [Cloud-native development - Creating RESTful microservices](https://cloud.ibm.com/docs/cloud-native?topic=cloud-native-rest-api) in [IBM Cloud Docs](https://cloud.ibm.com/docs)\n- 2019-09-14 - [Generating and Configuring a Mastercard API Client](https://developer.mastercard.com/platform/documentation/generating-and-configuring-a-mastercard-api-client/) at [Mastercard Developers Platform](https://developer.mastercard.com/platform/documentation/)\n- 2019-09-15 - [OpenAPI(Swagger)å°å…¥ä¸‹èª¿ã¹](https://qiita.com/ShoichiKuraoka/items/f1f7a3c2376f7cd9c56a) by [Shoichi Kuraoka](https://qiita.com/ShoichiKuraoka)\n- 2019-09-17 - [Tutorial: Documenting http4k APIs with OpenApi3](https://www.http4k.org/tutorials/documenting_apis_with_openapi/) by [http4k](https://www.http4k.org/)\n- 2019-09-22 - [OpenAPI 3ã‚’å®Œå…¨ã«ç†è§£ã§ãã‚‹æœ¬](https://booth.pm/ja/items/1571902) by [@ota42y](https://twitter.com/ota42y)\n- 2019-09-22 - [RESTful APIs: Tutorial of OpenAPI Specification](https://medium.com/@amirm.lavasani/restful-apis-tutorial-of-openapi-specification-eeada0e3901d) by [Amir Lavasani](https://medium.com/@amirm.lavasani)\n- 2019-09-22 - [Redefining SDKs as software diversity kits](https://devrel.net/dev-rel/redefining-sdks-as-software-diversity-kits) by [Sid Maestre (Xero)](https://twitter.com/sidneyallen) at [DevRelCon San Francisco 2019](https://sf2019.devrel.net/)\n- 2019-09-23 - [swaggerã‹ã‚‰OpenApi Generatorã§Springã®ã‚³ãƒ¼ãƒ‰ã‚’è‡ªå‹•ç”Ÿæˆ](https://qiita.com/littleFeet/items/492df2ad68a0799a5e5e) by [@littleFeet](https://qiita.com/littleFeet) at [Qiita](https://qiita.com/)\n- 2019-09-24 - [Eine Stunde was mit Api First!](https://www.slideshare.net/JanWeinschenker/eine-stunde-was-mit-api-first) by [@janweinschenker](https://twitter.com/janweinschenker) at [Java Forum Nord](https://javaforumnord.de/)\n- 2019-10-09 - [openapi-generator ã§ç”Ÿæˆã—ãŸ Go ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ Bearer èªè¨¼ã‚’ã™ã‚‹](https://autopp-tech.hatenablog.com/entry/2019/10/09/222039) by [Akira Tanimura](https://github.com/autopp)\n- 2019-10-10 - [Automatic Generation of REST Clients](https://www.meetup.com/fr-FR/Criteo-Labs-Tech-Talks/events/264775768/) by Thomas Peyrard, Senior Software Engineer at Criteo in [Full-Stack Tech Talks (Meetup)](https://www.meetup.com/fr-FR/Criteo-Labs-Tech-Talks/events/264775768/)\n- 2019-10-12 - [OpenApiè‡ªåŠ¨ç”Ÿæˆclient](https://blog.csdn.net/wxid2798226/article/details/102527467) by [éƒ‘æ³½æ´²](https://me.csdn.net/wxid2798226)\n- 2019-10-16 - [How to ship APIs faster?](https://medium.com/@accounts_76224/how-to-ship-apis-faster-cabef2f819e4) by [Simon Guilliams @ PoniCode](https://ponicode.dev)\n- 2019-10-22 - [OpenAPI + Spring Boot(Kotlin)ã§ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰APIã‚’ä½œæˆã™ã‚‹](https://qiita.com/boronngo/items/4b78b92526209daeaee9) by [Yuki Furukawa](https://twitter.com/yuki_furukawa5)\n- 2019-10-24 - [Microprofile OpenAPI - Code First or Design First?](https://github.com/pe-st/apidocs/blob/master/MicroProfile-OpenAPI-all-slides.pdf) by [Peter [pÉ›ÊƒÉ™] Steiner](https://twitter.com/pesche) at [eclipsecon Europe 2019](https://www.eclipsecon.org/europe2019/sessions/microprofile-openapi-code-first-or-design-first)\n- 2019-11-06 - [Generating API clients based on OpenAPI v3 specifications](https://98elements.com/blog/generating-api-clients-based-on-openapi-v3-specifications) by [Dominik JastrzÄ™bski @ 98elements](https://98elements.com)\n- 2019-11-06 - [OpenAPIã‚’åˆ©ç”¨ã—ã¦è‡ªå‰ã®APIã‚µãƒ¼ãƒãƒ¼(Sinatra)ã‚’ç§»æ¤ã—ãŸæ™‚ã®ãƒ¡ãƒ¢](https://qiita.com/YasuhiroABE/items/c73920eab2d9d6e97fd9) by [Yasuhiro ABE](https://twitter.com/YasuhiroABE)\n- 2019-11-07 - [API First development with OpenAPI - You should you practise it !?](https://www.youtube.com/watch?v=F9iF3a1Z8Y8) by [Nick Van Hoof](https://www.nickvanhoof.com/) at [Devoxx Belgium 2019](https://devoxx.be/)\n- 2019-11-08 - [JHipster beyond CRUD - API-First for Enterprises by Enrico Costanzi](https://www.youtube.com/watch?v=m28JFovKQ20) by [Enrico Costanzi](https://twitter.com/enricocostanzi) at [JHipster Conf 2019 in Paris](https://jhipster-conf.github.io/)\n- 2019-11-11 - [TypeScript REST APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ](https://qiita.com/unhurried/items/7b74f7d3c43545dadd2b) by [@unhurried](https://qiita.com/unhurried)\n- 2019-11-11 - [One Spec to Rule them all - OpenAPI in Action](https://www.youtube.com/watch?v=MMay_nht8ec) by [Andreas Litt](https://github.com/littldr) at [code.talks 2019](https://www.codetalks.com/)\n- 2019-11-13 - [OpenAPI 3.0 Editor And Generator With A Spring Boot Example](https://simply-how.com/design-and-generate-api-code-from-openapi) at [Simply How](https://simply-how.com/)\n- 2019-11-17 - [OpenAPI Generator YouTube playlist](https://www.youtube.com/playlist?list=PLtJyHVMdzfF6fBkOUV5VDVErP23CGgHIy) at [YouTube](https://www.youtube.com)\n- 2019-11-20 - [Introduction to OpenAPI](https://noti.st/lornajane/HvDH7U/introduction-to-openapi) by [Lorna Mitchell](https://twitter.com/lornajane) at [GOTO Copenhagen 2019](https://gotocph.com/2019/)\n- 2019-11-20 - [How to Generate Angular code from OpenAPI specifications](https://dotnetthoughts.net/how-to-generate-angular-code-from-openapi-specifications/) by Anuraj\n- 2019-11-23 - [Swagger ã§ã¯ãªã„ OpenAPI Specification 3.0 ã«ã‚ˆã‚‹ API ã‚µãƒ¼ãƒãƒ¼é–‹ç™º](https://www.slideshare.net/techblogyahoo/swagger-openapi-specification-30-api) by [Tetsuya Morimoto](https://github.com/t2y) at [JJUG CCC 2019 Fall](https://ccc2019fall.java-users.jp/)\n- 2019-11-24 - [Accelerate Flutter development with OpenAPI and Dart code generation](https://medium.com/@irinasouthwell_220/accelerate-flutter-development-with-openapi-and-dart-code-generation-1f16f8329a6a) by [Irina Southwell](https://medium.com/@irinasouthwell_220)\n- 2019-11-25 - [openapi-generatorã§æ‰‹è»½ã«ã‚¹ã‚¿ãƒ–ã‚µãƒ¼ãƒã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ç”Ÿæˆ](https://qiita.com/pochopocho13/items/8db662e1934fb2b408b8) by [@pochopocho13](https://twitter.com/pochopocho13)\n- 2019-11-26 - [CordaCon 2019 Highlights: Braid Server and OpenAPI Generator for Corda Client APIâ€™s](https://blog.b9lab.com/cordacon-2019-highlights-braid-server-and-openapi-generator-for-corda-flows-api-s-d24179ccb27c) by [Adel Rustum](https://blog.b9lab.com/@adelrestom) at [B9lab](https://blog.b9lab.com/)\n- 2019-12-03 - [A Road to Less Coding: Auto-Generate APILibrary](https://www.corda.net/blog/a-road-to-less-coding-auto-generate-apilibrary/) at [Corda Blog](https://www.corda.net/blog/)\n- 2019-12-04 - [Angularï¼‹NestJSï¼‹OpenAPIï¼ˆSwaggerï¼‰ã§ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚’è¦–é‡ã«å…¥ã‚ŒãŸç’°å¢ƒã‚’è€ƒãˆã‚‹](https://qiita.com/teracy55/items/0327c7a170ec772970c6) by [ã¦ã‚‰ã—ãƒ¼](https://twitter.com/teracy55)\n- 2019-12-05 - [Code generation on the Java VM](https://speakerdeck.com/sullis/code-generation-on-the-java-vm-2019-12-05) by [Sean Sullivan](https://speakerdeck.com/sullis)\n- 2019-12-17 - [OpenAPI Generator ã§ OAuth2 ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ç™ºè¡Œã®ã‚³ãƒ¼ãƒ‰ã¾ã§ç”Ÿæˆã—ã¦ã¿ã‚‹](https://www.techscore.com/blog/2019/12/17/openapi-generator-oauth2-accesstoken/) by [TECHSCORE](https://www.techscore.com/blog/)\n- 2019-12-23 - [Use Ada for Your Web Development](https://www.electronicdesign.com/technologies/embedded-revolution/article/21119177/use-ada-for-your-web-development) by [Stephane Carrez](https://github.com/stcarrez)\n- 2019-12-23 - [OpenAPIã®ã‚¹ã‚­ãƒ¼ãƒã‚’åˆ†å‰²ãƒ»æ§‹é€ åŒ–ã—ã¦ã„ãæ–¹æ³•](https://gift-tech.co.jp/articles/structured-openapi-schema) by [å°é£¯å¡šé”ä¹Ÿ](https://github.com/t2h5) at [GiFT, Inc](https://gift-tech.co.jp/)\n- 2020-01-17 - [OpenAPI demo for Pulp 3.0 GA](https://www.youtube.com/watch?v=mFBP-M0ZPfw&t=178s) by [Pulp](https://www.youtube.com/channel/UCI43Ffs4VPDv7awXvvBJfRQ) at [Youtube](https://www.youtube.com/)\n- 2020-01-19 - [Why document a REST API as code?](https://dev.to/rolfstreefkerk/why-document-a-rest-api-as-code-5e7p) by [Rolf Streefkerk](https://github.com/rpstreef) at [DEV Community](https://dev.to)\n- 2020-01-28 - [Get Your Serverless Swagger Back with OpenAPI](https://dev.to/matttyler/get-your-serverless-swagger-back-with-openapi-48gc) by [Matt Tyler](https://dev.to/matttyler)\n- 2020-01-30 - [OpenAPI Generatorã¸ã®ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆ](https://www.yutaka0m.work/entry/2020/01/30/163905) by [yutaka0m](https://github.com/yutaka0m)\n- 2020-02-01 - [Using OpenAPI to Maximise Your Pulp 3 Experience](https://fosdem.org/2020/schedule/event/openapi/) by [Dennis Kliban](https://github.com/dkliban/) at [FOSDEM](https://fosdem.org/)\n- 2020-02-07 - [Why you should use OpenAPI for your API design](https://www.youtube.com/watch?v=zhb7vUApLW8&t=927s) by [Nick Van Hoof](https://apiconference.net/speaker/nick-van-hoof/) at [API Conference](https://apiconference.net/)\n- 2020-02-17 - [Rubynetes: using OpenAPI to validate Kubernetes configs](https://www.brightbox.com/blog/2020/02/17/using-openapi-to-validate-kubernetes-configs/) by Neil Wilson at [Brightbox](https://www.brightbox.com/)\n- 2020-02-20 - [Building SDKs for the future](https://devblog.xero.com/building-sdks-for-the-future-b79ff726dfd6) by [Sid Maestre (Xero)](https://twitter.com/sidneyallen)\n- 2020-02-27 - [Nuxtåˆ©ç”¨ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã§IE11ã¨ä»²è‰¯ãã™ã‚‹ãŸã‚ã®E2E](https://tech.medpeer.co.jp/entry/e2e-ie11) at [Medpeer.co.jp Tech Blog](https://tech.medpeer.co.jp/)\n- 2020-02-29 - [Providing Support to IoT Devices Deployed in Disconnected Rural Environment (Conference paper)](https://link.springer.com/chapter/10.1007/978-3-030-41494-8_14) by Sergio Laso, Daniel Flores-MartÃ­n, Juan Luis HerreraCarlos, CanalJuan Manuel, MurilloJavier Berrocal\n- 2020-03-02 - [How To Generate Angular & Spring Code From OpenAPI Specification](https://www.mokkapps.de/blog/how-to-generate-angular-and-spring-code-from-open-api-specification/) by [Michael Hoffmann](https://www.mokkapps.de/)\n- 2020-03-02 - [OpenAPI Generator + TypeScript ã§å§‹ã‚ã‚‹è‡ªå‹•ç”Ÿæˆã®å‹ã«å®ˆã‚‰ã‚ŒãŸè±Šã‹ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç”Ÿæ´»](https://gift-tech.co.jp/articles/openapi-generator-typescript) by [äº”ç™¾è”µ ç›´æ¨¹](https://gift-tech.co.jp/members/naokiioroi) at [GiFTæ ªå¼ä¼šç¤¾](https://gift-tech.co.jp/)\n- 2020-03-10 - [OpenAPI Generator Meetup #1](https://speakerdeck.com/akihito_nakano/openapi-generator-meetup-number-1) by [ä¸­é‡æšäºº](https://github.com/ackintosh) at [OpenAPI Generator Meetup #1](https://openapi-generator-meetup.connpass.com/event/168187/)\n- 2020-03-15 - [Load Testing Your API with Swagger/OpenAPI and k6](https://k6.io/blog/load-testing-your-api-with-swagger-openapi-and-k6)\n- 2020-04-13 - [ä¿ºçš„ã€OASã€‘ã¨ã®å‘ãåˆã„æ–¹ (çˆ†é€Ÿã§OpenAPIã¨å‹é”ã«ãªã‚ã†)](https://tech-blog.optim.co.jp/entry/2020/04/13/100000) in [OPTim Blog](https://tech-blog.optim.co.jp/)\n- 2020-04-22 - [Introduction to OpenAPI Generator](https://nordicapis.com/introduction-to-openapi-generator/) by [Kristopher Sandoval](https://nordicapis.com/author/sandovaleffect/) in [Nordic APIs](https://nordicapis.com/)\n- 2020-04-27 - [How we use Open API v3 specification to auto-generate API documentation, code-snippets and clients](https://medium.com/pdf-generator-api/how-we-use-open-api-v3-specification-to-auto-generate-api-documentation-code-snippets-and-clients-d127a3cea784) by [Tanel TÃ¤hepÃµld](https://medium.com/@tanel.tahepold)\n- 2020-05-09 - [OpenAPIã§ãŠæ‰‹è»½ã«ãƒ¢ãƒƒã‚¯APIã‚µãƒ¼ãƒãƒ¼ã‚’å‹•ã‹ã™](https://qiita.com/kasa_le/items/97ca6a8dd4605695c25c) by [Sachie Kamba](https://qiita.com/kasa_le)\n- 2020-05-18 - [Spring Boot REST with OpenAPI 3](https://dev.to/alfonzjanfrithz/spring-boot-rest-with-openapi-3-59jm) by [Alfonz Jan Frithz](https://dev.to/alfonzjanfrithz)\n- 2020-05-19 - [Dead Simple APIs with Open API](https://www.youtube.com/watch?v=sIaXmR6xRAw) by [Chris Tankersley](https://github.com/dragonmantank) at [Nexmo](https://developer.nexmo.com/)\n- 2020-05-22 - [TypeScript REST API Client](https://dev.to/unhurried/typescript-rest-api-client-4in3) by [\"unhurried\"](https://dev.to/unhurried)\n- 2020-05-28 - [ã€ä½¿ç”¨ lotify + Swagger å»ºç½®å¯å…±ç”¨çš„ LINE Notify botã€‘ - #NiJia @ Chatbot Developer Taiwan ç¬¬ #19 å°èš](https://www.youtube.com/watch?v=agYVz6dzh1I) by [Chatbot Developer Taiwan](https://www.youtube.com/channel/UCxeYUyZNnHmpX23YNF-ewvw)\n- 2020-05-28 - [Building APIs with Laravel using OpenAPI](https://www.youtube.com/watch?v=xexLvQqAhiA) by [Chris Tankersley](https://github.com/dragonmantank) at [Laracon EU](https://laracon.eu/)\n- 2020-06-12 - [Interoperability by construction: code generation for Arrowhead Clients](https://ieeexplore.ieee.org/document/9274746) by Michele Albano, Brian Nielsen at [2020 IEEE Conference on Industrial Cyberphysical Systems (ICPS)](https://ieeexplore.ieee.org/xpl/conhome/9274544/proceeding)\n- 2020-06-23 - [æ–°è¦ã‚µãƒ¼ãƒãƒ¼ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«TypeScriptã‚’æ¡ç”¨ã—ã¦ã¿ãŸ](https://www.cam-inc.co.jp/news/20200623) at [CAM Tech Blog](https://www.cam-inc.co.jp/news/tech-blog/)\n- 2020-06-29 - [Artifact Abstract: Deployment of APIs on Android Mobile Devices and Microcontrollers](https://ieeexplore.ieee.org/document/9127353) by [Sergio Laso ; Marino Linaje ; Jose Garcia-Alonso ; Juan M. Murillo ; Javier Berrocal](https://ieeexplore.ieee.org/document/9127353/authors#authors) at [2020 IEEE International Conference on Pervasive Computing and Communications (PerCom)](https://ieeexplore.ieee.org/xpl/conhome/9125449/proceeding)\n- 2020-07-07 - [5 Best API Documentation Tools](https://blog.dreamfactory.com/5-best-api-documentation-tools/) by Susanna Bouse at [DreamFactory Blog](https://blog.dreamfactory.com/)\n- 2020-07-12 - [Open API 3.0ã®å®šç¾©ã‹ã‚‰golangã®ã‚µãƒ¼ãƒã‚³ãƒ¼ãƒ‰ã®ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã‚’ä½œæˆã™ã‚‹](https://qiita.com/professor/items/4cbd04ec084d13057bc2) by [@professor (Qiita Blog)](https://qiita.com/professor)\n- 2020-07-20 - [Datadog API client libraries now available for Java and Go](https://www.datadoghq.com/blog/java-go-libraries/) by Jordan Obey at [Datadog Blog](https://www.datadoghq.com/blog)\n- 2020-07-23 - [Generate Client SDK for .NET Core using Open Api](https://dev.to/no0law1/generate-client-sdk-for-net-core-using-open-api-2dgh) by [Nuno Reis](https://dev.to/no0law1)\n- 2020-07-26 - [Dartã®http_interceptorãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã†ã¨é…åˆ—ã®ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæ¶ˆãˆã¦ã—ã¾ã†ä»¶ã®å¿œæ€¥å‡¦ç½®](https://qiita.com/gyamoto/items/eeeff81b6770487319ed) by [@gyamoto](https://qiita.com/gyamoto)\n- 2020-08-01 - [Generate Angular ReactiveForms from Swagger/OpenAPI](https://dev.to/martinmcwhorter/generate-angular-reactiveforms-from-swagger-openapi-35h9) by [Martin McWhorter](https://dev.to/martinmcwhorter)\n- 2020-08-03 - [Criando Bibliotecas para APIs RESTful com OpenAPI, Swagger Editor e OpenAPI Generator](https://medium.com/@everisBrasil/criando-bibliotecas-para-apis-restful-com-openapi-swagger-editor-e-openapi-generator-75349a6420fd) by [everis Brasil (an NTT DATA Company)](https://medium.com/@everisBrasil)\n- 2020-08-19 - [ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚’é€£æºã—ã¦ã¿ã‚ˆã†](https://thinkit.co.jp/article/17704) by [å²¡äº• è£•çŸ¢(ãŠã‹ã„ ã‚†ã†ã‚„)](https://thinkit.co.jp/author/17588), [æ³‰ å‹(ã„ãšã¿ ã¾ã•ã‚‹)](https://thinkit.co.jp/author/17705) at [Think ITï¼ˆã‚·ãƒ³ã‚¯ã‚¤ãƒƒãƒˆï¼‰](https://thinkit.co.jp/)\n- 2020-08-25 - [OpenAPI Generator ã¨ TypeScript ã§å‹å®‰å…¨ã«ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰é–‹ç™ºã‚’ã—ã¦ã„ã‚‹è©±](https://tech.smarthr.jp/entry/2020/08/25/135631) at [SmartHR Tech Blog](https://tech.smarthr.jp/)\n- 2020-09-10 - [Introduction to OpenAPI with Instana](https://www.instana.com/blog/introduction-to-openapi-with-instana/) by [Cedric Ziel](https://www.instana.com/blog/author/cedricziel/) at [Instana Blog](https://www.instana.com/blog/)\n- 2020-09-17 - [Generate PowerShellSDK using openapi-generator](https://medium.com/@ghufz.learn/generate-powershellsdk-using-openapi-generator-33b700891e33) by [Ghufran Zahidi](https://medium.com/@ghufz.learn)\n- 2020-09-24 - [How to automate API code generation (OpenAPI/Swagger) and boost productivity - Tutorial with React Native featuring TypeScript](https://medium.com/@sceleski/how-to-automate-api-code-generation-openapi-swagger-and-boost-productivity-1176a0056d8a) by [Sanjin Celeski](https://medium.com/@sceleski)\n- 2020-09-25 - [Generate OpenAPI Angular Client](https://medium.com/@pguso/generate-openapi-angular-client-8c9288e8bbd4) by [Patric](https://medium.com/@pguso)\n- 2020-10-24 - [Working with Microsoft Identity - React Native Client](https://www.josephguadagno.net/2020/10/24/working-with-microsoft-identity-react-native-client) by [Joseph Guadagno](https://www.josephguadagno.net/)\n- 2020-10-31 - [[B2] OpenAPI Specificationìœ¼ë¡œ íƒ€ì…-ì„¸ì´í”„í•˜ê²Œ API ê°œë°œí•˜ê¸°: í¬ë§í¸ VS ì ˆë§í¸](https://www.youtube.com/watch?v=J4JHLESAiFk) by ìµœíƒœê±´ at [FEConf 2020](https://2020.feconf.kr/)\n- 2020-11-05 - [Automated REST-Api Code Generation: Wie IT-Systeme miteinander sprechen](https://www.massiveart.com/blog/automated-rest-api-code-generation-wie-it-systeme-miteinander-sprechen) by Stefan Rottensteiner at [MASSIVE ART Blog](https://www.massiveart.com/blog)\n- 2020-12-01 - [OpenAPI Generatorã§Goã®APIã‚µãƒ¼ãƒãƒ¼/ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚³ãƒ¼ãƒ‰ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹](https://qiita.com/saki-engineering/items/b20d8b6074c4da9664a5) by [@saki-engineering](https://qiita.com/saki-engineering)\n- 2020-12-04 - [Scaling the Test Coverage of OpenAPI Generator for 30+ Programming Languages](https://www.youtube.com/watch?v=7Lke9dHRqT0) by [William Cheng](https://github.com/wing328) at [Open Source Summit Japan + Automotive Linux Summit 2020](https://events.linuxfoundation.org/archive/2020/open-source-summit-japan/) ([Slides](https://speakerdeck.com/wing328/scaling-the-test-coverage-of-openapi-generator-for-30-plus-programming-languages))\n- 2020-12-09 - [ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«OpenAPI Generatorã§è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå‹ä»˜ãAPI Clientã‚’å°å…¥ã—ãŸè©±](https://qiita.com/yoshifujiT/items/905c18700ede23f40840) by [@yoshifujiT](https://github.com/yoshifujiT)\n- 2020-12-15 - [Next.js + NestJS + GraphQLã§å¤‰åŒ–ã«è¿½å¾“ã™ã‚‹ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã¸ ã€œ ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚¯ãƒ¼ãƒãƒ³ã®äº‹ä¾‹ç´¹ä»‹](https://techblog.yahoo.co.jp/entry/2020121530052952/) by [å°å€‰ é™¸](https://github.com/ogugu9) at [Yahoo! JAPAN Tech Blog](https://techblog.yahoo.co.jp/)\n- 2021-01-08 - [Hello, New API â€“ Part 1](https://www.nginx.com/blog/hello-new-api-part-1/) by [Jeremy Schulman](https://www.nginx.com/people/jeremy-schulman/) at [Major League Baseball](https://www.mlb.com)\n- 2021-01-18 - [ã€Œã‚¢ãƒ—ãƒªé–‹ç™ºã‚ã‚‹ã‚ã‚‹ã€ã‚’ç–‘ã†ã“ã¨ã‹ã‚‰å§‹ã¾ã£ãŸã€API Clientã‚³ãƒ¼ãƒ‰ã®è‡ªå‹•ç”Ÿæˆã€ãƒ‡ãƒ–ã‚¹ãƒˆ2020ã€‘](https://codezine.jp/article/detail/13406?p=2) by [CodeZineç·¨é›†éƒ¨](https://codezine.jp/author/1)\n- 2021-02-05 - [REST-API-Roundtrip with SpringDoc and OpenAPI Generator](https://blog.viadee.de/en/rest-api-roundtrip) by [Benjamin Klatt](https://twitter.com/benklatt) at [viadee](https://www.viadee.de/en/)\n- 2021-02-17 - [REST-API-Roundtrip with SpringDoc and OpenAPI Generator](https://medium.com/nerd-for-tech/rest-api-roundtrip-with-springdoc-and-openapi-generator-30bd27ccf698) by [cloud @viadee](https://cloud-viadee.medium.com/)\n- 2021-03-08 - [OpenAPI Generator å·¥å…·çš„èººå‘å°è¯•](https://blog.csdn.net/u013019701/article/details/114531975) by [ç‹¬å®¶é›¨å¤©](https://blog.csdn.net/u013019701) at [CSDNå®˜æ–¹åšå®¢](https://blog.csdn.net/)\n- 2021-03-16 - [å¦‚ä½•åŸºäº Swagger ä½¿ç”¨ OpenAPI Generator ç”Ÿæˆ JMeter è„šæœ¬ï¼Ÿ](https://cloud.tencent.com/developer/article/1802704) by [é«˜æ¥¼Zee](https://cloud.tencent.com/developer/user/5836255) at [è…¾è®¯äº‘ä¸“æ ](https://cloud.tencent.com/developer/column)\n- 2021-03-24 - [openapi-generator-cli ã«ã‚ˆã‚‹ TypeScript å‹å®šç¾©](https://zenn.dev/takepepe/articles/openapi-generator-cli-ts) by [Takefumi Yoshii](https://zenn.dev/takepepe)\n- 2021-03-28 - [Trying out NestJS part 4: Generate Typescript clients from OpenAPI documents](https://dev.to/arnaudcortisse/trying-out-nestjs-part-4-generate-typescript-clients-from-openapi-documents-28mk) by [Arnaud Cortisse](https://dev.to/arnaudcortisse)\n- 2021-03-31 - [Open API Server Implementation Using OpenAPI Generator](https://www.baeldung.com/java-openapi-generator-server) at [Baeldung](https://www.baeldung.com/)\n- 2021-03-31 - [ä½¿ç”¨OpenAPI Generatorå¯¦ç¾Open API Server](https://www.1ju.org/article/java-openapi-generator-server) at [å„„èšç¶²](https://www.1ju.org/)\n- 2021-04-19 - [Introducing Twilioâ€™s OpenAPI Specification Beta](https://www.twilio.com/blog/introducing-twilio-open-api-specification-beta) by [GARETH PAUL JONES](https://www.twilio.com/blog/author/gpj) at [Twilio Blog](https://www.twilio.com/blog)\n- 2021-04-22 - [Leveraging OpenApi strengths in a Micro-Service environment](https://medium.com/unibuddy-technology-blog/leveraging-openapi-strengths-in-a-micro-service-environment-3d7f9e7c26ff) by Nicolas Jellab at [Unibuddy Technology Blog](https://medium.com/unibuddy-technology-blog)\n- 2021-04-27 - [From zero to publishing PowerShell API clients in PowerShell Gallery within minutes](https://speakerdeck.com/wing328/from-zero-to-publishing-powershell-api-clients-in-powershell-gallery-within-minutes) by [William Cheng](https://github.com/wing328) at [PowerShell + DevOps Global Summit 2021](https://events.devopscollective.org/event/powershell-devops-global-summit-2021/)\n- 2021-05-31 - [Flutterã§Open Api Generator(Swagger)ã‚’ä½¿ã†](https://aakira.app/blog/2021/05/flutter-open-api/) by [AAkira](https://twitter.com/_a_akira)\n- 2021-06-22 - [Rest API Documentation and Client Generation With OpenAPI](https://dzone.com/articles/rest-api-documentation-and-client-generation-with) by [Prasanth Gullapalli](https://dzone.com/users/1011797/prasanthnath.g@gmail.com.html)\n- 2021-07-16 - [éŠ€è¡Œäº‹æ¥­ã®ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰é–‹ç™ºã«ã¤ã„ã¦ / LINE äº¬éƒ½é–‹ç™ºå®¤ ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢æ¡ç”¨èª¬æ˜ä¼š](https://www.youtube.com/watch?v=YrrKQHxLPpQ) by é‡ç”°èª äºº, Robert Mitchell\n- 2021-07-19 - [OpenAPI code generation with kotlin](https://sylhare.github.io/2021/07/19/Openapi-swagger-codegen-with-kotlin.html) by [sylhare](https://github.com/sylhare)\n- 2021-07-29 - [How To Rewrite a Huge Codebase](https://dzone.com/articles/how-to-rewrite-a-huge-code-base) by [Curtis Poe](https://dzone.com/users/4565446/publiusovidius.html)\n- 2021-08-21 - [Generating Client APIs using Swagger Part 1](https://medium.com/@flowsquad/generating-client-apis-using-swagger-part-1-2d46f13f5e92) by [FlowSquad.io](https://medium.com/@flowsquad)\n- 2021-09-11 - [Invoking AWS ParallelCluster API](https://docs.aws.amazon.com/parallelcluster/latest/ug/api-reference-v3.html) at [AWS ParallelCluster API official documentation](https://docs.aws.amazon.com/parallelcluster/latest/ug/api-reference-v3.html)\n- 2021-09-20 - [OpenAPI Generator - The Babel Fish of the API World](https://www.youtube.com/watch?v=s2zMtwd5klg) by [Cliffano Subagio (Principal Engineer at Shine Solutions)](https://github.com/cliffano) at [Apidays LIVE Australia 2021](https://www.apidays.global/australia2021/)\n- 2021-10-02 - [How to Write Fewer Lines of Code with the OpenAPI Generator](https://hackernoon.com/how-to-write-fewer-lines-of-code-with-the-openapi-generator) by [Mikhail Alfa](https://hackernoon.com/u/alphamikle)\n- 2021-10-12 - [OpenAPI Generator : 4000 Ã©toiles sur GitHub et des spaghettis](https://www.youtube.com/watch?v=9hEsNBSqTFk) by [JÃ©rÃ©mie Bresson](https://github.com/jmini) at [Devoxx FR 2021](https://cfp.devoxx.fr/2021/speaker/jeremie_bresson)\n- 2021-10-17 - [Generate a TypeScript HTTP Client From An OpenAPI Spec In DotNET 5](https://richardwillis.info/blog/generate-a-type-script-http-client-from-an-open-api-spec-in-dot-net-5) by [Richard Willis](https://github.com/badsyntax)\n- 2021-11-06 - [ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã®é–‹ç™ºã§æ„è­˜ã—ãŸã“ã¨](https://zenn.dev/woo_noo/articles/5cb09f8e2899ae782ad1) by [woo-noo](https://zenn.dev/woo_noo)\n- 2021-11-09 - [Effective Software Development using OpenAPI Generator](https://apexlabs.ai/post/effective-software-development-using-openapi-generator) by Ajil Oomme\n- 2021-12-07 - [An Introduction to OpenAPI](https://betterprogramming.pub/4-use-cases-of-openapi-which-are-good-to-know-1a041f4ad71e) by [Na'aman Hirschfeld](https://naamanhirschfeld.medium.com/)\n- 2022-01-02 - [Towards a secure API client generator for IoT devices](https://arxiv.org/abs/2201.00270) by Anders Aaen Springborg, Martin Kaldahl Andersen, Kaare Holland Hattel, Michele Albano\n- 2022-02-02 - [Use OpenApi generator to share your models between Flutter and your backend](https://www.youtube.com/watch?v=kPW7ccu9Yvk) by [Guillaume Bernos](https://feb2022.fluttervikings.com/speakers/guillaume_bernos) at [Flutter Vikings Conference 2022 (Hybrid)](https://feb2022.fluttervikings.com/)\n- 2022-03-15 - [OpenAPI Specã§ãƒã‚¤ãƒ•ãƒ³åŒºåˆ‡ã‚Šã®Enumå€¤ã‚’OpenAPI Generatorã§å‡ºåŠ›ã™ã‚‹ã¨ã€ãƒã‚¤ãƒ•ãƒ³åŒºåˆ‡ã‚Šã®ã¾ã¾å‡ºåŠ›ã•ã‚Œã‚‹](https://qiita.com/yuji38kwmt/items/824d74d4889055ab37d8) by [yuji38kwmt](https://qiita.com/yuji38kwmt)\n- 2022-04-01 - [OpenAPI Generatorã®ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã¨Spring Frameworkã®ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’å…±å­˜ã•ã›ã‚‹](https://techblog.zozo.com/entry/coexistence-of-openapi-and-spring) in [ZOZO Tech Blog](https://techblog.zozo.com/)\n- 2022-04-06 - [Effective Software Development using OpenAPI Generator](https://apexlabs.ai/post/openapi-generator) by Ajil Oommen (Senior Flutter Developer)\n- 2022-05-13 - [A Path From an API To Client Libraries](https://www.youtube.com/watch?v=XC8oVn_efTw) by [Filip Srnec](https://www.devoxx.co.uk/talk/?id=11211) at Infobip\n- 2022-06-01 - [API First, using OpenAPI and Spring Boot](https://medium.com/xgeeks/api-first-using-openapi-and-spring-boot-2602c04bb0d3) by [Micael EstrÃ¡zulas Vianna](https://estrazulas.medium.com/)\n- 2022-06-10 - [Autogenerating Clients with FastAPI and Github Actions](https://www.propelauth.com/post/autogenerating-clients-with-fastapi-and-github-actions) by [Andrew Israel](https://www.propelauth.com/author/andrew)\n- 2022-06-12 - [Mustache templates with OpenAPI specs](https://medium.com/geekculture/mustache-templates-with-openapi-specs-f24711c67dec) by [Beppe Catanese](https://github.com/gcatanese)\n- 2022-07-01 - [Generate API contract using OpenAPI Generator Maven plugin](https://huongdanjava.com/generate-api-contract-using-openapi-generator-maven-plugin.html) by [Khanh Nguyen](https://huongdanjava.com/)\n- 2022-07-22 - [ä½¿ç”¨OpenAPI Generator Maven pluginå¼€å‘apiä¼˜å…ˆçš„javaå®¢æˆ·ç«¯å’ŒæœåŠ¡ç«¯ä»£ç ](https://blog.roccoshi.top/2022/java/openapi-generator%E7%9A%84%E4%BD%BF%E7%94%A8/) by [Lincest](https://github.com/Lincest)\n- 2022-08-01 - [Tutorial: Etsy Open API v3 (ruby)](https://blog.tjoyal.dev/etsy-open-api-v3/) by [Thierry Joyal](https://github.com/tjoyal)\n- 2022-09-03 - [OpenAPI Generator For Go Web Development](https://blog.kevinhu.me/2022/09/03/03-openapi-generator/) by [Kevin Hu](https://twitter.com/Oldgunix)\n- 2022-10-01 - [OpenAPI Generatorã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆSwagger Codegenã¨ã»ã¼åŒã˜ï¼‰](https://nainaistar.hatenablog.com/entry/2022/10/03/120000) by [ãã‚Šä¸¸](https://twitter.com/nainaistar)\n- 2022-10-21 - [Kotlinï¼ˆSpring Bootï¼‰ã® API ã‚’ OpenAPI Generator ã§è‡ªå‹•ç”Ÿæˆ](https://zenn.dev/msksgm/articles/20221021-kotlin-spring-openapi-generator) by [msksgm](https://zenn.dev/msksgm)\n- 2022-10-26 - [Quarkus Insights #106: Quarkiverse Extension Spotlight: OpenApi Generator](https://www.youtube.com/watch?v=_s_if69t2iQ) by [Quarkusio](https://www.youtube.com/c/Quarkusio)\n- 2022-11-28 - [The REST API implementation flow](https://tmsvr.com/openapi-code-generation-for-rest-apis/) by [Imre TÃ¶mÃ¶svÃ¡ri](https://tmsvr.com/author/imre/)\n- 2022-12-13 - [API-First with Spring WebFlux and OpenAPI Generator](https://boottechnologies-ci.medium.com/api-first-with-spring-webflux-and-openapi-generator-38b7804c4ed4) by [Eric Anicet](https://boottechnologies-ci.medium.com/)\n- 2023-01-06 - [Major Improvements with Helidon and OpenAPI](https://medium.com/helidon/major-improvements-with-helidon-and-openapi-f76a0951508e) by [Tim Quinn](https://medium.com/@tquinno600)\n- 2023-02-02 - [Replacing Postman with the Jetbrains HTTP Client](https://lengrand.fr/replacing-postman-in-seconds-with-the-jetbrains-http-client/) by [julien Lengrand-Lambert](https://github.com/jlengrand)\n- 2023-03-15 - [OpenAPI Generatorã«é©ã—ãŸOpenAPIã®æ›¸ãæ–¹](https://techblog.zozo.com/entry/how-to-write-openapi-for-openapi-generator) by [ZOZO Tech Blog](https://techblog.zozo.com/)\n- 2023-03-19 - [EXOGEM: Extending OpenAPI Generator for Monitoring of RESTful APIs](https://link.springer.com/chapter/10.1007/978-3-031-26507-5_10) by Daniel Friis Holtebo, Jannik Lucas Sommer, Magnus MÃ¸lgaard Lund, Alessandro Tibo, Junior Dongo & Michele Albano at \"ICSOC 2022: Service-Oriented Computing â€“ ICSOC 2022 Workshops\"\n- 2023-03-28 - [API-First Design with OpenAPI Generator](https://www.linkedin.com/pulse/api-first-design-openapi-generator-jonathan-manera/) by [Jonathan Manera](https://www.linkedin.com/in/manerajona/)\n- 2023-03-28 - [ãƒãƒ³ã‚ºã‚ªãƒ³ã§å­¦ã¶ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ Kotlinï¼ˆSpring Boot&Arrow&OpenAPI Generatorï¼‰v1.0.1](https://zenn.dev/msksgm/books/implementing-server-side-kotlin-development) by [msk](https://zenn.dev/msksgm)\n- 2023-04-01 - [OpenAPI Client Code Generation](https://testingboss.com/blog/openapi-client-generation/) by Kwo Ding\n- 2023-04-27 - [Create an Angular Client using OpenAPI Specifications](Create an Angular Client using OpenAPI Specifications) by [Patric](https://pguso.medium.com/)\n- 2023-05-16 - [Adyen for Java developers](https://www.adyen.com/blog/adyen-java-library) by [Beppe Catanese, Developer Advocate, Adyen](https://github.com/gcatanese)\n- 2023-05-18 - [å¦‚ä½•åŸºäº Swagger ä½¿ç”¨ OpenAPI Generator ç”Ÿæˆ JMeter è„šæœ¬ï¼Ÿ](https://blog.51cto.com/u_15181572/6294974) by [é«˜æ¥¼ï¼ˆZee)](https://blog.51cto.com/u_15181572)\n- 2023-06-28 - [Generate API contract using OpenAPI Generator Maven plugin](https://huongdanjava.com/generate-api-contract-using-openapi-generator-maven-plugin.html) by [Khanh Nguyen](https://huongdanjava.com/)\n- 2023-06-30 - [Generate Client SDKs with OpenApi Generator in Springboot](https://medium.com/@ramavathvinayak/generate-client-sdks-with-openapi-generator-in-springboot-f9f012e73c0b) by [Vinayak Ramavath](https://medium.com/@ramavathvinayak)\n- 2023-12-10 - [Unityã§OpenAPI Generatorã‚’ä½¿ã†](https://www.youtube.com/watch?v=CbNwKVV5LRM) by [Soup Tori](https://www.youtube.com/@souptori8417)\n- 2024-01-24 - [Comment gÃ©nÃ©rer des stubs wiremock avec openapi generator](https://www.youtube.com/watch?v=0jhONfBrcKw) by [Alexis Couvreur](https://github.com/acouvreur)\n- 2024-03-04 - [Generating TypeScript Types with OpenAPI for REST API Consumption](https://www.pullrequest.com/blog/generating-typescript-types-with-openapi-for-rest-api-consumption/) by [PullRequest](https://www.pullrequest.com/)\n- 2024-03-07 - [Fully typed Web Apps with OpenAPI (Part 1)](https://medium.com/@gfox1984/fully-typed-web-apps-with-openapi-part-1-595d55766670) by [Guillaume Renard](https://medium.com/@gfox1984)\n- 2024-03-08 - [Laravel OpenAPIã«ã‚ˆã‚‹ \"è¾›ããªã„\" ã‚¹ã‚­ãƒ¼ãƒé§†å‹•é–‹ç™º](https://fortee.jp/phperkaigi-2024/proposal/9e2e6c38-d078-4efa-99b4-83ebf9033b34) by [KentarouTakeda](https://twitter.com/KentarouTakeda)\n- 2024-04-04 - [Working with OpenAPI using Rust](https://www.shuttle.dev/blog/2024/04/04/using-openapi-rust) by [Joshua Mo](https://twitter.com/joshmo_dev)\n- 2024-04-08 - [Implement API first strategy with OpenAPI generator plugin](https://medium.com/javarevisited/implement-api-first-strategy-with-openapi-generator-plugin-e4bbe7f0d778) by [Rui Zhou](https://medium.com/@wirelesser)\n- 2024-05-06 - [OpenAPI Generator Custom Templates](https://www.javacodegeeks.com/openapi-generator-custom-templates.html) by [Mary Zheng](https://www.javacodegeeks.com/author/mary-zheng)\n- 2025-02-09 - [Custom validation with OpenApiGenerator and Spring Boot 3](https://medium.com/@jugurtha.aitoufella/custom-validation-with-openapigenerator-and-spring-boot-3-34a656e815c8) by [Jugurtha Aitoufella](https://medium.com/@jugurtha.aitoufella)\n- 2025-02-20 - [Optimizing API Integration in a Large React Application Using OpenAPI Generator](https://www.youtube.com/watch?v=-B33pQnGQUI) by Stefano Marzo\n\n\n## [6 - About Us](#table-of-contents)\n\nWhat's the design philosophy or principle behind OpenAPI Generator?\n\nWe focus on developer experience. The generators should produce code, config, documentation, and more that are easily understandable and consumable by users. We focused on simple use cases to start with (bottom-up approach). Since then the project and the community have grown a lot: 600k weekly downloads via NPM CLI wrapper, 30M downloads via openapi-generator-cli docker image just to highlight a few. We've gradually supported more features (e.g. oneOf, anyOf introduced in OpenAPI 3.0) in various generators and we will continue this approach to deliver something based on our understanding of user demand and what they want, and continue to add support of new features introduced in OpenAPI specification (such as v3.1 and future versions of the OpenAPI specification).\n\n### [6.1 - OpenAPI Generator Core Team](#table-of-contents)\n\nOpenAPI Generator core team members are contributors who have been making significant contributions (review issues, fix bugs, make enhancements, etc) to the project on a regular basis.\n\n#### Core Team Members\n* [@wing328](https://github.com/wing328) (2015/07) [:heart:](https://www.patreon.com/wing328)\n* [@jimschubert](https://github.com/jimschubert) (2016/05) [:heart:](https://www.patreon.com/jimschubert)\n* [@cbornet](https://github.com/cbornet) (2016/05)\n* [@jmini](https://github.com/jmini) (2018/04)  [:heart:](https://www.patreon.com/jmini)\n* [@etherealjoy](https://github.com/etherealjoy) (2019/06)\n\n:heart: = Link to support the contributor directly\n\n#### Template Creator\n\n**NOTE**: Embedded templates are only supported in _Mustache_ format. Support for all other formats is experimental and subject to change at any time.\n\nHere is a list of template creators:\n * API Clients:\n   * Ada: @stcarrez\n   * Apex: @asnelling\n   * Bash: @bkryza\n   * C: @PowerOfCreation @zhemant [:heart:](https://www.patreon.com/zhemant)\n   * C++ Oat++: @Kraust\n   * C++ REST: @Danielku15\n   * C++ Tiny: @AndersSpringborg @kaareHH @michelealbano @mkakbas\n   * C++ UE4: @Kahncode\n   * C# (.NET 2.0): @who\n   * C# (.NET Standard 1.3 ): @Gronsak\n   * C# (.NET 4.5 refactored): @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * C# (GenericHost): @devhl-labs\n   * C# (HttpClient): @Blackclaws\n   * Clojure: @xhh\n   * Crystal: @wing328\n   * Dart: @yissachar\n   * Dart (refactor): @joernahrens\n   * Dart 2: @swipesight\n   * Dart (Jaguar): @jaumard\n   * Dart (Dio): @josh-burton\n   * Elixir: @niku\n   * Elm: @eriktim\n   * Eiffel: @jvelilla\n   * Erlang: @tsloughter\n   * Erlang (PropEr): @jfacorro @robertoaloi\n   * Groovy: @victorgit\n   * Go: @wing328 [:heart:](https://www.patreon.com/wing328)\n   * Go (rewritten in 2.3.0): @antihax\n   * Godot (GDScript): @Goutte [:heart:](https://liberapay.com/Goutte)\n   * Haskell (http-client): @jonschoning\n   * Java (Feign): @davidkiss\n   * Java (Retrofit): @0legg\n   * Java (Retrofit2): @emilianobonassi\n   * Java (Jersey2): @xhh\n   * Java (okhttp-gson): @xhh\n   * Java (RestTemplate): @nbruno\n   * Java (Spring 5 WebClient): @daonomic\n   * Java (Spring 6 RestClient): @nicklas2751\n   * Java (RESTEasy): @gayathrigs\n   * Java (Vertx): @lopesmcc\n   * Java (Google APIs Client Library): @charlescapps\n   * Java (Rest-assured): @viclovsky\n   * Java (Java 11 Native HTTP client): @bbdouglas\n   * Java (Apache HttpClient 5.x): @harrywhite4 @andrevegas\n   * Java (Helidon): @spericas @tjquinno @tvallin\n   * Javascript/NodeJS: @jfiala\n   * JavaScript (Apollo DataSource): @erithmetic\n   * JavaScript (Closure-annotated Angular) @achew22\n   * JavaScript (Flow types) @jaypea\n   * Jetbrains HTTP Client : @jlengrand\n   * JMeter: @davidkiss\n   * Julia: @tanmaykm\n   * Kotlin: @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * Kotlin (MultiPlatform): @andrewemery\n   * Kotlin (Volley): @alisters\n   * Kotlin (jvm-spring-webclient): @stefankoppier\n   * Kotlin (jvm-spring-restclient): @stefankoppier\n   * Lua: @daurnimator\n   * N4JS: @mmews-n4\n   * Nim: @hokamoto\n   * OCaml: @cgensoul\n   * Perl: @wing328 [:heart:](https://www.patreon.com/wing328)\n   * PHP (Guzzle): @baartosz\n   * PHP (with Data Transfer): @Articus\n   * PowerShell: @beatcracker\n   * PowerShell (refactored in 5.0.0): @wing328\n   * Python: @spacether [:heart:][spacether sponsorship]\n   * Python-Experimental: @spacether [:heart:][spacether sponsorship]\n   * Python (refactored in 7.0.0): @wing328\n   * R: @ramnov\n   * Ruby (Faraday): @meganemura @dkliban\n   * Ruby (HTTPX): @honeyryderchuck\n   * Rust: @farcaller\n   * Rust (rust-server): @metaswitch\n   * Scala (scalaz & http4s): @tbrown1979\n   * Scala (Akka): @cchafer\n   * Scala (sttp): @chameleon82\n   * Scala (sttp4): @flsh86\n   * Scala (scala-sttp4-jsoniter): @lbialy\n   * Scala (Pekko): @mickaelmagniez\n   * Scala (http4s): @JennyLeahy\n   * Swift: @tkqubo\n   * Swift 3: @hexelon\n   * Swift 4: @ehyche\n   * Swift 5: @4brunu\n   * Swift 6: @4brunu\n   * Swift Combine: @dydus0x14\n   * TypeScript (Angular1): @mhardorf\n   * TypeScript (Angular2): @roni-frantchi\n   * TypeScript (Angular6): @akehir\n   * TypeScript (Angular7): @topce\n   * TypeScript (Axios): @nicokoenig\n   * TypeScript (Fetch): @leonyu\n   * TypeScript (Inversify): @gualtierim\n   * TypeScript (jQuery): @bherila\n   * TypeScript (Nestjs): @vfrank66\n   * TypeScript (Node):  @mhardorf\n   * TypeScript (Rxjs): @denyo\n   * TypeScript (redux-query): @petejohansonxo\n   * Xojo: @Topheee\n   * Zapier: @valmoz, @emajo\n * Server Stubs\n   * Ada: @stcarrez\n   * C# ASP.NET 5: @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * C# ASP.NET Core 3.0: @A-Joshi\n   * C# APS.NET Core 3.1: @phatcher\n   * C# Azure functions: @Abrhm7786\n   * C# NancyFX: @mstefaniuk\n   * C++ (Qt5 QHttpEngine): @etherealjoy\n   * C++ Oat++: @Kraust\n   * C++ Pistache: @sebymiano\n   * C++ Restbed: @stkrwork\n   * Erlang Server: @galaxie @nelsonvides\n   * F# (Giraffe) Server: @nmfisher\n   * Go Server: @guohuang\n   * Go Server (refactored in 7.0.0): @lwj5\n   * Go (Echo) Server: @ph4r5h4d\n   * Go (Gin) Server: @kemokemo\n   * GraphQL Express Server: @renepardon\n   * Haskell Servant: @algas\n   * Haskell Yesod: @yotsuya\n   * Java Camel: @carnevalegiacomo\n   * Java Dubbo: @redoom\n   * Java MSF4J: @sanjeewa-malalgoda\n   * Java Spring Boot: @diyfr\n   * Java Undertow: @stevehu\n   * Java Play Framework: @JFCote\n   * Java PKMST: @anshu2185 @sanshuman @rkumar-pk @ninodpillai\n   * Java Vert.x: @lwlee2608\n   * Java Micronaut: @andriy-dmytruk\n   * Java Helidon: @spericas @tjquinno @tvallin\n   * Java WireMock: [@acouvreur](https://github.com/acouvreur)\n   * JAX-RS RestEasy: @chameleon82\n   * JAX-RS CXF: @hiveship\n   * JAX-RS CXF (CDI): @nickcmaynard\n   * JAX-RS RestEasy (JBoss EAP): @jfiala\n   * Julia: @tanmaykm\n   * Kotlin: @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * Kotlin (Spring Boot): @dr4ke616\n   * Kotlin (Vertx): @Wooyme\n   * Kotlin (JAX-RS): @anttileppa\n   * Kotlin Misk: @andrewwilsonnew @guiarn\n   * Kotlin WireMock: @stefankoppier\n   * NodeJS Express: @YishTish\n   * PHP Flight: @daniel-sc\n   * PHP Laravel: @renepardon\n   * PHP Laravel (refactor in 7.12.0): @gijs-blanken\n   * PHP Lumen: @abcsun\n   * PHP Mezzio (with Path Handler): @Articus\n   * PHP Slim: @jfastnacht\n   * PHP Slim4: [@ybelenko](https://github.com/ybelenko)\n   * PHP Symfony: @ksm2\n   * PHP Symfony6: @BenjaminHae\n   * Python FastAPI: @krjakbrjak\n   * Python AIOHTTP:\n   * Ruby on Rails 5: @zlx\n   * Rust (rust-server): @metaswitch\n   * Rust (rust-axum): @linxGnu\n   * Scala Akka: @Bouillie\n   * Scala Cask: @aaronp\n   * Scala Finch: @jimschubert [:heart:](https://www.patreon.com/jimschubert)\n   * Scala Lagom: @gmkumar2005\n   * Scala Play: @adigerber\n   * TypeScript NestJS: @aryobenholzner\n * Documentation\n   * AsciiDoc: @man-at-home\n   * HTML Doc 2: @jhitchcock\n   * Confluence Wiki: @jhitchcock\n   * PlantUML: @pburls\n * Configuration\n   * Apache2: @stkrwork\n   * k6: @mostafa\n * Schema\n   * Avro: @sgadouar\n   * GraphQL: @wing328 [:heart:](https://www.patreon.com/wing328)\n   * Ktorm: @Luiz-Monad\n   * MySQL: [@ybelenko](https://github.com/ybelenko)\n   * PostgreSQL: [@iri](https://github.com/iri)\n   * Postman Collection: @gcatanese\n   * Protocol Buffer: @wing328\n   * WSDL: @adessoDpd\n\n:heart: = Link to support the contributor directly\n\n#### How to join the core team\n\nHere are the requirements to become a core team member:\n- rank within top 50 in https://github.com/openapitools/openapi-generator/graphs/contributors\n  - to contribute, here are some good [starting points](https://github.com/openapitools/openapi-generator/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)\n- regular contributions to the project\n  - about 3 hours per week\n  - for contribution, it can be addressing issues, reviewing PRs submitted by others, submitting PR to fix bugs or make enhancements, etc\n  - must be active in the past 3 months at the time of application\n\n To join the core team, please reach out to team@openapitools.org for more information.\n\n To become a Template Creator, simply submit a PR for new API client (e.g. Rust, Elixir) or server stub (e.g. Ruby Grape) generator.\n\n### [6.2 - OpenAPI Generator Technical Committee](#table-of-contents)\n\nMembers of the OpenAPI Generator technical committee shoulder the following responsibilities:\n\n- Provides guidance and direction to other users\n- Reviews pull requests and issues\n- Improves the generator by making enhancements, fixing bugs or updating documentations\n- Sets the technical direction of the generator\n\nWho is eligible? Those who want to join must have at least 3 PRs merged into a generator. (Exceptions can be granted to template creators or contributors who have made a lot of code changes with less than 3 merged PRs)\n\nIf you want to join the committee, please kindly apply by sending an email to team@openapitools.org with your Github ID.\n\n#### Members of Technical Committee\n\n| Languages/Generators  | Member (join date)                                                                                                                                                                                                                                    |\n|:----------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| ActionScript          |                                                                                                                                                                                                                                                       |\n| Ada                   | @stcarrez (2018/02) @michelealbano (2018/02)                                                                                                                                                                                                          |\n| Android               | @jaz-ah (2017/09)                                                                                                                                                                                                                                     |\n| Apex                  |                                                                                                                                                                                                                                                       |\n| Bash                  | @frol (2017/07) @bkryza (2017/08) @kenjones-cisco (2017/09)                                                                                                                                                                                           |\n| C                     | @zhemant (2018/11) @ityuhui (2019/12) @michelealbano (2020/03) @eafer (2024/12)                                                                                                                                                                                        |\n| C++                   | @ravinikam (2017/07) @stkrwork (2017/07) @etherealjoy (2018/02) @martindelille (2018/03) @muttleyxd (2019/08) @aminya (2025/05)                                                                                                                                         |\n| C#                    | @mandrean (2017/08) @shibayan (2020/02) @Blackclaws (2021/03) @lucamazzanti (2021/05) @iBicha (2023/07)                                                                                                                                          |\n| Clojure               |                                                                                                                                                                                                                                                       |\n| Crystal               | @cyangle (2021/01)                                                                                                                                                                                                                                    |\n| Dart                  | @jaumard (2018/09) @josh-burton (2019/12) @amondnet (2019/12) @sbu-WBT (2020/12) @kuhnroyal (2020/12) @agilob (2020/12) @ahmednfwela (2021/08)                                                                                                        |\n| Eiffel                | @jvelilla (2017/09)                                                                                                                                                                                                                                   |\n| Elixir                | @mrmstn (2018/12)                                                                                                                                                                                                                                     |\n| Elm                   | @eriktim (2018/09)                                                                                                                                                                                                                                    |\n| Erlang                | @tsloughter (2017/11) @jfacorro (2018/10) @robertoaloi (2018/10) @nelsonvides (2024/09)                                                                                                                                                               |\n| F#                    | @nmfisher (2019/05)                                                                                                                                                                                                                                   |\n| Go                    | @antihax (2017/11) @grokify (2018/07) @kemokemo (2018/09) @jirikuncar (2021/01) @ph4r5h4d (2021/04) @lwj5 (2023/04)                                                                                                                                                   |\n| GraphQL               | @renepardon (2018/12)                                                                                                                                                                                                                                 |\n| Groovy                |                                                                                                                                                                                                                                                       |\n| Haskell               |                                                                                                                                                                                                                                                       |\n| Java                  | @bbdouglas (2017/07) @sreeshas (2017/08) @jfiala (2017/08) @lukoyanov (2017/09) @cbornet (2017/09) @jeff9finger (2018/01) @karismann (2019/03) @Zomzog (2019/04) @lwlee2608 (2019/10) @martin-mfg (2023/08)                                                                 |\n| Java Spring           | @cachescrubber (2022/02) @welshm (2022/02) @MelleD (2022/02) @atextor (2022/02) @manedev79 (2022/02) @javisst (2022/02) @borsch (2022/02) @banlevente (2022/02) @Zomzog (2022/09) @martin-mfg (2023/08)                                                                     |\n| JMeter                | @kannkyo (2021/01)                                                                                                                                                                                                                                    |\n| Jetbrains HTTP Client | @jlengrand (2023/01)                                                                                                                                                                                                                                  |\n| Julia                 | @tanmaykm (2023/01)                                                                                                                                                                                                                                   |\n| Kotlin                | @karismann (2019/03) @Zomzog (2019/04) @andrewemery (2019/10) @4brunu (2019/11) @yutaka0m (2020/03) @stefankoppier (2022/06) @e5l (2024/10)                                          |\n| Lua                   | @daurnimator (2017/08)                                                                                                                                                                                                                                |\n| N4JS                  | @mmews-n4 (2023/03)                                                                                                                                                                                      |\n| Nim                   |                                                                                                                                                                                                                                                       |\n| NodeJS/Javascript     | @CodeNinjai (2017/07) @frol (2017/07) @cliffano (2017/07)                                                                                                                                                                                             |\n| ObjC                  |                                                                                                                                                                                                                                                       |\n| OCaml                 | @cgensoul (2019/08), @sir4ur0n (2025/08)                                                                                                                                                                                                              |\n| Perl                  | @wing328 (2017/07) [:heart:](https://www.patreon.com/wing328) @yue9944882 (2019/06)                                                                                                                                                                   |\n| PHP                   | @jebentier (2017/07), @dkarlovi (2017/07), @mandrean (2017/08), @jfastnacht (2017/09), [@ybelenko](https://github.com/ybelenko) (2018/07), @renepardon (2018/12)                                                                                      |\n| PowerShell            | @wing328 (2020/05)                                                                                                                                                                                                                                    |\n| Python                | @cbornet (2017/09) @tomplus (2018/10) @krjakbrjak (2023/02) @fa0311 (2023/10) @multani (2023/10) |\n| R                     | @Ramanth (2019/07) @saigiridhar21 (2019/07)                                                                                                                                                                                                           |\n| Ruby                  | @cliffano (2017/07) @zlx (2017/09) @autopp (2019/02)                                                                                                                                                                                                  |\n| Rust                  | @frol (2017/07) @farcaller (2017/08) @richardwhiuk (2019/07) @paladinzh (2020/05) @jacob-pro (2022/10) @dsteeley (2025/07)                                                                                                                                               |\n| Scala                 | @clasnake (2017/07), @shijinkui  (2018/01), @ramzimaalej (2018/03), @chameleon82 (2020/03), @Bouillie (2020/04) @fish86 (2023/06)                                                               |\n| Swift                 | @jgavris (2017/07) @ehyche (2017/08) @Edubits (2017/09) @jaz-ah (2017/09) @4brunu (2019/11) @dydus0x14 (2023/06)                                                                                                                                                           |\n| TypeScript            | @TiFu (2017/07) @taxpon (2017/07) @sebastianhaas (2017/07) @kenisteward (2017/07) @Vrolijkx (2017/09) @macjohnny (2018/01) @topce (2018/10) @akehir (2019/07) @petejohansonxo (2019/11) @amakhrov (2020/02) @davidgamero (2022/03) @mkusaka (2022/04) @joscha (2024/10)    |\n| Xojo                  | @Topheee (2023/04)                                                                                                                                                                                                                                    |\n\n\nPast Members of Technical Committee:\n| Languages/Generators         | Member (join date)                                                                                                                                                                                                                |\n| :---------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Python            | @taxpon (2017/07) @frol (2017/07) @mbohlool (2017/07) @cbornet (2017/09) @kenjones-cisco (2017/11) @tomplus (2018/10) @arun-nalla (2019/11)  |\n\n\n:heart: = Link to support the contributor directly\n\n### [6.3 - History of OpenAPI Generator](#table-of-contents)\n\nOpenAPI Generator is a fork of [Swagger Codegen](https://github.com/swagger-api/swagger-codegen). In view of the issues with the Swagger Codegen 3.0.0 (beta) release and the disagreement on the project's direction, more than 40 top contributors and template creators of Swagger Codegen decided to fork Swagger Codegen and maintain a community-driven version called \"OpenAPI Generator\". Please refer to the [Q&A](docs/qna.md) for more information.\n\n#### Founding Members (alphabetical order):\n\n- [Akihito Nakano](https://github.com/ackintosh)\n- [Artem Ocheredko](https://github.com/galaxie)\n- [Arthur Mogliev](https://github.com/Articus)\n- [Bartek Kryza](https://github.com/bkryza)\n- [Ben Wells](https://github.com/bvwells)\n- [Benjamin Gill](https://github.com/bjgill)\n- [Christophe Bornet](https://github.com/cbornet)\n- [Cliffano Subagio](https://github.com/cliffano)\n- [Daiki Matsudate](https://github.com/d-date)\n- [Daniel](https://github.com/Danielku15)\n- [Emiliano Bonassi](https://github.com/emilianobonassi)\n- [Erik Timmers](https://github.com/eriktim)\n- [Esteban Gehring](https://github.com/macjohnny)\n- [Gustavo Paz](https://github.com/gustavoapaz)\n- [Javier Velilla](https://github.com/jvelilla)\n- [Jean-FranÃ§ois CÃ´tÃ©](https://github.com/JFCote)\n- [Jim Schubert](https://github.com/jimschubert)\n- [Jon Schoning](https://github.com/jonschoning)\n- [JÃ©rÃ©mie Bresson](https://github.com/jmini) [:heart:](https://www.patreon.com/jmini)\n- [JÃ¶rn Ahrens](https://github.com/jayearn)\n- [Keni Steward](https://github.com/kenisteward)\n- [Marcin Stefaniuk](https://github.com/mstefaniuk)\n- [Martin Delille](https://github.com/MartinDelille)\n- [Masahiro Yamauchi](https://github.com/algas)\n- [Michele Albano](https://github.com/michelealbano)\n- [Ramzi Maalej](https://github.com/ramzimaalej)\n- [Ravindra Nikam](https://github.com/ravinikam)\n- [Ricardo Cardona](https://github.com/ricardona)\n- [Sebastian Haas](https://github.com/sebastianhaas)\n- [Sebastian Mandrean](https://github.com/mandrean)\n- [Sreenidhi Sreesha](https://github.com/sreeshas)\n- [Stefan Krismann](https://github.com/stkrwork)\n- [Stephane Carrez](https://github.com/stcarrez)\n- [Takuro Wada](https://github.com/taxpon)\n- [Tomasz Prus](https://github.com/tomplus)\n- [Tristan Sloughter](https://github.com/tsloughter)\n- [Victor Orlovsky](https://github.com/viclovsky)\n- [Victor Trakhtenberg](https://github.com/victorgit)\n- [Vlad Frolov](https://github.com/frol)\n- [Vladimir Pouzanov](https://github.com/farcaller)\n- [William Cheng](https://github.com/wing328)\n- [Xin Meng](https://github.com/xmeng1) [:heart:](https://www.patreon.com/user/overview?u=16435385)\n- [Xu Hui Hui](https://github.com/xhh)\n- [antihax](https://github.com/antihax)\n- [beatcracker](https://github.com/beatcracker)\n- [daurnimator](https:/github.com/daurnimator)\n- [etherealjoy](https://github.com/etherealjoy)\n- [jfiala](https://github.com/jfiala)\n- [lukoyanov](https://github.com/lukoyanov)\n\n:heart: = Link to support the contributor directly\n\n## [7 - License](#table-of-contents)\n-------\n\nCopyright 2018 OpenAPI-Generator Contributors (https://openapi-generator.tech)\nCopyright 2018 SmartBear Software\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at [apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n---\n",
      "stars_today": 12
    },
    {
      "id": 10270722,
      "name": "go-github",
      "full_name": "google/go-github",
      "description": "Go library for accessing the GitHub v3 API",
      "html_url": "https://github.com/google/go-github",
      "stars": 11095,
      "forks": 2207,
      "language": "Go",
      "topics": [
        "github",
        "github-api",
        "go",
        "golang",
        "hacktoberfest"
      ],
      "created_at": "2013-05-24T16:42:58Z",
      "updated_at": "2026-01-25T01:31:37Z",
      "pushed_at": "2026-01-24T16:09:48Z",
      "open_issues": 59,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# go-github #\n\n[![go-github release (latest SemVer)](https://img.shields.io/github/v/release/google/go-github?sort=semver)](https://github.com/google/go-github/releases)\n[![Go Reference](https://img.shields.io/static/v1?label=godoc&message=reference&color=blue)](https://pkg.go.dev/github.com/google/go-github/v81/github)\n[![Test Status](https://github.com/google/go-github/actions/workflows/tests.yml/badge.svg?branch=master)](https://github.com/google/go-github/actions/workflows/tests.yml)\n[![Test Coverage](https://codecov.io/gh/google/go-github/branch/master/graph/badge.svg)](https://codecov.io/gh/google/go-github)\n[![Discuss at go-github@googlegroups.com](https://img.shields.io/badge/discuss-go--github%40googlegroups.com-blue.svg)](https://groups.google.com/group/go-github)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/796/badge)](https://bestpractices.coreinfrastructure.org/projects/796)\n\ngo-github is a Go client library for accessing the [GitHub API v3][].\n\ngo-github tracks [Go's version support policy][support-policy] supporting any\nminor version of the latest two major releases of Go and the go directive in\ngo.mod reflects that.\nWe do our best not to break older versions of Go if we don't have to, but we\ndon't explicitly test older versions and as of Go 1.23 the go directive in\ngo.mod declares a hard required _minimum_ version of Go to use with this module\nand this _must_ be greater than or equal to the go line of all dependencies so\ngo-github will require the N-1 major release of Go by default.\n\n[support-policy]: https://golang.org/doc/devel/release.html#policy\n\n## Development\n\nIf you're interested in using the [GraphQL API v4][], the recommended library is\n[shurcooL/githubv4][].\n\n## Installation ##\n\ngo-github is compatible with modern Go releases in module mode, with Go installed:\n\n```bash\ngo get github.com/google/go-github/v81\n```\n\nwill resolve and add the package to the current development module, along with its dependencies.\n\nAlternatively the same can be achieved if you use import in a package:\n\n```go\nimport \"github.com/google/go-github/v81/github\"\n```\n\nand run `go get` without parameters.\n\nFinally, to use the top-of-trunk version of this repo, use the following command:\n\n```bash\ngo get github.com/google/go-github/v81@master\n```\n\n## Usage ##\n\n```go\nimport \"github.com/google/go-github/v81/github\"\t// with go modules enabled (GO111MODULE=on or outside GOPATH)\nimport \"github.com/google/go-github/github\" // with go modules disabled\n```\n\nConstruct a new GitHub client, then use the various services on the client to\naccess different parts of the GitHub API. For example:\n\n```go\nclient := github.NewClient(nil)\n\n// list all organizations for user \"willnorris\"\norgs, _, err := client.Organizations.List(context.Background(), \"willnorris\", nil)\n```\n\nSome API methods have optional parameters that can be passed. For example:\n\n```go\nclient := github.NewClient(nil)\n\n// list public repositories for org \"github\"\nopt := &github.RepositoryListByOrgOptions{Type: \"public\"}\nrepos, _, err := client.Repositories.ListByOrg(context.Background(), \"github\", opt)\n```\n\nThe services of a client divide the API into logical chunks and correspond to\nthe structure of the [GitHub API documentation](https://docs.github.com/en/rest).\n\nNOTE: Using the [context](https://pkg.go.dev/context) package, one can easily\npass cancellation signals and deadlines to various services of the client for\nhandling a request. In case there is no context available, then `context.Background()`\ncan be used as a starting point.\n\nFor more sample code snippets, head over to the\n[example](https://github.com/google/go-github/tree/master/example) directory.\n\n### Authentication ###\n\nUse the `WithAuthToken` method to configure your client to authenticate using an\nOAuth token (for example, a [personal access token][]). This is what is needed\nfor a majority of use cases aside from GitHub Apps.\n\n```go\nclient := github.NewClient(nil).WithAuthToken(\"... your access token ...\")\n```\n\nNote that when using an authenticated Client, all calls made by the client will\ninclude the specified OAuth token. Therefore, authenticated clients should\nalmost never be shared between different users.\n\nFor API methods that require HTTP Basic Authentication, use the\n[`BasicAuthTransport`](https://pkg.go.dev/github.com/google/go-github/v81/github#BasicAuthTransport).\n\n#### As a GitHub App ####\n\nGitHub Apps authentication can be provided by different pkgs like [bradleyfalzon/ghinstallation](https://github.com/bradleyfalzon/ghinstallation)\nor [jferrl/go-githubauth](https://github.com/jferrl/go-githubauth).\n\n> **Note**: Most endpoints (ex. [`GET /rate_limit`]) require access token authentication\n> while a few others (ex. [`GET /app/hook/deliveries`]) require [JWT] authentication.\n\n[`GET /rate_limit`]: https://docs.github.com/en/rest/rate-limit#get-rate-limit-status-for-the-authenticated-user\n[`GET /app/hook/deliveries`]: https://docs.github.com/en/rest/apps/webhooks#list-deliveries-for-an-app-webhook\n[JWT]: https://docs.github.com/en/developers/apps/building-github-apps/authenticating-with-github-apps#authenticating-as-a-github-app\n\n`ghinstallation` provides `Transport`, which implements `http.RoundTripper` to provide authentication as an installation for GitHub Apps.\n\nHere is an example of how to authenticate as a GitHub App using the `ghinstallation` package:\n\n```go\nimport (\n\t\"net/http\"\n\n\t\"github.com/bradleyfalzon/ghinstallation/v2\"\n\t\"github.com/google/go-github/v81/github\"\n)\n\nfunc main() {\n\t// Wrap the shared transport for use with the integration ID 1 authenticating with installation ID 99.\n\titr, err := ghinstallation.NewKeyFromFile(http.DefaultTransport, 1, 99, \"2016-10-19.private-key.pem\")\n\n\t// Or for endpoints that require JWT authentication\n\t// itr, err := ghinstallation.NewAppsTransportKeyFromFile(http.DefaultTransport, 1, \"2016-10-19.private-key.pem\")\n\n\tif err != nil {\n\t\t// Handle error.\n\t}\n\n\t// Use installation transport with client.\n\tclient := github.NewClient(&http.Client{Transport: itr})\n\n\t// Use client...\n}\n```\n\n`go-githubauth` implements a set of `oauth2.TokenSource` to be used with `oauth2.Client`. An `oauth2.Client` can be injected into the `github.Client` to authenticate requests.\n\nOther example using `go-githubauth`:\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"strconv\"\n\n\t\"github.com/google/go-github/v81/github\"\n\t\"github.com/jferrl/go-githubauth\"\n\t\"golang.org/x/oauth2\"\n)\n\nfunc main() {\n\tprivateKey := []byte(os.Getenv(\"GITHUB_APP_PRIVATE_KEY\"))\n\n\tappTokenSource, err := githubauth.NewApplicationTokenSource(1112, privateKey)\n\tif err != nil {\n\t\tfmt.Println(\"Error creating application token source:\", err)\n\t\treturn\n\t }\n\n\tinstallationTokenSource := githubauth.NewInstallationTokenSource(1113, appTokenSource)\n\n\t// oauth2.NewClient uses oauth2.ReuseTokenSource to reuse the token until it expires.\n\t// The token will be automatically refreshed when it expires.\n\t// InstallationTokenSource has the mechanism to refresh the token when it expires.\n\thttpClient := oauth2.NewClient(context.Background(), installationTokenSource)\n\n\tclient := github.NewClient(httpClient)\n}\n```\n\n*Note*: In order to interact with certain APIs, for example writing a file to a repo, one must generate an installation token\nusing the installation ID of the GitHub app and authenticate with the OAuth method mentioned above. See the examples.\n\n### Rate Limiting ###\n\nGitHub imposes rate limits on all API clients. The [primary rate limit](https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api#about-primary-rate-limits)\nis the limit to the number of REST API requests that a client can make within a\nspecific amount of time. This limit helps prevent abuse and denial-of-service\nattacks, and ensures that the API remains available for all users. Some\nendpoints, like the search endpoints, have more restrictive limits.\nUnauthenticated clients may request public data but have a low rate limit,\nwhile authenticated clients have rate limits based on the client\nidentity.\n\nIn addition to primary rate limits, GitHub enforces [secondary rate limits](https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api#about-secondary-rate-limits)\nin order to prevent abuse and keep the API available for all users.\nSecondary rate limits generally limit the number of concurrent requests that a\nclient can make.\n\nThe client returned `Response.Rate` value contains the rate limit information\nfrom the most recent API call. If a recent enough response isn't\navailable, you can use the client `RateLimits` service to fetch the most\nup-to-date rate limit data for the client.\n\nTo detect a primary API rate limit error, you can check if the error is a\n`RateLimitError`.\n\n```go\nrepos, _, err := client.Repositories.List(ctx, \"\", nil)\nvar rateErr *github.RateLimitError\nif errors.As(err, &rateErr) {\n\tlog.Printf(\"hit primary rate limit, used %v of %v\\n\", rateErr.Rate.Used, rateErr.Rate.Limit)\n}\n```\n\nTo detect an API secondary rate limit error, you can check if the error is an\n`AbuseRateLimitError`.\n\n```go\nrepos, _, err := client.Repositories.List(ctx, \"\", nil)\nvar rateErr *github.AbuseRateLimitError\nif errors.As(err, &rateErr) {\n\tlog.Printf(\"hit secondary rate limit, retry after %v\\n\", rateErr.RetryAfter)\n}\n```\n\nIf you hit the primary rate limit, you can use the `SleepUntilPrimaryRateLimitResetWhenRateLimited`\nmethod to block until the rate limit is reset.\n\n```go\nrepos, _, err := client.Repositories.List(context.WithValue(ctx, github.SleepUntilPrimaryRateLimitResetWhenRateLimited, true), \"\", nil)\n```\n\nIf you need to make a request even if the rate limit has been hit you can use\nthe `BypassRateLimitCheck` method to bypass the rate limit check and make the\nrequest anyway.\n\n```go\nrepos, _, err := client.Repositories.List(context.WithValue(ctx, github.BypassRateLimitCheck, true), \"\", nil)\n```\n\nFor more advanced use cases, you can use [gofri/go-github-ratelimit](https://github.com/gofri/go-github-ratelimit)\nwhich provides a middleware (`http.RoundTripper`) that handles both the primary\nrate limit and secondary rate limit for the GitHub API. In this case you can\nset the client `DisableRateLimitCheck` to `true` so the client doesn't track the rate limit usage.\n\nIf the client is an [OAuth app](https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api#primary-rate-limit-for-oauth-apps)\nyou can use the apps higher rate limit to request public data by using the\n`UnauthenticatedRateLimitedTransport` to make calls as the app instead of as\nthe user.\n\n### Accepted Status ###\n\nSome endpoints may return a 202 Accepted status code, meaning that the\ninformation required is not yet ready and was scheduled to be gathered on\nthe GitHub side. Methods known to behave like this are documented specifying\nthis behavior.\n\nTo detect this condition of error, you can check if its type is\n`*github.AcceptedError`:\n\n```go\nstats, _, err := client.Repositories.ListContributorsStats(ctx, org, repo)\nif errors.As(err, new(*github.AcceptedError)) {\n\tlog.Println(\"scheduled on GitHub side\")\n}\n```\n\n### Conditional Requests ###\n\nThe GitHub REST API has good support for [conditional HTTP requests](https://docs.github.com/en/rest/using-the-rest-api/best-practices-for-using-the-rest-api?apiVersion=2022-11-28#use-conditional-requests-if-appropriate)\nvia the `ETag` header which will help prevent you from burning through your\nrate limit, as well as help speed up your application. `go-github` does not\nhandle conditional requests directly, but is instead designed to work with a\ncaching `http.Transport`.\n\nTypically, an [RFC 9111](https://datatracker.ietf.org/doc/html/rfc9111)\ncompliant HTTP cache such as [bartventer/httpcache](https://github.com/bartventer/httpcache)\nis recommended, ex:\n\n```go\nimport (\n\t\"github.com/bartventer/httpcache\"\n\t_ \"github.com/bartventer/httpcache/store/memcache\" //  Register the in-memory backend\n)\n\nclient := github.NewClient(\n\thttpcache.NewClient(\"memcache://\"),\n).WithAuthToken(os.Getenv(\"GITHUB_TOKEN\"))\n```\n\nAlternatively, the [bored-engineer/github-conditional-http-transport](https://github.com/bored-engineer/github-conditional-http-transport)\npackage relies on (undocumented) GitHub specific cache logic and is\nrecommended when making requests using short-lived credentials such as a \n[GitHub App installation token](https://docs.github.com/en/apps/creating-github-apps/authenticating-with-a-github-app/authenticating-as-a-github-app-installation).\n\n### Creating and Updating Resources ###\n\nAll structs for GitHub resources use pointer values for all non-repeated fields.\nThis allows distinguishing between unset fields and those set to a zero-value.\nHelper functions have been provided to easily create these pointers for string,\nbool, and int values. For example:\n\n```go\n// create a new private repository named \"foo\"\nrepo := &github.Repository{\n\tName:    github.Ptr(\"foo\"),\n\tPrivate: github.Ptr(true),\n}\nclient.Repositories.Create(ctx, \"\", repo)\n```\n\nUsers who have worked with protocol buffers should find this pattern familiar.\n\n### Pagination ###\n\nAll requests for resource collections (repos, pull requests, issues, etc.)\nsupport pagination. Pagination options are described in the\n`github.ListOptions` struct and passed to the list methods directly or as an\nembedded type of a more specific list options struct (for example\n`github.PullRequestListOptions`). Pages information is available via the\n`github.Response` struct.\n\n```go\nclient := github.NewClient(nil)\n\nopt := &github.RepositoryListByOrgOptions{\n\tListOptions: github.ListOptions{PerPage: 10},\n}\n// get all pages of results\nvar allRepos []*github.Repository\nfor {\n\trepos, resp, err := client.Repositories.ListByOrg(ctx, \"github\", opt)\n\tif err != nil {\n\t\treturn err\n\t}\n\tallRepos = append(allRepos, repos...)\n\tif resp.NextPage == 0 {\n\t\tbreak\n\t}\n\topt.Page = resp.NextPage\n}\n```\n\n#### Iterators (**experimental**) ####\n\nGo v1.23 introduces the new `iter` package.  \n\nWith the `enrichman/gh-iter` package, it is possible to create iterators for `go-github`. The iterator will handle pagination for you, looping through all the available results.\n\n```go\nclient := github.NewClient(nil)\nvar allRepos []*github.Repository\n\n// create an iterator and start looping through all the results\nrepos := ghiter.NewFromFn1(client.Repositories.ListByOrg, \"github\")\nfor repo := range repos.All() {\n\tallRepos = append(allRepos, repo)\n}\n```\n\nFor complete usage of `enrichman/gh-iter`, see the full [package docs](https://github.com/enrichman/gh-iter).\n\n#### Middleware ####\n\nYou can use [gofri/go-github-pagination](https://github.com/gofri/go-github-pagination) to handle\npagination for you. It supports both sync and async modes, as well as customizations.  \nBy default, the middleware automatically paginates through all pages, aggregates results, and returns them as an array.  \nSee `example/ratelimit/main.go` for usage.\n\n### Webhooks ###\n\n`go-github` provides structs for almost all [GitHub webhook events][] as well as functions to validate them and unmarshal JSON payloads from `http.Request` structs.\n\n```go\nfunc (s *GitHubEventMonitor) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\tpayload, err := github.ValidatePayload(r, s.webhookSecretKey)\n\tif err != nil { ... }\n\tevent, err := github.ParseWebHook(github.WebHookType(r), payload)\n\tif err != nil { ... }\n\tswitch event := event.(type) {\n\tcase *github.CommitCommentEvent:\n\t\tprocessCommitCommentEvent(event)\n\tcase *github.CreateEvent:\n\t\tprocessCreateEvent(event)\n\t...\n\t}\n}\n```\n\nFurthermore, there are libraries like [cbrgm/githubevents][] that build upon the example above and provide functions to subscribe callbacks to specific events.\n\nFor complete usage of go-github, see the full [package docs][].\n\n[GitHub API v3]: https://docs.github.com/en/rest\n[personal access token]: https://github.com/blog/1509-personal-api-tokens\n[package docs]: https://pkg.go.dev/github.com/google/go-github/v81/github\n[GraphQL API v4]: https://developer.github.com/v4/\n[shurcooL/githubv4]: https://github.com/shurcooL/githubv4\n[GitHub webhook events]: https://docs.github.com/en/developers/webhooks-and-events/webhooks/webhook-events-and-payloads\n[cbrgm/githubevents]: https://github.com/cbrgm/githubevents\n\n### Testing code that uses `go-github` ###\n\nThe repo [migueleliasweb/go-github-mock](https://github.com/migueleliasweb/go-github-mock) provides a way to mock responses. Check the repo for more details.\n\n### Integration Tests ###\n\nYou can run integration tests from the `test` directory. See the integration tests [README](test/README.md).\n\n## Contributing ##\n\nI would like to cover the entire GitHub API and contributions are of course always welcome. The\ncalling pattern is pretty well established, so adding new methods is relatively\nstraightforward. See [`CONTRIBUTING.md`](CONTRIBUTING.md) for details.\n\n## Versioning ##\n\nIn general, go-github follows [semver](https://semver.org/) as closely as we\ncan for tagging releases of the package. For self-contained libraries, the\napplication of semantic versioning is relatively straightforward and generally\nunderstood. But because go-github is a client library for the GitHub API, which\nitself changes behavior, and because we are typically pretty aggressive about\nimplementing preview features of the GitHub API, we've adopted the following\nversioning policy:\n\n* We increment the **major version** with any incompatible change to\n\tnon-preview functionality, including changes to the exported Go API surface\n\tor behavior of the API.\n* We increment the **minor version** with any backwards-compatible changes to\n\tfunctionality, as well as any changes to preview functionality in the GitHub\n\tAPI. GitHub makes no guarantee about the stability of preview functionality,\n\tso neither do we consider it a stable part of the go-github API.\n* We increment the **patch version** with any backwards-compatible bug fixes.\n\nPreview functionality may take the form of entire methods or simply additional\ndata returned from an otherwise non-preview method. Refer to the GitHub API\ndocumentation for details on preview functionality.\n\n### Calendar Versioning ###\n\nAs of 2022-11-28, GitHub [has announced](https://github.blog/2022-11-28-to-infinity-and-beyond-enabling-the-future-of-githubs-rest-api-with-api-versioning/)\nthat they are starting to version their v3 API based on \"calendar-versioning\".\n\nIn practice, our goal is to make per-method version overrides (at\nleast in the core library) rare and temporary.\n\nOur understanding of the GitHub docs is that they will be revving the\nentire API to each new date-based version, even if only a few methods\nhave breaking changes. Other methods will accept the new version with\ntheir existing functionality. So when a new date-based version of the\nGitHub API is released, we (the repo maintainers) plan to:\n\n* update each method that had breaking changes, overriding their\n  per-method API version header. This may happen in one or multiple\n  commits and PRs, and is all done in the main branch.\n\n* once all of the methods with breaking changes have been updated,\n  have a final commit that bumps the default API version, and remove\n  all of the per-method overrides. That would now get a major version\n  bump when the next go-github release is made.\n\n### Version Compatibility Table ###\n\nThe following table identifies which version of the GitHub API is\nsupported by this (and past) versions of this repo (go-github).\nVersions prior to 48.2.0 are not listed.\n\n| go-github Version | GitHub v3 API Version |\n| ----------------- | --------------------- |\n| 81.0.0            | 2022-11-28            |\n| ...               | 2022-11-28            |\n| 48.2.0            | 2022-11-28            |\n\n## License ##\n\nThis library is distributed under the BSD-style license found in the [LICENSE](./LICENSE)\nfile.\n",
      "stars_today": 12
    },
    {
      "id": 693187866,
      "name": "rolldown",
      "full_name": "rolldown/rolldown",
      "description": "Fast Rust bundler for JavaScript/TypeScript with Rollup-compatible API.",
      "html_url": "https://github.com/rolldown/rolldown",
      "stars": 12708,
      "forks": 683,
      "language": "Rust",
      "topics": [
        "bundler",
        "javascript",
        "typescript"
      ],
      "created_at": "2023-09-18T14:20:28Z",
      "updated_at": "2026-01-24T21:43:00Z",
      "pushed_at": "2026-01-24T16:15:11Z",
      "open_issues": 231,
      "owner": {
        "login": "rolldown",
        "avatar_url": "https://avatars.githubusercontent.com/u/94954945?v=4"
      },
      "readme": "<p align=\"center\">\n  <br>\n  <br>\n  <a href=\"https://rolldown.rs\" target=\"_blank\" rel=\"noopener noreferrer\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://rolldown.rs/rolldown-light.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://rolldown.rs/rolldown-dark.svg\">\n      <img alt=\"rolldown logo\" src=\"https://rolldown.rs/rolldown-dark.svg\" height=\"60\">\n    </picture>\n  </a>\n  <br>\n  <br>\n  <br>\n</p>\n\n<div align=\"center\">\n\n[![MIT licensed][badge-license]][url-license]\n[![NPM version][badge-npm-version]][url-npm]\n[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/rolldown/rolldown)\n[![Discord chat][badge-discord]][discord-url]\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/rolldown/rolldown)\n\n</div>\n\n<div align=\"center\">\n\n[![NPM Unpacked Size (with version)](https://img.shields.io/npm/unpacked-size/rolldown/latest?label=npm)][url-npm]\n[![NPM Unpacked Size darwin-arm64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-arm64/latest?label=darwin-arm64)](https://www.npmjs.com/package/@rolldown/binding-darwin-arm64)\n[![NPM Unpacked Size darwin-x64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-x64/latest?label=darwin-x64)](https://www.npmjs.com/package/@rolldown/binding-darwin-x64)\n[![NPM Unpacked Size linux-x64-gnu](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-linux-x64-gnu/latest?label=linux-x64-gnu)](https://www.npmjs.com/package/@rolldown/binding-linux-x64-gnu)\n[![NPM Unpacked Size win32-x64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-win32-x64-msvc/latest?label=win32-x64)](https://www.npmjs.com/package/@rolldown/binding-win32-x64-msvc)\n[![NPM Unpacked Size wasm32-wasi](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-wasm32-wasi/latest?label=wasm32-wasi)](https://www.npmjs.com/package/@rolldown/binding-wasm32-wasi)\n\n</div>\n\n<div align=\"center\">\n\n[![pkg.pr.new](https://pkg.pr.new/badge/pkg.pr.new/pkg.pr.new?style=flat&color=000&logoSize=auto)](https://pkg.pr.new/~/rolldown/rolldown)\n\n</div>\n\n<div align=\"center\">\n\n[![rolldown-starter-stackblitz](https://developer.stackblitz.com/img/open_in_stackblitz.svg)](https://stackblitz.com/fork/github/rolldown/rolldown-starter-stackblitz)\n\n</div>\n\n> ğŸš§ **Release Candidate**\n>\n> Rolldown is currently in RC status. While it can already handle most production use cases, there may still be bugs and rough edges. Most notably, the built-in minification feature is still in alpha status.\n\n# Rolldown\n\nRolldown is a JavaScript/TypeScript bundler written in Rust intended to serve as the future bundler used in [Vite](https://vitejs.dev/). It provides Rollup-compatible APIs and plugin interface, but will be more similar to esbuild in scope.\n\nFor more information, please check out the documentation at [rolldown.rs](https://rolldown.rs/guide/getting-started).\n\n## VoidZero Inc.\n\nRolldown is a project of [VoidZero](https://voidzero.dev/), see our announcement [Announcing VoidZero - Next Generation Toolchain for JavaScript](https://voidzero.dev/posts/announcing-voidzero-inc).\n\nIf you have requirements for JavaScript tools at scale, please [get in touch](https://forms.gle/WQgjyzYJpwurpxWKA)!\n\n## Contributing\n\nWe would love to have more contributors involved!\n\nTo get started, please read our [Contributing Guide](https://rolldown.rs/contribution-guide/).\n\n## Credits\n\nThe Rolldown project is heavily inspired by:\n\n- [Rollup](https://github.com/rollup/rollup), created by [Rich Harris](https://github.com/Rich-Harris) and maintained by [Lukas Taegert-Atkinson](https://github.com/lukastaegert).\n- [esbuild](https://github.com/evanw/esbuild), created by [Evan Wallace](https://github.com/evanw).\n\nAnd supported by:\n\n- [napi-rs](https://github.com/napi-rs/napi-rs) for Node.js add-ons in Rust via Node-API.\n- [oxc](https://github.com/oxc-project/oxc) for the underlying parser, resolver, and sourcemap support.\n\n## Licenses\n\nThis project is licensed under the [MIT License](LICENSE).\n\nThis project also partially contains code derived or copied from the following projects:\n\n- [rollup(MIT)](https://github.com/rollup/rollup/blob/680912e2ceb42c8d5e571e01c6ece0e4889aecbb/LICENSE-CORE.md)\n- [esbuild(MIT)](https://github.com/evanw/esbuild/blob/0c8a0a901d9a6c7bbff9b4dd347c8a3f65f6c6dd/LICENSE.md)\n\nLicenses of these projects are listed in [THIRD-PARTY-LICENSE](/THIRD-PARTY-LICENSE)\n\n[badge-discord]: https://img.shields.io/discord/1079625926024900739?logo=discord&label=Discord\n[discord-url]: https://chat.rolldown.rs\n[badge-license]: https://img.shields.io/badge/license-MIT-blue.svg\n[url-license]: https://github.com/rolldown/rolldown/blob/main/LICENSE\n[badge-npm-version]: https://img.shields.io/npm/v/rolldown/latest?color=brightgreen\n[url-npm]: https://www.npmjs.com/package/rolldown/v/latest\n\n[badge-binary-size-windows]: [https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-win32-x64-msvc/latest]\n[badge-binary-size-macos]: [https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-arm64/latest]\n",
      "stars_today": 12
    },
    {
      "id": 370557198,
      "name": "sonic",
      "full_name": "bytedance/sonic",
      "description": "A blazingly fast JSON serializing & deserializing library",
      "html_url": "https://github.com/bytedance/sonic",
      "stars": 9079,
      "forks": 428,
      "language": "Go",
      "topics": [
        "high-performance",
        "jit",
        "json",
        "simd"
      ],
      "created_at": "2021-05-25T03:52:51Z",
      "updated_at": "2026-01-25T01:00:03Z",
      "pushed_at": "2026-01-22T12:46:00Z",
      "open_issues": 26,
      "owner": {
        "login": "bytedance",
        "avatar_url": "https://avatars.githubusercontent.com/u/4158466?v=4"
      },
      "readme": "# Sonic\n\nEnglish | [ä¸­æ–‡](README_ZH_CN.md)\n\nA blazingly fast JSON serializing &amp; deserializing library, accelerated by JIT (just-in-time compiling) and SIMD (single-instruction-multiple-data).\n\n## Requirement\n\n- Go: 1.18~1.25\n  - Notice: Go1.24.0 is not supported due to the [issue](https://github.com/golang/go/issues/71672), please use higher go version or add build tag `--ldflags=\"-checklinkname=0\"` \n- OS: Linux / MacOS / Windows\n- CPU: AMD64 / (ARM64, need go1.20 above)\n\n## Features\n\n- Runtime object binding without code generation\n- Complete APIs for JSON value manipulation\n- Fast, fast, fast!\n\n## APIs\n\nsee [go.dev](https://pkg.go.dev/github.com/bytedance/sonic)\n\n## Benchmarks\n\nFor **all sizes** of json and **all scenarios** of usage, **Sonic performs best**.\n\n- [Medium](https://github.com/bytedance/sonic/blob/main/decoder/testdata_test.go#L19) (13KB, 300+ key, 6 layers)\n\n```powershell\ngoversion: 1.17.1\ngoos: darwin\ngoarch: amd64\ncpu: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz\nBenchmarkEncoder_Generic_Sonic-16                      32393 ns/op         402.40 MB/s       11965 B/op          4 allocs/op\nBenchmarkEncoder_Generic_Sonic_Fast-16                 21668 ns/op         601.57 MB/s       10940 B/op          4 allocs/op\nBenchmarkEncoder_Generic_JsonIter-16                   42168 ns/op         309.12 MB/s       14345 B/op        115 allocs/op\nBenchmarkEncoder_Generic_GoJson-16                     65189 ns/op         199.96 MB/s       23261 B/op         16 allocs/op\nBenchmarkEncoder_Generic_StdLib-16                    106322 ns/op         122.60 MB/s       49136 B/op        789 allocs/op\nBenchmarkEncoder_Binding_Sonic-16                       6269 ns/op        2079.26 MB/s       14173 B/op          4 allocs/op\nBenchmarkEncoder_Binding_Sonic_Fast-16                  5281 ns/op        2468.16 MB/s       12322 B/op          4 allocs/op\nBenchmarkEncoder_Binding_JsonIter-16                   20056 ns/op         649.93 MB/s        9488 B/op          2 allocs/op\nBenchmarkEncoder_Binding_GoJson-16                      8311 ns/op        1568.32 MB/s        9481 B/op          1 allocs/op\nBenchmarkEncoder_Binding_StdLib-16                     16448 ns/op         792.52 MB/s        9479 B/op          1 allocs/op\nBenchmarkEncoder_Parallel_Generic_Sonic-16              6681 ns/op        1950.93 MB/s       12738 B/op          4 allocs/op\nBenchmarkEncoder_Parallel_Generic_Sonic_Fast-16         4179 ns/op        3118.99 MB/s       10757 B/op          4 allocs/op\nBenchmarkEncoder_Parallel_Generic_JsonIter-16           9861 ns/op        1321.84 MB/s       14362 B/op        115 allocs/op\nBenchmarkEncoder_Parallel_Generic_GoJson-16            18850 ns/op         691.52 MB/s       23278 B/op         16 allocs/op\nBenchmarkEncoder_Parallel_Generic_StdLib-16            45902 ns/op         283.97 MB/s       49174 B/op        789 allocs/op\nBenchmarkEncoder_Parallel_Binding_Sonic-16              1480 ns/op        8810.09 MB/s       13049 B/op          4 allocs/op\nBenchmarkEncoder_Parallel_Binding_Sonic_Fast-16         1209 ns/op        10785.23 MB/s      11546 B/op          4 allocs/op\nBenchmarkEncoder_Parallel_Binding_JsonIter-16           6170 ns/op        2112.58 MB/s        9504 B/op          2 allocs/op\nBenchmarkEncoder_Parallel_Binding_GoJson-16             3321 ns/op        3925.52 MB/s        9496 B/op          1 allocs/op\nBenchmarkEncoder_Parallel_Binding_StdLib-16             3739 ns/op        3486.49 MB/s        9480 B/op          1 allocs/op\n\nBenchmarkDecoder_Generic_Sonic-16                      66812 ns/op         195.10 MB/s       57602 B/op        723 allocs/op\nBenchmarkDecoder_Generic_Sonic_Fast-16                 54523 ns/op         239.07 MB/s       49786 B/op        313 allocs/op\nBenchmarkDecoder_Generic_StdLib-16                    124260 ns/op         104.90 MB/s       50869 B/op        772 allocs/op\nBenchmarkDecoder_Generic_JsonIter-16                   91274 ns/op         142.81 MB/s       55782 B/op       1068 allocs/op\nBenchmarkDecoder_Generic_GoJson-16                     88569 ns/op         147.17 MB/s       66367 B/op        973 allocs/op\nBenchmarkDecoder_Binding_Sonic-16                      32557 ns/op         400.38 MB/s       28302 B/op        137 allocs/op\nBenchmarkDecoder_Binding_Sonic_Fast-16                 28649 ns/op         455.00 MB/s       24999 B/op         34 allocs/op\nBenchmarkDecoder_Binding_StdLib-16                    111437 ns/op         116.97 MB/s       10576 B/op        208 allocs/op\nBenchmarkDecoder_Binding_JsonIter-16                   35090 ns/op         371.48 MB/s       14673 B/op        385 allocs/op\nBenchmarkDecoder_Binding_GoJson-16                     28738 ns/op         453.59 MB/s       22039 B/op         49 allocs/op\nBenchmarkDecoder_Parallel_Generic_Sonic-16             12321 ns/op        1057.91 MB/s       57233 B/op        723 allocs/op\nBenchmarkDecoder_Parallel_Generic_Sonic_Fast-16        10644 ns/op        1224.64 MB/s       49362 B/op        313 allocs/op\nBenchmarkDecoder_Parallel_Generic_StdLib-16            57587 ns/op         226.35 MB/s       50874 B/op        772 allocs/op\nBenchmarkDecoder_Parallel_Generic_JsonIter-16          38666 ns/op         337.12 MB/s       55789 B/op       1068 allocs/op\nBenchmarkDecoder_Parallel_Generic_GoJson-16            30259 ns/op         430.79 MB/s       66370 B/op        974 allocs/op\nBenchmarkDecoder_Parallel_Binding_Sonic-16              5965 ns/op        2185.28 MB/s       27747 B/op        137 allocs/op\nBenchmarkDecoder_Parallel_Binding_Sonic_Fast-16         5170 ns/op        2521.31 MB/s       24715 B/op         34 allocs/op\nBenchmarkDecoder_Parallel_Binding_StdLib-16            27582 ns/op         472.58 MB/s       10576 B/op        208 allocs/op\nBenchmarkDecoder_Parallel_Binding_JsonIter-16          13571 ns/op         960.51 MB/s       14685 B/op        385 allocs/op\nBenchmarkDecoder_Parallel_Binding_GoJson-16            10031 ns/op        1299.51 MB/s       22111 B/op         49 allocs/op\n\nBenchmarkGetOne_Sonic-16                                3276 ns/op        3975.78 MB/s          24 B/op          1 allocs/op\nBenchmarkGetOne_Gjson-16                                9431 ns/op        1380.81 MB/s           0 B/op          0 allocs/op\nBenchmarkGetOne_Jsoniter-16                            51178 ns/op         254.46 MB/s       27936 B/op        647 allocs/op\nBenchmarkGetOne_Parallel_Sonic-16                      216.7 ns/op       60098.95 MB/s          24 B/op          1 allocs/op\nBenchmarkGetOne_Parallel_Gjson-16                       1076 ns/op        12098.62 MB/s          0 B/op          0 allocs/op\nBenchmarkGetOne_Parallel_Jsoniter-16                   17741 ns/op         734.06 MB/s       27945 B/op        647 allocs/op\nBenchmarkSetOne_Sonic-16                               9571 ns/op         1360.61 MB/s        1584 B/op         17 allocs/op\nBenchmarkSetOne_Sjson-16                               36456 ns/op         357.22 MB/s       52180 B/op          9 allocs/op\nBenchmarkSetOne_Jsoniter-16                            79475 ns/op         163.86 MB/s       45862 B/op        964 allocs/op\nBenchmarkSetOne_Parallel_Sonic-16                      850.9 ns/op       15305.31 MB/s        1584 B/op         17 allocs/op\nBenchmarkSetOne_Parallel_Sjson-16                      18194 ns/op         715.77 MB/s       52247 B/op          9 allocs/op\nBenchmarkSetOne_Parallel_Jsoniter-16                   33560 ns/op         388.05 MB/s       45892 B/op        964 allocs/op\nBenchmarkLoadNode/LoadAll()-16                         11384 ns/op        1143.93 MB/s        6307 B/op         25 allocs/op\nBenchmarkLoadNode_Parallel/LoadAll()-16                 5493 ns/op        2370.68 MB/s        7145 B/op         25 allocs/op\nBenchmarkLoadNode/Interface()-16                       17722 ns/op         734.85 MB/s       13323 B/op         88 allocs/op\nBenchmarkLoadNode_Parallel/Interface()-16              10330 ns/op        1260.70 MB/s       15178 B/op         88 allocs/op\n```\n\n- [Small](https://github.com/bytedance/sonic/blob/main/testdata/small.go) (400B, 11 keys, 3 layers)\n![small benchmarks](./docs/imgs/bench-small.png)\n- [Large](https://github.com/bytedance/sonic/blob/main/testdata/twitter.json) (635KB, 10000+ key, 6 layers)\n![large benchmarks](./docs/imgs/bench-large.png)\n\nSee [bench.sh](https://github.com/bytedance/sonic/blob/main/scripts/bench.sh) for benchmark codes.\n\n## How it works\n\nSee [INTRODUCTION.md](./docs/INTRODUCTION.md).\n\n## Usage\n\n### Marshal/Unmarshal\n\nDefault behaviors are mostly consistent with `encoding/json`, except HTML escaping form (see [Escape HTML](https://github.com/bytedance/sonic/blob/main/README.md#escape-html)) and `SortKeys` feature (optional support see [Sort Keys](https://github.com/bytedance/sonic/blob/main/README.md#sort-keys)) that is **NOT** in conformity to [RFC8259](https://datatracker.ietf.org/doc/html/rfc8259).\n\n ```go\nimport \"github.com/bytedance/sonic\"\n\nvar data YourSchema\n// Marshal\noutput, err := sonic.Marshal(&data)\n// Unmarshal\nerr := sonic.Unmarshal(output, &data)\n ```\n\n### Streaming IO\n\nSonic supports decoding json from `io.Reader` or encoding objects into `io.Writer`, aims at handling multiple values as well as reducing memory consumption.\n\n- encoder\n\n```go\nvar o1 = map[string]interface{}{\n    \"a\": \"b\",\n}\nvar o2 = 1\nvar w = bytes.NewBuffer(nil)\nvar enc = sonic.ConfigDefault.NewEncoder(w)\nenc.Encode(o1)\nenc.Encode(o2)\nfmt.Println(w.String())\n// Output:\n// {\"a\":\"b\"}\n// 1\n```\n\n- decoder\n\n```go\nvar o =  map[string]interface{}{}\nvar r = strings.NewReader(`{\"a\":\"b\"}{\"1\":\"2\"}`)\nvar dec = sonic.ConfigDefault.NewDecoder(r)\ndec.Decode(&o)\ndec.Decode(&o)\nfmt.Printf(\"%+v\", o)\n// Output:\n// map[1:2 a:b]\n```\n\n### Use Number/Use Int64\n\n ```go\nimport \"github.com/bytedance/sonic/decoder\"\n\nvar input = `1`\nvar data interface{}\n\n// default float64\ndc := decoder.NewDecoder(input)\ndc.Decode(&data) // data == float64(1)\n// use json.Number\ndc = decoder.NewDecoder(input)\ndc.UseNumber()\ndc.Decode(&data) // data == json.Number(\"1\")\n// use int64\ndc = decoder.NewDecoder(input)\ndc.UseInt64()\ndc.Decode(&data) // data == int64(1)\n\nroot, err := sonic.GetFromString(input)\n// Get json.Number\njn := root.Number()\njm := root.InterfaceUseNumber().(json.Number) // jn == jm\n// Get float64\nfn := root.Float64()\nfm := root.Interface().(float64) // jn == jm\n ```\n\n### Sort Keys\n\nOn account of the performance loss from sorting (roughly 10%), sonic doesn't enable this feature by default. If your component depends on it to work (like [zstd](https://github.com/facebook/zstd)), Use it like this:\n\n```go\nimport \"github.com/bytedance/sonic\"\nimport \"github.com/bytedance/sonic/encoder\"\n\n// Binding map only\nm := map[string]interface{}{}\nv, err := encoder.Encode(m, encoder.SortMapKeys)\n\n// Or ast.Node.SortKeys() before marshal\nvar root := sonic.Get(JSON)\nerr := root.SortKeys()\n```\n\n### Escape HTML\n\nOn account of the performance loss (roughly 15%), sonic doesn't enable this feature by default. You can use `encoder.EscapeHTML` option to open this feature (align with `encoding/json.HTMLEscape`).\n\n```go\nimport \"github.com/bytedance/sonic\"\n\nv := map[string]string{\"&&\":\"<>\"}\nret, err := Encode(v, EscapeHTML) // ret == `{\"\\u0026\\u0026\":{\"X\":\"\\u003c\\u003e\"}}`\n```\n\n### Compact Format\n\nSonic encodes primitive objects (struct/map...) as compact-format JSON by default, except marshaling `json.RawMessage` or `json.Marshaler`: sonic ensures validating their output JSON but **DO NOT** compacting them for performance concerns. We provide the option `encoder.CompactMarshaler` to add compacting process.\n\n### Print Error\n\nIf there invalid syntax in input JSON, sonic will return `decoder.SyntaxError`, which supports pretty-printing of error position\n\n```go\nimport \"github.com/bytedance/sonic\"\nimport \"github.com/bytedance/sonic/decoder\"\n\nvar data interface{}\nerr := sonic.UnmarshalString(\"[[[}]]\", &data)\nif err != nil {\n    /* One line by default */\n    println(e.Error()) // \"Syntax error at index 3: invalid char\\n\\n\\t[[[}]]\\n\\t...^..\\n\"\n    /* Pretty print */\n    if e, ok := err.(decoder.SyntaxError); ok {\n        /*Syntax error at index 3: invalid char\n\n            [[[}]]\n            ...^..\n        */\n        print(e.Description())\n    } else if me, ok := err.(*decoder.MismatchTypeError); ok {\n        // decoder.MismatchTypeError is new to Sonic v1.6.0\n        print(me.Description())\n    }\n}\n```\n\n#### Mismatched Types [Sonic v1.6.0]\n\nIf there a **mismatch-typed** value for a given key, sonic will report `decoder.MismatchTypeError` (if there are many, report the last one), but still skip wrong the value and keep decoding next JSON.\n\n```go\nimport \"github.com/bytedance/sonic\"\nimport \"github.com/bytedance/sonic/decoder\"\n\nvar data = struct{\n    A int\n    B int\n}{}\nerr := UnmarshalString(`{\"A\":\"1\",\"B\":1}`, &data)\nprintln(err.Error())    // Mismatch type int with value string \"at index 5: mismatched type with value\\n\\n\\t{\\\"A\\\":\\\"1\\\",\\\"B\\\":1}\\n\\t.....^.........\\n\"\nfmt.Printf(\"%+v\", data) // {A:0 B:1}\n```\n\n### Ast.Node\n\nSonic/ast.Node is a completely self-contained AST for JSON. It implements serialization and deserialization both and provides robust APIs for obtaining and modification of generic data.\n\n#### Get/Index\n\nSearch partial JSON by given paths, which must be non-negative integer or string, or nil\n\n```go\nimport \"github.com/bytedance/sonic\"\n\ninput := []byte(`{\"key1\":[{},{\"key2\":{\"key3\":[1,2,3]}}]}`)\n\n// no path, returns entire json\nroot, err := sonic.Get(input)\nraw := root.Raw() // == string(input)\n\n// multiple paths\nroot, err := sonic.Get(input, \"key1\", 1, \"key2\")\nsub := root.Get(\"key3\").Index(2).Int64() // == 3\n```\n\n**Tip**: since `Index()` uses offset to locate data, which is much faster than scanning like `Get()`, we suggest you use it as much as possible. And sonic also provides another API `IndexOrGet()` to underlying use offset as well as ensure the key is matched.\n\n#### SearchOption\n\n`Searcher` provides some options for user to meet different needs:\n\n```go\nopts := ast.SearchOption{ CopyReturn: true ... }\nval, err := sonic.GetWithOptions(JSON, opts, \"key\")\n```\n\n- CopyReturn\nIndicate the searcher to copy the result JSON string instead of refer from the input. This can help to reduce memory usage if you cache the results\n- ConcurentRead\nSince `ast.Node` use `Lazy-Load` design, it doesn't support Concurrently-Read by default. If you want to read it concurrently, please specify it.\n- ValidateJSON\nIndicate the searcher to validate the entire JSON. This option is enabled by default, which slow down the search speed a little.\n\n#### Set/Unset\n\nModify the json content by Set()/Unset()\n\n```go\nimport \"github.com/bytedance/sonic\"\n\n// Set\nexist, err := root.Set(\"key4\", NewBool(true)) // exist == false\nalias1 := root.Get(\"key4\")\nprintln(alias1.Valid()) // true\nalias2 := root.Index(1)\nprintln(alias1 == alias2) // true\n\n// Unset\nexist, err := root.UnsetByIndex(1) // exist == true\nprintln(root.Get(\"key4\").Check()) // \"value not exist\"\n```\n\n#### Serialize\n\nTo encode `ast.Node` as json, use `MarshalJson()` or `json.Marshal()` (MUST pass the node's pointer)\n\n```go\nimport (\n    \"encoding/json\"\n    \"github.com/bytedance/sonic\"\n)\n\nbuf, err := root.MarshalJson()\nprintln(string(buf))                // {\"key1\":[{},{\"key2\":{\"key3\":[1,2,3]}}]}\nexp, err := json.Marshal(&root)     // WARN: use pointer\nprintln(string(buf) == string(exp)) // true\n```\n\n#### APIs\n\n- validation: `Check()`, `Error()`, `Valid()`, `Exist()`\n- searching: `Index()`, `Get()`, `IndexPair()`, `IndexOrGet()`, `GetByPath()`\n- go-type casting: `Int64()`, `Float64()`, `String()`, `Number()`, `Bool()`, `Map[UseNumber|UseNode]()`, `Array[UseNumber|UseNode]()`, `Interface[UseNumber|UseNode]()`\n- go-type packing: `NewRaw()`, `NewNumber()`, `NewNull()`, `NewBool()`, `NewString()`, `NewObject()`, `NewArray()`\n- iteration: `Values()`, `Properties()`, `ForEach()`, `SortKeys()`\n- modification: `Set()`, `SetByIndex()`, `Add()`\n\n### Ast.Visitor\n\nSonic provides an advanced API for fully parsing JSON into non-standard types (neither `struct` not `map[string]interface{}`) without using any intermediate representation (`ast.Node` or `interface{}`). For example, you might have the following types which are like `interface{}` but actually not `interface{}`:\n\n```go\ntype UserNode interface {}\n\n// the following types implement the UserNode interface.\ntype (\n    UserNull    struct{}\n    UserBool    struct{ Value bool }\n    UserInt64   struct{ Value int64 }\n    UserFloat64 struct{ Value float64 }\n    UserString  struct{ Value string }\n    UserObject  struct{ Value map[string]UserNode }\n    UserArray   struct{ Value []UserNode }\n)\n```\n\nSonic provides the following API to return **the preorder traversal of a JSON AST**. The `ast.Visitor` is a SAX style interface which is used in some C++ JSON library. You should implement `ast.Visitor` by yourself and pass it to `ast.Preorder()` method. In your visitor you can make your custom types to represent JSON values. There may be an O(n) space container (such as stack) in your visitor to record the object / array hierarchy.\n\n```go\nfunc Preorder(str string, visitor Visitor, opts *VisitorOptions) error\n\ntype Visitor interface {\n    OnNull() error\n    OnBool(v bool) error\n    OnString(v string) error\n    OnInt64(v int64, n json.Number) error\n    OnFloat64(v float64, n json.Number) error\n    OnObjectBegin(capacity int) error\n    OnObjectKey(key string) error\n    OnObjectEnd() error\n    OnArrayBegin(capacity int) error\n    OnArrayEnd() error\n}\n```\n\nSee [ast/visitor.go](https://github.com/bytedance/sonic/blob/main/ast/visitor.go) for detailed usage. We also implement a demo visitor for `UserNode` in [ast/visitor_test.go](https://github.com/bytedance/sonic/blob/main/ast/visitor_test.go).\n\n## Compatibility\n\nFor developers who want to use sonic to meet different scenarios, we provide some integrated configs as `sonic.API`\n\n- `ConfigDefault`: the sonic's default config (`EscapeHTML=false`,`SortKeys=false`...) to run sonic fast meanwhile ensure security.\n- `ConfigStd`: the std-compatible config (`EscapeHTML=true`,`SortKeys=true`...)\n- `ConfigFastest`: the fastest config (`NoQuoteTextMarshaler=true`) to run on sonic as fast as possible.\nSonic **DOES NOT** ensure to support all environments, due to the difficulty of developing high-performance codes. On non-sonic-supporting environment, the implementation will fall back to `encoding/json`. Thus below configs will all equal to `ConfigStd`.\n\n## Tips\n\n### Pretouch\n\nSince Sonic uses [golang-asm](https://github.com/twitchyliquid64/golang-asm) as a JIT assembler, which is NOT very suitable for runtime compiling, first-hit running of a huge schema may cause request-timeout or even process-OOM. For better stability, we advise **using `Pretouch()` for huge-schema or compact-memory applications** before `Marshal()/Unmarshal()`.\n\n```go\nimport (\n    \"reflect\"\n    \"github.com/bytedance/sonic\"\n    \"github.com/bytedance/sonic/option\"\n)\n\nfunc init() {\n    var v HugeStruct\n\n    // For most large types (nesting depth <= option.DefaultMaxInlineDepth)\n    err := sonic.Pretouch(reflect.TypeOf(v))\n\n    // with more CompileOption...\n    err := sonic.Pretouch(reflect.TypeOf(v),\n        // If the type is too deep nesting (nesting depth > option.DefaultMaxInlineDepth),\n        // you can set compile recursive loops in Pretouch for better stability in JIT.\n        option.WithCompileRecursiveDepth(loop),\n        // For a large nested struct, try to set a smaller depth to reduce compiling time.\n        option.WithCompileMaxInlineDepth(depth),\n    )\n}\n```\n\n### Copy string\n\nWhen decoding **string values without any escaped characters**, sonic references them from the origin JSON buffer instead of mallocing a new buffer to copy. This helps a lot for CPU performance but may leave the whole JSON buffer in memory as long as the decoded objects are being used. In practice, we found the extra memory introduced by referring JSON buffer is usually 20% ~ 80% of decoded objects. Once an application holds these objects for a long time (for example, cache the decoded objects for reusing), its in-use memory on the server may go up. - `Config.CopyString`/`decoder.CopyString()`: We provide the option for `Decode()` / `Unmarshal()` users to choose not to reference the JSON buffer, which may cause a decline in CPU performance to some degree.\n\n- `GetFromStringNoCopy()`: For memory safety, `sonic.Get()` / `sonic.GetFromString()` now copies return JSON. If users want to get json more quickly and not care about memory usage, you can use `GetFromStringNoCopy()` to return a JSON directly referenced from source.\n\n### Pass string or []byte?\n\nFor alignment to `encoding/json`, we provide API to pass `[]byte` as an argument, but the string-to-bytes copy is conducted at the same time considering safety, which may lose performance when the origin JSON is huge. Therefore, you can use `UnmarshalString()` and `GetFromString()` to pass a string, as long as your origin data is a string or **nocopy-cast** is safe for your []byte. We also provide API `MarshalString()` for convenient **nocopy-cast** of encoded JSON []byte, which is safe since sonic's output bytes is always duplicated and unique.\n\n### Accelerate `encoding.TextMarshaler`\n\nTo ensure data security, sonic.Encoder quotes and escapes string values from `encoding.TextMarshaler` interfaces by default, which may degrade performance much if most of your data is in form of them. We provide `encoder.NoQuoteTextMarshaler` to skip these operations, which means you **MUST** ensure their output string escaped and quoted following [RFC8259](https://datatracker.ietf.org/doc/html/rfc8259).\n\n### Better performance for generic data\n\nIn **fully-parsed** scenario, `Unmarshal()` performs better than `Get()`+`Node.Interface()`. But if you only have a part of the schema for specific json, you can combine `Get()` and `Unmarshal()` together:\n\n```go\nimport \"github.com/bytedance/sonic\"\n\nnode, err := sonic.GetFromString(_TwitterJson, \"statuses\", 3, \"user\")\nvar user User // your partial schema...\nerr = sonic.UnmarshalString(node.Raw(), &user)\n```\n\nEven if you don't have any schema, use `ast.Node` as the container of generic values instead of `map` or `interface`:\n\n```go\nimport \"github.com/bytedance/sonic\"\n\nroot, err := sonic.GetFromString(_TwitterJson)\nuser := root.GetByPath(\"statuses\", 3, \"user\")  // === root.Get(\"status\").Index(3).Get(\"user\")\nerr = user.Check()\n\n// err = user.LoadAll() // only call this when you want to use 'user' concurrently...\ngo someFunc(user)\n```\n\nWhy? Because `ast.Node` stores its children using `array`:\n\n- `Array`'s performance is **much better** than `Map` when Inserting (Deserialize) and Scanning (Serialize) data;\n- **Hashing** (`map[x]`) is not as efficient as **Indexing** (`array[x]`), which `ast.Node` can conduct on **both array and object**;\n- Using `Interface()`/`Map()` means Sonic must parse all the underlying values, while `ast.Node` can parse them **on demand**.\n\n**CAUTION:** `ast.Node` **DOESN'T** ensure concurrent security directly, due to its **lazy-load** design. However, you can call `Node.Load()`/`Node.LoadAll()` to achieve that, which may bring performance reduction while it still works faster than converting to `map` or `interface{}`\n\n### Ast.Node or Ast.Visitor?\n\nFor generic data, `ast.Node` should be enough for your needs in most cases.\n\nHowever, `ast.Node` is designed for partially processing JSON string. It has some special designs such as lazy-load which might not be suitable for directly parsing the whole JSON string like `Unmarshal()`. Although `ast.Node` is better then `map` or `interface{}`, it's also a kind of intermediate representation after all if your final types are customized and you have to convert the above types to your custom types after parsing.\n\nFor better performance, in previous case the `ast.Visitor` will be the better choice. It performs JSON decoding like `Unmarshal()` and you can directly use your final types to represents a JSON AST without any intermediate representations.\n\nBut `ast.Visitor` is not a very handy API. You might need to write a lot of code to implement your visitor and carefully maintain the tree hierarchy during decoding. Please read the comments in [ast/visitor.go](https://github.com/bytedance/sonic/blob/main/ast/visitor.go) carefully if you decide to use this API.\n\n### Buffer Size\n\nSonic use memory pool in many places like `encoder.Encode`, `ast.Node.MarshalJSON` to improve performance, which may produce more memory usage (in-use) when server's load is high. See [issue 614](https://github.com/bytedance/sonic/issues/614). Therefore, we introduce some options to let user control the behavior of memory pool. See [option](https://pkg.go.dev/github.com/bytedance/sonic@v1.11.9/option#pkg-variables) package.\n\n### Faster JSON Skip\n\nFor security, sonic use [FSM](native/skip_one.c) algorithm to  validate JSON when decoding raw JSON or encoding `json.Marshaler`, which is much slower (1~10x) than [SIMD-searching-pair](native/skip_one_fast.c) algorithm. If user has many redundant JSON value and DO NOT NEED to strictly validate JSON correctness, you can enable below options:\n\n- `Config.NoValidateSkipJSON`: for faster skipping JSON when decoding, such as unknown fields, json.Unmarshaler(json.RawMessage), mismatched values, and redundant array elements\n- `Config.NoValidateJSONMarshaler`: avoid validating JSON when encoding `json.Marshaler`\n- `SearchOption.ValidateJSON`: indicates if validate located JSON value when `Get`\n\n## JSON-Path Support (GJSON)\n\n[tidwall/gjson](https://github.com/tidwall/gjson) has provided a comprehensive and popular JSON-Path API, and\n a lot of older codes heavily relies on it. Therefore, we provides a wrapper library, which combines gjson's API with sonic's SIMD algorithm to boost up the performance. See [cloudwego/gjson](https://github.com/cloudwego/gjson).\n\n## Community\n\nSonic is a subproject of [CloudWeGo](https://www.cloudwego.io/). We are committed to building a cloud native ecosystem.\n",
      "stars_today": 12
    },
    {
      "id": 17728164,
      "name": "terraform",
      "full_name": "hashicorp/terraform",
      "description": "Terraform enables you to safely and predictably create, change, and improve infrastructure. It is a source-available tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned.",
      "html_url": "https://github.com/hashicorp/terraform",
      "stars": 47517,
      "forks": 10182,
      "language": "Go",
      "topics": [
        "cloud",
        "cloud-management",
        "graph",
        "infrastructure-as-code",
        "terraform"
      ],
      "created_at": "2014-03-13T22:25:48Z",
      "updated_at": "2026-01-24T19:54:59Z",
      "pushed_at": "2026-01-23T15:33:49Z",
      "open_issues": 1924,
      "owner": {
        "login": "hashicorp",
        "avatar_url": "https://avatars.githubusercontent.com/u/761456?v=4"
      },
      "readme": "# Terraform\n\n- Website: https://developer.hashicorp.com/terraform\n- Forums: [HashiCorp Discuss](https://discuss.hashicorp.com/c/terraform-core)\n- Documentation: [https://developer.hashicorp.com/terraform/docs](https://developer.hashicorp.com/terraform/docs)\n- Tutorials: [HashiCorp's Learn Platform](https://developer.hashicorp.com/terraform/tutorials)\n- Certification Exam: [HashiCorp Certified: Terraform Associate](https://www.hashicorp.com/certification/#hashicorp-certified-terraform-associate)\n\n<img alt=\"Terraform\" src=\"https://www.datocms-assets.com/2885/1731373310-terraform_white.svg\" width=\"600px\">\n\nTerraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions.\n\nThe key features of Terraform are:\n\n- **Infrastructure as Code**: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used.\n\n- **Execution Plans**: Terraform has a \"planning\" step where it generates an execution plan. The execution plan shows what Terraform will do when you call apply. This lets you avoid any surprises when Terraform manipulates infrastructure.\n\n- **Resource Graph**: Terraform builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, Terraform builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure.\n\n- **Change Automation**: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what Terraform will change and in what order, avoiding many possible human errors.\n\nFor more information, refer to the [What is Terraform?](https://www.terraform.io/intro) page on the Terraform website.\n\n## Getting Started & Documentation\n\nDocumentation is available on the [Terraform website](https://developer.hashicorp.com/terraform):\n\n- [Introduction](https://developer.hashicorp.com/terraform/intro)\n- [Documentation](https://developer.hashicorp.com/terraform/docs)\n\nIf you're new to Terraform and want to get started creating infrastructure, please check out our [Getting Started guides](https://learn.hashicorp.com/terraform#getting-started) on HashiCorp's learning platform. There are also [additional guides](https://learn.hashicorp.com/terraform#operations-and-development) to continue your learning.\n\nShow off your Terraform knowledge by passing a certification exam. Visit the [certification page](https://www.hashicorp.com/certification/) for information about exams and find [study materials](https://learn.hashicorp.com/terraform/certification/terraform-associate) on HashiCorp's learning platform.\n\n## Developing Terraform\n\nThis repository contains only Terraform core, which includes the command line interface and the main graph engine. Providers are implemented as plugins, and Terraform can automatically download providers that are published on [the Terraform Registry](https://registry.terraform.io). HashiCorp develops some providers, and others are developed by other organizations. For more information, refer to [Plugin development](https://developer.hashicorp.com/terraform/plugin).\n\n- To learn more about compiling Terraform and contributing suggested changes, refer to [the contributing guide](.github/CONTRIBUTING.md).\n\n- To learn more about how we handle bug reports, refer to the [bug triage guide](./BUGPROCESS.md).\n\n- To learn how to contribute to the Terraform documentation, refer to the [Web Unified Docs repository](https://github.com/hashicorp/web-unified-docs).\n\n## License\n\n[Business Source License 1.1](https://github.com/hashicorp/terraform/blob/main/LICENSE)\n",
      "stars_today": 11
    },
    {
      "id": 671654508,
      "name": "biome",
      "full_name": "biomejs/biome",
      "description": "A toolchain for web projects, aimed to provide functionalities to maintain them. Biome offers formatter and linter, usable via CLI and LSP.",
      "html_url": "https://github.com/biomejs/biome",
      "stars": 23290,
      "forks": 828,
      "language": "Rust",
      "topics": [
        "css",
        "formatter",
        "javascript",
        "json",
        "jsx",
        "linter",
        "static-code-analysis",
        "typescript",
        "web"
      ],
      "created_at": "2023-07-27T20:30:22Z",
      "updated_at": "2026-01-25T01:50:19Z",
      "pushed_at": "2026-01-25T00:19:58Z",
      "open_issues": 491,
      "owner": {
        "login": "biomejs",
        "avatar_url": "https://avatars.githubusercontent.com/u/140182603?v=4"
      },
      "readme": "<div align=\"center\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-dark-transparent.svg\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-light-transparent.svg\">\n    <img alt=\"Shows the banner of Biome, with its logo and the phrase 'Biome - Toolchain of the web'.\" src=\"https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-light-transparent.svg\" width=\"700\">\n  </picture>\n\n  <br>\n  <br>\n\n  [![CI on main][ci-badge]][ci-url]\n  [![Discord chat][discord-badge]][discord-url]\n  [![npm version][npm-badge]][npm-url]\n  [![VSCode version][vscode-badge]][vscode-url]\n  [![Open VSX version][open-vsx-badge]][open-vsx-url]\n\n  [ci-badge]: https://github.com/biomejs/biome/actions/workflows/main.yml/badge.svg\n  [ci-url]: https://github.com/biomejs/biome/actions/workflows/main.yml\n  [discord-badge]: https://badgen.net/discord/online-members/BypW39g6Yc?icon=discord&label=discord&color=60a5fa\n  [discord-url]: https://biomejs.dev/chat\n  [npm-badge]: https://badgen.net/npm/v/@biomejs/biome?icon=npm&color=60a5fa&label=%40biomejs%2Fbiome\n  [npm-url]: https://www.npmjs.com/package/@biomejs/biome/v/latest\n  [vscode-badge]: https://img.shields.io/visual-studio-marketplace/v/biomejs.biome?label=Visual%20Studio%20Marketplace&labelColor=374151&color=60a5fa\n  [vscode-url]: https://marketplace.visualstudio.com/items?itemName=biomejs.biome\n  [open-vsx-badge]: https://img.shields.io/visual-studio-marketplace/v/biomejs.biome?label=Open%20VSX%20Registry&logo=data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPHN2ZyB2aWV3Qm94PSI0LjYgNSA5Ni4yIDEyMi43IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogIDxwYXRoIGQ9Ik0zMCA0NC4yTDUyLjYgNUg3LjN6TTQuNiA4OC41aDQ1LjNMMjcuMiA0OS40em01MSAwbDIyLjYgMzkuMiAyMi42LTM5LjJ6IiBmaWxsPSIjYzE2MGVmIi8+CiAgPHBhdGggZD0iTTUyLjYgNUwzMCA0NC4yaDQ1LjJ6TTI3LjIgNDkuNGwyMi43IDM5LjEgMjIuNi0zOS4xem01MSAwTDU1LjYgODguNWg0NS4yeiIgZmlsbD0iI2E2MGVlNSIvPgo8L3N2Zz4=&labelColor=374151&color=60a5fa\n  [open-vsx-url]: https://open-vsx.org/extension/biomejs/biome\n\n<!-- Insert new entries lexicographically by language code.\n     For example given below is the same order as these files appear on page:\n     https://github.com/biomejs/biome/tree/main/packages/@biomejs/biome -->\n\n  [à¤¹à¤¿à¤¨à¥à¤¦à¥€](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.hi.md) | English | [EspaÃ±ol](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.es.md) | [FranÃ§ais](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.fr.md) | [ç¹é«”ä¸­æ–‡](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.zh-TW.md) | [ç®€ä½“ä¸­æ–‡](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.zh-CN.md) | [æ—¥æœ¬èª](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.ja.md) | [Polski](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.pl.md) | [PortuguÃªs do Brasil](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.pt-BR.md) | [í•œêµ­ì–´](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.kr.md) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.ru.md) | [Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°](https://github.com/biomejs/biome/blob/main/packages/%40biomejs/biome/README.uk.md)\n</div>\n\n<br>\n\n**Biome** is a performant toolchain for web projects, it aims to provide developer tools to maintain the health of said projects.\n\n**Biome is a [fast formatter](./benchmark#formatting)** for _JavaScript_, _TypeScript_, _JSX_, _JSON_, _CSS_ and _GraphQL_ that scores **[97% compatibility with _Prettier_](https://console.algora.io/challenges/prettier)**.\n\n**Biome is a [performant linter](https://github.com/biomejs/biome/tree/main/benchmark#linting)** for _JavaScript_, _TypeScript_, _JSX_, _JSON_, _CSS_, and _GraphQL_ that features **[more than 340 rules](https://biomejs.dev/linter/javascript/rules/)** from ESLint, typescript-eslint, and [other sources](https://github.com/biomejs/biome/discussions/3).\nIt **outputs detailed and contextualized diagnostics** that help you to improve your code and become a better programmer!\n\n**Biome** is designed from the start to be used [interactively within an editor](https://biomejs.dev/guides/editors/first-party-extensions/).\nIt can format and lint malformed code as you are writing it.\n\n### Installation\n\n```shell\nnpm install --save-dev --save-exact @biomejs/biome\n```\n\n### Usage\n\n```shell\n# format files\nnpx @biomejs/biome format --write\n\n# lint files and apply the safe fixes\nnpx @biomejs/biome lint --write\n\n# run format, lint, etc. and apply the safe fixes\nnpx @biomejs/biome check --write\n\n# check all files against format, lint, etc. in CI environments\nnpx @biomejs/biome ci\n```\n\nIf you want to give Biome a run without installing it, use the [online playground](https://biomejs.dev/playground/), compiled to WebAssembly.\n\n## Documentation\n\nCheck out our [homepage][biomejs] to learn more about Biome,\nor directly head to the [Getting Started guide][getting-started] to start using Biome.\n\n## More about Biome\n\n**Biome** has sane defaults and it doesn't require configuration.\n\n**Biome** aims to support [all main languages][language-support] of modern web development.\n\n**Biome** [doesn't require Node.js](https://biomejs.dev/guides/manual-installation/) to function.\n\n**Biome** has first-class LSP support, with a sophisticated parser that represents the source text in full fidelity and top-notch error recovery.\n\n**Biome** wants to offer a high-quality *Developer Experience*, with descriptive diagnostics and great performance.\n\n**Biome** unifies functionalities that have previously been separate tools. Building upon a shared base allows us to provide a cohesive experience for processing code, displaying errors, parallelize work, caching, and configuration.\n\nRead more about our [project philosophy][biome-philosophy].\n\n**Biome** is [MIT licensed](https://github.com/biomejs/biome/tree/main/LICENSE-MIT) or [Apache 2.0 licensed](https://github.com/biomejs/biome/tree/main/LICENSE-APACHE) and moderated under the [Contributor Covenant Code of Conduct](https://github.com/biomejs/biome/tree/main/CODE_OF_CONDUCT.md).\n\n## Funding\n\nYou can fund the project in different ways\n\n### Project sponsorship and funding\n\nYou can sponsor or fund the project via [Open collective](https://opencollective.com/biome) or [GitHub sponsors](https://github.com/sponsors/biomejs)\n\nBiome offers a simple sponsorship program that allows companies to get visibility and recognition among various developers.\n\nBiome offers [enterprise support](https://biomejs.dev/enterprise), where Core Contributors can be employed to work on company-focused projects.\n\n## Sponsors\n\n### Platinum Sponsors\n\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://depot.dev/?utm_source=biome&utm_medium=readme\" target=\"_blank\">\n          <picture>\n            <source media=\"(prefers-color-scheme: light)\" srcset=\"https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-light@3x.png\" />\n            <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-dark@3x.png\" />\n            <img src=\"https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-light@3x.png\" width=\"600\" alt=\"Depot logo\" />\n          </picture>\n        </a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n### Silver Sponsors\n\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://l2beat.com/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://images.opencollective.com/l2beat/c2b2a27/logo/256.png\" height=\"100\" alt=\"L2BEAT logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://lokalise.com/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/14294501?s=200&v=4\" height=\"100\" alt=\"Lokalise logo\"></a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n### Bronze Sponsors\n\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://vital.io/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/25357309?s=200\" width=\"80\" alt=\"Vital logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://coderabbit.ai/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/132028505?s=200&v=4\" width=\"80\" alt=\"CodeRabbit logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://forge42.dev/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/161314831?s=200&v=4\" width=\"80\" alt=\"Forge42 logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"http://rstudio.org/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/513560?s=200&v=4\" width=\"80\" alt=\"RStudio logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://pennylane.com/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/57875210?s=200&v=4\" width=\"80\" alt=\"Pennylane logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://jetbrains.com/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.png\" width=\"100\" alt=\"JetBrains logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.egstock.co.jp/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://images.opencollective.com/egstock/b18c836/logo/256.png?height=256\" width=\"80\" alt=\"EGSTOCK, Inc. logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://www.convex.dev/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/81530787?s=200&v=4\" width=\"80\" alt=\"Convex logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://graphite.dev/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/61942612?s=200&v=4\" width=\"80\" alt=\"Graphite logo\"></a>\n      </td>\n      <td align=\"center\" valign=\"middle\">\n        <a href=\"https://kraken.tech/?utm_source=biome&utm_medium=readme\" target=\"_blank\"><img src=\"https://avatars.githubusercontent.com/u/105941848?s=200&v=4\" width=\"80\" alt=\"Kraken Tech logo\"></a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n[biomejs]: https://biomejs.dev/\n[biome-philosophy]: https://biomejs.dev/internals/philosophy/\n[language-support]: https://biomejs.dev/internals/language-support/\n[getting-started]: https://biomejs.dev/guides/getting-started/\n",
      "stars_today": 11
    },
    {
      "id": 920805662,
      "name": "documentdb",
      "full_name": "documentdb/documentdb",
      "description": "MongoDB-compatible database engine for cloud-native and open-source workloads. Built for scalability, performance, and developer productivity.",
      "html_url": "https://github.com/documentdb/documentdb",
      "stars": 3160,
      "forks": 206,
      "language": "C",
      "topics": [],
      "created_at": "2025-01-22T19:59:22Z",
      "updated_at": "2026-01-25T01:54:24Z",
      "pushed_at": "2026-01-20T08:09:15Z",
      "open_issues": 71,
      "owner": {
        "login": "documentdb",
        "avatar_url": "https://avatars.githubusercontent.com/u/204920982?v=4"
      },
      "readme": "# Introduction\n\n`DocumentDB` is a MongoDB compatible open source document database built on PostgreSQL. It offers a native implementation of a document-oriented NoSQL database, enabling seamless CRUD (Create, Read, Update, Delete) operations on BSON(Binary JSON) data types within a PostgreSQL framework. Beyond basic operations, DocumentDB empowers users to execute complex workloads, including full-text searches, geospatial queries, and vector search, delivering robust functionality and flexibility for diverse data management needs.\n\n[PostgreSQL](https://www.postgresql.org/about/) is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that safely store and scale the most complicated data workloads.\n\n## Components\n\nThe project comprises of three components, which work together to support document operations.\n\n- **pg_documentdb_core :** PostgreSQL extension introducing BSON datatype support and operations for native Postgres.\n- **pg_documentdb :** The public API surface for DocumentDB providing CRUD functionality on documents in the store.\n- **pg_documentdb_gw :** The gateway protocol translation layer that converts the user's MongoDB APIs into PostgreSQL queries.\n\n## Why DocumentDB ?\n\nAt DocumentDB, we believe in the power of open-source to drive innovation and collaboration. Our commitment to being a fully open-source MongoDB compatible document database means that we are dedicated to transparency, community involvement, and continuous improvement. We are open-sourced under the most permissive [MIT](https://opensource.org/license/mit) license, where developers and organizations alike have no restrictions incorporating the project into new and existing solutions of their own. DocumentDB introduces the BSON data type to PostgreSQL and provides APIs for seamless operation within native PostgreSQL, enhancing efficiency and aligning with operational advantages.\n\nDocumentDB also provides a powerful on-premise solution, allowing organizations to maintain full control over their data and infrastructure. This flexibility ensures that you can deploy it in your own environment, meeting your specific security, compliance, and performance requirements. With DocumentDB, you get the best of both worlds: the innovation of open-source and the control of on-premise deployment.\n\n### Based on Postgres\n\nWe chose PostgreSQL as our platform for several reasons:\n\n1. **Proven Stability and Performance**: PostgreSQL has a long history of stability and performance, making it a trusted choice for mission-critical applications.\n2. **Extensibility**: The extensible architecture of PostgreSQL allows us to integrate a DocumentDB API on BSON data type seamlessly, providing the flexibility to handle both relational and document data.\n3. **Active Community**: PostgreSQL has a vibrant and active community that continuously contributes to its development, ensuring that it remains at the forefront of database technology.\n4. **Advanced Features**: PostgreSQL offers a rich feature set, including advanced indexing, full-text search, and powerful querying capabilities, which enhance the functionality of DocumentDB.\n5. **Compliance and Security**: PostgreSQL's robust security features and compliance with various standards makes it an ideal choice for organizations with stringent security and regulatory requirements.\n\n## Get Started\n\n[Building From Source](/docs/v1/building.md)\n\n### Prerequisites\n- Python 3.7+\n- pip package manager\n- Docker\n- Git (for cloning the repository)\n\nStep 1: Install Python\n\n```bash\n\npip install pymongo\n\n```\n\nStep 2. Install optional dependencies\n\n```bash\n\npip install dnspython\n\n```\n\nStep 3. Setup DocumentDB using Docker\n\n```bash\n\n   # Pull the latest DocumentDB Docker image\n   docker pull ghcr.io/documentdb/documentdb/documentdb-local:latest\n\n   # Tag the image for convenience\n   docker tag ghcr.io/documentdb/documentdb/documentdb-local:latest documentdb\n\n   # Run the container with your chosen username and password\n   docker run -dt -p 10260:10260 --name documentdb-container documentdb --username <YOUR_USERNAME> --password <YOUR_PASSWORD>\n   docker image rm -f ghcr.io/documentdb/documentdb/documentdb-local:latest || echo \"No existing documentdb image to remove\"\n\n```\n\n   > **Note:** Replace `<YOUR_USERNAME>` and `<YOUR_PASSWORD>` with your desired credentials. You must set these when creating the container for authentication to work.\n   > \n   > **Port Note:** Port `10260` is used by default in these instructions to avoid conflicts with other local database services. You can use port `27017` (the standard MongoDB port) or any other available port if you prefer. If you do, be sure to update the port number in both your `docker run` command and your connection string accordingly.\n\nStep 4: Initialize the pymongo client with the credentials from the previous step\n\n```python\n\nimport pymongo\n\nfrom pymongo import MongoClient\n\n# Create a MongoDB client and open a connection to DocumentDB\nclient = pymongo.MongoClient(\n    'mongodb://<YOUR_USERNAME>:<YOUR_PASSWORD>@localhost:10260/?tls=true&tlsAllowInvalidCertificates=true'\n)\n\n```\n\nStep 5: Create a database and collection\n\n```python\n\nquickStartDatabase = client[\"quickStartDatabase\"]\nquickStartCollection = quickStartDatabase.create_collection(\"quickStartCollection\")\n\n```\n\nStep 6: Insert documents\n\n```python\n\n# Insert a single document\nquickStartCollection.insert_one({\n       'name': 'John Doe',\n       'email': 'john@email.com',\n       'address': '123 Main St, Anytown, USA',\n       'phone': '555-1234'\n   })\n\n# Insert multiple documents\nquickStartCollection.insert_many([\n    {\n        'name': 'Jane Smith',\n        'email': 'jane@email.com',\n        'address': '456 Elm St, Othertown, USA',\n        'phone': '555-5678'\n    },\n    {\n        'name': 'Alice Johnson',\n        'email': 'alice@email.com',\n        'address': '789 Oak St, Sometown, USA',\n        'phone': '555-8765'\n    }\n])\n\n```\n\nStep 7: Read documents\n\n```python\n\n# Read all documents\nfor document in quickStartCollection.find():\n    print(document)\n\n# Read a specific document\nsingleDocumentReadResult = quickStartCollection.find_one({'name': 'John Doe'})\nprint(singleDocumentReadResult)\n\n```\n\nStep 8: Run aggregation pipeline operation\n\n```python\n\npipeline = [\n    {'$match': {'name': 'Alice Johnson'}},\n    {'$project': {\n        '_id': 0,\n        'name': 1,\n        'email': 1\n    }}\n]\n\nresults = quickStartCollection.aggregate(pipeline)\nprint(\"Aggregation results:\")\nfor eachDocument in results:\n    print(eachDocument)\n\n```\n\n### Helpful Links\n\n- Check out our [website](https://documentdb.io) to stay up to date with the latest on the project.\n- Check out our [docs](https://documentdb.io/docs) for MongoDB API compatibility, quickstarts and more.\n- Contributors and users can join the [DocumentDB Discord channel](https://discord.gg/vH7bYu524D) for quick collaboration.\n- Check out [FerretDB](https://github.com/FerretDB/FerretDB) and their integration of DocumentDB as a backend engine.\n",
      "stars_today": 11
    },
    {
      "id": 7691631,
      "name": "moby",
      "full_name": "moby/moby",
      "description": "The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems",
      "html_url": "https://github.com/moby/moby",
      "stars": 71416,
      "forks": 18888,
      "language": "Go",
      "topics": [
        "containers",
        "docker",
        "go",
        "golang"
      ],
      "created_at": "2013-01-18T18:10:57Z",
      "updated_at": "2026-01-24T23:15:57Z",
      "pushed_at": "2026-01-24T00:09:19Z",
      "open_issues": 3785,
      "owner": {
        "login": "moby",
        "avatar_url": "https://avatars.githubusercontent.com/u/27259197?v=4"
      },
      "readme": "The Moby Project\n================\n\n[![PkgGoDev](https://pkg.go.dev/badge/github.com/moby/moby/v2)](https://pkg.go.dev/github.com/moby/moby/v2)\n![GitHub License](https://img.shields.io/github/license/moby/moby)\n[![Go Report Card](https://goreportcard.com/badge/github.com/moby/moby/v2)](https://goreportcard.com/report/github.com/moby/moby/v2)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/moby/moby/badge)](https://scorecard.dev/viewer/?uri=github.com/moby/moby)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10989/badge)](https://www.bestpractices.dev/projects/10989)\n\n\n![Moby Project logo](docs/static_files/moby-project-logo.png \"The Moby Project\")\n\nMoby is an open-source project created by Docker to enable and accelerate software containerization.\n\nIt provides a \"Lego set\" of toolkit components, the framework for assembling them into custom container-based systems, and a place for all container enthusiasts and professionals to experiment and exchange ideas.\nComponents include container build tools, a container registry, orchestration tools, a runtime and more, and these can be used as building blocks in conjunction with other tools and projects.\n\n## Principles\n\nMoby is an open project guided by strong principles, aiming to be modular, flexible and without too strong an opinion on user experience.\nIt is open to the community to help set its direction.\n\n- Modular: the project includes lots of components that have well-defined functions and APIs that work together.\n- Batteries included but swappable: Moby includes enough components to build fully featured container systems, but its modular architecture ensures that most of the components can be swapped by different implementations.\n- Usable security: Moby provides secure defaults without compromising usability.\n- Developer focused: The APIs are intended to be functional and useful to build powerful tools.\nThey are not necessarily intended as end user tools but as components aimed at developers.\nDocumentation and UX is aimed at developers not end users.\n\n## Audience\n\nThe Moby Project is intended for engineers, integrators and enthusiasts looking to modify, hack, fix, experiment, invent and build systems based on containers.\nIt is not for people looking for a commercially supported system, but for people who want to work and learn with open source code.\n\n## Relationship with Docker\n\nThe components and tools in the Moby Project are initially the open source components that Docker and the community have built for the Docker Project.\nNew projects can be added if they fit with the community goals. Docker is committed to using Moby as the upstream for the Docker Product.\nHowever, other projects are also encouraged to use Moby as an upstream, and to reuse the components in diverse ways, and all these uses will be treated in the same way. External maintainers and contributors are welcomed.\n\nThe Moby project is not intended as a location for support or feature requests for Docker products, but as a place for contributors to work on open source code, fix bugs, and make the code more useful.\nThe releases are supported by the maintainers, community and users, on a best efforts basis only. For customers who want enterprise or commercial support, [Docker Desktop](https://www.docker.com/products/docker-desktop/) and [Mirantis Container Runtime](https://www.mirantis.com/software/mirantis-container-runtime/) are the appropriate products for these use cases.\n\n-----\n\nLegal\n=====\n\n*Brought to you courtesy of our legal counsel. For more context,\nplease see the [NOTICE](https://github.com/moby/moby/blob/master/NOTICE) document in this repo.*\n\nUse and transfer of Moby may be subject to certain restrictions by the\nUnited States and other governments.\n\nIt is your responsibility to ensure that your use and/or transfer does not\nviolate applicable laws.\n\nFor more information, please see https://www.bis.doc.gov\n\nLicensing\n=========\nMoby is licensed under the Apache License, Version 2.0. See\n[LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full\nlicense text.\n",
      "stars_today": 10
    },
    {
      "id": 14747598,
      "name": "json-server",
      "full_name": "typicode/json-server",
      "description": "Get a full fake REST API with zero coding in less than 30 seconds (seriously)",
      "html_url": "https://github.com/typicode/json-server",
      "stars": 75601,
      "forks": 7270,
      "language": "JavaScript",
      "topics": [],
      "created_at": "2013-11-27T13:21:13Z",
      "updated_at": "2026-01-24T22:36:12Z",
      "pushed_at": "2026-01-24T00:12:03Z",
      "open_issues": 712,
      "owner": {
        "login": "typicode",
        "avatar_url": "https://avatars.githubusercontent.com/u/5502029?v=4"
      },
      "readme": "# JSON-Server\n\n[![Node.js CI](https://github.com/typicode/json-server/actions/workflows/node.js.yml/badge.svg)](https://github.com/typicode/json-server/actions/workflows/node.js.yml)\n\n> [!IMPORTANT]\n> Viewing beta v1 documentation â€“ usable but expect breaking changes. For stable version, see [here](https://github.com/typicode/json-server/tree/v0.17.4)\n\n> [!NOTE]\n> Using React âš›ï¸ and tired of CSS-in-JS? See [MistCSS](https://github.com/typicode/mistcss) ğŸ‘€\n\n## Install\n\n```shell\nnpm install json-server\n```\n\n## Usage\n\nCreate a `db.json` or `db.json5` file\n\n```json\n{\n  \"$schema\": \"./node_modules/json-server/schema.json\",\n  \"posts\": [\n    { \"id\": \"1\", \"title\": \"a title\", \"views\": 100 },\n    { \"id\": \"2\", \"title\": \"another title\", \"views\": 200 }\n  ],\n  \"comments\": [\n    { \"id\": \"1\", \"text\": \"a comment about post 1\", \"postId\": \"1\" },\n    { \"id\": \"2\", \"text\": \"another comment about post 1\", \"postId\": \"1\" }\n  ],\n  \"profile\": {\n    \"name\": \"typicode\"\n  }\n}\n```\n\n<details>\n\n<summary>View db.json5 example</summary>\n\n```json5\n{\n  posts: [\n    { id: \"1\", title: \"a title\", views: 100 },\n    { id: \"2\", title: \"another title\", views: 200 },\n  ],\n  comments: [\n    { id: \"1\", text: \"a comment about post 1\", postId: \"1\" },\n    { id: \"2\", text: \"another comment about post 1\", postId: \"1\" },\n  ],\n  profile: {\n    name: \"typicode\",\n  },\n}\n```\n\nYou can read more about JSON5 format [here](https://github.com/json5/json5).\n\n</details>\n\nPass it to JSON Server CLI\n\n```shell\n$ npx json-server db.json\n```\n\nGet a REST API\n\n```shell\n$ curl http://localhost:3000/posts/1\n{\n  \"id\": \"1\",\n  \"title\": \"a title\",\n  \"views\": 100\n}\n```\n\nRun `json-server --help` for a list of options\n\n## Sponsors âœ¨\n\n### Gold\n\n|                                                                                                                                                            |\n| :--------------------------------------------------------------------------------------------------------------------------------------------------------: |\n|               <a href=\"https://mockend.com/\" target=\"_blank\"><img src=\"https://jsonplaceholder.typicode.com/mockend.svg\" height=\"100px\"></a>               |\n| <a href=\"https://zuplo.link/json-server-gh\"><img src=\"https://github.com/user-attachments/assets/adfee31f-a8b6-4684-9a9b-af4f03ac5b75\" height=\"100px\"></a> |\n|     <a href=\"https://www.mintlify.com/\"><img src=\"https://github.com/user-attachments/assets/bcc8cc48-b2d9-4577-8939-1eb4196b7cc5\" height=\"100px\"></a>     |\n\n### Silver\n\n|                                                                                                                                                                                                                                         |\n| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |\n| <a href=\"https://requestly.com?utm_source=githubsponsor&utm_medium=jsonserver&utm_campaign=jsonserver\"><img src=\"https://github.com/user-attachments/assets/f7e7b3cf-97e2-46b8-81c8-cb3992662a1c\" style=\"height:70px; width:auto;\"></a> |\n\n### Bronze\n\n|                                                                                                                                                                                |                                                                                                                                                                              |\n| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |\n| <a href=\"https://www.storyblok.com/\" target=\"_blank\"><img src=\"https://github.com/typicode/json-server/assets/5502029/c6b10674-4ada-4616-91b8-59d30046b45a\" height=\"35px\"></a> | <a href=\"https://betterstack.com/\" target=\"_blank\"><img src=\"https://github.com/typicode/json-server/assets/5502029/44679f8f-9671-470d-b77e-26d90b90cbdc\" height=\"35px\"></a> |\n\n[Become a sponsor and have your company logo here](https://github.com/users/typicode/sponsorship)\n\n## Sponsorware\n\n> [!NOTE]\n> This project uses the [Fair Source License](https://fair.io/). Only organizations with 3+ users are kindly asked to contribute a small amount through sponsorship [sponsor](https://github.com/sponsors/typicode) for usage. **This license helps keep the project sustainable and healthy, benefiting everyone.**\n>\n> For more information, FAQs, and the rationale behind this, visit [https://fair.io/](https://fair.io/).\n\n## Routes\n\nBased on the example `db.json`, you'll get the following routes:\n\n```\nGET    /posts\nGET    /posts/:id\nPOST   /posts\nPUT    /posts/:id\nPATCH  /posts/:id\nDELETE /posts/:id\n\n# Same for comments\n```\n\n```\nGET   /profile\nPUT   /profile\nPATCH /profile\n```\n\n## Params\n\n### Conditions\n\n- ` ` â†’ `==`\n- `lt` â†’ `<`\n- `lte` â†’ `<=`\n- `gt` â†’ `>`\n- `gte` â†’ `>=`\n- `ne` â†’ `!=`\n\n```\nGET /posts?views_gt=9000\n```\n\n### Range\n\n- `start`\n- `end`\n- `limit`\n\n```\nGET /posts?_start=10&_end=20\nGET /posts?_start=10&_limit=10\n```\n\n### Paginate\n\n- `page`\n- `per_page` (default = 10)\n\n```\nGET /posts?_page=1&_per_page=25\n```\n\n### Sort\n\n- `_sort=f1,f2`\n\n```\nGET /posts?_sort=id,-views\n```\n\n### Nested and array fields\n\n- `x.y.z...`\n- `x.y.z[i]...`\n\n```\nGET /foo?a.b=bar\nGET /foo?x.y_lt=100\nGET /foo?arr[0]=bar\n```\n\n### Embed\n\n```\nGET /posts?_embed=comments\nGET /comments?_embed=post\n```\n\n## Delete\n\n```\nDELETE /posts/1\nDELETE /posts/1?_dependent=comments\n```\n\n## Serving static files\n\nIf you create a `./public` directory, JSON Server will serve its content in addition to the REST API.\n\nYou can also add custom directories using `-s/--static` option.\n\n```sh\njson-server -s ./static\njson-server -s ./static -s ./node_modules\n```\n\n## Notable differences with v0.17\n\n- `id` is always a string and will be generated for you if missing\n- use `_per_page` with `_page` instead of `_limit`for pagination\n- use Chrome's `Network tab > throtling` to delay requests instead of `--delay` CLI option\n",
      "stars_today": 10
    },
    {
      "id": 569041,
      "name": "curl",
      "full_name": "curl/curl",
      "description": "A command line tool and library for transferring data with URL syntax, supporting DICT, FILE, FTP, FTPS, GOPHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET, TFTP, WS and WSS. libcurl offers a myriad of powerful features",
      "html_url": "https://github.com/curl/curl",
      "stars": 40503,
      "forks": 7040,
      "language": "C",
      "topics": [
        "c",
        "client",
        "curl",
        "ftp",
        "gopher",
        "hacktoberfest",
        "http",
        "https",
        "imaps",
        "ldap",
        "libcurl",
        "library",
        "mqtt",
        "pop3",
        "scp",
        "sftp",
        "transfer-data",
        "transferring-data",
        "user-agent",
        "websocket"
      ],
      "created_at": "2010-03-18T22:32:22Z",
      "updated_at": "2026-01-25T02:25:25Z",
      "pushed_at": "2026-01-24T21:25:15Z",
      "open_issues": 38,
      "owner": {
        "login": "curl",
        "avatar_url": "https://avatars.githubusercontent.com/u/16928085?v=4"
      },
      "readme": "<!--\nCopyright (C) Daniel Stenberg, <daniel@haxx.se>, et al.\n\nSPDX-License-Identifier: curl\n-->\n\n# [![curl logo](https://curl.se/logo/curl-logo.svg)](https://curl.se/)\n\ncurl is a command-line tool for transferring data from or to a server using\nURLs. It supports these protocols: DICT, FILE, FTP, FTPS, GOPHER, GOPHERS,\nHTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP,\nSCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET, TFTP, WS and WSS.\n\nLearn how to use curl by reading [the\nman page](https://curl.se/docs/manpage.html) or [everything\ncurl](https://everything.curl.dev/).\n\nFind out how to install curl by reading [the INSTALL\ndocument](https://curl.se/docs/install.html).\n\nlibcurl is the library curl is using to do its job. It is readily available to\nbe used by your software. Read [the libcurl\nman page](https://curl.se/libcurl/c/libcurl.html) to learn how.\n\n## Open Source\n\ncurl is Open Source and is distributed under an MIT-like\n[license](https://curl.se/docs/copyright.html).\n\n## Contact\n\nContact us on a suitable [mailing list](https://curl.se/mail/) or\nuse GitHub [issues](https://github.com/curl/curl/issues)/\n[pull requests](https://github.com/curl/curl/pulls)/\n[discussions](https://github.com/curl/curl/discussions).\n\nAll contributors to the project are listed in [the THANKS\ndocument](https://curl.se/docs/thanks.html).\n\n## Commercial support\n\nFor commercial support, maybe private and dedicated help with your problems or\napplications using (lib)curl visit [the support page](https://curl.se/support.html).\n\n## Website\n\nVisit the [curl website](https://curl.se/) for the latest news and downloads.\n\n## Source code\n\nDownload the latest source from the Git server:\n\n    git clone https://github.com/curl/curl\n\n## Security problems\n\nReport suspected security problems via [our HackerOne\npage](https://hackerone.com/curl) and not in public.\n\n## Backers\n\nThank you to all our backers :pray: [Become a backer](https://opencollective.com/curl#section-contribute).\n\n## Sponsors\n\nSupport this project by becoming a [sponsor](https://curl.se/sponsors.html).\n",
      "stars_today": 10
    },
    {
      "id": 59771425,
      "name": "zephyr",
      "full_name": "zephyrproject-rtos/zephyr",
      "description": "Primary Git Repository for the Zephyr Project. Zephyr is a new generation, scalable, optimized, secure RTOS for multiple hardware architectures.",
      "html_url": "https://github.com/zephyrproject-rtos/zephyr",
      "stars": 14272,
      "forks": 8551,
      "language": "C",
      "topics": [
        "bluetooth",
        "bluetooth-le",
        "embedded",
        "embedded-c",
        "iot",
        "mcu",
        "microcontroller",
        "real-time",
        "rtos",
        "zephyr",
        "zephyr-rtos",
        "zephyros"
      ],
      "created_at": "2016-05-26T17:54:19Z",
      "updated_at": "2026-01-24T23:13:17Z",
      "pushed_at": "2026-01-24T14:52:47Z",
      "open_issues": 3419,
      "owner": {
        "login": "zephyrproject-rtos",
        "avatar_url": "https://avatars.githubusercontent.com/u/19595895?v=4"
      },
      "readme": ".. raw:: html\n\n   <a href=\"https://www.zephyrproject.org\">\n     <p align=\"center\">\n       <picture>\n         <source media=\"(prefers-color-scheme: dark)\" srcset=\"doc/_static/images/logo-readme-dark.svg\">\n         <source media=\"(prefers-color-scheme: light)\" srcset=\"doc/_static/images/logo-readme-light.svg\">\n         <img src=\"doc/_static/images/logo-readme-light.svg\">\n       </picture>\n     </p>\n   </a>\n\n   <a href=\"https://bestpractices.coreinfrastructure.org/projects/74\"><img src=\"https://bestpractices.coreinfrastructure.org/projects/74/badge\"></a>\n   <a href=\"https://scorecard.dev/viewer/?uri=github.com/zephyrproject-rtos/zephyr\"><img src=\"https://api.securityscorecards.dev/projects/github.com/zephyrproject-rtos/zephyr/badge\"></a>\n   <a href=\"https://github.com/zephyrproject-rtos/zephyr/actions/workflows/twister.yaml?query=branch%3Amain\"><img src=\"https://github.com/zephyrproject-rtos/zephyr/actions/workflows/twister.yaml/badge.svg?event=push\"></a>\n\n\nThe Zephyr Project is a scalable real-time operating system (RTOS) supporting\nmultiple hardware architectures, optimized for resource constrained devices,\nand built with security in mind.\n\nThe Zephyr OS is based on a small-footprint kernel designed for use on\nresource-constrained systems: from simple embedded environmental sensors and\nLED wearables to sophisticated smart watches and IoT wireless gateways.\n\nThe Zephyr kernel supports multiple architectures, including ARM (Cortex-A,\nCortex-R, Cortex-M), Intel x86, ARC, Tensilica Xtensa, and RISC-V,\nSPARC, MIPS, and a large number of `supported boards`_.\n\n.. below included in doc/introduction/introduction.rst\n\n\nGetting Started\n***************\n\nWelcome to Zephyr! See the `Introduction to Zephyr`_ for a high-level overview,\nand the documentation's `Getting Started Guide`_ to start developing.\n\n.. start_include_here\n\nCommunity Support\n*****************\n\nCommunity support is provided via mailing lists and Discord; see the Resources\nbelow for details.\n\n.. _project-resources:\n\nResources\n*********\n\nHere's a quick summary of resources to help you find your way around:\n\nGetting Started\n---------------\n\n  | ğŸ“– `Zephyr Documentation`_\n  | ğŸš€ `Getting Started Guide`_\n  | ğŸ™‹ğŸ½ `Tips when asking for help`_\n  | ğŸ’» `Code samples`_\n\nCode and Development\n--------------------\n\n  | ğŸŒ `Source Code Repository`_\n  | ğŸ“¦ `Releases`_\n  | ğŸ¤ `Contribution Guide`_\n\nCommunity and Support\n---------------------\n\n  | ğŸ’¬ `Discord Server`_ for real-time community discussions\n  | ğŸ“§ `User mailing list (users@lists.zephyrproject.org)`_\n  | ğŸ“§ `Developer mailing list (devel@lists.zephyrproject.org)`_\n  | ğŸ“¬ `Other project mailing lists`_\n  | ğŸ“š `Project Wiki`_\n\nIssue Tracking and Security\n---------------------------\n\n  | ğŸ› `GitHub Issues`_\n  | ğŸ”’ `Security documentation`_\n  | ğŸ›¡ï¸ `Security Advisories Repository`_\n  | âš ï¸ Report security vulnerabilities at vulnerabilities@zephyrproject.org\n\nAdditional Resources\n--------------------\n  | ğŸŒ `Zephyr Project Website`_\n  | ğŸ“º `Zephyr Tech Talks`_\n\n.. _Zephyr Project Website: https://www.zephyrproject.org\n.. _Discord Server: https://chat.zephyrproject.org\n.. _supported boards: https://docs.zephyrproject.org/latest/boards/index.html\n.. _Zephyr Documentation: https://docs.zephyrproject.org\n.. _Introduction to Zephyr: https://docs.zephyrproject.org/latest/introduction/index.html\n.. _Getting Started Guide: https://docs.zephyrproject.org/latest/develop/getting_started/index.html\n.. _Contribution Guide: https://docs.zephyrproject.org/latest/contribute/index.html\n.. _Source Code Repository: https://github.com/zephyrproject-rtos/zephyr\n.. _GitHub Issues: https://github.com/zephyrproject-rtos/zephyr/issues\n.. _Releases: https://github.com/zephyrproject-rtos/zephyr/releases\n.. _Project Wiki: https://github.com/zephyrproject-rtos/zephyr/wiki\n.. _User mailing list (users@lists.zephyrproject.org): https://lists.zephyrproject.org/g/users\n.. _Developer mailing list (devel@lists.zephyrproject.org): https://lists.zephyrproject.org/g/devel\n.. _Other project mailing lists: https://lists.zephyrproject.org/g/main/subgroups\n.. _Code samples: https://docs.zephyrproject.org/latest/samples/index.html\n.. _Security documentation: https://docs.zephyrproject.org/latest/security/index.html\n.. _Security Advisories Repository: https://github.com/zephyrproject-rtos/zephyr/security\n.. _Tips when asking for help: https://docs.zephyrproject.org/latest/develop/getting_started/index.html#asking-for-help\n.. _Zephyr Tech Talks: https://www.zephyrproject.org/tech-talks\n",
      "stars_today": 10
    },
    {
      "id": 17420913,
      "name": "cargo",
      "full_name": "rust-lang/cargo",
      "description": "The Rust package manager",
      "html_url": "https://github.com/rust-lang/cargo",
      "stars": 14492,
      "forks": 2788,
      "language": "Rust",
      "topics": [
        "cargo",
        "package-manager",
        "rust"
      ],
      "created_at": "2014-03-04T23:20:42Z",
      "updated_at": "2026-01-24T17:31:43Z",
      "pushed_at": "2026-01-23T23:43:25Z",
      "open_issues": 1576,
      "owner": {
        "login": "rust-lang",
        "avatar_url": "https://avatars.githubusercontent.com/u/5430905?v=4"
      },
      "readme": "# Cargo\n\nCargo downloads your Rust projectâ€™s dependencies and compiles your project.\n\n**To start using Cargo**, learn more at [The Cargo Book].\n\n**To start developing Cargo itself**, read the [Cargo Contributor Guide].\n\n[The Cargo Book]: https://doc.rust-lang.org/cargo/\n[Cargo Contributor Guide]: https://rust-lang.github.io/cargo/contrib/\n\n> The Cargo binary distributed through with Rust is maintained by the Cargo\n> team for use by the wider ecosystem.\n> For all other uses of this crate (as a binary or library) this is maintained\n> by the Cargo team, primarily for use by Cargo and not intended for external\n> use (except as a transitive dependency). This crate may make major changes to\n> its APIs.\n\n## Code Status\n\n[![CI](https://github.com/rust-lang/cargo/actions/workflows/main.yml/badge.svg?branch=auto-cargo)](https://github.com/rust-lang/cargo/actions/workflows/main.yml)\n\nCode documentation: <https://doc.rust-lang.org/nightly/nightly-rustc/cargo/>\n\n## Compiling from Source\n\n### Requirements\n\nCargo requires the following tools and packages to build:\n\n* `cargo` and `rustc`\n* A C compiler [for your platform](https://github.com/rust-lang/cc-rs#compile-time-requirements)\n* `git` (to clone this repository)\n\n**Other requirements:**\n\nThe following are optional based on your platform and needs.\n\n* `pkg-config` â€” This is used to help locate system packages, such as `libssl` headers/libraries. This may not be required in all cases, such as using vendored OpenSSL, or on Windows.\n* OpenSSL â€” Only needed on Unix-like systems and only if the `vendored-openssl` Cargo feature is not used.\n\n  This requires the development headers, which can be obtained from the `libssl-dev` package on Ubuntu or `openssl-devel` with apk or yum or the `openssl` package from Homebrew on macOS.\n\n  If using the `vendored-openssl` Cargo feature, then a static copy of OpenSSL will be built from source instead of using the system OpenSSL.\n  This may require additional tools such as `perl` and `make`.\n\n  On macOS, common installation directories from Homebrew, MacPorts, or pkgsrc will be checked. Otherwise it will fall back to `pkg-config`.\n\n  On Windows, the system-provided Schannel will be used instead.\n\n  LibreSSL is also supported.\n\n**Optional system libraries:**\n\nThe build will automatically use vendored versions of the following libraries. However, if they are provided by the system and can be found with `pkg-config`, then the system libraries will be used instead:\n\n* [`libcurl`](https://curl.se/libcurl/) â€” Used for network transfers.\n* [`libgit2`](https://libgit2.org/) â€” Used for fetching git dependencies.\n* [`libssh2`](https://www.libssh2.org/) â€” Used for SSH access to git repositories.\n* [`libz`](https://zlib.net/) (AKA zlib) â€” Used by the above C libraries for data compression. (Rust code uses [`zlib-rs`](https://github.com/trifectatechfoundation/zlib-rs) instead.)\n\nIt is recommended to use the vendored versions as they are the versions that are tested to work with Cargo.\n\n### Compiling\n\nFirst, you'll want to check out this repository\n\n```\ngit clone https://github.com/rust-lang/cargo.git\ncd cargo\n```\n\nWith `cargo` already installed, you can simply run:\n\n```\ncargo build --release\n```\n\n## Adding new subcommands to Cargo\n\nCargo is designed to be extensible with new subcommands without having to modify\nCargo itself. See [the Wiki page][third-party-subcommands] for more details and\na list of known community-developed subcommands.\n\n[third-party-subcommands]: https://github.com/rust-lang/cargo/wiki/Third-party-cargo-subcommands\n\n\n## Releases\n\nCargo releases coincide with Rust releases.\nHigh level release notes are available as part of [Rust's release notes][rel].\nDetailed release notes are available in the [changelog].\n\n[rel]: https://github.com/rust-lang/rust/blob/master/RELEASES.md\n[changelog]: https://doc.rust-lang.org/nightly/cargo/CHANGELOG.html\n\n## Reporting issues\n\nFound a bug? We'd love to know about it!\n\nPlease report all issues on the GitHub [issue tracker][issues].\n\n[issues]: https://github.com/rust-lang/cargo/issues\n\n## Contributing\n\nSee the **[Cargo Contributor Guide]** for a complete introduction\nto contributing to Cargo.\n\n## License\n\nCargo is primarily distributed under the terms of both the MIT license\nand the Apache License (Version 2.0).\n\nSee [LICENSE-APACHE](LICENSE-APACHE) and [LICENSE-MIT](LICENSE-MIT) for details.\n\n### Third party software\n\nThis product includes software developed by the OpenSSL Project\nfor use in the OpenSSL Toolkit (https://www.openssl.org/).\n\nIn binary form, this product includes software that is licensed under the\nterms of the GNU General Public License, version 2, with a linking exception,\nwhich can be obtained from the [upstream repository][1].\n\nSee [LICENSE-THIRD-PARTY](LICENSE-THIRD-PARTY) for details.\n\n[1]: https://github.com/libgit2/libgit2\n\n",
      "stars_today": 9
    },
    {
      "id": 40217904,
      "name": "sway",
      "full_name": "swaywm/sway",
      "description": "i3-compatible Wayland compositor",
      "html_url": "https://github.com/swaywm/sway",
      "stars": 16494,
      "forks": 1231,
      "language": "C",
      "topics": [
        "compositor",
        "wayland"
      ],
      "created_at": "2015-08-05T01:31:45Z",
      "updated_at": "2026-01-25T01:55:04Z",
      "pushed_at": "2026-01-14T09:33:52Z",
      "open_issues": 1299,
      "owner": {
        "login": "swaywm",
        "avatar_url": "https://avatars.githubusercontent.com/u/32400794?v=4"
      },
      "readme": "# sway\n\n**[English][en]** - [Ø¹Ø±Ø¨ÙŠ][ar] - [AzÉ™rbaycanca][az] - [ÄŒesky][cs] - [Deutsch][de] - [Dansk][dk] - [EspaÃ±ol][es] - [FranÃ§ais][fr] - [áƒ¥áƒáƒ áƒ—áƒ£áƒšáƒ˜][ge] - [Î•Î»Î»Î·Î½Î¹ÎºÎ¬][gr] - [à¤¹à¤¿à¤¨à¥à¤¦à¥€][hi] - [Magyar][hu] - [ÙØ§Ø±Ø³ÛŒ][ir] - [Italiano][it] - [æ—¥æœ¬èª][ja] - [í•œêµ­ì–´][ko] - [Nederlands][nl] - [Norsk][no] - [Polski][pl] - [PortuguÃªs][pt] - [RomÃ¢nÄƒ][ro] - [Ğ ÑƒÑÑĞºĞ¸Ğ¹][ru] - [Ğ¡Ñ€Ğ¿ÑĞºĞ¸][sr] - [Svenska][sv] - [TÃ¼rkÃ§e][tr] - [Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°][uk] - [ä¸­æ–‡-ç®€ä½“][zh-CN] - [ä¸­æ–‡-ç¹é«”][zh-TW]\n\nsway is an [i3]-compatible [Wayland] compositor. Read the [FAQ]. Join the\n[IRC channel] \\(#sway on irc.libera.chat).\n\n## Release Signatures\n\nReleases are signed with [E88F5E48] and published [on GitHub][GitHub releases].\n\n## Installation\n\n### From Packages\n\nSway is available in many distributions. Try installing the \"sway\" package for\nyours.\n\n### Compiling from Source\n\nCheck out [this wiki page][Development setup] if you want to build the HEAD of\nsway and wlroots for testing or development.\n\nInstall dependencies:\n\n* meson \\*\n* [wlroots]\n* wayland\n* wayland-protocols \\*\n* pcre2\n* json-c\n* pango\n* cairo\n* gdk-pixbuf2 (optional: additional image formats for system tray)\n* [swaybg] (optional: wallpaper)\n* [scdoc] (optional: man pages) \\*\n* git (optional: version info) \\*\n\n_\\* Compile-time dep_\n\nRun these commands:\n\n    meson setup build/\n    ninja -C build/\n    sudo ninja -C build/ install\n\n## Configuration\n\nIf you already use i3, then copy your i3 config to `~/.config/sway/config` and\nit'll work out of the box. Otherwise, copy the sample configuration file to\n`~/.config/sway/config`. It is usually located at `/etc/sway/config`.\nRun `man 5 sway` for information on the configuration.\n\n## Running\n\nRun `sway` from a TTY or from a display manager.\n\n[en]: https://github.com/swaywm/sway#readme\n[ar]: README.ar.md\n[az]: README.az.md\n[cs]: README.cs.md\n[de]: README.de.md\n[dk]: README.dk.md\n[es]: README.es.md\n[fr]: README.fr.md\n[ge]: README.ge.md\n[gr]: README.gr.md\n[hi]: README.hi.md\n[hu]: README.hu.md\n[ir]: README.ir.md\n[it]: README.it.md\n[ja]: README.ja.md\n[ko]: README.ko.md\n[nl]: README.nl.md\n[no]: README.no.md\n[pl]: README.pl.md\n[pt]: README.pt.md\n[ro]: README.ro.md\n[ru]: README.ru.md\n[sr]: README.sr.md\n[sv]: README.sv.md\n[tr]: README.tr.md\n[uk]: README.uk.md\n[zh-CN]: README.zh-CN.md\n[zh-TW]: README.zh-TW.md\n[i3]: https://i3wm.org/\n[Wayland]: http://wayland.freedesktop.org/\n[FAQ]: https://github.com/swaywm/sway/wiki\n[IRC channel]: https://web.libera.chat/gamja/?channels=#sway\n[E88F5E48]: https://keys.openpgp.org/search?q=34FF9526CFEF0E97A340E2E40FDE7BE0E88F5E48\n[GitHub releases]: https://github.com/swaywm/sway/releases\n[Development setup]: https://github.com/swaywm/sway/wiki/Development-Setup\n[wlroots]: https://gitlab.freedesktop.org/wlroots/wlroots\n[swaybg]: https://github.com/swaywm/swaybg/\n[scdoc]: https://git.sr.ht/~sircmpwn/scdoc\n",
      "stars_today": 9
    },
    {
      "id": 654870350,
      "name": "SpacetimeDB",
      "full_name": "clockworklabs/SpacetimeDB",
      "description": "Multiplayer at the speed of light",
      "html_url": "https://github.com/clockworklabs/SpacetimeDB",
      "stars": 18941,
      "forks": 677,
      "language": "Rust",
      "topics": [
        "database",
        "dataoriented",
        "game-development",
        "relational",
        "relational-database",
        "smart-contracts"
      ],
      "created_at": "2023-06-17T07:28:29Z",
      "updated_at": "2026-01-25T01:37:38Z",
      "pushed_at": "2026-01-25T02:22:40Z",
      "open_issues": 725,
      "owner": {
        "login": "clockworklabs",
        "avatar_url": "https://avatars.githubusercontent.com/u/48072542?v=4"
      },
      "readme": "<p align=\"center\">\n    <a href=\"https://spacetimedb.com#gh-dark-mode-only\" target=\"_blank\">\n\t<img width=\"320\" src=\"./images/dark/logo.svg\" alt=\"SpacetimeDB Logo\">\n    </a>\n    <a href=\"https://spacetimedb.com#gh-light-mode-only\" target=\"_blank\">\n\t<img width=\"320\" src=\"./images/light/logo.svg\" alt=\"SpacetimeDB Logo\">\n    </a>\n</p>\n<p align=\"center\">\n    <a href=\"https://spacetimedb.com#gh-dark-mode-only\" target=\"_blank\">\n        <img width=\"250\" src=\"./images/dark/logo-text.svg\" alt=\"SpacetimeDB\">\n    </a>\n    <a href=\"https://spacetimedb.com#gh-light-mode-only\" target=\"_blank\">\n        <img width=\"250\" src=\"./images/light/logo-text.svg\" alt=\"SpacetimeDB\">\n    </a>\n    <h3 align=\"center\">\n        Multiplayer at the speed of light.\n    </h3>\n</p>\n<p align=\"center\">\n    <a href=\"https://github.com/clockworklabs/spacetimedb\"><img src=\"https://img.shields.io/github/v/release/clockworklabs/spacetimedb?color=%23ff00a0&include_prereleases&label=version&sort=semver&style=flat-square\"></a>\n    &nbsp;\n    <a href=\"https://github.com/clockworklabs/spacetimedb\"><img src=\"https://img.shields.io/badge/built_with-Rust-dca282.svg?style=flat-square\"></a>\n    &nbsp;\n\t<a href=\"https://github.com/clockworklabs/spacetimedb/actions\"><img src=\"https://img.shields.io/github/actions/workflow/status/clockworklabs/spacetimedb/ci.yml?style=flat-square&branch=master\"></a>\n    &nbsp;\n    <a href=\"https://status.spacetimedb.com\"><img src=\"https://img.shields.io/uptimerobot/ratio/7/m784409192-e472ca350bb615372ededed7?label=cloud%20uptime&style=flat-square\"></a>\n    &nbsp;\n    <a href=\"https://hub.docker.com/r/clockworklabs/spacetimedb\"><img src=\"https://img.shields.io/docker/pulls/clockworklabs/spacetimedb?style=flat-square\"></a>\n    &nbsp;\n    <a href=\"https://github.com/clockworklabs/spacetimedb/blob/master/LICENSE.txt\"><img src=\"https://img.shields.io/badge/license-BSL_1.1-00bfff.svg?style=flat-square\"></a>\n</p>\n<p align=\"center\">\n    <a href=\"https://crates.io/crates/spacetimedb\"><img src=\"https://img.shields.io/crates/d/spacetimedb?color=e45928&label=Rust%20Crate&style=flat-square\"></a>\n    &nbsp;\n    <a href=\"https://www.nuget.org/packages/SpacetimeDB.Runtime\"><img src=\"https://img.shields.io/nuget/dt/spacetimedb.runtime?color=0b6cff&label=NuGet%20Package&style=flat-square\"></a>\n</p>\n<p align=\"center\">\n    <a href=\"https://discord.gg/spacetimedb\"><img src=\"https://img.shields.io/discord/1037340874172014652?label=discord&style=flat-square&color=5a66f6\"></a>\n    &nbsp;\n    <a href=\"https://twitter.com/spacetime_db\"><img src=\"https://img.shields.io/badge/twitter-Follow_us-1d9bf0.svg?style=flat-square\"></a>\n    &nbsp;\n    <a href=\"https://clockworklabs.io/join\"><img src=\"https://img.shields.io/badge/careers-Join_us-86f7b7.svg?style=flat-square\"></a>\n    &nbsp;\n    <a href=\"https://www.linkedin.com/company/clockworklabs/\"><img src=\"https://img.shields.io/badge/linkedin-Connect_with_us-0a66c2.svg?style=flat-square\"></a>\n</p>\n\n<p align=\"center\">\n    <a href=\"https://discord.gg/spacetimedb\"><img height=\"25\" src=\"./images/social/discord.svg\" alt=\"Discord\"></a>\n    &nbsp;\n    <a href=\"https://twitter.com/spacetime_db\"><img height=\"25\" src=\"./images/social/twitter.svg\" alt=\"Twitter\"></a>\n    &nbsp;\n    <a href=\"https://github.com/clockworklabs/spacetimedb\"><img height=\"25\" src=\"./images/social/github.svg\" alt=\"GitHub\"></a>\n    &nbsp;\n    <a href=\"https://twitch.tv/SpacetimeDB\"><img height=\"25\" src=\"./images/social/twitch.svg\" alt=\"Twitch\"></a>\n    &nbsp;\n    <a href=\"https://youtube.com/@SpacetimeDB\"><img height=\"25\" src=\"./images/social/youtube.svg\" alt=\"YouTube\"></a>\n    &nbsp;\n    <a href=\"https://www.linkedin.com/company/clockwork-labs/\"><img height=\"25\" src=\"./images/social/linkedin.svg\" alt=\"LinkedIn\"></a>\n    &nbsp;\n    <a href=\"https://stackoverflow.com/questions/tagged/spacetimedb\"><img height=\"25\" src=\"./images/social/stackoverflow.svg\" alt=\"StackOverflow\"></a>\n</p>\n\n<br>\n\n## What is [SpacetimeDB](https://spacetimedb.com)?\n\nYou can think of SpacetimeDB as both a database and server combined into one.\n\nIt is a relational database system that lets you upload your application logic directly into the database by way of fancy stored procedures called \"modules.\"\n\nInstead of deploying a web or game server that sits in between your clients and your database, your clients connect directly to the database and execute your application logic inside the database itself. You can write all of your permission and authorization logic right inside your module just as you would in a normal server.\n\nThis means that you can write your entire application in a single language, Rust, and deploy it as a single binary. No more microservices, no more containers, no more Kubernetes, no more Docker, no more VMs, no more DevOps, no more infrastructure, no more ops, no more servers.\n\n<figure>\n    <img src=\"./images/basic-architecture-diagram.png\" alt=\"SpacetimeDB Architecture\" style=\"width:100%\">\n    <figcaption align=\"center\">\n        <p align=\"center\"><b>SpacetimeDB application architecture</b><br /><sup><sub>(elements in white are provided by SpacetimeDB)</sub></sup></p>\n    </figcaption>\n</figure>\n\nIt's actually similar to the idea of smart contracts, except that SpacetimeDB is a database, has nothing to do with blockchain, and is orders of magnitude faster than any smart contract system.\n\nSo fast, in fact, that the entire backend of our MMORPG [BitCraft Online](https://bitcraftonline.com) is just a SpacetimeDB module. We don't have any other servers or services running, which means that everything in the game, all of the chat messages, items, resources, terrain, and even the locations of the players are stored and processed by the database before being synchronized out to all of the clients in real-time.\n\nSpacetimeDB is optimized for maximum speed and minimum latency rather than batch processing or OLAP workloads. It is designed to be used for real-time applications like games, chat, and collaboration tools.\n\nThis speed and latency is achieved by holding all of application state in memory, while persisting the data in a write-ahead-log (WAL) which is used to recover application state.\n\n## Installation\n\nYou can run SpacetimeDB as a standalone database server via the `spacetime` CLI tool.\nInstall instructions for supported platforms are outlined below.\nThe same install instructions can be found on our website at https://spacetimedb.com/install.\n\n#### Install on macOS\n\nInstalling on macOS is as simple as running our install script. After that you can use the spacetime command to manage versions.\n\n```bash\ncurl -sSf https://install.spacetimedb.com | sh\n```\n\n#### Install on Linux\n\nInstalling on Linux is as simple as running our install script. After that you can use the spacetime command to manage versions.\n\n```bash\ncurl -sSf https://install.spacetimedb.com | sh\n```\n\n#### Install on Windows\n\nInstalling on Windows is as simple as pasting the snippet below into PowerShell. If you would like to use WSL instead, please follow the Linux install instructions.\n\n```ps1\niwr https://windows.spacetimedb.com -useb | iex\n```\n\n#### Installing from Source\n\nA quick note on installing from source: we recommend that you don't install from source unless there is a feature that is available in `master` that hasn't been released yet, otherwise follow the official installation instructions.\n\n##### MacOS + Linux\n\nInstalling on macOS + Linux is pretty straightforward. First we are going to build all of the binaries that we need:\n\n```bash\n# Install rustup, you can skip this step if you have cargo and the wasm32-unknown-unknown target already installed.\ncurl https://sh.rustup.rs -sSf | sh\n# Clone SpacetimeDB\ngit clone https://github.com/clockworklabs/SpacetimeDB\n# Build and install the CLI\ncd SpacetimeDB\ncargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli\n\n# Create directories\nmkdir -p ~/.local/bin\nexport STDB_VERSION=\"$(./target/release/spacetimedb-cli --version | sed -n 's/.*spacetimedb tool version \\([0-9.]*\\);.*/\\1/p')\"\nmkdir -p ~/.local/share/spacetime/bin/$STDB_VERSION\n\n# Install the update binary\ncp target/release/spacetimedb-update ~/.local/bin/spacetime\ncp target/release/spacetimedb-cli ~/.local/share/spacetime/bin/$STDB_VERSION\ncp target/release/spacetimedb-standalone ~/.local/share/spacetime/bin/$STDB_VERSION\n```\n\nAt this stage you'll need to add ~/.local/bin to your path if you haven't already.\n\n```\n# Please add the following line to your shell configuration and open a new shell session:\nexport PATH=\"$HOME/.local/bin:$PATH\"\n\n```\n\nThen finally set your SpacetimeDB version:\n```\n\n# Then, in a new shell, set the current version:\nspacetime version use $STDB_VERSION\n\n# If STDB_VERSION is not set anymore then you can use the following command to list your versions:\nspacetime version list\n```\n\nYou can verify that the correct version has been installed via `spacetime --version`.\n\n##### Windows\n\nBuilding on windows is a bit more complicated. You'll need a slightly different version of perl compared to what comes pre-bundled in most Windows terminals. We recommend [Strawberry Perl](https://strawberryperl.com/). You may also need access to an `openssl` binary which actually comes pre-installed with [Git for Windows](https://git-scm.com/downloads/win). Also, you'll need to install [rustup](https://rustup.rs/) for Windows.\n\nIn a Git for Windows shell you should have something that looks like this:\n```\n$ which perl\n/c/Strawberry/perl/bin/perl\n$ which openssl\n/mingw64/bin/openssl\n$ which cargo \n/c/Users/<user>/.cargo/bin/cargo\n```\n\nIf that looks correct then you're ready to proceed!\n\n```powershell\n# Clone SpacetimeDB\ngit clone https://github.com/clockworklabs/SpacetimeDB\n\n# Build and install the CLI\ncd SpacetimeDB\ncargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli\n\n# Create directories\n$stdbDir = \"$HOME\\AppData\\Local\\SpacetimeDB\"\n$stdbVersion = & \".\\target\\release\\spacetimedb-cli\" --version | Select-String -Pattern 'spacetimedb tool version ([0-9.]+);' | ForEach-Object { $_.Matches.Groups[1].Value }\nNew-Item -ItemType Directory -Path \"$stdbDir\\bin\\$stdbVersion\" -Force | Out-Null\n\n# Install the update binary\nCopy-Item \"target\\release\\spacetimedb-update.exe\" \"$stdbDir\\spacetime.exe\"\nCopy-Item \"target\\release\\spacetimedb-cli.exe\" \"$stdbDir\\bin\\$stdbVersion\\\"\nCopy-Item \"target\\release\\spacetimedb-standalone.exe\" \"$stdbDir\\bin\\$stdbVersion\\\"\n\n```\n\nNow add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!\n\n```\n%USERPROFILE%\\AppData\\Local\\SpacetimeDB\n```\n\nThen finally, open a new shell and use the installed SpacetimeDB version:\n```\nspacetime version use $stdbVersion\n\n# If stdbVersion is no longer set, list versions using the following command:\nspacetime version list\n```\n\nYou can verify that the correct version has been installed via `spacetime --version`.\n\nIf you're using Git for Windows you can follow these instructions instead:\n\n```bash\n# Clone SpacetimeDB\ngit clone https://github.com/clockworklabs/SpacetimeDB\n# Build and install the CLI\ncd SpacetimeDB\n# Build the CLI binaries - this takes a while on windows so go grab a coffee :)\ncargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli\n\n# Create directories\nexport STDB_VERSION=\"$(./target/release/spacetimedb-cli --version | sed -n 's/.*spacetimedb tool version \\([0-9.]*\\);.*/\\1/p')\"\nmkdir -p ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION\n\n# Install the update binary\ncp target/release/spacetimedb-update ~/AppData/Local/SpacetimeDB/spacetime\ncp target/release/spacetimedb-cli ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION\ncp target/release/spacetimedb-standalone ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION\n\n# Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!\n# %USERPROFILE%\\AppData\\Local\\SpacetimeDB\n\n# Set the current version\nspacetime version use $STDB_VERSION\n```\n\nYou can verify that the correct version has been installed via `spacetime --version`.\n\n#### Running with Docker\n\nIf you prefer to run Spacetime in a container, you can use the following command to start a new instance.\n\n```bash\ndocker run --rm --pull always -p 3000:3000 clockworklabs/spacetime start\n```\n\n## Documentation\n\nFor more information about SpacetimeDB, getting started guides, game development guides, and reference material please see our [documentation](https://spacetimedb.com/docs).\n\n## Getting Started\n\nWe've prepared several getting started guides in each of our supported languages to help you get up and running with SpacetimeDB as quickly as possible. You can find them on our [docs page](https://spacetimedb.com/docs).\n\nIn summary there are only 4 steps to getting started with SpacetimeDB.\n\n1. Install the `spacetime` CLI tool.\n2. Start a SpacetimeDB standalone node with `spacetime start`.\n3. Write and upload a module in one of our supported module languages.\n4. Connect to the database with one of our client libraries.\n\nYou can see a summary of the supported languages below with a link to the getting started guide for each.\n\n## Language Support\n\nYou can write SpacetimeDB modules in several popular languages, with more to come in the future!\n\n#### Serverside Libraries\n\n- [Rust](https://spacetimedb.com/docs/modules/rust/quickstart)\n- [C#](https://spacetimedb.com/docs/modules/c-sharp/quickstart)\n\n#### Client Libraries\n\n- [Rust](https://spacetimedb.com/docs/sdks/rust/quickstart)\n- [C#](https://spacetimedb.com/docs/sdks/c-sharp/quickstart)\n- [Typescript](https://spacetimedb.com/docs/sdks/typescript/quickstart)\n\n## License\n\nSpacetimeDB is licensed under the BSL 1.1 license. This is not an open source or free software license, however, it converts to the AGPL v3.0 license with a linking exception after a few years.\n\nNote that the AGPL v3.0 does not typically include a linking exception. We have added a custom linking exception to the AGPL license for SpacetimeDB. Our motivation for choosing a free software license is to ensure that contributions made to SpacetimeDB are propagated back to the community. We are expressly not interested in forcing users of SpacetimeDB to open source their own code if they link with SpacetimeDB, so we needed to include a linking exception.\n",
      "stars_today": 9
    },
    {
      "id": 76064827,
      "name": "mailcow-dockerized",
      "full_name": "mailcow/mailcow-dockerized",
      "description": "mailcow: dockerized - ğŸ® + ğŸ‹ = ğŸ’•",
      "html_url": "https://github.com/mailcow/mailcow-dockerized",
      "stars": 11984,
      "forks": 1600,
      "language": "JavaScript",
      "topics": [
        "acme",
        "clamav",
        "docker",
        "docker-compose",
        "dovecot",
        "groupware",
        "hacktoberfest",
        "imap",
        "mail",
        "mailcow",
        "mailserver",
        "olefy",
        "postfix",
        "rspamd",
        "servercow",
        "smtp",
        "sogo"
      ],
      "created_at": "2016-12-09T19:38:35Z",
      "updated_at": "2026-01-24T19:22:32Z",
      "pushed_at": "2026-01-23T21:02:55Z",
      "open_issues": 458,
      "owner": {
        "login": "mailcow",
        "avatar_url": "https://avatars.githubusercontent.com/u/23747925?v=4"
      },
      "readme": "# mailcow: dockerized - ğŸ® + ğŸ‹ = ğŸ’•\n\n[![Translation status](https://translate.mailcow.email/widgets/mailcow-dockerized/-/translation/svg-badge.svg)](https://translate.mailcow.email/engage/mailcow-dockerized/)\n[![Twitter URL](https://img.shields.io/twitter/url/https/twitter.com/mailcow_email.svg?style=social&label=Follow%20%40mailcow_email)](https://twitter.com/mailcow_email)\n![Mastodon Follow](https://img.shields.io/mastodon/follow/109388212176073348?domain=https%3A%2F%2Fmailcow.social&label=Follow%20%40doncow%40mailcow.social&link=https%3A%2F%2Fmailcow.social%2F%40doncow)\n\n\n## Want to support mailcow?\n\nPlease [consider a support contract with Servercow](https://www.servercow.de/mailcow?lang=en#support) to support further development. _We_ support _you_ while _you_ support _us_. :)\n\nYou can also [get a SAL](https://www.servercow.de/mailcow?lang=en#sal) which is a one-time payment with no liabilities or returning fees.\n\nOr just spread the word: moo.\n\n## Many thanks to our GitHub Sponsors â¤ï¸\nA big thank you to everyone supporting us on GitHub Sponsorsâ€”your contributions mean the world to us! Special thanks to the following amazing supporters:\n\n### 100$/Month Sponsors\n  <a href=\"https://www.colba.net/\" target=_blank><img\n    src=\"https://avatars.githubusercontent.com/u/204464723\" height=\"58\"\n  /></a>\n  <a href=\"https://www.maehdros.com/\" target=_blank><img\n    src=\"https://avatars.githubusercontent.com/u/173894712\" height=\"58\"\n  /></a>\n\n### 50$/Month Sponsors\n  <a href=\"https://github.com/vnukhr\" target=_blank><img\n    src=\"https://avatars.githubusercontent.com/u/7805987?s=52&v=4\" height=\"58\"\n  /></a>\n\n## Info, documentation and support\n\nPlease see [the official documentation](https://docs.mailcow.email/) for installation and support instructions. ğŸ„\n\nğŸ› **If you found a critical security issue, please mail us to [info at servercow.de](mailto:info@servercow.de).**\n\n## Cowmunity\n\n[mailcow community](https://community.mailcow.email)\n\n[Telegram mailcow channel](https://telegram.me/mailcow)\n\n[Telegram mailcow Off-Topic channel](https://t.me/mailcowOfftopic)\n\n[Official ğ• (Twitter) Account](https://twitter.com/mailcow_email)\n\n[Official Mastodon Account](https://mailcow.social/@doncow)\n\nTelegram desktop clients are available for [multiple platforms](https://desktop.telegram.org). You can search the groups history for keywords.\n\n## Misc\n\n**Important**: mailcow makes use of various open-source software. Please assure you agree with their license before using mailcow.\nAny part of mailcow itself is released under **GNU General Public License, Version 3**.\n\nmailcow is a registered word mark of The Infrastructure Company GmbH, Parkstr. 42, 47877 Willich, Germany.\n\nThe project is managed and maintained by The Infrastructure Company GmbH.\n\nOriginated from @andryyy (AndrÃ©)\n",
      "stars_today": 9
    },
    {
      "id": 1079469057,
      "name": "playwright-skill",
      "full_name": "lackeyjb/playwright-skill",
      "description": "Claude Code Skill for browser automation with Playwright. Model-invoked - Claude autonomously writes and executes custom automation for testing and validation.",
      "html_url": "https://github.com/lackeyjb/playwright-skill",
      "stars": 1440,
      "forks": 80,
      "language": "JavaScript",
      "topics": [
        "ai-tools",
        "automation",
        "browser-automation",
        "claude",
        "claude-code",
        "claude-plugin",
        "claude-skills",
        "developer-tools",
        "e2e-testing",
        "model-invoked",
        "nodejs",
        "playwright",
        "web-testing"
      ],
      "created_at": "2025-10-19T21:33:51Z",
      "updated_at": "2026-01-25T02:19:28Z",
      "pushed_at": "2025-12-19T16:23:38Z",
      "open_issues": 12,
      "owner": {
        "login": "lackeyjb",
        "avatar_url": "https://avatars.githubusercontent.com/u/9823496?v=4"
      },
      "readme": "# Playwright Skill for Claude Code\n\n**General-purpose browser automation as a Claude Skill**\n\nA [Claude Skill](https://www.anthropic.com/blog/skills) that enables Claude to write and execute any Playwright automation on-the-fly - from simple page tests to complex multi-step flows. Packaged as a [Claude Code Plugin](https://docs.claude.com/en/docs/claude-code/plugins) for easy installation and distribution.\n\nClaude autonomously decides when to use this skill based on your browser automation needs, loading only the minimal information required for your specific task.\n\nMade using Claude Code.\n\n## Features\n\n- **Any Automation Task** - Claude writes custom code for your specific request, not limited to pre-built scripts\n- **Visible Browser by Default** - See automation in real-time with `headless: false`\n- **Zero Module Resolution Errors** - Universal executor ensures proper module access\n- **Progressive Disclosure** - Concise SKILL.md with full API reference loaded only when needed\n- **Safe Cleanup** - Smart temp file management without race conditions\n- **Comprehensive Helpers** - Optional utility functions for common tasks\n\n## Installation\n\nThis repository is structured as a [Claude Code Plugin](https://docs.claude.com/en/docs/claude-code/plugins) containing a skill. You can install it as either a **plugin** (recommended) or extract it as a **standalone skill**.\n\n### Understanding the Structure\n\nThis repository uses the plugin format with a nested structure:\n\n```\nplaywright-skill/              # Plugin root\nâ”œâ”€â”€ .claude-plugin/           # Plugin metadata\nâ””â”€â”€ skills/\n    â””â”€â”€ playwright-skill/     # The actual skill\n        â””â”€â”€ SKILL.md\n```\n\nClaude Code expects skills to be directly in folders under `.claude/skills/`, so manual installation requires extracting the nested skill folder.\n\n---\n\n### Option 1: Plugin Installation (Recommended)\n\nInstall via Claude Code's plugin system for automatic updates and team distribution:\n\n```bash\n# Add this repository as a marketplace\n/plugin marketplace add lackeyjb/playwright-skill\n\n# Install the plugin\n/plugin install playwright-skill@playwright-skill\n\n# Navigate to the skill directory and run setup\ncd ~/.claude/plugins/marketplaces/playwright-skill/skills/playwright-skill\nnpm run setup\n```\n\nVerify installation by running `/help` to confirm the skill is available.\n\n---\n\n### Option 2: Standalone Skill Installation\n\nTo install as a standalone skill (without the plugin system), extract only the skill folder:\n\n**Global Installation (Available Everywhere):**\n\n```bash\n# Clone to a temporary location\ngit clone https://github.com/lackeyjb/playwright-skill.git /tmp/playwright-skill-temp\n\n# Copy only the skill folder to your global skills directory\nmkdir -p ~/.claude/skills\ncp -r /tmp/playwright-skill-temp/skills/playwright-skill ~/.claude/skills/\n\n# Navigate to the skill and run setup\ncd ~/.claude/skills/playwright-skill\nnpm run setup\n\n# Clean up temporary files\nrm -rf /tmp/playwright-skill-temp\n```\n\n**Project-Specific Installation:**\n\n```bash\n# Clone to a temporary location\ngit clone https://github.com/lackeyjb/playwright-skill.git /tmp/playwright-skill-temp\n\n# Copy only the skill folder to your project\nmkdir -p .claude/skills\ncp -r /tmp/playwright-skill-temp/skills/playwright-skill .claude/skills/\n\n# Navigate to the skill and run setup\ncd .claude/skills/playwright-skill\nnpm run setup\n\n# Clean up temporary files\nrm -rf /tmp/playwright-skill-temp\n```\n\n**Why this structure?** The plugin format requires the `skills/` directory for organizing multiple skills within a plugin. When installing as a standalone skill, you only need the inner `skills/playwright-skill/` folder contents.\n\n---\n\n### Option 3: Download Release\n\n1. Download and extract the latest release from [GitHub Releases](https://github.com/lackeyjb/playwright-skill/releases)\n2. Copy only the `skills/playwright-skill/` folder to:\n   - Global: `~/.claude/skills/playwright-skill`\n   - Project: `/path/to/your/project/.claude/skills/playwright-skill`\n3. Navigate to the skill directory and run setup:\n   ```bash\n   cd ~/.claude/skills/playwright-skill  # or your project path\n   npm run setup\n   ```\n\n---\n\n### Verify Installation\n\nRun `/help` to confirm the skill is loaded, then ask Claude to perform a simple browser task like \"Test if google.com loads\".\n\n## Quick Start\n\nAfter installation, simply ask Claude to test or automate any browser task. Claude will write custom Playwright code, execute it, and return results with screenshots and console output.\n\n## Usage Examples\n\n### Test Any Page\n\n```\n\"Test the homepage\"\n\"Check if the contact form works\"\n\"Verify the signup flow\"\n```\n\n### Visual Testing\n\n```\n\"Take screenshots of the dashboard in mobile and desktop\"\n\"Test responsive design across different viewports\"\n```\n\n### Interaction Testing\n\n```\n\"Fill out the registration form and submit it\"\n\"Click through the main navigation\"\n\"Test the search functionality\"\n```\n\n### Validation\n\n```\n\"Check for broken links\"\n\"Verify all images load\"\n\"Test form validation\"\n```\n\n## How It Works\n\n1. Describe what you want to test or automate\n2. Claude writes custom Playwright code for the task\n3. The universal executor (run.js) runs it with proper module resolution\n4. Browser opens (visible by default) and automation executes\n5. Results are displayed with console output and screenshots\n\n## Configuration\n\nDefault settings:\n\n- **Headless:** `false` (browser visible unless explicitly requested otherwise)\n- **Slow Motion:** `100ms` for visibility\n- **Timeout:** `30s`\n- **Screenshots:** Saved to `/tmp/`\n\n## Project Structure\n\n```\nplaywright-skill/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â”œâ”€â”€ plugin.json          # Plugin metadata for distribution\nâ”‚   â””â”€â”€ marketplace.json     # Marketplace configuration\nâ”œâ”€â”€ skills/\nâ”‚   â””â”€â”€ playwright-skill/    # The actual skill (Claude discovers this)\nâ”‚       â”œâ”€â”€ SKILL.md         # What Claude reads\nâ”‚       â”œâ”€â”€ run.js           # Universal executor (proper module resolution)\nâ”‚       â”œâ”€â”€ package.json     # Dependencies & setup scripts\nâ”‚       â””â”€â”€ lib/\nâ”‚           â””â”€â”€ helpers.js   # Optional utility functions\nâ”‚       â””â”€â”€ API_REFERENCE.md # Full Playwright API reference\nâ”œâ”€â”€ README.md                # This file - user documentation\nâ”œâ”€â”€ CONTRIBUTING.md          # Contribution guidelines\nâ””â”€â”€ LICENSE                  # MIT License\n```\n\n## Advanced Usage\n\nClaude will automatically load `API_REFERENCE.md` when needed for comprehensive documentation on selectors, network interception, authentication, visual regression testing, mobile emulation, performance testing, and debugging.\n\n## Dependencies\n\n- Node.js\n- Playwright (installed via `npm run setup`)\n- Chromium (installed via `npm run setup`)\n\n## Troubleshooting\n\n**Playwright not installed?**\nNavigate to the skill directory and run `npm run setup`.\n\n**Module not found errors?**\nEnsure automation runs via `run.js`, which handles module resolution.\n\n**Browser doesn't open?**\nVerify `headless: false` is set. The skill defaults to visible browser unless headless mode is requested.\n\n**Install all browsers?**\nRun `npm run install-all-browsers` from the skill directory.\n\n## What is a Skill?\n\n[Agent Skills](https://agentskills.io) are folders of instructions, scripts, and resources that agents can discover and use to do things more accurately and efficiently. When you ask Claude to test a webpage or automate browser interactions, Claude discovers this skill, loads the necessary instructions, executes custom Playwright code, and returns results with screenshots and console output.\n\nThis Playwright skill implements the [open Agent Skills specification](https://agentskills.io), making it compatible across agent platforms.\n\n## Contributing\n\nContributions are welcome. Fork the repository, create a feature branch, make your changes, and submit a pull request. See [CONTRIBUTING.md](CONTRIBUTING.md) for details.\n\n## Learn More\n\n- [Agent Skills Specification](https://agentskills.io) - Open specification for agent skills\n- [Claude Code Skills Documentation](https://docs.claude.com/en/docs/claude-code/skills)\n- [Claude Code Plugins Documentation](https://docs.claude.com/en/docs/claude-code/plugins)\n- [Plugin Marketplaces](https://docs.claude.com/en/docs/claude-code/plugin-marketplaces)\n- [API_REFERENCE.md](skills/playwright-skill/API_REFERENCE.md) - Full Playwright documentation\n- [GitHub Issues](https://github.com/lackeyjb/playwright-skill/issues)\n\n## License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n",
      "stars_today": 9
    },
    {
      "id": 71995937,
      "name": "nuxt",
      "full_name": "nuxt/nuxt",
      "description": "The Full-Stack Vue Framework.",
      "html_url": "https://github.com/nuxt/nuxt",
      "stars": 59424,
      "forks": 5505,
      "language": "TypeScript",
      "topics": [
        "csr",
        "framework",
        "full-stack",
        "hacktoberfest",
        "hybrid",
        "node",
        "nuxt",
        "server-rendering",
        "ssg",
        "ssr",
        "static-site-generator",
        "universal",
        "vue"
      ],
      "created_at": "2016-10-26T11:18:47Z",
      "updated_at": "2026-01-25T01:27:37Z",
      "pushed_at": "2026-01-25T01:27:28Z",
      "open_issues": 930,
      "owner": {
        "login": "nuxt",
        "avatar_url": "https://avatars.githubusercontent.com/u/23360933?v=4"
      },
      "readme": "[![Nuxt banner](./.github/assets/banner.svg)](https://nuxt.com)\n\n# Nuxt\n\n<p>\n  <a href=\"https://www.npmjs.com/package/nuxt\"><img src=\"https://img.shields.io/npm/v/nuxt.svg?style=flat&colorA=18181B&colorB=28CF8D\" alt=\"Version\"></a>\n  <a href=\"https://www.npmjs.com/package/nuxt\"><img src=\"https://img.shields.io/npm/dm/nuxt.svg?style=flat&colorA=18181B&colorB=28CF8D\" alt=\"Downloads\"></a>\n  <a href=\"https://github.com/nuxt/nuxt/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/nuxt/nuxt.svg?style=flat&colorA=18181B&colorB=28CF8D\" alt=\"License\"></a>\n  <a href=\"https://nuxt.com/modules\"><img src=\"https://img.shields.io/badge/dynamic/json?url=https://nuxt.com/api/v1/modules&query=$.stats.modules&label=Modules&style=flat&colorA=18181B&colorB=28CF8D\" alt=\"Modules\"></a>\n  <a href=\"https://nuxt.com\"><img src=\"https://img.shields.io/badge/Nuxt%20Docs-18181B?logo=nuxt\" alt=\"Website\"></a>\n  <a href=\"https://chat.nuxt.dev\"><img src=\"https://img.shields.io/badge/Nuxt%20Discord-18181B?logo=discord\" alt=\"Discord\"></a>\n  <a href=\"https://securityscorecards.dev/\"><img src=\"https://api.securityscorecards.dev/projects/github.com/nuxt/nuxt/badge\" alt=\"Nuxt openssf scorecard score\"></a>\n  <a href=\"https://deepwiki.com/nuxt/nuxt\"><img src=\"https://deepwiki.com/badge.svg\" alt=\"Ask DeepWiki\"></a>\n</p>\n\nNuxt is a free and open-source framework with an intuitive and extendable way to create type-safe, performant and production-grade full-stack web applications and websites with Vue.js.\n\nIt provides a number of features that make it easy to build fast, SEO-friendly, and scalable web applications, including:\n- Server-side rendering, static site generation, hybrid rendering and edge-side rendering\n- Automatic routing with code-splitting and pre-fetching\n- Data fetching and state management\n- Search engine optimization and defining meta tags\n- Auto imports of components, composables and utils\n- TypeScript with zero configuration\n- Go full-stack with our server/ directory\n- Extensible with [300+ modules](https://nuxt.com/modules)\n- Deployment to a variety of [hosting platforms](https://nuxt.com/deploy)\n- ...[and much more](https://nuxt.com) ğŸš€\n\n### Table of Contents\n\n- ğŸš€ [Getting Started](#getting-started)\n- ğŸ’» [Vue Development](#vue-development)\n- ğŸ“– [Documentation](#documentation)\n- ğŸ§© [Modules](#modules)\n- â¤ï¸ [Contribute](#contribute)\n- ğŸ  [Local Development](#local-development)\n- ğŸ›Ÿ [Professional Support](#professional-support)\n- ğŸ”— [Follow Us](#follow-us)\n- âš–ï¸ [License](#license)\n\n---\n\n## <a name=\"getting-started\">ğŸš€ Getting Started</a>\n\nUse the following command to create a new starter project. This will create a starter project with all the necessary files and dependencies:\n\n```bash\nnpm create nuxt@latest <my-project>\n```\n\n> [!TIP]\n> Discover also [nuxt.new](https://nuxt.new): Open a Nuxt starter on CodeSandbox, StackBlitz or locally to get up and running in a few seconds.\n\n## <a name=\"vue-development\">ğŸ’» Vue Development</a>\n\nSimple, intuitive and powerful, Nuxt lets you write Vue components in a way that makes sense. Every repetitive task is automated, so you can focus on writing your full-stack Vue application with confidence.\n\nExample of an `app.vue`:\n\n```vue\n<script setup lang=\"ts\">\nuseSeoMeta({\n  title: 'Meet Nuxt',\n  description: 'The Intuitive Vue Framework.',\n})\n</script>\n\n<template>\n  <div id=\"app\">\n    <AppHeader />\n    <NuxtPage />\n    <AppFooter />\n  </div>\n</template>\n\n<style scoped>\n#app {\n  background-color: #020420;\n  color: #00DC82;\n}\n</style>\n```\n\n## <a name=\"documentation\">ğŸ“– Documentation</a>\n\nWe highly recommend you take a look at the [Nuxt documentation](https://nuxt.com/docs) to level up. Itâ€™s a great resource for learning more about the framework. It covers everything from getting started to advanced topics.\n\n## <a name=\"modules\">ğŸ§© Modules</a>\n\nDiscover our [list of modules](https://nuxt.com/modules) to supercharge your Nuxt project, created by the Nuxt team and community.\n\n## <a name=\"contribute\">â¤ï¸ Contribute</a>\n\nWe invite you to contribute and help improve Nuxt ğŸ’š\n\nHere are a few ways you can get involved:\n- **Reporting Bugs:** If you come across any bugs or issues, please check out the [reporting bugs guide](https://nuxt.com/docs/4.x/community/reporting-bugs) to learn how to submit a bug report.\n- **Suggestions:** Have ideas to enhance Nuxt? We'd love to hear them! Check out the [contribution guide](https://nuxt.com/docs/4.x/community/contribution) to share your suggestions.\n- **Questions:** If you have questions or need assistance, the [getting help guide](https://nuxt.com/docs/4.x/community/getting-help) provides resources to help you out.\n\n## <a name=\"local-development\">ğŸ  Local Development</a>\n\nFollow the docs to [Set Up Your Local Development Environment](https://nuxt.com/docs/4.x/community/framework-contribution#setup) to contribute to the framework and documentation.\n\n## <a name=\"professional-support\">ğŸ›Ÿ Professional Support</a>\n\n- Technical audit & consulting: [Nuxt Experts](https://nuxt.com/enterprise/support)\n- Custom development & more: [Nuxt Agencies Partners](https://nuxt.com/enterprise/agencies)\n\n## <a name=\"follow-us\">ğŸ”— Follow Us</a>\n\n<p valign=\"center\">\n  <a href=\"https://go.nuxt.com/discord\"><img width=\"20\" src=\"./.github/assets/discord.svg\" alt=\"Discord\"></a>&nbsp;&nbsp;<a href=\"https://go.nuxt.com/x\"><img width=\"20\" src=\"./.github/assets/twitter.svg\" alt=\"Twitter\"></a>&nbsp;&nbsp;<a href=\"https://go.nuxt.com/github\"><img width=\"20\" src=\"./.github/assets/github.svg\" alt=\"GitHub\"></a>&nbsp;&nbsp;<a href=\"https://go.nuxt.com/bluesky\"><img width=\"20\" src=\"./.github/assets/bluesky.svg\" alt=\"Bluesky\"></a>\n</p>\n\n## <a name=\"license\">âš–ï¸ License</a>\n\n[MIT](https://github.com/nuxt/nuxt/blob/main/LICENSE)\n",
      "stars_today": 8
    },
    {
      "id": 39840932,
      "name": "googletest",
      "full_name": "google/googletest",
      "description": "GoogleTest - Google Testing and Mocking Framework",
      "html_url": "https://github.com/google/googletest",
      "stars": 38127,
      "forks": 10677,
      "language": "C++",
      "topics": [],
      "created_at": "2015-07-28T15:07:53Z",
      "updated_at": "2026-01-24T23:06:48Z",
      "pushed_at": "2026-01-17T05:52:03Z",
      "open_issues": 506,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# GoogleTest\n\n### Announcements\n\n#### Documentation Updates\n\nOur documentation is now live on GitHub Pages at\nhttps://google.github.io/googletest/. We recommend browsing the documentation on\nGitHub Pages rather than directly in the repository.\n\n#### Release 1.17.0\n\n[Release 1.17.0](https://github.com/google/googletest/releases/tag/v1.17.0) is\nnow available.\n\nThe 1.17.x branch\n[requires at least C++17](https://opensource.google/documentation/policies/cplusplus-support#c_language_standard).\n\n#### Continuous Integration\n\nWe use Google's internal systems for continuous integration.\n\n#### Coming Soon\n\n*   We are planning to take a dependency on\n    [Abseil](https://github.com/abseil/abseil-cpp).\n\n## Welcome to **GoogleTest**, Google's C++ test framework!\n\nThis repository is a merger of the formerly separate GoogleTest and GoogleMock\nprojects. These were so closely related that it makes sense to maintain and\nrelease them together.\n\n### Getting Started\n\nSee the [GoogleTest User's Guide](https://google.github.io/googletest/) for\ndocumentation. We recommend starting with the\n[GoogleTest Primer](https://google.github.io/googletest/primer.html).\n\nMore information about building GoogleTest can be found at\n[googletest/README.md](googletest/README.md).\n\n## Features\n\n*   xUnit test framework: \\\n    Googletest is based on the [xUnit](https://en.wikipedia.org/wiki/XUnit)\n    testing framework, a popular architecture for unit testing\n*   Test discovery: \\\n    Googletest automatically discovers and runs your tests, eliminating the need\n    to manually register your tests\n*   Rich set of assertions: \\\n    Googletest provides a variety of assertions, such as equality, inequality,\n    exceptions, and more, making it easy to test your code\n*   User-defined assertions: \\\n    You can define your own assertions with Googletest, making it simple to\n    write tests that are specific to your code\n*   Death tests: \\\n    Googletest supports death tests, which verify that your code exits in a\n    certain way, making it useful for testing error-handling code\n*   Fatal and non-fatal failures: \\\n    You can specify whether a test failure should be treated as fatal or\n    non-fatal with Googletest, allowing tests to continue running even if a\n    failure occurs\n*   Value-parameterized tests: \\\n    Googletest supports value-parameterized tests, which run multiple times with\n    different input values, making it useful for testing functions that take\n    different inputs\n*   Type-parameterized tests: \\\n    Googletest also supports type-parameterized tests, which run with different\n    data types, making it useful for testing functions that work with different\n    data types\n*   Various options for running tests: \\\n    Googletest provides many options for running tests including running\n    individual tests, running tests in a specific order and running tests in\n    parallel\n\n## Supported Platforms\n\nGoogleTest follows Google's\n[Foundational C++ Support Policy](https://opensource.google/documentation/policies/cplusplus-support).\nSee\n[this table](https://github.com/google/oss-policies-info/blob/main/foundational-cxx-support-matrix.md)\nfor a list of currently supported versions of compilers, platforms, and build\ntools.\n\n## Who Is Using GoogleTest?\n\nIn addition to many internal projects at Google, GoogleTest is also used by the\nfollowing notable projects:\n\n*   The [Chromium projects](https://www.chromium.org/) (behind the Chrome\n    browser and Chrome OS).\n*   The [LLVM](https://llvm.org/) compiler.\n*   [Protocol Buffers](https://github.com/google/protobuf), Google's data\n    interchange format.\n*   The [OpenCV](https://opencv.org/) computer vision library.\n\n## Related Open Source Projects\n\n[GTest Runner](https://github.com/nholthaus/gtest-runner) is a Qt5 based\nautomated test-runner and Graphical User Interface with powerful features for\nWindows and Linux platforms.\n\n[GoogleTest UI](https://github.com/ospector/gtest-gbar) is a test runner that\nruns your test binary, allows you to track its progress via a progress bar, and\ndisplays a list of test failures. Clicking on one shows failure text. GoogleTest\nUI is written in C#.\n\n[GTest TAP Listener](https://github.com/kinow/gtest-tap-listener) is an event\nlistener for GoogleTest that implements the\n[TAP protocol](https://en.wikipedia.org/wiki/Test_Anything_Protocol) for test\nresult output. If your test runner understands TAP, you may find it useful.\n\n[gtest-parallel](https://github.com/google/gtest-parallel) is a test runner that\nruns tests from your binary in parallel to provide significant speed-up.\n\n[GoogleTest Adapter](https://marketplace.visualstudio.com/items?itemName=DavidSchuldenfrei.gtest-adapter)\nis a VS Code extension allowing to view GoogleTest in a tree view and run/debug\nyour tests.\n\n[C++ TestMate](https://github.com/matepek/vscode-catch2-test-adapter) is a VS\nCode extension allowing to view GoogleTest in a tree view and run/debug your\ntests.\n\n[Cornichon](https://pypi.org/project/cornichon/) is a small Gherkin DSL parser\nthat generates stub code for GoogleTest.\n\n## Contributing Changes\n\nPlease read\n[`CONTRIBUTING.md`](https://github.com/google/googletest/blob/main/CONTRIBUTING.md)\nfor details on how to contribute to this project.\n\nHappy testing!\n",
      "stars_today": 8
    },
    {
      "id": 413918947,
      "name": "turborepo",
      "full_name": "vercel/turborepo",
      "description": "Build system optimized for JavaScriptÂ and TypeScript, written in Rust",
      "html_url": "https://github.com/vercel/turborepo",
      "stars": 29619,
      "forks": 2222,
      "language": "Rust",
      "topics": [
        "build-system",
        "build-tool",
        "javascript",
        "monorepo",
        "typescript"
      ],
      "created_at": "2021-10-05T17:37:11Z",
      "updated_at": "2026-01-25T00:22:25Z",
      "pushed_at": "2026-01-24T21:11:26Z",
      "open_issues": 131,
      "owner": {
        "login": "vercel",
        "avatar_url": "https://avatars.githubusercontent.com/u/14985020?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://turborepo.dev\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://user-images.githubusercontent.com/4060187/196936123-f6e1db90-784d-4174-b774-92502b718836.png\">\n      <img src=\"https://user-images.githubusercontent.com/4060187/196936104-5797972c-ab10-4834-bd61-0d1e5f442c9c.png\" height=\"128\">\n    </picture>\n    <h1 align=\"center\">Turborepo</h1>\n  </a>\n</p>\n\n<p align=\"center\">\n  <a aria-label=\"Vercel logo\" href=\"https://vercel.com/\"><img src=\"https://img.shields.io/badge/MADE%20BY%20Vercel-000000.svg?style=for-the-badge&logo=Vercel&labelColor=000\"></a>\n  <a aria-label=\"NPM version\" href=\"https://www.npmjs.com/package/turbo\"><img alt=\"\" src=\"https://img.shields.io/npm/v/turbo.svg?style=for-the-badge&labelColor=000000\"></a>\n  <a aria-label=\"License\" href=\"https://github.com/vercel/turborepo/blob/main/LICENSE\"><img alt=\"\" src=\"https://img.shields.io/npm/l/turbo.svg?style=for-the-badge&labelColor=000000&color=\"></a>\n  <a aria-label=\"Join the community on GitHub\" href=\"https://github.com/vercel/turborepo/discussions\"><img alt=\"\" src=\"https://img.shields.io/badge/Join%20the%20community-blueviolet.svg?style=for-the-badge&logo=turborepo&labelColor=000000&logoWidth=20&logoColor=white\"></a>\n</p>\n\nTurborepo is a high-performance build system for JavaScript and TypeScript codebases, written in Rust.\n\n## Getting Started\n\nVisit https://turborepo.dev to get started with Turborepo.\n\n## Contributing\n\nSee [CONTRIBUTING.md](https://github.com/vercel/turborepo/blob/main/CONTRIBUTING.md) for more information.\n\n## Community\n\nThe Turborepo community can be found on [GitHub Discussions](https://github.com/vercel/turborepo/discussions), where you can ask questions, voice ideas, and share your projects.\n\nTo chat with other community members, you can join [Vercel Community's `#turborepo` tag](https://vercel.community/tag/turborepo).\n\nOur [Code of Conduct](https://github.com/vercel/turborepo/blob/main/CODE_OF_CONDUCT.md) applies to all Turborepo community channels.\n\n## Who is using Turborepo?\n\nTurborepo is used by the world's leading companies. Check out the [Turborepo Showcase](https://turborepo.dev/showcase) to learn more.\n\n## Updates\n\nFollow [@turborepo](https://x.com/turborepo) on X for project updates.\n\n## Security\n\nIf you believe you have found a security vulnerability in Turborepo, we encourage you to responsibly disclose this and not open a public issue. We will investigate all legitimate reports. Email `security@vercel.com` to disclose any security vulnerabilities.\n\nhttps://vercel.com/security\n",
      "stars_today": 8
    },
    {
      "id": 3199002,
      "name": "linux",
      "full_name": "raspberrypi/linux",
      "description": "Kernel source tree for Raspberry Pi-provided kernel builds. Issues unrelated to the linux kernel should be posted on the community forum at https://forums.raspberrypi.com/",
      "html_url": "https://github.com/raspberrypi/linux",
      "stars": 12454,
      "forks": 5351,
      "language": "C",
      "topics": [],
      "created_at": "2012-01-17T12:10:20Z",
      "updated_at": "2026-01-24T20:18:51Z",
      "pushed_at": "2026-01-23T15:55:18Z",
      "open_issues": 1053,
      "owner": {
        "login": "raspberrypi",
        "avatar_url": "https://avatars.githubusercontent.com/u/1294177?v=4"
      },
      "readme": "Linux kernel\n============\n\nThere are several guides for kernel developers and users. These guides can\nbe rendered in a number of formats, like HTML and PDF. Please read\nDocumentation/admin-guide/README.rst first.\n\nIn order to build the documentation, use ``make htmldocs`` or\n``make pdfdocs``.  The formatted documentation can also be read online at:\n\n    https://www.kernel.org/doc/html/latest/\n\nThere are various text files in the Documentation/ subdirectory,\nseveral of them using the Restructured Text markup notation.\n\nPlease read the Documentation/process/changes.rst file, as it contains the\nrequirements for building and running the kernel, and information about\nthe problems which may result by upgrading your kernel.\n\nBuild status for rpi-6.1.y:\n[![Pi kernel build tests](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml/badge.svg?branch=rpi-6.1.y)](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml)\n[![dtoverlaycheck](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml/badge.svg?branch=rpi-6.1.y)](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml)\n\nBuild status for rpi-6.6.y:\n[![Pi kernel build tests](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml/badge.svg?branch=rpi-6.6.y)](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml)\n[![dtoverlaycheck](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml/badge.svg?branch=rpi-6.6.y)](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml)\n\nBuild status for rpi-6.12.y:\n[![Pi kernel build tests](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml/badge.svg?branch=rpi-6.12.y)](https://github.com/raspberrypi/linux/actions/workflows/kernel-build.yml)\n[![dtoverlaycheck](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml/badge.svg?branch=rpi-6.12.y)](https://github.com/raspberrypi/linux/actions/workflows/dtoverlaycheck.yml)\n",
      "stars_today": 8
    },
    {
      "id": 488177011,
      "name": "nekoray",
      "full_name": "MatsuriDayo/nekoray",
      "description": "ä¸å†ç»´æŠ¤ï¼Œè‡ªå¯»æ›¿ä»£å“ã€‚ Qt based cross-platform GUI proxy configuration manager (backend: sing-box)",
      "html_url": "https://github.com/MatsuriDayo/nekoray",
      "stars": 15109,
      "forks": 1460,
      "language": "C++",
      "topics": [],
      "created_at": "2022-05-03T11:12:00Z",
      "updated_at": "2026-01-25T00:36:45Z",
      "pushed_at": "2024-12-12T08:25:39Z",
      "open_issues": 218,
      "owner": {
        "login": "MatsuriDayo",
        "avatar_url": "https://avatars.githubusercontent.com/u/95122236?v=4"
      },
      "readme": "# NekoBox For PC\n\nQt based cross-platform GUI proxy configuration manager (backend: sing-box)\n\nSupport Windows / Linux out of the box now.\n\nåŸºäº Qt çš„è·¨å¹³å°ä»£ç†é…ç½®ç®¡ç†å™¨ (åç«¯ sing-box)\n\nç›®å‰æ”¯æŒ Windows / Linux å¼€ç®±å³ç”¨\n\n## ä¸‹è½½ / Download\n\n### GitHub Releases (Portable ZIP)\n\nä¾¿æºæ ¼å¼ï¼Œæ— å®‰è£…å™¨ã€‚è½¬åˆ° Releases ä¸‹è½½é¢„ç¼–è¯‘çš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œè§£å‹åå³å¯ä½¿ç”¨ã€‚\n\n[![GitHub All Releases](https://img.shields.io/github/downloads/Matsuridayo/nekoray/total?label=downloads-total&logo=github&style=flat-square)](https://github.com/Matsuridayo/nekoray/releases)\n\n[ä¸‹è½½ / Download](https://github.com/Matsuridayo/nekoray/releases)\n\n[å®‰è£…åŒ…çš„è¯´æ˜ï¼Œå¦‚æœä½ ä¸çŸ¥é“è¦ä¸‹è½½å“ªä¸€ä¸ª](https://github.com/MatsuriDayo/nekoray/wiki/Installation-package-description)\n\n### Package\n\n#### AUR\n\n- [nekoray](https://aur.archlinux.org/packages/nekoray)\n- [nekoray-git](https://aur.archlinux.org/packages/nekoray-git)\n\n#### archlinuxcn\n\n- [nekoray](https://github.com/archlinuxcn/repo/tree/master/archlinuxcn/nekoray)\n- [nekoray-git](https://github.com/archlinuxcn/repo/tree/master/archlinuxcn/nekoray-git)\n\n#### Scoop Extras\n\n`scoop install nekoray`\n\n## æ›´æ”¹è®°å½• & å‘å¸ƒé¢‘é“ / Changelog & Telegram Channel\n\nhttps://t.me/Matsuridayo\n\n## é¡¹ç›®ä¸»é¡µ & æ–‡æ¡£ / Homepage & Documents\n\nhttps://matsuridayo.github.io\n\n## ä»£ç† / Proxy\n\n- SOCKS (4/4a/5)\n- HTTP(S)\n- Shadowsocks\n- VMess\n- VLESS\n- Trojan\n- TUIC ( sing-box )\n- NaÃ¯veProxy ( Custom Core )\n- Hysteria2 ( Custom Core or sing-box )\n- Custom Outbound\n- Custom Config\n- Custom Core\n\n## è®¢é˜… / Subscription\n\n- Raw: some widely used formats (like Shadowsocks, Clash and v2rayN)\n- åŸå§‹æ ¼å¼: ä¸€äº›å¹¿æ³›ä½¿ç”¨çš„æ ¼å¼ (å¦‚ Shadowsocksã€Clash å’Œ v2rayN)\n\n## è¿è¡Œå‚æ•°\n\n[è¿è¡Œå‚æ•°](docs/RunFlags.md)\n\n## Windows è¿è¡Œ\n\nè‹¥æç¤º DLL ç¼ºå¤±ï¼Œæ— æ³•è¿è¡Œï¼Œè¯·ä¸‹è½½ å®‰è£… [å¾®è½¯ C++ è¿è¡Œåº“](https://aka.ms/vs/17/release/vc_redist.x64.exe)\n\n## Linux è¿è¡Œ\n\n[Linux è¿è¡Œæ•™ç¨‹](docs/Run_Linux.md)\n\n## ç¼–è¯‘æ•™ç¨‹ / Compile Tutorial\n\nè¯·çœ‹ [æŠ€æœ¯æ–‡æ¡£ / Technical documentation](https://github.com/MatsuriDayo/nekoray/tree/main/docs)\n\n## æåŠ© / Donate\n\nå¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œå¯ä»¥é€šè¿‡æèµ çš„æ–¹å¼å¸®åŠ©æˆ‘ä»¬ç»´æŒè¿™ä¸ªé¡¹ç›®ã€‚\n\næèµ æ»¡ç­‰é¢ 50 USD å¯ä»¥åœ¨ã€Œ[æèµ æ¦œ](https://mtrdnt.pages.dev/donation_list)ã€æ˜¾ç¤ºå¤´åƒï¼Œå¦‚æœæ‚¨æœªè¢«æ·»åŠ åˆ°è¿™é‡Œï¼Œæ¬¢è¿è”ç³»æˆ‘ä»¬è¡¥å……ã€‚\n\nDonations of 50 USD or more can display your avatar on the [Donation List](https://mtrdnt.pages.dev/donation_list). If you are not added here, please contact us to add it.\n\nUSDT TRC20\n\n`TRhnA7SXE5Sap5gSG3ijxRmdYFiD4KRhPs`\n\nXMR\n\n`49bwESYQjoRL3xmvTcjZKHEKaiGywjLYVQJMUv79bXonGiyDCs8AzE3KiGW2ytTybBCpWJUvov8SjZZEGg66a4e59GXa6k5`\n\n## Credits\n\nCore:\n\n- [v2fly/v2ray-core](https://github.com/v2fly/v2ray-core) ( < 3.10 )\n- [MatsuriDayo/Matsuri](https://github.com/MatsuriDayo/Matsuri) ( < 3.10 )\n- [MatsuriDayo/v2ray-core](https://github.com/MatsuriDayo/v2ray-core) ( < 3.10 )\n- [XTLS/Xray-core](https://github.com/XTLS/Xray-core) ( 3.10 <= Version <= 3.26 )\n- [MatsuriDayo/Xray-core](https://github.com/MatsuriDayo/Xray-core) ( 3.10 <= Version <= 3.26 )\n- [SagerNet/sing-box](https://github.com/SagerNet/sing-box)\n- [Matsuridayo/sing-box-extra](https://github.com/MatsuriDayo/sing-box-extra)\n\nGui:\n\n- [Qv2ray](https://github.com/Qv2ray/Qv2ray)\n- [Qt](https://www.qt.io/)\n- [protobuf](https://github.com/protocolbuffers/protobuf)\n- [yaml-cpp](https://github.com/jbeder/yaml-cpp)\n- [zxing-cpp](https://github.com/nu-book/zxing-cpp)\n- [QHotkey](https://github.com/Skycoder42/QHotkey)\n- [AppImageKit](https://github.com/AppImage/AppImageKit)\n",
      "stars_today": 8
    },
    {
      "id": 254202848,
      "name": "florisboard",
      "full_name": "florisboard/florisboard",
      "description": "An open-source keyboard for Android which respects your privacy. Currently in beta.",
      "html_url": "https://github.com/florisboard/florisboard",
      "stars": 7952,
      "forks": 570,
      "language": "Kotlin",
      "topics": [
        "android",
        "input-method",
        "keyboard",
        "kotlin",
        "kotlin-android"
      ],
      "created_at": "2020-04-08T21:18:23Z",
      "updated_at": "2026-01-24T19:58:48Z",
      "pushed_at": "2026-01-22T23:58:00Z",
      "open_issues": 441,
      "owner": {
        "login": "florisboard",
        "avatar_url": "https://avatars.githubusercontent.com/u/63373248?v=4"
      },
      "readme": "<img align=\"left\" width=\"80\" height=\"80\"\nsrc=\".github/repo_icon.png\" alt=\"App icon\">\n\n# FlorisBoard [![Crowdin](https://badges.crowdin.net/florisboard/localized.svg)](https://crowdin.florisboard.org) [![Matrix badge](https://img.shields.io/badge/chat-%23florisboard%3amatrix.org-blue)](https://matrix.to/#/#florisboard:matrix.org) [![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](CODE_OF_CONDUCT.md) [![FlorisBoard CI](https://github.com/florisboard/florisboard/actions/workflows/android.yml/badge.svg?event=push)](https://github.com/florisboard/florisboard/actions/workflows/android.yml)\n\n**FlorisBoard** is a free and open-source keyboard for Android 8.0+\ndevices. It aims at being modern, user-friendly and customizable while\nfully respecting your privacy. Currently in beta state.\n\n<table>\n<tr>\n<th align=\"center\" width=\"50%\">\n<h3>Stable <a href=\"https://github.com/florisboard/florisboard/releases/latest\"><img alt=\"Latest stable release\" src=\"https://img.shields.io/github/v/release/florisboard/florisboard?sort=semver&display_name=tag&color=28a745\"></a></h3>\n</th>\n<th align=\"center\" width=\"50%\">\n<h3>Preview <a href=\"https://github.com/florisboard/florisboard/releases\"><img alt=\"Latest preview release\" src=\"https://img.shields.io/github/v/release/florisboard/florisboard?include_prereleases&sort=semver&display_name=tag&color=fd7e14\"></a></h3>\n</th>\n</tr>\n<tr>\n<td valign=\"top\">\n<p><i>Major versions only</i><br><br>Updates are more polished, new features are matured and tested through to ensure a stable experience.</p>\n</td>\n<td valign=\"top\">\n<p><i>Major + Alpha/Beta/Rc versions</i><br><br>Updates contain new features that may not be fully matured yet and bugs are more likely to occur. Allows you to give early feedback.</p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\">\n<p>\n<a href=\"https://apt.izzysoft.de/fdroid/index/apk/dev.patrickgold.florisboard\"><img src=\"https://gitlab.com/IzzyOnDroid/repo/-/raw/master/assets/IzzyOnDroid.png\" height=\"64\" alt=\"IzzySoft repo badge\"></a>\n<a href=\"https://f-droid.org/packages/dev.patrickgold.florisboard\"><img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\" height=\"64\" alt=\"F-Droid badge\"></a>\n</p>\n<p>\n\n**Google Play**: Join the [FlorisBoard Test Group](https://groups.google.com/g/florisboard-closed-beta-test), then visit the [testing page](https://play.google.com/apps/testing/dev.patrickgold.florisboard). Once joined and installed, updates will be delivered like for any other app. ([Store entry](https://play.google.com/store/apps/details?id=dev.patrickgold.florisboard))\n\n</p>\n<p>\n\n**Obtainium**: [Auto-import stable config][obtainium_stable]\n\n</p>\n<p>\n\n**Manual**: Download and install the APK from the release page.\n\n</p>\n</td>\n<td valign=\"top\">\n<p><a href=\"https://apt.izzysoft.de/fdroid/index/apk/dev.patrickgold.florisboard.beta\"><img src=\"https://gitlab.com/IzzyOnDroid/repo/-/raw/master/assets/IzzyOnDroid.png\" height=\"64\" alt=\"IzzySoft repo badge\"></a></p>\n<p>\n\n**Google Play**: Join the [FlorisBoard Test Group](https://groups.google.com/g/florisboard-closed-beta-test), then visit the [preview testing page](https://play.google.com/apps/testing/dev.patrickgold.florisboard.beta). Once joined and installed, updates will be delivered like for any other app. ([Store entry](https://play.google.com/store/apps/details?id=dev.patrickgold.florisboard.beta))\n\n</p>\n<p>\n\n**Obtainium**: [Auto-import preview config][obtainium_preview]\n\n</p>\n<p>\n\n**Manual**: Download and install the APK from the release page.\n\n</p>\n</td>\n</tr>\n</table>\n\nBeginning with v0.7 FlorisBoard will enter the public beta on Google Play.\n\n## Highlighted features\n- Integrated clipboard manager / history\n- Advanced theming support and customization\n- Integrated extension support (still evolving)\n- Emoji keyboard / history / suggestions\n\n> [!IMPORTANT]\n> Word suggestions/spell checking are not included in the current releases\n> and are a major goal for the v0.6 milestone.\n\nFeature roadmap: See [ROADMAP.md](ROADMAP.md)\n\n## Contributing\nWant to contribute to FlorisBoard? That's great to hear! There are lots of\ndifferent ways to help out, please see the [contribution guidelines](CONTRIBUTING.md) for more info.\n\n## Addons Store\nThe official [Addons Store](https://beta.addons.florisboard.org) offers the possibility for the community to share and download FlorisBoard extensions.\nInstructions on how to publish addons can be found [here](https://github.com/florisboard/florisboard/wiki/How-to-publish-on-FlorisBoard-Addons).\n\nMany thanks to Ali ([@4H1R](https://github.com/4H1R)) for implementing the store!\n\n> [!NOTE]\n> During the initial beta release phase, the Addons Store _will_ only accept theme extensions.\n> Later on we plan to add support for language packs and keyboard extensions.\n\n## List of permissions FlorisBoard requests\nPlease refer to this [page](https://github.com/florisboard/florisboard/wiki/List-of-permissions-FlorisBoard-requests)\nto get more information on this topic.\n\n## APK signing certificate hashes\n\nThe package names and SHA-256 hashes of the signature certificate are listed below, so you can verify both FlorisBoard variants with apksigner by using `apksigner verify --print-certs florisboard-<version>-<track>.apk` when you download the APK.\nIf you have [AppVerifier](https://github.com/soupslurpr/AppVerifier) installed, you can alternatively copy both the package name and the hash of the corresponding track and share them to AppVerifier.\n\n##### Stable track:\n\ndev.patrickgold.florisboard<br>\n0B:80:71:64:50:8E:AF:EB:1F:BB:81:5B:E7:A2:3C:77:FE:68:9D:94:B1:43:75:C9:9B:DA:A9:B6:57:7F:D6:D6\n\n##### Preview track:\n\ndev.patrickgold.florisboard.beta<br>\n0B:80:71:64:50:8E:AF:EB:1F:BB:81:5B:E7:A2:3C:77:FE:68:9D:94:B1:43:75:C9:9B:DA:A9:B6:57:7F:D6:D6\n\n\n## Used libraries, components and icons\n* [AndroidX libraries](https://github.com/androidx/androidx) by\n  [Android Jetpack](https://github.com/androidx)\n* [AboutLibraries](https://github.com/mikepenz/AboutLibraries) by\n  [mikepenz](https://github.com/mikepenz)\n* [Google Material icons](https://github.com/google/material-design-icons) by\n  [Google](https://github.com/google)\n* [JetPref preference library](https://github.com/patrickgold/jetpref) by\n  [patrickgold](https://github.com/patrickgold)\n* [KotlinX coroutines library](https://github.com/Kotlin/kotlinx.coroutines) by\n  [Kotlin](https://github.com/Kotlin)\n* [KotlinX serialization library](https://github.com/Kotlin/kotlinx.serialization) by\n  [Kotlin](https://github.com/Kotlin)\n\nMany thanks to [Nikolay Anzarov](https://www.behance.net/nikolayanzarov) ([@BloodRaven0](https://github.com/BloodRaven0)) for designing and providing the main app icons to this project!\n\n## License\n```\nCopyright 2020-2026 The FlorisBoard Contributors\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\nThanks to [The FlorisBoard Contributors](https://github.com/florisboard/florisboard/graphs/contributors) for making this project possible!\n\n<!-- BEGIN SECTION: obtainium_links -->\n<!-- auto-generated link templates, do NOT edit by hand -->\n<!-- see fastlane/update-readme.sh -->\n[obtainium_preview]: https://apps.obtainium.imranr.dev/redirect.html?r=obtainium://app/%7B%22id%22%3A%22dev.patrickgold.florisboard.beta%22%2C%22url%22%3A%22https%3A%2F%2Fgithub.com%2Fflorisboard%2Fflorisboard%22%2C%22author%22%3A%22florisboard%22%2C%22name%22%3A%22FlorisBoard%20Preview%22%2C%22additionalSettings%22%3A%22%7B%5C%22includePrereleases%5C%22%3Atrue%2C%5C%22fallbackToOlderReleases%5C%22%3Atrue%2C%5C%22apkFilterRegEx%5C%22%3A%5C%22preview%5C%22%7D%22%7D%0A\n[obtainium_stable]: https://apps.obtainium.imranr.dev/redirect.html?r=obtainium://app/%7B%22id%22%3A%22dev.patrickgold.florisboard%22%2C%22url%22%3A%22https%3A%2F%2Fgithub.com%2Fflorisboard%2Fflorisboard%22%2C%22author%22%3A%22florisboard%22%2C%22name%22%3A%22FlorisBoard%20Stable%22%2C%22additionalSettings%22%3A%22%7B%5C%22includePrereleases%5C%22%3Afalse%2C%5C%22fallbackToOlderReleases%5C%22%3Atrue%2C%5C%22apkFilterRegEx%5C%22%3A%5C%22stable%5C%22%7D%22%7D%0A\n<!-- END SECTION: obtainium_links -->\n",
      "stars_today": 8
    },
    {
      "id": 748528018,
      "name": "WhisperKit",
      "full_name": "argmaxinc/WhisperKit",
      "description": "On-device Speech Recognition for Apple Silicon",
      "html_url": "https://github.com/argmaxinc/WhisperKit",
      "stars": 5514,
      "forks": 492,
      "language": "Swift",
      "topics": [
        "inference",
        "ios",
        "macos",
        "speech-recognition",
        "swift",
        "transformers",
        "visionos",
        "watchos",
        "whisper"
      ],
      "created_at": "2024-01-26T07:11:52Z",
      "updated_at": "2026-01-24T20:59:40Z",
      "pushed_at": "2026-01-22T19:43:45Z",
      "open_issues": 93,
      "owner": {
        "login": "argmaxinc",
        "avatar_url": "https://avatars.githubusercontent.com/u/150409474?v=4"
      },
      "readme": "\n<div align=\"center\">\n  \n<a href=\"https://github.com/argmaxinc/WhisperKit#gh-light-mode-only\">\n  <img src=\"https://github.com/user-attachments/assets/f0699c07-c29f-45b6-a9c6-f6d491b8f791\" alt=\"WhisperKit\" width=\"20%\" />\n</a>\n\n<a href=\"https://github.com/argmaxinc/WhisperKit#gh-dark-mode-only\">\n  <img src=\"https://github.com/user-attachments/assets/1be5e31c-de42-40ab-9b85-790cb911ed47\" alt=\"WhisperKit\" width=\"20%\" />\n</a>\n\n# WhisperKit\n\n[![Tests](https://github.com/argmaxinc/whisperkit/actions/workflows/release-tests.yml/badge.svg)](https://github.com/argmaxinc/whisperkit/actions/workflows/release-tests.yml)\n[![License](https://img.shields.io/github/license/argmaxinc/whisperkit?logo=github&logoColor=969da4&label=License&labelColor=353a41&color=32d058)](LICENSE.md)\n[![Supported Swift Version](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fargmaxinc%2FWhisperKit%2Fbadge%3Ftype%3Dswift-versions&labelColor=353a41&color=32d058)](https://swiftpackageindex.com/argmaxinc/WhisperKit) [![Supported Platforms](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fargmaxinc%2FWhisperKit%2Fbadge%3Ftype%3Dplatforms&labelColor=353a41&color=32d058)](https://swiftpackageindex.com/argmaxinc/WhisperKit)\n[![Discord](https://img.shields.io/discord/1171912382512115722?style=flat&logo=discord&logoColor=969da4&label=Discord&labelColor=353a41&color=32d058&link=https%3A%2F%2Fdiscord.gg%2FG5F5GZGecC)](https://discord.gg/G5F5GZGecC)\n\n\n</div>\n\nWhisperKit is an [Argmax](https://www.takeargmax.com) framework for deploying state-of-the-art speech-to-text systems (e.g. [Whisper](https://github.com/openai/whisper)) on device with advanced features such as real-time streaming, word timestamps, voice activity detection, and more.\n\n[[TestFlight Demo App]](https://testflight.apple.com/join/Q1cywTJw) [[Python Tools]](https://github.com/argmaxinc/whisperkittools) [[Benchmarks & Device Support]](https://huggingface.co/spaces/argmaxinc/whisperkit-benchmarks) [[WhisperKit Android]](https://github.com/argmaxinc/WhisperKitAndroid)\n\n> [!IMPORTANT]\n> WhisperKit is ideal for getting started with on-device speech-to-text. When you are ready to scale your on-device deployment with real-time transcription and speaker diarization, start your [14-day trial](https://app.argmaxinc.com) for [Argmax Pro SDK](https://www.argmaxinc.com/#SDK) with 9x faster and higher accuracy models such as Nvidia Parakeet V3, [pyannoteAI's flagship](https://www.argmaxinc.com/blog/pyannote-argmax) speaker diarization model, and a Deepgram-compatible WebSocket [local server](https://www.argmaxinc.com/blog/argmax-local-server) for easy integration into non-Swift projects.\n\n## Table of Contents\n\n- [Installation](#installation)\n  - [Swift Package Manager](#swift-package-manager)\n  - [Prerequisites](#prerequisites)\n  - [Xcode Steps](#xcode-steps)\n  - [Package.swift](#packageswift)\n  - [Homebrew](#homebrew)\n- [Getting Started](#getting-started)\n  - [Quick Example](#quick-example)\n  - [Model Selection](#model-selection)\n  - [Generating Models](#generating-models)\n  - [Swift CLI](#swift-cli)\n- [WhisperKit Local Server](#whisperkit-local-server)\n- [Contributing \\& Roadmap](#contributing--roadmap)\n- [License](#license)\n- [Citation](#citation)\n\n## Installation\n\n### Swift Package Manager\n\nWhisperKit can be integrated into your Swift project using the Swift Package Manager.\n\n### Prerequisites\n\n- macOS 14.0 or later.\n- Xcode 15.0 or later.\n\n### Xcode Steps\n\n1. Open your Swift project in Xcode.\n2. Navigate to `File` > `Add Package Dependencies...`.\n3. Enter the package repository URL: `https://github.com/argmaxinc/whisperkit`.\n4. Choose the version range or specific version.\n5. Click `Finish` to add WhisperKit to your project.\n\n### Package.swift\n\nIf you're using WhisperKit as part of a swift package, you can include it in your Package.swift dependencies as follows:\n\n```swift\ndependencies: [\n    .package(url: \"https://github.com/argmaxinc/WhisperKit.git\", from: \"0.9.0\"),\n],\n```\n\nThen add `WhisperKit` as a dependency for your target:\n\n```swift\n.target(\n    name: \"YourApp\",\n    dependencies: [\"WhisperKit\"]\n),\n```\n\n### Homebrew\n\nYou can install `WhisperKit` command line app using [Homebrew](https://brew.sh) by running the following command:\n\n```bash\nbrew install whisperkit-cli\n```  \n\n## Getting Started\n\nTo get started with WhisperKit, you need to initialize it in your project.\n\n### Quick Example\n\nThis example demonstrates how to transcribe a local audio file:\n\n```swift\nimport WhisperKit\n\n// Initialize WhisperKit with default settings\nTask {\n   let pipe = try? await WhisperKit()\n   let transcription = try? await pipe!.transcribe(audioPath: \"path/to/your/audio.{wav,mp3,m4a,flac}\")?.text\n    print(transcription)\n}\n```\n\n### Model Selection\n\nWhisperKit automatically downloads the recommended model for the device if not specified. You can also select a specific model by passing in the model name:\n\n```swift\nlet pipe = try? await WhisperKit(WhisperKitConfig(model: \"large-v3\"))\n```\n\nThis method also supports glob search, so you can use wildcards to select a model:\n\n```swift\nlet pipe = try? await WhisperKit(WhisperKitConfig(model: \"distil*large-v3\"))\n```\n\nNote that the model search must return a single model from the source repo, otherwise an error will be thrown.\n\nFor a list of available models, see our [HuggingFace repo](https://huggingface.co/argmaxinc/whisperkit-coreml).\n\n### Generating Models\n\nWhisperKit also comes with the supporting repo [`whisperkittools`](https://github.com/argmaxinc/whisperkittools) which lets you create and deploy your own fine tuned versions of Whisper in CoreML format to HuggingFace. Once generated, they can be loaded by simply changing the repo name to the one used to upload the model:\n\n```swift\nlet config = WhisperKitConfig(model: \"large-v3\", modelRepo: \"username/your-model-repo\")\nlet pipe = try? await WhisperKit(config)\n```\n\n### Swift CLI\n\nThe Swift CLI allows for quick testing and debugging outside of an Xcode project. To install it, run the following:\n\n```bash\ngit clone https://github.com/argmaxinc/whisperkit.git\ncd whisperkit\n```\n\nThen, setup the environment and download your desired model.\n\n```bash\nmake setup\nmake download-model MODEL=large-v3\n```\n\n**Note**:\n\n1. This will download only the model specified by `MODEL` (see what's available in our [HuggingFace repo](https://huggingface.co/argmaxinc/whisperkit-coreml), where we use the prefix `openai_whisper-{MODEL}`)\n2. Before running `download-model`, make sure [git-lfs](https://git-lfs.com) is installed\n\nIf you would like download all available models to your local folder, use this command instead:\n\n```bash\nmake download-models\n```\n\nYou can then run them via the CLI with:\n\n```bash\nswift run whisperkit-cli transcribe --model-path \"Models/whisperkit-coreml/openai_whisper-large-v3\" --audio-path \"path/to/your/audio.{wav,mp3,m4a,flac}\" \n```\n\nWhich should print a transcription of the audio file. If you would like to stream the audio directly from a microphone, use:\n\n```bash\nswift run whisperkit-cli transcribe --model-path \"Models/whisperkit-coreml/openai_whisper-large-v3\" --stream\n```\n\n### WhisperKit Local Server\n\nWhisperKit includes a local server that implements the OpenAI Audio API, allowing you to use existing OpenAI SDK clients or generate new ones. The server supports transcription and translation with **output streaming** capabilities (real-time transcription results as they're generated).\n\n> [!NOTE]\n> **For real-time transcription server with full-duplex streaming capabilities**, check out [WhisperKit Pro Local Server](https://www.argmaxinc.com/blog/argmax-local-server) which provides live audio streaming and real-time transcription for applications requiring continuous audio processing.\n\n#### Building the Server\n\n```bash\n# Build with server support\nmake build-local-server\n\n# Or manually with the build flag\nBUILD_ALL=1 swift build --product whisperkit-cli\n```\n\n#### Starting the Server\n\n```bash\n# Start server with default settings\nBUILD_ALL=1 swift run whisperkit-cli serve\n\n# Custom host and port\nBUILD_ALL=1 swift run whisperkit-cli serve --host 0.0.0.0 --port 8080\n\n# With specific model and verbose logging\nBUILD_ALL=1 swift run whisperkit-cli serve --model tiny --verbose\n\n# See all configurable parameters\nBUILD_ALL=1 swift run whisperkit-cli serve --help\n```\n\n#### API Endpoints\n\n- **POST** `/v1/audio/transcriptions` - Transcribe audio to text\n- **POST** `/v1/audio/translations` - Translate audio to English\n\n#### Supported Parameters\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `file` | Audio file (wav, mp3, m4a, flac) | Required |\n| `model` | Model identifier | Server default |\n| `language` | Source language code | Auto-detect |\n| `prompt` | Text to guide transcription | None |\n| `response_format` | Output format (json, verbose_json) | verbose_json |\n| `temperature` | Sampling temperature (0.0-1.0) | 0.0 |\n| `timestamp_granularities[]` | Timing detail (word, segment) | segment |\n| `stream` | Enable streaming | false |\n\n#### Client Examples\n\n**Python Client (OpenAI SDK)**\n```bash\ncd Examples/ServeCLIClient/Python\nuv sync\npython whisperkit_client.py transcribe --file audio.wav --language en\npython whisperkit_client.py translate --file audio.wav\n```\n\nQuick Python example:\n```python\nfrom openai import OpenAI\nclient = OpenAI(base_url=\"http://localhost:50060/v1\")\nresult = client.audio.transcriptions.create(\n    file=open(\"audio.wav\", \"rb\"),\n    model=\"tiny\"  # Model parameter is required\n)\nprint(result.text)\n```\n\n**Swift Client (Generated from OpenAPI Spec, see ServeCLIClient/Swift/updateClient.sh)**\n```bash\ncd Examples/ServeCLIClient/Swift\nswift run whisperkit-client transcribe audio.wav --language en\nswift run whisperkit-client translate audio.wav\n```\n\n**CurlClient (Shell Scripts)**\n```bash\ncd Examples/ServeCLIClient/Curl\nchmod +x *.sh\n./transcribe.sh audio.wav --language en\n./translate.sh audio.wav --language es\n./test.sh  # Run comprehensive test suite\n```\n\n#### Generating the API Specification\n\nThe server's OpenAPI specification and code are generated from the official OpenAI API:\n\n```bash\n# Generate latest spec and server code\nmake generate-server\n```\n\n#### Client Generation\n\nYou can generate clients for any language using the OpenAPI specification, for example:\n\n```bash\n# Generate Python client\nswift run swift-openapi-generator generate scripts/specs/localserver_openapi.yaml \\\n  --output-directory python-client \\\n  --mode client \\\n  --mode types\n\n# Generate TypeScript client\nnpx @openapitools/openapi-generator-cli generate \\\n  -i scripts/specs/localserver_openapi.yaml \\\n  -g typescript-fetch \\\n  -o typescript-client\n```\n\n#### API Limitations\n\nCompared to the official OpenAI API, the local server has these limitations:\n\n- **Response formats**: Only `json` and `verbose_json` supported (no plain text, SRT, VTT formats)\n- **Model selection**: Client must launch server with desired model via `--model` flag\n\n#### Fully Supported Features\n\nThe local server fully supports these OpenAI API features:\n\n- **Include parameters**: `logprobs` parameter for detailed token-level log probabilities\n- **Streaming responses**: Server-Sent Events (SSE) for real-time transcription\n- **Timestamp granularities**: Both `word` and `segment` level timing\n- **Language detection**: Automatic language detection or manual specification\n- **Temperature control**: Sampling temperature for transcription randomness\n- **Prompt text**: Text guidance for transcription style and context\n\n## Contributing & Roadmap\n\nOur goal is to make WhisperKit better and better over time and we'd love your help! Just search the code for \"TODO\" for a variety of features that are yet to be built. Please refer to our [contribution guidelines](CONTRIBUTING.md) for submitting issues, pull requests, and coding standards, where we also have a public roadmap of features we are looking forward to building in the future.\n\n## License\n\nWhisperKit is released under the MIT License. See [LICENSE](LICENSE) for more details.\n\n## Citation\n\nIf you use WhisperKit for something cool or just find it useful, please drop us a note at [info@argmaxinc.com](mailto:info@argmaxinc.com)!\n\nIf you use WhisperKit for academic work, here is the BibTeX:\n\n```bibtex\n@misc{whisperkit-argmax,\n   title = {WhisperKit},\n   author = {Argmax, Inc.},\n   year = {2024},\n   URL = {https://github.com/argmaxinc/WhisperKit}\n}\n```\n",
      "stars_today": 8
    },
    {
      "id": 67836789,
      "name": "tokio",
      "full_name": "tokio-rs/tokio",
      "description": "A runtime for writing reliable asynchronous applications with Rust. Provides I/O, networking, scheduling, timers, ...",
      "html_url": "https://github.com/tokio-rs/tokio",
      "stars": 30855,
      "forks": 2897,
      "language": "Rust",
      "topics": [
        "asynchronous",
        "networking",
        "rust"
      ],
      "created_at": "2016-09-09T22:31:36Z",
      "updated_at": "2026-01-24T23:44:52Z",
      "pushed_at": "2026-01-24T16:09:05Z",
      "open_issues": 388,
      "owner": {
        "login": "tokio-rs",
        "avatar_url": "https://avatars.githubusercontent.com/u/20248544?v=4"
      },
      "readme": "# Tokio\n\nA runtime for writing reliable, asynchronous, and slim applications with\nthe Rust programming language. It is:\n\n* **Fast**: Tokio's zero-cost abstractions give you bare-metal\n  performance.\n\n* **Reliable**: Tokio leverages Rust's ownership, type system, and\n  concurrency model to reduce bugs and ensure thread safety.\n\n* **Scalable**: Tokio has a minimal footprint, and handles backpressure\n  and cancellation naturally.\n\n[![Crates.io][crates-badge]][crates-url]\n[![MIT licensed][mit-badge]][mit-url]\n[![Build Status][actions-badge]][actions-url]\n[![Discord chat][discord-badge]][discord-url]\n\n[crates-badge]: https://img.shields.io/crates/v/tokio.svg\n[crates-url]: https://crates.io/crates/tokio\n[mit-badge]: https://img.shields.io/badge/license-MIT-blue.svg\n[mit-url]: https://github.com/tokio-rs/tokio/blob/master/LICENSE\n[actions-badge]: https://github.com/tokio-rs/tokio/workflows/CI/badge.svg\n[actions-url]: https://github.com/tokio-rs/tokio/actions?query=workflow%3ACI+branch%3Amaster\n[discord-badge]: https://img.shields.io/discord/500028886025895936.svg?logo=discord&style=flat-square\n[discord-url]: https://discord.gg/tokio\n\n[Website](https://tokio.rs) |\n[Guides](https://tokio.rs/tokio/tutorial) |\n[API Docs](https://docs.rs/tokio/latest/tokio) |\n[Chat](https://discord.gg/tokio)\n\n## Overview\n\nTokio is an event-driven, non-blocking I/O platform for writing\nasynchronous applications with the Rust programming language. At a high\nlevel, it provides a few major components:\n\n* A multithreaded, work-stealing based task [scheduler].\n* A reactor backed by the operating system's event queue (epoll, kqueue,\n  IOCP, etc.).\n* Asynchronous [TCP and UDP][net] sockets.\n\nThese components provide the runtime components necessary for building\nan asynchronous application.\n\n[net]: https://docs.rs/tokio/latest/tokio/net/index.html\n[scheduler]: https://docs.rs/tokio/latest/tokio/runtime/index.html\n\n## Example\n\nA basic TCP echo server with Tokio.\n\nMake sure you enable the full features of the tokio crate on Cargo.toml:\n\n```toml\n[dependencies]\ntokio = { version = \"1.49.0\", features = [\"full\"] }\n```\nThen, on your main.rs:\n\n```rust,no_run\nuse tokio::net::TcpListener;\nuse tokio::io::{AsyncReadExt, AsyncWriteExt};\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let listener = TcpListener::bind(\"127.0.0.1:8080\").await?;\n\n    loop {\n        let (mut socket, _) = listener.accept().await?;\n\n        tokio::spawn(async move {\n            let mut buf = [0; 1024];\n\n            // In a loop, read data from the socket and write the data back.\n            loop {\n                let n = match socket.read(&mut buf).await {\n                    // socket closed\n                    Ok(0) => return,\n                    Ok(n) => n,\n                    Err(e) => {\n                        eprintln!(\"failed to read from socket; err = {:?}\", e);\n                        return;\n                    }\n                };\n\n                // Write the data back\n                if let Err(e) = socket.write_all(&buf[0..n]).await {\n                    eprintln!(\"failed to write to socket; err = {:?}\", e);\n                    return;\n                }\n            }\n        });\n    }\n}\n```\n\nMore examples can be found [here][examples]. For a larger \"real world\" example, see the\n[mini-redis] repository.\n\n[examples]: https://github.com/tokio-rs/tokio/tree/master/examples\n[mini-redis]: https://github.com/tokio-rs/mini-redis/\n\nTo see a list of the available feature flags that can be enabled, check our\n[docs][feature-flag-docs].\n\n## Getting Help\n\nFirst, see if the answer to your question can be found in the [Guides] or the\n[API documentation]. If the answer is not there, there is an active community in\nthe [Tokio Discord server][chat]. We would be happy to try to answer your\nquestion. You can also ask your question on [the discussions page][discussions].\n\n[Guides]: https://tokio.rs/tokio/tutorial\n[API documentation]: https://docs.rs/tokio/latest/tokio\n[chat]: https://discord.gg/tokio\n[discussions]: https://github.com/tokio-rs/tokio/discussions\n[feature-flag-docs]: https://docs.rs/tokio/#feature-flags\n\n## Contributing\n\n:balloon: Thanks for your help improving the project! We are so happy to have\nyou! We have a [contributing guide][guide] to help you get involved in the Tokio\nproject.\n\n[guide]: https://github.com/tokio-rs/tokio/blob/master/docs/contributing/README.md\n\n## Related Projects\n\nIn addition to the crates in this repository, the Tokio project also maintains\nseveral other libraries, including:\n\n* [`axum`]: A web application framework that focuses on ergonomics and modularity.\n\n* [`hyper`]: A fast and correct HTTP/1.1 and HTTP/2 implementation for Rust.\n\n* [`tonic`]: A gRPC over HTTP/2 implementation focused on high performance, interoperability, and flexibility.\n\n* [`warp`]: A super-easy, composable, web server framework for warp speeds.\n\n* [`tower`]: A library of modular and reusable components for building robust networking clients and servers.\n\n* [`tracing`] (formerly `tokio-trace`): A framework for application-level tracing and async-aware diagnostics.\n\n* [`mio`]: A low-level, cross-platform abstraction over OS I/O APIs that powers `tokio`.\n\n* [`bytes`]: Utilities for working with bytes, including efficient byte buffers.\n\n* [`loom`]: A testing tool for concurrent Rust code.\n\n[`axum`]: https://github.com/tokio-rs/axum\n[`warp`]: https://github.com/seanmonstar/warp\n[`hyper`]: https://github.com/hyperium/hyper\n[`tonic`]: https://github.com/hyperium/tonic\n[`tower`]: https://github.com/tower-rs/tower\n[`loom`]: https://github.com/tokio-rs/loom\n[`tracing`]: https://github.com/tokio-rs/tracing\n[`mio`]: https://github.com/tokio-rs/mio\n[`bytes`]: https://github.com/tokio-rs/bytes\n\n## Changelog\n\nThe Tokio repository contains multiple crates. Each crate has its own changelog.\n\n * `tokio` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio/CHANGELOG.md)\n * `tokio-util` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-util/CHANGELOG.md)\n * `tokio-stream` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-stream/CHANGELOG.md)\n * `tokio-macros` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-macros/CHANGELOG.md)\n * `tokio-test` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-test/CHANGELOG.md)\n\n## Supported Rust Versions\n\n<!--\nWhen updating this, also update:\n- .github/workflows/ci.yml\n- CONTRIBUTING.md\n- README.md\n- tokio/README.md\n- tokio/Cargo.toml\n- tokio-util/Cargo.toml\n- tokio-test/Cargo.toml\n- tokio-stream/Cargo.toml\n-->\n\nTokio will keep a rolling MSRV (minimum supported rust version) policy of **at\nleast** 6 months. When increasing the MSRV, the new Rust version must have been\nreleased at least six months ago. The current MSRV is 1.71.\n\nNote that the MSRV is not increased automatically, and only as part of a minor\nrelease. The MSRV history for past minor releases can be found below:\n\n * 1.48 to now  - Rust 1.71\n * 1.39 to 1.47 - Rust 1.70\n * 1.30 to 1.38 - Rust 1.63\n * 1.27 to 1.29 - Rust 1.56\n * 1.17 to 1.26 - Rust 1.49\n * 1.15 to 1.16 - Rust 1.46\n * 1.0 to 1.14 - Rust 1.45\n\nNote that although we try to avoid the situation where a dependency transitively\nincreases the MSRV of Tokio, we do not guarantee that this does not happen.\nHowever, every minor release will have some set of versions of dependencies that\nworks with the MSRV of that minor release.\n\n## Release schedule\n\nTokio doesn't follow a fixed release schedule, but we typically make one minor\nrelease each month. We make patch releases for bugfixes as necessary.\n\n## Bug patching policy\n\nFor the purposes of making patch releases with bugfixes, we have designated\ncertain minor releases as LTS (long term support) releases. Whenever a bug\nwarrants a patch release with a fix for the bug, it will be backported and\nreleased as a new patch release for each LTS minor version. Our current LTS\nreleases are:\n\n * `1.43.x` - LTS release until March 2026. (MSRV 1.70)\n * `1.47.x` - LTS release until September 2026. (MSRV 1.70)\n\nEach LTS release will continue to receive backported fixes for at least a year.\nIf you wish to use a fixed minor release in your project, we recommend that you\nuse an LTS release.\n\nTo use a fixed minor version, you can specify the version with a tilde. For\nexample, to specify that you wish to use the newest `1.43.x` patch release, you\ncan use the following dependency specification:\n```text\ntokio = { version = \"~1.43\", features = [...] }\n```\n\n### Previous LTS releases\n\n * `1.8.x` - LTS release until February 2022.\n * `1.14.x` - LTS release until June 2022.\n * `1.18.x` - LTS release until June 2023.\n * `1.20.x` - LTS release until September 2023.\n * `1.25.x` - LTS release until March 2024.\n * `1.32.x` - LTS release until September 2024.\n * `1.36.x` - LTS release until March 2025.\n * `1.38.x` - LTS release until July 2025.\n\n## License\n\nThis project is licensed under the [MIT license].\n\n[MIT license]: https://github.com/tokio-rs/tokio/blob/master/LICENSE\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in Tokio by you shall be licensed as MIT, without any additional\nterms or conditions.\n",
      "stars_today": 7
    },
    {
      "id": 60667730,
      "name": "lvgl",
      "full_name": "lvgl/lvgl",
      "description": "Embedded graphics library to create beautiful UIs for any MCU, MPU and display type. ",
      "html_url": "https://github.com/lvgl/lvgl",
      "stars": 22571,
      "forks": 4004,
      "language": "C",
      "topics": [
        "c",
        "embedded",
        "graphics",
        "gui",
        "mcu",
        "microcontroller",
        "tft"
      ],
      "created_at": "2016-06-08T04:14:34Z",
      "updated_at": "2026-01-24T19:43:53Z",
      "pushed_at": "2026-01-24T10:31:43Z",
      "open_issues": 142,
      "owner": {
        "login": "lvgl",
        "avatar_url": "https://avatars.githubusercontent.com/u/19811762?v=4"
      },
      "readme": "<p align=\"right\">\n  <b>English</b> | <a href=\"./docs/README_zh.md\">ä¸­æ–‡</a> | <a href=\"./docs/README_pt_BR.md\">PortuguÃªs do Brasil</a> | <a href=\"./docs/README_jp.md\">æ—¥æœ¬èª</a> | <a href=\"./docs/README_he.md\">×¢×‘×¨×™×ª</a>\n</p>\n\n<br>\n\n<p align=\"center\">\nÂ  <img src=\"https://lvgl.io/github-assets/logo-colored.png\" width=300px>\n</p>\n\n<h1 align=\"center\">Light and Versatile Graphics Library</h1>\n\n<br/>\n\n<div align=\"center\">\n  <img src=\"https://lvgl.io/github-assets/smartwatch-demo.gif\">\n  &nbsp;\nÂ  <img border=\"1px\" src=\"https://lvgl.io/github-assets/widgets-demo.gif\">\n</div>\n\n<br/>\n\n<p align=\"center\">\n  <a href=\"https://lvgl.io\" title=\"Homepage of LVGL\">Website</a> |\n  <a href=\"https://pro.lvgl.io\" title=\"LVGL Pro XML based UI Editor\">LVGL Pro Editor</a> |\n  <a href=\"https://docs.lvgl.io/\" title=\"Detailed documentation with 100+ examples\">Docs</a> |\n  <a href=\"https://forum.lvgl.io\" title=\"Get help and help others\">Forum</a> |\n  <a href=\"https://lvgl.io/demos\" title=\"Demos running in your browser\">Demos</a> |\n<a href=\"https://lvgl.io/services\" title=\"Graphics design, UI implementation and consulting\">Services</a>\n</p>\n\n<br/>\n\n### Table of Contents\n<p>\n  <a href=\"#ledger-overview\">Overview</a> <br/>\n  <a href=\"#-features\">Features</a> <br/>\n  <a href=\"#%EF%B8%8F-platform-support\">Platform Support</a> <br/>\n  <a href=\"#-lvgl-pro-editor\">LVGL Pro Editor</a> <br/>\n  <a href=\"#-commercial-services\">Commercial Services</a> <br/>\n  <a href=\"#%E2%80%8D-integrating-lvgl\">Integrating LVGL</a> <br/>\n  <a href=\"#-examples\">Examples</a> <br/>\n  <a href=\"#-contributing\">Contributing</a>\n</p>\n\n<br/>\n\n## ğŸ“’ Overview\n\n**LVGL** is a free and open-source UI library that enables you to create graphical user interfaces\nfor any MCUs and MPUs from any vendor on any platform.\n\n**Requirements**: LVGL has no external dependencies, which makes it easy to compile for any modern target,\nfrom small MCUs to multi-core Linux-based MPUs with 3D support. For a simple UI, you need only ~100kB RAM,\n~200â€“300kB flash, and a buffer size of 1/10 of the screen for rendering.\n\n**To get started**, pick a ready-to-use VSCode, Eclipse, or any other project and try out LVGL\non your PC. The LVGL UI code is fully platform-independent, so you can use the same UI code\non embedded targets too.\n\n**LVGL Pro** is a complete toolkit to help you build, test, share, and ship UIs faster.\nIt comes with an XML Editor where you can quickly create and test reusable components,\nexport C code, or load the XMLs at runtime. Learn more here.\n\n## ğŸ’¡ Features\n\n**Free and Portable**\n  - A fully portable C (C++ compatible) library with no external dependencies.\n  - Can be compiled for any MCU or MPU, with any (RT)OS. Make, CMake, and simple globbing are all supported.\n  - Supports monochrome, ePaper, OLED, or TFT displays, or even monitors. [Displays](https://docs.lvgl.io/master/main-modules/display/index.html)\n  - Distributed under the MIT license, so you can easily use it in commercial projects too.\n  - Needs only 32kB RAM and 128kB Flash, a frame buffer, and at least a 1/10 screen-sized buffer for rendering.\n  - OS, external memory, and GPU are supported but not required.\n\n**Widgets, Styles, Layouts, and More**\n  - 30+ built-in [Widgets](https://docs.lvgl.io/master/widgets/index.html): Button, Label, Slider, Chart, Keyboard, Meter, Arc, Table, and many more.\n  - Flexible [Style system](https://docs.lvgl.io/master/common-widget-features/styles/index.html) with ~100 style properties to customize any part of the widgets in any state.\n  - [Flexbox](https://docs.lvgl.io/master/common-widget-features/layouts/flex.html) and [Grid](https://docs.lvgl.io/master/common-widget-features/layouts/grid.html)-like layout engines to automatically size and position the widgets responsively.\n  - Text is rendered with UTF-8 encoding, supporting CJK, Thai, Hindi, Arabic, and Persian writing systems.\n  - [Data bindings](https://docs.lvgl.io/master/main-modules/observer/index.html) to easily connect the UI with the application.\n  - Rendering engine supports animations, anti-aliasing, opacity, smooth scrolling, shadows, image transformation, etc.\n  - [Powerful 3D rendering engine](https://docs.lvgl.io/master/libs/gltf.html) to show [glTF models](https://sketchfab.com/) with OpenGL.\n  - Supports Mouse, Touchpad, Keypad, Keyboard, External buttons, Encoder [Input devices](https://docs.lvgl.io/master/main-modules/indev.html).\n  - [Multiple display](https://docs.lvgl.io/master/main-modules/display/overview.html#how-many-displays-can-lvgl-use) support.\n\n## ğŸ“¦ï¸ Platform Support\n\nLVGL has no external dependencies, so it can be easily compiled for any devices and it's  also available in many package managers and RTOSes:\n\n- [Arduino library](https://docs.lvgl.io/master/integration/framework/arduino.html)\n- [PlatformIO package](https://registry.platformio.org/libraries/lvgl/lvgl)\n- [Zephyr library](https://docs.lvgl.io/master/integration/os/zephyr.html)\n- [ESP-IDF(ESP32) component](https://components.espressif.com/components/lvgl/lvgl)\n- [NXP MCUXpresso component](https://www.nxp.com/design/software/embedded-software/lvgl-open-source-graphics-library:LITTLEVGL-OPEN-SOURCE-GRAPHICS-LIBRARY)\n- [NuttX library](https://docs.lvgl.io/master/integration/os/nuttx.html)\n- [RT-Thread RTOS](https://docs.lvgl.io/master/integration/os/rt-thread.html)\n- CMSIS-Pack\n- [RIOT OS package](https://doc.riot-os.org/group__pkg__lvgl.html#details)\n\n## ğŸš€ LVGL Pro Editor\n\nLVGL Pro is a complete toolkit to build, test, share, and ship embedded UIs efficiently.\n\nIt consists of four tightly related tools:\n\n1. **XML Editor**: The heart of LVGL Pro. A desktop app to build components and screens in XML, manage data bindings, translations, animations, tests, and more. Learn more about the [XML Format](https://docs.lvgl.io/master/xml/xml/index.html) and the [Editor](https://docs.lvgl.io/master/xml/editor/index.html).\n2. **Online Viewer**: Run the Editor in your browser, open GitHub projects, and share easily without setting up a developer environment. Visit [https://viewer.lvgl.io](https://viewer.lvgl.io).\n3. **CLI Tool**: Generate C code and run tests in CI/CD. See the details [here](https://docs.lvgl.io/master/xml/tools/cli.html).\n4. **Figma Plugin**: Sync and extract styles directly from Figma. See how it works [here](https://docs.lvgl.io/master/xml/tools/figma.html).\n\nTogether, these tools let developers build UIs efficiently, test them reliably, and collaborate with team members and customers.\n\nLearn more at https://pro.lvgl.io\n\n## ğŸ¤ Commercial Services\n\nLVGL LLC provides several types of commercial services to help you with UI development. With 15+ years of experience in the user interface and graphics industry, we can help bring your UI to the next level.\n\n- **Graphics design**: Our in-house graphic designers are experts in creating beautiful modern designs that fit your product and the capabilities of your hardware.\n- **UI implementation**: We can implement your UI based on the design you or we have created. You can be sure that we will make the most of your hardware and LVGL. If a feature or widget is missing from LVGL, don't worry, we will implement it for you.\n- **Consulting and Support**: We also offer consulting to help you avoid costly and time-consuming mistakes during UI development.\n- **Board certification**: For companies offering development boards or production-ready kits, we provide board certification to show how the board can run LVGL.\n\nCheck out our [Demos](https://lvgl.io/demos) as references. For more information, take a look at the [Services page](https://lvgl.io/services).\n\n[Contact us](https://lvgl.io/#contact) and tell us how we can help.\n\n## ğŸ§‘â€ğŸ’» Integrating LVGL\n\nIntegrating LVGL is very simple. Just drop it into any project and compile it as you would compile other files.\nTo configure LVGL, copy `lv_conf_template.h` as `lv_conf.h`, enable the first `#if 0`, and adjust the configs as needed.\n(The default config is usually fine.) If available, LVGL can also be used with Kconfig.\n\nOnce in the project, you can initialize LVGL and create display and input devices as follows:\n\n```c\n#include \"lvgl/lvgl.h\" /*Define LV_LVGL_H_INCLUDE_SIMPLE to include as \"lvgl.h\"*/\n\n#define TFT_HOR_RES 320\n#define TFT_VER_RES 240\n\nstatic uint32_t my_tick_cb(void)\n{\n    return my_get_millisec();\n}\n\nstatic void my_flush_cb(lv_display_t * disp, const lv_area_t * area, uint8_t * px_map)\n{\n    /*Write px_map to the area->x1, area->x2, area->y1, area->y2 area of the\n     *frame buffer or external display controller. */\n}\n\nstatic void my_touch_read_cb(lv_indev_t * indev, lv_indev_data_t * data)\n{\n   if(my_touch_is_pressed()) {\n       data->point.x = touchpad_x;\n       data->point.y = touchpad_y;\n       data->state = LV_INDEV_STATE_PRESSED;\n   } else {\n       data->state = LV_INDEV_STATE_RELEASED;\n   }\n}\n\nvoid main(void)\n{\n    my_hardware_init();\n\n    /*Initialize LVGL*/\n    lv_init();\n\n    /*Set millisecond-based tick source for LVGL so that it can track time.*/\n    lv_tick_set_cb(my_tick_cb);\n\n    /*Create a display where screens and widgets can be added*/\n    lv_display_t * display = lv_display_create(TFT_HOR_RES, TFT_VER_RES);\n\n    /*Add rendering buffers to the screen.\n     *Here adding a smaller partial buffer assuming 16-bit (RGB565 color format)*/\n    static uint8_t buf[TFT_HOR_RES * TFT_VER_RES / 10 * 2]; /* x2 because of 16-bit color depth */\n    lv_display_set_buffers(display, buf, NULL, sizeof(buf), LV_DISPLAY_RENDER_MODE_PARTIAL);\n\n    /*Add a callback that can flush the content from `buf` when it has been rendered*/\n    lv_display_set_flush_cb(display, my_flush_cb);\n\n    /*Create an input device for touch handling*/\n    lv_indev_t * indev = lv_indev_create();\n    lv_indev_set_type(indev, LV_INDEV_TYPE_POINTER);\n    lv_indev_set_read_cb(indev, my_touch_read_cb);\n\n    /*The drivers are in place; now we can create the UI*/\n    lv_obj_t * label = lv_label_create(lv_screen_active());\n    lv_label_set_text(label, \"Hello world\");\n    lv_obj_center(label);\n\n    /*Execute the LVGL-related tasks in a loop*/\n    while(1) {\n        lv_timer_handler();\n        my_sleep_ms(5);         /*Wait a little to let the system breathe*/\n    }\n}\n```\n\n## ğŸ¤– Examples\n\nYou can check out more than 100 examples at https://docs.lvgl.io/master/examples.html\n\nThe Online Viewer also contains tutorials to easily learn XML: https://viewer.lvgl.io/\n\n\n### Hello World Button with an Event\n\n<img width=\"311\" height=\"232\" alt=\"image\" src=\"https://github.com/user-attachments/assets/5948b485-e3f7-4a63-bb21-984381417c4a\" />\n\n<details>\n  <summary>C code</summary>\n\n  ```c\nstatic void button_clicked_cb(lv_event_t * e)\n{\n\tprintf(\"Clicked\\n\");\n}\n\n[...]\n\n  lv_obj_t * button = lv_button_create(lv_screen_active());\n  lv_obj_center(button);\n  lv_obj_add_event_cb(button, button_clicked_cb, LV_EVENT_CLICKED, NULL);\n\n  lv_obj_t * label = lv_label_create(button);\n  lv_label_set_text(label, \"Hello from LVGL!\");\n```\n</details>\n\n<details>\n  <summary>In XML with LVGL Pro</summary>\n\n```xml\n<screen>\n\t<view>\n\t\t<lv_button align=\"center\">\n\t\t\t<event_cb callback=\"button_clicked_cb\" />\n\t\t\t<lv_label text=\"Hello from LVGL!\" />\n\t\t</lv_button>\n\t</view>\n</screen>\n```\n\n</details>\n\n### Styled Slider with Data-binding\n\n<img width=\"314\" height=\"233\" alt=\"image\" src=\"https://github.com/user-attachments/assets/268db1a0-946c-42e2-aee4-9550bdf5f4f9\" />\n\n<details>\n  <summary>C code</summary>\n\n```c\nstatic void my_observer_cb(lv_observer_t * observer, lv_subject_t * subject)\n{\n\tprintf(\"Slider value: %d\\n\", lv_subject_get_int(subject));\n}\n\n[...]\n\nstatic lv_subject_t subject_value;\nlv_subject_init_int(&subject_value, 35);\nlv_subject_add_observer(&subject_value, my_observer_cb, NULL);\n\nlv_style_t style_base;\nlv_style_init(&style_base);\nlv_style_set_bg_color(&style_base, lv_color_hex(0xff8800));\nlv_style_set_bg_opa(&style_base, 255);\nlv_style_set_radius(&style_base, 4);\n\nlv_obj_t * slider = lv_slider_create(lv_screen_active());\nlv_obj_center(slider);\nlv_obj_set_size(slider, lv_pct(80), 16);\nlv_obj_add_style(slider, &style_base, LV_PART_INDICATOR);\nlv_obj_add_style(slider, &style_base, LV_PART_KNOB);\nlv_obj_add_style(slider, &style_base, 0);\nlv_obj_set_style_bg_opa(slider, LV_OPA_50, 0);\nlv_obj_set_style_border_width(slider, 3, LV_PART_KNOB);\nlv_obj_set_style_border_color(slider, lv_color_hex3(0xfff), LV_PART_KNOB);\nlv_slider_bind_value(slider, &subject_value);\n\nlv_obj_t * label = lv_label_create(lv_screen_active());\nlv_obj_align(label, LV_ALIGN_CENTER, 0, -30);\nlv_label_bind_text(label, &subject_value, \"Temperature: %d Â°C\");\n```\n\n</details>\n\n<details>\n  <summary>In XML with LVGL Pro</summary>\n\n```xml\n<screen>\n\t<styles>\n\t\t<style name=\"style_base\" bg_opa=\"100%\" bg_color=\"0xff8800\" radius=\"4\" />\n\t\t<style name=\"style_border\" border_color=\"0xfff\" border_width=\"3\" />\n\t</styles>\n\n\t<view>\n\t\t<lv_label bind_text=\"value\" bind_text-fmt=\"Temperature: %d Â°C\" align=\"center\" y=\"-30\" />\n\t\t<lv_slider align=\"center\" bind_value=\"value\" style_bg_opa=\"30%\">\n\t\t\t<style name=\"style_base\" />\n\t\t\t<style name=\"style_base\" selector=\"knob\" />\n\t\t\t<style name=\"style_base\" selector=\"indicator\" />\n\t\t\t<style name=\"style_border\" selector=\"knob\" />\n\t\t</lv_slider>\n\t</view>\n</screen>\n```\n\n</details>\n\n### Checkboxes in a Layout\n\n<img width=\"311\" height=\"231\" alt=\"image\" src=\"https://github.com/user-attachments/assets/ba9af647-2ea1-4bc8-b53d-c7b43ce24b6e\" />\n\n<details>\n  <summary>C code</summary>\n\n  ```c\n/*Create a new screen and load it*/\nlv_obj_t * scr = lv_obj_create(NULL);\nlv_screen_load(scr);\n\n/*Set a column layout*/\nlv_obj_set_flex_flow(scr, LV_FLEX_FLOW_COLUMN);\nlv_obj_set_flex_align(scr, LV_FLEX_ALIGN_SPACE_EVENLY, /*Vertical alignment*/\n\t\t\t\t\t\t   LV_FLEX_ALIGN_START,\t       /*Horizontal alignment in the track*/\n\t\t\t\t\t\t   LV_FLEX_ALIGN_CENTER);      /*Horizontal alignment of the track*/\n\n/*Create 5 checkboxes*/\nconst char * texts[5] = {\"Input 1\", \"Input 2\", \"Input 3\", \"Output 1\", \"Output 2\"};\nfor(int i = 0; i < 5; i++) {\n\tlv_obj_t * cb = lv_checkbox_create(scr);\n\tlv_checkbox_set_text(cb, texts[i]);\n}\n\n/*Change some states*/\nlv_obj_add_state(lv_obj_get_child(scr, 1), LV_STATE_CHECKED);\nlv_obj_add_state(lv_obj_get_child(scr, 3), LV_STATE_DISABLED);\n```\n\n</details>\n\n<details>\n  <summary>In XML with LVGL Pro</summary>\n\n```xml\n<screen>\n\t<view\n\t\tflex_flow=\"column\"\n\t\tstyle_flex_main_place=\"space_evenly\"\n\t\tstyle_flex_cross_place=\"start\"\n\t\tstyle_flex_track_place=\"center\"\n\t>\n\t\t<lv_checkbox text=\"Input 1\"/>\n\t\t<lv_checkbox text=\"Input 2\"/>\n\t\t<lv_checkbox text=\"Input 3\" checked=\"true\"/>\n\t\t<lv_checkbox text=\"Output 1\"/>\n\t\t<lv_checkbox text=\"Output 2\" disabled=\"true\"/>\n   </view>\n</screen>\n```\n\n</details>\n\n\n## ğŸŒŸ Contributing\n\nLVGL is an open project, and contributions are very welcome. There are many ways to contribute, from simply speaking about your project, writing examples, improving the documentation, fixing bugs, or even hosting your own project under the LVGL organization.\n\nFor a detailed description of contribution opportunities, visit the [Contributing](https://docs.lvgl.io/master/contributing/index.html)\nsection of the documentation.\n\nMore than 600 people have already left their fingerprint on LVGL. Be one of them! See you here! ğŸ™‚\n\n<a href=\"https://github.com/lvgl/lvgl/graphs/contributors\"> <img src=\"https://contrib.rocks/image?repo=lvgl/lvgl&max=48\" /> </a>\n\n... and many more.\n",
      "stars_today": 7
    },
    {
      "id": 521189491,
      "name": "cloudstream",
      "full_name": "recloudstream/cloudstream",
      "description": "Android app for streaming and downloading media.",
      "html_url": "https://github.com/recloudstream/cloudstream",
      "stars": 8684,
      "forks": 760,
      "language": "Kotlin",
      "topics": [
        "android",
        "good-first-issue",
        "home-theater",
        "media-center",
        "multimedia",
        "video-streaming"
      ],
      "created_at": "2022-08-04T08:42:38Z",
      "updated_at": "2026-01-25T01:33:16Z",
      "pushed_at": "2026-01-24T19:14:20Z",
      "open_issues": 445,
      "owner": {
        "login": "recloudstream",
        "avatar_url": "https://avatars.githubusercontent.com/u/110591699?v=4"
      },
      "readme": "# CloudStream\n\n**âš ï¸ Warning: By default, this app doesn't provide any video sources; you have to install extensions to add functionality to the app.**\n\n[![Discord](https://invidget.switchblade.xyz/5Hus6fM)](https://discord.gg/5Hus6fM)\n\n\n## Table of Contents: \n+ [About Us:](#about_us)\n+ [Installation Steps:](#install_rules)\n+ [Contributing:](#contributing)\n+ [Issues:](#issues)\n  + [Bugs Reports:](#bug_report)\n  + [Enhancement:](#enhancment)\n+ [Extension Development:](#extensions)\n+ [Language Support:](#languages)\n+ [Further Sources](#contact_and_sources)\n\n\n<a id=\"about_us\"></a>\n\n## About us: \n\n**CloudStream is a media center that prioritizes and emphasizes complete freedom and flexibility for users and developers.** \n\nCloudStream is an extension-based multimedia player with tracking support. There are extensions to view videos from: \n\n+ [Librevox (audio-books)](https://librivox.org/) \n+ [Youtube](https://www.youtube.com/)\n+ [Twitch](https://www.twitch.tv/)\n+ [iptv-org (A collection of publicly available IPTV (Internet Protocol television) channels from all over the world.)](https://github.com/iptv-org/iptv) \n+ [nginx](https://nginx.org/)\n+ And more... \n\n\n**Please don't create illegal extensions or use any that host any copyrighted media.** For more details about our stance on the DMCA and EUCD, you can read about it on our organization: [reCloudStream](https://github.com/recloudstream)\n\n#### Important Copyright Note: \n\nOur documentation is unmaintained and open to contributions; therefore, apps and sources, extensions in recommended sources, and recommended apps are not officially moderated or endorsed by CloudStream; if you or another copyright owner identify an extension that breaches your copyright, please let us know. \n\n\n#### Features:\n+ **AdFree**, No ads whatsoever\n+ No tracking/analytics\n+ Bookmarks\n+ Phone and TV support\n+ Chromecast\n+ Extension system for personal customization\n\n\n<a id=\"install_rules\"></a>\n\n## Installation: \n\nOur documentation provides the steps to install and configure CloudStream for your streaming needs.\n\n[Getting Started With CloudStream:](https://recloudstream.github.io/csdocs/)\n\n<a id=\"contributing\"></a>\n\n## Contributing:\nWe **happily** accept any contributions to our project. To find out where you can start contributing towards the project, please look [at our issues tab](/cloudstream/issues)\n\n\n\n<a id=\"issues\"></a> \n \n### Issues: \nWhile we **actively** accept issues and pull requests, we do require you fill out an [template](https://github.com/recloudstream/cloudstream/issues/new/choose) for issues. These include the following:\n\n<a id=\"bug_report\"></a>\n\n- [Bug Report Template: ](https://github.com/recloudstream/cloudstream/issues/new?assignees=&labels=bug&projects=&template=application-bug.yml)\n  - For bug reports, we want as much info as possible, including your downloaded version of CloudeStream, device and updated version (if possible, current API),\n    expected behavior of the program, and the actual behavior that the program did, most importantly we require clear, reproducible steps of the bug. If your bug can't be       reproduced, it is unlikely we'll work on your issue.\n    \n<a id=\"enhancment\"></a>\n  \n- [Feature Request Template: ](https://github.com/recloudstream/cloudstream/issues/new?assignees=&labels=enhancement&projects=&template=feature-request.yml)\n  - Before adding a feature request, please check to see if a feature request already has been requested.  \n\n\n### Extensions:\n \n**Further details on creating extensions for CloudStream are found in our documentation.**\n\n[Guide: For Extension Developers](https://recloudstream.github.io/csdocs/devs/gettingstarted/) \n\n<a id=\"contact_and_sources\"></a>\n\n## Further Sources: \n\nAs well as providing clear install steps, our [website](https://dweb.link/ipns/cloudstream.on.fleek.co/) includes a wide variety of other tools, such as: \n- [Troubleshooting](https://recloudstream.github.io/csdocs/troubleshooting/)\n- [Further CloudStream Repositories](https://recloudstream.github.io/csdocs/repositories/) \n- Set-Up for other devices, such as:\n  - [Android TV](https://recloudstream.github.io/csdocs/other-devices/tv/)\n  - [Windows](https://recloudstream.github.io/csdocs/other-devices/windows/)\n  - [Linux](https://recloudstream.github.io/csdocs/other-devices/linux/)\n- And more...\n\n<a id=\"languages\"> </a>  \n\n### Supported languages:\n\nEven if you can't contribute to the code or documentation, we always look for those who can contribute to translation and language support. Your contribution is exceptionally appreciated; you can check our translation from the figure below. \n\n<a href=\"https://hosted.weblate.org/engage/cloudstream/\">\n  <img src=\"https://hosted.weblate.org/widgets/cloudstream/-/app/multi-auto.svg\" alt=\"Translation status\" />\n</a>\n",
      "stars_today": 7
    },
    {
      "id": 7190986,
      "name": "shadowsocks-android",
      "full_name": "shadowsocks/shadowsocks-android",
      "description": "A shadowsocks client for Android",
      "html_url": "https://github.com/shadowsocks/shadowsocks-android",
      "stars": 36610,
      "forks": 11542,
      "language": "Kotlin",
      "topics": [
        "android",
        "shadowsocks"
      ],
      "created_at": "2012-12-16T13:40:29Z",
      "updated_at": "2026-01-24T19:19:14Z",
      "pushed_at": "2026-01-20T04:02:51Z",
      "open_issues": 58,
      "owner": {
        "login": "shadowsocks",
        "avatar_url": "https://avatars.githubusercontent.com/u/3006190?v=4"
      },
      "readme": "## [Shadowsocks](https://shadowsocks.org) for Android\n\n[![CircleCI](https://circleci.com/gh/shadowsocks/shadowsocks-android.svg?style=shield)](https://circleci.com/gh/shadowsocks/shadowsocks-android)\n[![API](https://img.shields.io/badge/API-23%2B-brightgreen.svg?style=flat)](https://android-arsenal.com/api?level=23)\n[![Releases](https://img.shields.io/github/downloads/shadowsocks/shadowsocks-android/total.svg)](https://github.com/shadowsocks/shadowsocks-android/releases)\n[![Language: Kotlin](https://img.shields.io/github/languages/top/shadowsocks/shadowsocks-android.svg)](https://github.com/shadowsocks/shadowsocks-android/search?l=kotlin)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/22ca240f272445548e332a42d5a20d95)](https://www.codacy.com/gh/shadowsocks/shadowsocks-android/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=shadowsocks/shadowsocks-android&amp;utm_campaign=Badge_Grade)\n[![License: GPL-3.0](https://img.shields.io/badge/license-GPL--3.0-orange.svg)](https://www.gnu.org/licenses/gpl-3.0)\n\n<a href=\"https://play.google.com/store/apps/details?id=com.github.shadowsocks\"><img src=\"https://play.google.com/intl/en_us/badges/images/generic/en-play-badge.png\" height=\"48\"></a>\nfor Android & Chrome OS ([beta](https://play.google.com/apps/testing/com.github.shadowsocks))  \n<a href=\"https://play.google.com/store/apps/details?id=com.github.shadowsocks.tv\"><img src=\"https://play.google.com/intl/en_us/badges/images/generic/en-play-badge.png\" height=\"48\"></a>\nfor Android TV ([beta](https://play.google.com/apps/testing/com.github.shadowsocks.tv))\n\n\n### PREREQUISITES\n\n* JDK 11+\n* Android SDK\n  - Android NDK\n* Rust with Android targets installed using `rustup target add armv7-linux-androideabi aarch64-linux-android i686-linux-android x86_64-linux-android`\n\n### BUILD\n\nYou can check whether the latest commit builds under UNIX environment by checking Travis status.\n\n* Install prerequisites\n* Clone the repo using `git clone --recurse-submodules <repo>` or update submodules using `git submodule update --init --recursive`\n* Build it using Android Studio or gradle script\n\n### CONTRIBUTING\n\nIf you are interested in contributing or getting involved with this project, please read the CONTRIBUTING page for more information.  The page can be found [here](https://github.com/shadowsocks/shadowsocks-android/blob/master/CONTRIBUTING.md).\n\n\n### [TRANSLATE](https://discourse.shadowsocks.org/t/poeditor-translation-main-thread/30)\n\n## OPEN SOURCE LICENSES\n\n<ul>\n    <li>redsocks: <a href=\"https://github.com/shadowsocks/redsocks/blob/shadowsocks-android/README\">APL 2.0</a></li>\n    <li>libevent: <a href=\"https://github.com/shadowsocks/libevent/blob/master/LICENSE\">BSD</a></li>\n    <li>tun2socks: <a href=\"https://github.com/shadowsocks/badvpn/blob/shadowsocks-android/COPYING\">BSD</a></li>\n    <li>shadowsocks-rust: <a href=\"https://github.com/shadowsocks/shadowsocks-rust/blob/master/LICENSE\">MIT</a></li>\n    <li>libsodium: <a href=\"https://github.com/jedisct1/libsodium/blob/master/LICENSE\">ISC</a></li>\n    <li>OpenSSL: <a href=\"https://www.openssl.org/source/license-openssl-ssleay.txt\">OpenSSL License</a></li>\n</ul>\n\n\n### LICENSE\n\nCopyright (C) 2017 by Max Lv <<max.c.lv@gmail.com>>  \nCopyright (C) 2017 by Mygod Studio <<contact-shadowsocks-android@mygod.be>>\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program. If not, see <http://www.gnu.org/licenses/>.\n",
      "stars_today": 6
    },
    {
      "id": 7613257,
      "name": "selenium",
      "full_name": "SeleniumHQ/selenium",
      "description": "A browser automation framework and ecosystem.",
      "html_url": "https://github.com/SeleniumHQ/selenium",
      "stars": 33935,
      "forks": 8642,
      "language": "Java",
      "topics": [
        "dotnet",
        "java",
        "javascript",
        "python",
        "ruby",
        "rust",
        "selenium",
        "webdriver"
      ],
      "created_at": "2013-01-14T21:40:56Z",
      "updated_at": "2026-01-25T00:31:30Z",
      "pushed_at": "2026-01-25T01:49:13Z",
      "open_issues": 230,
      "owner": {
        "login": "SeleniumHQ",
        "avatar_url": "https://avatars.githubusercontent.com/u/983927?v=4"
      },
      "readme": "<h1 align=\"center\">\n  <br/>\n  <a href=\"https://selenium.dev\"><img src=\"common/images/selenium_logo_mark_green.svg\" alt=\"Selenium\" width=\"100\"></a>\n  <br/>\n  Selenium\n  <br/>\n</h1>\n\n<h3 align=\"center\">Automates browsers. That's it!</h3>\n\n<p align=\"center\">\n  <a href=\"#contributing\">Contributing</a> â€¢\n  <a href=\"#installing\">Installing</a> â€¢\n  <a href=\"#building\">Building</a> â€¢\n  <a href=\"#developing\">Developing</a> â€¢\n  <a href=\"#testing\">Testing</a> â€¢\n  <a href=\"#documenting\">Documenting</a> â€¢\n  <a href=\"#releasing\">Releasing</a>\n</p>\n\n<br>\n\nSelenium is an umbrella project encapsulating a variety of tools and\nlibraries enabling web browser automation. Selenium specifically\nprovides an infrastructure for the [W3C WebDriver specification](https://w3c.github.io/webdriver/)\nâ€” a platform and language-neutral coding interface compatible with all\nmajor web browsers.\n\nThe project is made possible by volunteer contributors who've\ngenerously donated thousands of hours in code development and upkeep.\n\nThis README is for developers interested in contributing to the project.\nFor people looking to get started using Selenium, please check out\nour [User Manual](https://selenium.dev/documentation/) for detailed examples and descriptions, and if you\nget stuck, there are several ways to [Get Help](https://www.selenium.dev/support/).\n\n[![CI](https://github.com/SeleniumHQ/selenium/actions/workflows/ci.yml/badge.svg)](https://github.com/SeleniumHQ/selenium/actions/workflows/ci.yml)\n[![CI - RBE](https://github.com/SeleniumHQ/selenium/actions/workflows/ci-rbe.yml/badge.svg)](https://github.com/SeleniumHQ/selenium/actions/workflows/ci-rbe.yml)\n[![Releases downloads](https://img.shields.io/github/downloads/SeleniumHQ/selenium/total.svg)](https://github.com/SeleniumHQ/selenium/releases)\n\n## Contributing\n\nPlease read [CONTRIBUTING.md](https://github.com/SeleniumHQ/selenium/blob/trunk/CONTRIBUTING.md)\nbefore submitting your pull requests.\n\n## Installing\n\nThese are the requirements to create your own local dev environment to contribute to Selenium.\n\n### All Platforms\n\n* [Bazelisk](https://github.com/bazelbuild/bazelisk), a Bazel wrapper that automatically downloads\n  the version of Bazel specified in `.bazelversion` file and transparently passes through all\n  command-line arguments to the real Bazel binary.\n* Java JDK version 17 or greater (e.g., [Java 17 Temurin](https://adoptium.net/temurin/releases/?version=17))\n  * Set `JAVA_HOME` environment variable to location of Java executable (the JDK not the JRE)\n  * To test this, try running the command `javac`. This command won't exist if you only have the JRE\n  installed. If you're met with a list of command-line options, you're referencing the JDK properly.\n\n### MacOS\n\n  * Xcode including the command-line tools. Install the latest version using: `xcode-select --install`\n  * Rosetta for Apple Silicon Macs. Add `build --host_platform=//:rosetta` to the `.bazelrc.local` file. We are working\n  to make sure this isn't required in the long run.\n\n### Windows\n\nSeveral years ago [Jim Evans](https://www.linkedin.com/in/jimevansmusic/) published a great article on\n[Setting Up a Windows Development Environment for the Selenium .NET Language Bindings](https://jimevansmusic.blogspot.com/2020/04/setting-up-windows-development.html);\nThis article is out of date, but it includes more detailed descriptions and screenshots that some people might find useful.\n\n<details>\n<summary>Click to see Current Windows Setup Requirements</summary>\n\n#### Option 1: Automatic Installation from Scratch\n\nThis script will ensure a complete ready to execute developer environment.\n(nothing is installed or set that is already present unless otherwise prompted)\n\n1. Open Powershell as an Administrator\n2. Execute: `Set-ExecutionPolicy Bypass -Scope Process -Force` to allow running the script in the process\n3. Navigate to the directory you want to clone Selenium in, or the parent directory of an already cloned Selenium repo\n4. Download and execute this script in the powershell terminal: [scripts/dev-environment-setup.ps1]`\n\n#### Option 2: Manual Installation\n\n1. Allow running scripts in Selenium in general:\n    ```\n    Set-ExecutionPolicy -ExecutionPolicy RemoteSigned\n    ```\n2. Enable Developer Mode:\n    ```\n    reg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\AppModelUnlock\" /t REG_DWORD /f /v \"AllowDevelopmentWithoutDevLicense\" /d \"1\"\n    ```\n3. Install [MSYS2](https://www.msys2.org/), which is an alternative shell environment that provides Unix-like commands\n    * Add bin directory to `PATH` environment variable (e.g., `\"C:\\tools\\msys64\\usr\\bin\"`)\n    * Add `bash.exe` location as the `BAZEL_SH` environment variable (e.g., `\"C:\\tools\\msys64\\usr\\bin\\bash.exe\"`)\n4. Install the latest version of [Visual Studio Community](https://visualstudio.microsoft.com/vs/community/)\n    * Use the visual studio installer to modify and add the \"Desktop development with C++\" Workload\n    * Add Visual C++ build tools installation directory location to `BAZEL_VC` environment variable (e.g. `\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\"`)\n    * Add Visual C++ Build tools version to `BAZEL_VC_FULL_VERSION` environment variable (this can be discovered from the directory name in `\"$BAZEL_VC\\Tools\\MSVC\\<BAZEL_VC_FULL_VERSION>\"`)\n5. Add support for long file names (bazel has a lot of nested directories that can exceed default limits in Windows)\n    * Enable Long Paths support with these 2 registry commands:\n    ```shell\n    reg add \"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Command Processor\" /t REG_DWORD /f /v \"DisableUNCCheck\" /d \"1\"\n    reg add \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\" /t REG_DWORD /f /v \"LongPathsEnabled\" /d \"1\"\n    ```\n    * Allow Bazel to create short name versions of long file paths: `fsutil 8dot3name set 0`\n    * Set bazel output to `C:/tmp` instead of nested inside project directory:\n        * Create a file `selenium/.bazelrc.windows.local`\n        * Add \"startup --output_user_root=C:/tmp\" to the file\n\n</details>\n\n### Alternative Dev Environments\n\nIf you want to contribute to the project, but do not want to set up your own local dev environment,\nthere are two alternatives available.\n\n#### Using GitPod\n\nRather than creating your own local dev environment, GitPod provides a ready to use environment for you.\n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/SeleniumHQ/selenium)\n\n#### Using Dev Container\n\nAs an alternative you can build a [Dev Container](https://containers.dev/) - basically a docker container -\nsuitable for building and testing Selenium using the devcontainer.json in the\n[.devcontainer](.devcontainer/devcontainer.json) directory. Supporting IDEs like VS Code or IntelliJ IDEA\nshould point you to how such a container can be created.\n\n#### Using Docker Image\n\nYou can also build a Docker image suitable\nfor building and testing Selenium using the Dockerfile in the\n[dev image](scripts/dev-image/Dockerfile) directory.\n\n## Building\n\nSelenium is built using a common build tool called [Bazel](https://bazel.build/), to\nallow us to easily manage dependency downloads, generate required binaries, build and release packages, and execute tests;\nall in a fast, efficient manner. For a more detailed discussion, read Simon Stewart's article on [Building Selenium](https://www.selenium.dev/blog/2023/building-selenium/)\n\nOften we wrap Bazel commands with our custom [Rake](http://rake.rubyforge.org/) wrapper. These are run with the `./go` command.\n\nThe common Bazel commands are:\n* `bazel build` â€” evaluates dependencies, compiles source files and generates output files for the specified target.\nIt's used to create executable binaries, libraries, or other artifacts.\n* `bazel run` â€” builds the target and then executes it.\nIt's typically used for targets that produce executable binaries.\n* `bazel test` â€” builds and runs the target in a context with additional testing functionality\n* `bazel query` â€” identifies available targets for the provided path.\n\nEach module that can be built is defined in a `BUILD.bazel` file. To execute the module you refer to it starting with a\n`//`, then include the relative path to the file that defines it, then `:`, then the name of the target.\nFor example, the target to build the Grid is named `executable-grid` and it is\ndefined in the `'selenium/java/src/org/openqa/selenium/grid/BAZEL.build'` file.\nSo to build the grid you would run: `bazel build //java/src/org/openqa/selenium/grid:executable-grid`.\n\nThe Bazel documentation has a [handy guide](https://bazel.build/run/build#specifying-build-targets)\nfor various shortcuts and all the ways to build multiple targets, which Selenium makes frequent use of.\n\nTo build everything for a given language:\n\n```shell\nbazel build //<language>/...\n```\n\nTo build just the grid there is an alias name to use (the log will show where the output jar is located):\n\n```shell\nbazel build grid\n```\n\nTo make things more simple, building each of the bindings is available with this `./go` command:\n\n```shell\n./go <language>:build\n```\n\n## Developing\n\n### Java\n\n#### IntelliJ\n\nMost of the team uses Intellij for their day-to-day editing. If you're\nworking in IntelliJ, then we highly recommend installing the [Bazel IJ\nplugin](https://plugins.jetbrains.com/plugin/8609-bazel) which is documented on\n[its own site](https://plugins.jetbrains.com/plugin/8609-bazel).\n\nTo use Selenium with the IntelliJ Bazel plugin, import the repository as a Bazel project, and select the project\nview file from the [scripts](scripts) directory. `ij.bazelproject` for Mac/Linux and `ij-win.bazelproject` for Windows.\n\n#### Linting\n\nWe also use Google Java Format for linting, so using the Google Java Formatter Plugin is useful;\nthere are a few steps to get it working, so read their [configuration documentation](https://github.com/google/google-java-format/blob/master/README.md#intellij-jre-config).\nThere is also an auto-formatting script that can be run: `./scripts/format.sh`\n\n#### Local Installation\n\nWhile Selenium is not built with Maven, you can build and install the Selenium pieces\nfor Maven to use locally by deploying to your local maven repository (`~/.m2/repository`), using:\n\n```shell\n./go java:install\n```\n\n#### Updating Dependencies\n\nDependencies are defined in the file [MODULE.bazel](https://github.com/SeleniumHQ/selenium/blob/trunk/MODULE.bazel).\n\nTo update a dependency, modify the version in the `MODULE.bazel` file and run:\n\n```shell\nRULES_JVM_EXTERNAL_REPIN=1 bazel run @maven//:pin\n```\n\nTo automatically update and pin new dependencies, run:\n\n```shell\n./go java:update\n```\n\n### Python\n\n#### Linting and Formatting\n\nWe follow the [PEP8 Style Guide for Python Code](https://peps.python.org/pep-0008) (except we use a 120 character line length).\nThis is checked and enforced with [ruff](https://docs.astral.sh/ruff/), a linting/formatting tool.\nThere is also an auto-formatting script that can be run: `./scripts/format.sh`\n\n#### Local Installation\n\nTo run Python code locally without building/installing the package, you must first install the dependencies:\n\n```shell\npip install -r py/requirements.txt\n```\n\nThen, build the generated files and copy them into your local source tree:\n\n```shell\n./go py:local_dev\n```\n\nAfter that, you can import the selenium package directly from source from the `py` directory.\n\nInstead of running from source, you can build and install the selenium package (wheel) locally:\n\n```shell\n./go py:install\n```\n\nThis will attempt to install into the global Python `site-packages` directory,\nwhich might not be writable. To avoid this, you should create and activate a\n[virtual environment](https://packaging.python.org/en/latest/tutorials/installing-packages/#creating-virtual-environments)\nbefore installing.\n\n\n### Ruby\n\nInstead of using `irb`, you can create an interactive REPL with all gems loaded using: `bazel run //rb:console`\n\nIf you want to debug code, you can do it via [`debug`](https://github.com/ruby/debug) gem:\n\n1. Add `binding.break` to the code where you want the debugger to start.\n2. Run tests with  `ruby_debug` configuration: `bazel test --config ruby_debug <test>`.\n3. When debugger starts, run the following in a separate terminal to connect to debugger:\n\n```shell\nbazel-selenium/external/bundle/bin/rdbg -A\n```\n\nIf you want to use [RubyMine](https://www.jetbrains.com/ruby/) for development,\nyou can configure it use Bazel artifacts:\n\n1. Open `rb/` as a main project directory.\n2. From the `selenium` (parent) directory, run `./go rb:local_dev` to create up-to-date artifacts.\n3. In <kbd>Settings / Languages & Frameworks / Ruby SDK and Gems</kbd> add new <kbd>Interpreter</kbd> pointing to `../bazel-selenium/external/rules_ruby++ruby+ruby/dist/bin/ruby`.\n4. You should now be able to run and debug any spec. It uses Chrome by default, but you can alter it using environment variables specified in [Ruby Testing](#ruby-2) section below.\n\n### Rust\n\nTo keep `Cargo.Bazel.lock` synchronized with `Cargo.lock`, run:\n\n```shell\nCARGO_BAZEL_REPIN=true bazel run @crates//:all\n```\n\n## Testing\n\nThere are a number of bazel configurations specific for testing.\n\n### Common Options Examples\n\nHere are examples of arguments we make use of in testing the Selenium code:\n* `--pin_browsers=false` - use Selenium Manager to locate browsers/drivers\n* `--headless` - run browsers in headless mode (supported be Chrome, Edge and Firefox)\n* `--flaky_test_attempts 3` - re-run failed tests up to 3 times\n* `--local_test_jobs 1` - control parallelism of tests\n* `--cache_test_results=no`, `-t-` - disable caching of test results and re-runs all of them\n* `--test_output all` - print all output from the tests, not just errors\n* `--test_output streamed` - run all tests one by one and print its output immediately\n* `--test_env FOO=bar` - pass extra environment variable to test process\n* `--run_under=\"xvfb-run -a\"` - prefix to insert before the execution\n\n### Filtering\n\nSelenium tests can be filtered by size:\n* small â€” typically unit tests where no browser is opened\n* large â€” typically tests that actually drive a browser\n* medium â€” tests that are more involved than simple unit tests, but not fully driving a browser\n\nThese can be filtered using the `test_size_filters` argument like this:\n\n```shell\nbazel test //<language>/... --test_size_filters=small\n```\n\nTests can also be filtered by tag like:\n\n```shell\nbazel test //<language>/... --test_tag_filters=this,-not-this\n```\n\nIf there are multiple `--test_tag_filters`, only the last one is considered,\nso be careful if also using an inherited config\n\n### Java\n\n<details>\n<summary>Click to see Java Test Commands</summary>\n\nTo run unit tests:\n\n```shell\nbazel test //java/... --test_size_filters=small\n```\nTo run integration tests:\n\n```shell\nbazel test //java/... --test_size_filters=medium\n```\nTo run browser tests:\n\n```shell\nbazel test //java/... --test_size_filters=large --test_tag_filters=<browser>\n```\n\nTo run a specific test:\n\n```shell\nbazel test //java/test/org/openqa/selenium/chrome:ChromeDriverFunctionalTest\n```\n\n</details>\n\n### JavaScript\n\n<details>\n<summary>Click to see JavaScript Test Commands</summary>\n\nTo run the tests run:\n\n```shell\nbazel test //javascript/selenium-webdriver:all\n```\n\nYou can use `--test_env` to pass in the browser name as `SELENIUM_BROWSER`.\n\n```shell\nbazel test //javascript/selenium-webdriver:all --test_env=SELENIUM_BROWSER=firefox\n```\n\n</details>\n\n### Python\n\n<details>\n<summary>Click to see Python Test Commands</summary>\n\nRun unit tests with:\n```shell\nbazel test //py:unit\n```\n\nTo run all tests with a specific browser:\n\n```shell\nbazel test //py:test-<browsername>\n```\n\nTo run common tests with a specific browser (include BiDi tests):\n\n```shell\nbazel test //py:test-<browsername>-bidi\n```\n\nTo run all Python tests:\n\n```shell\nbazel test //py:all\n```\n\nTo run tests headless:\n```shell\nbazel test //py:test-<browsername> --//common:headless=true\n```\n\n\n</details>\n\n### Ruby\n\n<details>\n<summary>Click to see Ruby Test Commands</summary>\n\nTest targets:\n\n| Command                                                                          | Description                                        |\n| -------------------------------------------------------------------------------- | -------------------------------------------------- |\n| `bazel test //rb/...`                                                            | Run unit, all integration tests and lint           |\n| `bazel test //rb:lint`                                                           | Run RuboCop linter                                 |\n| `bazel test //rb/spec/...`                                                       | Run unit and integration tests for all browsers    |\n| `bazel test //rb/spec/... --test_size_filters small`                             | Run unit tests                                     |\n| `bazel test //rb/spec/unit/...`                                                  | Run unit tests                                     |\n| `bazel test //rb/spec/... --test_size_filters large`                             | Run integration tests for all browsers             |\n| `bazel test //rb/spec/integration/...`                                           | Run integration tests for all browsers             |\n| `bazel test //rb/spec/integration/... --test_tag_filters firefox`                | Run integration tests for local Firefox only       |\n| `bazel test //rb/spec/integration/... --test_tag_filters firefox-remote`         | Run integration tests for remote Firefox only      |\n| `bazel test //rb/spec/integration/... --test_tag_filters firefox,firefox-remote` | Run integration tests for local and remote Firefox |\n\nRuby test targets have the same name as the spec file with `_spec.rb` removed, so you can run them individually.\nIntegration tests targets also have a browser and remote suffix to control which browser to pick and whether to use Grid.\n\n| Test file                                               | Test target                                                      |\n| ------------------------------------------------------- | ---------------------------------------------------------------- |\n| `rb/spec/unit/selenium/webdriver/proxy_spec.rb`         | `//rb/spec/unit/selenium/webdriver:proxy`                        |\n| `rb/spec/integration/selenium/webdriver/driver_spec.rb` | `//rb/spec/integration/selenium/webdriver:driver-chrome`         |\n| `rb/spec/integration/selenium/webdriver/driver_spec.rb` | `//rb/spec/integration/selenium/webdriver:driver-chrome-remote`  |\n| `rb/spec/integration/selenium/webdriver/driver_spec.rb` | `//rb/spec/integration/selenium/webdriver:driver-firefox`        |\n| `rb/spec/integration/selenium/webdriver/driver_spec.rb` | `//rb/spec/integration/selenium/webdriver:driver-firefox-remote` |\n\nSupported browsers:\n\n* `chrome`\n* `edge`\n* `firefox`\n* `firefox-beta`\n* `ie`\n* `safari`\n* `safari-preview`\n\nIn addition to the [Common Options Examples](#common-options-examples), here are some additional Ruby specific ones:\n* `--test_arg \"-eTimeouts\"` - test only specs which name include \"Timeouts\"\n* `--test_arg \"<any other RSpec argument>\"` - pass any extra RSpec arguments (see `bazel run @bundle//bin:rspec -- --help`)\n\nSupported environment variables for use with `--test_env`:\n\n- `WD_SPEC_DRIVER` - the driver to test; either the browser name or 'remote' (gets set by Bazel)\n- `WD_REMOTE_BROWSER` - when `WD_SPEC_DRIVER` is `remote`; the name of the browser to test (gets set by Bazel)\n- `WD_REMOTE_URL` - URL of an already running server to use for remote tests\n- `DOWNLOAD_SERVER` - when `WD_REMOTE_URL` not set; whether to download and use most recently released server version for remote tests\n- `DEBUG` - turns on verbose debugging\n- `HEADLESS` - for chrome, edge and firefox; runs tests in headless mode\n- `DISABLE_BUILD_CHECK` - for chrome and edge; whether to ignore driver and browser version mismatches (allows testing Canary builds)\n- `CHROME_BINARY` - path to test specific Chrome browser\n- `CHROMEDRIVER_BINARY` - path to test specific ChromeDriver\n- `EDGE_BINARY` - path to test specific Edge browser\n- `MSEDGEDRIVER_BINARY` - path to test specific msedgedriver\n- `FIREFOX_BINARY` - path to test specific Firefox browser\n- `GECKODRIVER_BINARY` - path to test specific GeckoDriver\n\nTo run with a specific version of Ruby you can change the version in `rb/.ruby-version` or from command line:\n\n```shell\necho '<X.Y.Z>' > rb/.ruby-version\n```\n</details>\n\n### .NET\n\n<details>\n<summary>Click to see .NET Test Commands</summary>\n\n.NET tests currently only work with pinned browsers, so make sure to include that.\n\nRun all tests with:\n\n```shell\nbazel test //dotnet/test/common:AllTests\n```\n\nYou can run specific tests by specifying the class name:\n\n```shell\nbazel test //dotnet/test/common:ElementFindingTest\n```\n\nIf the module supports multiple browsers:\n\n```shell\nbazel test //dotnet/test/common:ElementFindingTest-edge\n```\n\n</details>\n\n### Rust\n\n<details>\n<summary>Click to see Rust Test Commands</summary>\n\nRust tests are run with:\n\n```shell\nbazel test //rust/...\n```\n</details>\n\n### Linux\n\n<details>\n<summary>Click to see Linux Testing Requirements</summary>\n\nBy default, Bazel runs these tests in your current X-server UI. If you prefer, you can\nalternatively run them in a virtual or nested X-server.\n\n1. Run the X server `Xvfb :99` or `Xnest :99`\n2. Run a window manager, for example, `DISPLAY=:99 jwm`\n3. Run the tests you are interested in:\n\n```shell\nbazel test --test_env=DISPLAY=:99 //java/... --test_tag_filters=chrome\n```\n\nAn easy way to run tests in a virtual X-server is to use Bazel's `--run_under`\nfunctionality:\n\n```\nbazel test --run_under=\"xvfb-run -a\" //java/...\n```\n</details>\n\n\n## Documenting\n\nAPI documentation can be found here:\n\n* [C#](https://seleniumhq.github.io/selenium/docs/api/dotnet/)\n* [JavaScript](https://seleniumhq.github.io/selenium/docs/api/javascript/)\n* [Java](https://seleniumhq.github.io/selenium/docs/api/java/index.html)\n* [Python](https://seleniumhq.github.io/selenium/docs/api/py/)\n* [Ruby](https://seleniumhq.github.io/selenium/docs/api/rb/)\n\nTo update API documentation for a specific language: `./go <language>:docs`\n\nTo update all documentation: `./go all:docs`\n\n\n## Releasing\n\nThe full process for doing a release can be found in [the wiki](https://github.com/SeleniumHQ/selenium/wiki/Releasing-Selenium)\n\nReleasing is a combination of building and publishing, which often requires coordination of multiple executions\nand additional processing.\nAs discussed in the [Building](#building) section, we use Rake tasks with the `./go` command for these things.\nThese `./go` commands include the `--stamp` argument to provide necessary information about the constructed asset.\n\nYou can build and release everything with:\n\n```shell\n./go all:release\n```\n\nTo build and release a specific language:\n\n```shell\n./go <language>:release\n```\n\nIf you have access to the Selenium EngFlow repository, you can have the assets built remotely and downloaded locally using:\n\n```shell\n./go all:release['--config', 'release']\n```\n",
      "stars_today": 6
    },
    {
      "id": 16587283,
      "name": "xgboost",
      "full_name": "dmlc/xgboost",
      "description": "Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or GBM) Library,  for Python, R, Java, Scala, C++ and more. Runs on single machine, Hadoop, Spark, Dask, Flink and DataFlow",
      "html_url": "https://github.com/dmlc/xgboost",
      "stars": 27903,
      "forks": 8834,
      "language": "C++",
      "topics": [
        "distributed-systems",
        "gbdt",
        "gbm",
        "gbrt",
        "machine-learning",
        "xgboost"
      ],
      "created_at": "2014-02-06T17:28:03Z",
      "updated_at": "2026-01-24T23:03:50Z",
      "pushed_at": "2026-01-23T17:26:32Z",
      "open_issues": 494,
      "owner": {
        "login": "dmlc",
        "avatar_url": "https://avatars.githubusercontent.com/u/11508361?v=4"
      },
      "readme": "<img src=\"https://xgboost.ai/images/logo/xgboost-logo-trimmed.png\" width=200/> eXtreme Gradient Boosting\n===========\n\n[![XGBoost-CI](https://github.com/dmlc/xgboost/workflows/XGBoost%20CI/badge.svg?branch=master)](https://github.com/dmlc/xgboost/actions)\n[![Documentation Status](https://readthedocs.org/projects/xgboost/badge/?version=latest)](https://xgboost.readthedocs.org)\n[![GitHub license](https://dmlc.github.io/img/apache2.svg)](./LICENSE)\n[![CRAN Status Badge](https://www.r-pkg.org/badges/version/xgboost)](https://cran.r-project.org/web/packages/xgboost)\n[![PyPI version](https://badge.fury.io/py/xgboost.svg)](https://pypi.python.org/pypi/xgboost/)\n[![Conda version](https://img.shields.io/conda/vn/conda-forge/py-xgboost.svg)](https://anaconda.org/conda-forge/py-xgboost)\n[![Optuna](https://img.shields.io/badge/Optuna-integrated-blue)](https://optuna.org)\n[![Twitter](https://img.shields.io/badge/@XGBoostProject--_.svg?style=social&logo=twitter)](https://twitter.com/XGBoostProject)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/dmlc/xgboost/badge)](https://api.securityscorecards.dev/projects/github.com/dmlc/xgboost)\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/comet-examples/blob/master/integrations/model-training/xgboost/notebooks/how_to_use_comet_with_xgboost_tutorial.ipynb)\n\n[Community](https://xgboost.ai/community) |\n[Documentation](https://xgboost.readthedocs.org) |\n[Resources](demo/README.md) |\n[Contributors](CONTRIBUTORS.md) |\n[Release Notes](https://xgboost.readthedocs.io/en/latest/changes/index.html)\n\nXGBoost is an optimized distributed gradient boosting library designed to be highly ***efficient***, ***flexible*** and ***portable***.\nIt implements machine learning algorithms under the [Gradient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting) framework.\nXGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way.\nThe same code runs on major distributed environment (Kubernetes, Hadoop, SGE, Dask, Spark, PySpark) and can solve problems beyond billions of examples.\n\nLicense\n-------\nÂ© Contributors, 2021. Licensed under an [Apache-2](https://github.com/dmlc/xgboost/blob/master/LICENSE) license.\n\nContribute to XGBoost\n---------------------\nXGBoost has been developed and used by a group of active community members. Your help is very valuable to make the package better for everyone.\nCheckout the [Community Page](https://xgboost.ai/community).\n\nReference\n---------\n- Tianqi Chen and Carlos Guestrin. [XGBoost: A Scalable Tree Boosting System](https://arxiv.org/abs/1603.02754). In 22nd SIGKDD Conference on Knowledge Discovery and Data Mining, 2016\n- XGBoost originates from research project at University of Washington.\n\nSponsors\n--------\nBecome a sponsor and get a logo here. See details at [Sponsoring the XGBoost Project](https://xgboost.ai/sponsors). The funds are used to defray the cost of continuous integration and testing infrastructure (https://xgboost-ci.net).\n\n## Open Source Collective sponsors\n[![Backers on Open Collective](https://opencollective.com/xgboost/backers/badge.svg)](#backers) [![Sponsors on Open Collective](https://opencollective.com/xgboost/sponsors/badge.svg)](#sponsors)\n\n### Sponsors\n[[Become a sponsor](https://opencollective.com/xgboost#sponsor)]\n\n<a href=\"https://www.nvidia.com/en-us/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/xgboost-ai/xgboost-ai.github.io/master/images/sponsors/nvidia.jpg\" alt=\"NVIDIA\" width=\"72\" height=\"72\"></a>\n<a href=\"https://www.comet.com/site/?utm_source=xgboost&utm_medium=github&utm_content=readme\" target=\"_blank\"><img src=\"https://cdn.comet.ml/img/notebook_logo.png\" height=\"72\"></a>\n<a href=\"https://opencollective.com/tomislav1\" target=\"_blank\"><img src=\"https://images.opencollective.com/tomislav1/avatar/256.png\" height=\"72\"></a>\n<a href=\"https://databento.com/?utm_source=xgboost&utm_medium=sponsor&utm_content=display\"><img src=\"https://raw.githubusercontent.com/xgboost-ai/xgboost-ai.github.io/refs/heads/master/images/sponsors/databento.png\" height=\"72\"></a>\n<a href=\"https://www.intel.com/\" target=\"_blank\"><img src=\"https://images.opencollective.com/intel-corporation/2fa85c1/logo/256.png\" width=\"72\" height=\"72\"></a>\n\n### Backers\n[[Become a backer](https://opencollective.com/xgboost#backer)]\n\n<a href=\"https://opencollective.com/xgboost#backers\" target=\"_blank\"><img src=\"https://opencollective.com/xgboost/backers.svg?width=890\"></a>\n",
      "stars_today": 6
    },
    {
      "id": 16563587,
      "name": "cockroach",
      "full_name": "cockroachdb/cockroach",
      "description": "CockroachDB â€” the cloud native, distributed SQL database designed for high availability, effortless scale, and control over data placement.",
      "html_url": "https://github.com/cockroachdb/cockroach",
      "stars": 31779,
      "forks": 4065,
      "language": "Go",
      "topics": [
        "cockroachdb",
        "database",
        "distributed-database",
        "go",
        "hacktoberfest",
        "sql"
      ],
      "created_at": "2014-02-06T00:18:47Z",
      "updated_at": "2026-01-24T23:27:17Z",
      "pushed_at": "2026-01-24T23:28:30Z",
      "open_issues": 7865,
      "owner": {
        "login": "cockroachdb",
        "avatar_url": "https://avatars.githubusercontent.com/u/6748139?v=4"
      },
      "readme": "<p align=\"center\">\n  <img src='docs/media/cockroach_db.png?raw=true' width='70%'>\n</p>\n\n---\n\nCockroachDB is a cloud-native distributed SQL database designed to build,\nscale, and manage modern, data-intensive applications. \n\n- [What is CockroachDB?](#what-is-cockroachdb)\n- [Docs](#docs)\n- [Starting with Cockroach Cloud](#starting-with-cockroachcloud)\n- [Starting with CockroachDB](#starting-with-cockroachdb)\n- [Client Drivers](#client-drivers)\n- [Deployment](#deployment)\n- [Need Help?](#need-help)\n- [Contributing](#contributing)\n- [Design](#design)\n- [Comparison with Other Databases](#comparison-with-other-databases)\n- [See Also](#see-also)\n\n## What is CockroachDB?\n\nCockroachDB is a distributed SQL database built on a transactional and\nstrongly-consistent key-value store. It **scales** horizontally;\n**survives** disk, machine, rack, and even datacenter failures with\nminimal latency disruption and no manual intervention; supports\n**strongly-consistent** ACID transactions; and provides a familiar\n**SQL** API for structuring, manipulating, and querying data.\n\nFor more details, see our [product overview](https://www.cockroachlabs.com/product/overview/), [FAQ](https://cockroachlabs.com/docs/stable/frequently-asked-questions.html) or [architecture document](\nhttps://www.cockroachlabs.com/docs/stable/architecture/overview.html).\n\n## Docs\n\nFor guidance on installation, development, deployment, and administration, see our [User Documentation](https://cockroachlabs.com/docs/stable/).\n\n## Starting with CockroachCloud\n\nWe can run CockroachDB for you, so you don't have to run your own cluster.\n\nSee our online documentation: [Quickstart with CockroachCloud](https://www.cockroachlabs.com/docs/cockroachcloud/quickstart.html)\n\n## Starting with CockroachDB\n\n1. Install CockroachDB:  [using a pre-built executable](https://www.cockroachlabs.com/docs/stable/install-cockroachdb.html) or [build it from source](https://cockroachlabs.atlassian.net/wiki/spaces/CRDB/pages/181338446/Getting+and+building+CockroachDB+from+source).\n2. [Start a local cluster](https://www.cockroachlabs.com/docs/stable/start-a-local-cluster.html) and connect to it via the [built-in SQL client](https://www.cockroachlabs.com/docs/stable/use-the-built-in-sql-client.html).\n3. [Learn more about CockroachDB SQL](https://www.cockroachlabs.com/docs/stable/learn-cockroachdb-sql.html).\n4. Use a PostgreSQL-compatible driver or ORM to [build an app with CockroachDB](https://www.cockroachlabs.com/docs/stable/hello-world-example-apps.html).\n5. [Explore core features](https://www.cockroachlabs.com/docs/stable/demo-data-replication.html), such as data replication, automatic rebalancing, and fault tolerance and recovery.\n\n## Client Drivers\n\nCockroachDB supports the PostgreSQL wire protocol, so you can use any available PostgreSQL client drivers to connect from various languages.\n\n- For recommended drivers that we've tested, see [Install Client Drivers](https://www.cockroachlabs.com/docs/stable/install-client-drivers.html).\n- For tutorials using these drivers, as well as supported ORMs, see [Example Apps](https://www.cockroachlabs.com/docs/stable/example-apps.html).\n\n## Deployment\n\n- [CockroachCloud](https://www.cockroachlabs.com/docs/cockroachcloud/quickstart) - Steps to create a [free CockroachCloud cluster](https://cockroachlabs.cloud/signup?referralId=githubquickstart) on your preferred Cloud platform.\n- [Manual](https://www.cockroachlabs.com/docs/stable/manual-deployment.html) - Steps to deploy a CockroachDB cluster manually on multiple machines.\n- [Cloud](https://www.cockroachlabs.com/docs/stable/cloud-deployment.html) - Guides for deploying CockroachDB on various cloud platforms.\n- [Orchestration](https://www.cockroachlabs.com/docs/stable/orchestration.html) - Guides for running CockroachDB with popular open-source orchestration systems.\n\n## Need Help?\n\n- [CockroachDB Community Slack](https://go.crdb.dev/p/slack) - Join our slack to connect with our engineers and other users running CockroachDB.\n- [CockroachDB Forum](https://forum.cockroachlabs.com/) and [Stack Overflow](https://stackoverflow.com/questions/tagged/cockroachdb) - Ask questions, find answers, and help other users.\n- [Troubleshooting documentation](https://www.cockroachlabs.com/docs/stable/troubleshooting-overview.html) - Learn how to troubleshoot common errors, cluster setup, and SQL query behavior.\n- For filing bugs, suggesting improvements, or requesting new features, help us out by [opening an issue](https://github.com/cockroachdb/cockroach/issues/new).\n\n## Building from source\n\nSee [our wiki](https://wiki.crdb.io/wiki/spaces/CRDB/pages/181338446/Getting+and+building+from+source) for more details.\n\n## Contributing\n\nWe welcome your contributions! If you're looking for issues to work on, try looking at the [good first issue list](https://github.com/cockroachdb/cockroach/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22). We do our best to tag issues suitable for new external contributors with that label, so it's a great way to find something you can help with!\n\nSee [our wiki](https://wiki.crdb.io/wiki/spaces/CRDB/pages/73204033/Contributing+to+CockroachDB) for more details.\n\nEngineering discussions take place on our public mailing list, [cockroach-db@googlegroups.com](https://groups.google.com/forum/#!forum/cockroach-db). Also please join our [Community Slack](https://go.crdb.dev/p/slack) (there's a dedicated #contributors channel!) to ask questions, discuss your ideas, and connect with other contributors.\n\n## Design\n\nFor an in-depth discussion of the CockroachDB architecture, see our\n[Architecture\nGuide](https://www.cockroachlabs.com/docs/stable/architecture/overview.html).\nFor the original design motivation, see our [design\ndoc](https://github.com/cockroachdb/cockroach/blob/master/docs/design.md).\n\n## Licensing\n\nAll versions released on or after November 18, 2024 (specifically, major version series v24.3 and later, and patch fixes for v23.1.29+, v23.2.16+, v24.1.7+, and v24.2.5+) are published under the [CockroachDB Software License (CSL)](./LICENSE). Source code in a given file is licensed under the CSL and the copyright belongs to The Cockroach Authors unless otherwise noted in the file or in a LICENSE or README file located in the same or a parent directory of the file.\n\n## Comparison with Other Databases\n\nTo see how key features of CockroachDB stack up against other databases,\ncheck out [CockroachDB in Comparison](https://www.cockroachlabs.com/docs/stable/cockroachdb-in-comparison.html).\n\n## See Also\n\n- [Tech Talks](https://www.cockroachlabs.com/community/tech-talks/) (by CockroachDB founders, engineers, and customers!)\n- [CockroachDB User Documentation](https://cockroachlabs.com/docs/stable/)\n- [The CockroachDB Blog](https://www.cockroachlabs.com/blog/)\n- Key design documents\n  - [Serializable, Lockless, Distributed: Isolation in CockroachDB](https://www.cockroachlabs.com/blog/serializable-lockless-distributed-isolation-cockroachdb/)\n  - [Consensus, Made Thrive](https://www.cockroachlabs.com/blog/consensus-made-thrive/)\n  - [Trust, But Verify: How CockroachDB Checks Replication](https://www.cockroachlabs.com/blog/trust-but-verify-cockroachdb-checks-replication/)\n  - [Living Without Atomic Clocks](https://www.cockroachlabs.com/blog/living-without-atomic-clocks/)\n  - [The CockroachDB Architecture Document](https://github.com/cockroachdb/cockroach/blob/master/docs/design.md)\n",
      "stars_today": 6
    },
    {
      "id": 104231541,
      "name": "abseil-cpp",
      "full_name": "abseil/abseil-cpp",
      "description": "Abseil Common Libraries (C++)",
      "html_url": "https://github.com/abseil/abseil-cpp",
      "stars": 16970,
      "forks": 2953,
      "language": "C++",
      "topics": [],
      "created_at": "2017-09-20T15:10:30Z",
      "updated_at": "2026-01-24T23:03:46Z",
      "pushed_at": "2026-01-22T20:16:23Z",
      "open_issues": 210,
      "owner": {
        "login": "abseil",
        "avatar_url": "https://avatars.githubusercontent.com/u/26718316?v=4"
      },
      "readme": "# Abseil - C++ Common Libraries\n\nThe repository contains the Abseil C++ library code. Abseil is an open-source\ncollection of C++ code (compliant to C++17) designed to augment the C++\nstandard library.\n\n## Table of Contents\n\n- [About Abseil](#about)\n- [Quickstart](#quickstart)\n- [Building Abseil](#build)\n- [Support](#support)\n- [Codemap](#codemap)\n- [Releases](#releases)\n- [License](#license)\n- [Links](#links)\n\n<a name=\"about\"></a>\n## About Abseil\n\nAbseil is an open-source collection of C++ library code designed to augment\nthe C++ standard library. The Abseil library code is collected from Google's\nown C++ code base, has been extensively tested and used in production, and\nis the same code we depend on in our daily coding lives.\n\nIn some cases, Abseil provides pieces missing from the C++ standard; in\nothers, Abseil provides alternatives to the standard for special needs\nwe've found through usage in the Google code base. We denote those cases\nclearly within the library code we provide you.\n\nAbseil is not meant to be a competitor to the standard library; we've\njust found that many of these utilities serve a purpose within our code\nbase, and we now want to provide those resources to the C++ community as\na whole.\n\n<a name=\"quickstart\"></a>\n## Quickstart\n\nIf you want to just get started, make sure you at least run through the\n[Abseil Quickstart](https://abseil.io/docs/cpp/quickstart). The Quickstart\ncontains information about setting up your development environment, downloading\nthe Abseil code, running tests, and getting a simple binary working.\n\n<a name=\"build\"></a>\n## Building Abseil\n\n[Bazel](https://bazel.build) and [CMake](https://cmake.org/) are the official\nbuild systems for Abseil.\nSee the [quickstart](https://abseil.io/docs/cpp/quickstart) for more information\non building Abseil using the Bazel build system.\nIf you require CMake support, please check the [CMake build\ninstructions](CMake/README.md) and [CMake\nQuickstart](https://abseil.io/docs/cpp/quickstart-cmake).\n\n<a name=\"support\"></a>\n## Support\n\nAbseil follows Google's [Foundational C++ Support\nPolicy](https://opensource.google/documentation/policies/cplusplus-support). See\n[this\ntable](https://github.com/google/oss-policies-info/blob/main/foundational-cxx-support-matrix.md)\nfor a list of currently supported versions compilers, platforms, and build\ntools.\n\n<a name=\"codemap\"></a>\n## Codemap\n\nAbseil contains the following C++ library components:\n\n* [`base`](absl/base/)\n  <br /> The `base` library contains initialization code and other code which\n  all other Abseil code depends on. Code within `base` may not depend on any\n  other code (other than the C++ standard library).\n* [`algorithm`](absl/algorithm/)\n  <br /> The `algorithm` library contains additions to the C++ `<algorithm>`\n  library and container-based versions of such algorithms.\n* [`cleanup`](absl/cleanup/)\n  <br /> The `cleanup` library contains the control-flow-construct-like type\n  `absl::Cleanup` which is used for executing a callback on scope exit.\n* [`container`](absl/container/)\n  <br /> The `container` library contains additional STL-style containers,\n  including Abseil's unordered \"Swiss table\" containers.\n* [`crc`](absl/crc/) The `crc` library contains code for\n  computing error-detecting cyclic redundancy checks on data.\n* [`debugging`](absl/debugging/)\n  <br /> The `debugging` library contains code useful for enabling leak\n  checks, and stacktrace and symbolization utilities.\n* [`flags`](absl/flags/)\n  <br /> The `flags` library contains code for handling command line flags for\n  libraries and binaries built with Abseil.\n* [`hash`](absl/hash/)\n  <br /> The `hash` library contains the hashing framework and default hash\n  functor implementations for hashable types in Abseil.\n* [`log`](absl/log/)\n  <br /> The `log` library contains `LOG` and `CHECK` macros and facilities\n  for writing logged messages out to disk, `stderr`, or user-extensible\n  destinations.\n* [`memory`](absl/memory/)\n  <br /> The `memory` library contains memory management facilities that augment\n  C++'s `<memory>` library.\n* [`meta`](absl/meta/)\n  <br /> The `meta` library contains type checks\n  similar to those available in the C++ `<type_traits>` library.\n* [`numeric`](absl/numeric/)\n  <br /> The `numeric` library contains 128-bit integer types as well as\n  implementations of C++20's bitwise math functions.\n* [`profiling`](absl/profiling/)\n  <br /> The `profiling` library contains utility code for profiling C++\n  entities.  It is currently a private dependency of other Abseil libraries.\n* [`random`](absl/random/)\n  <br /> The `random` library contains functions for generating pseudorandom\n  values.\n* [`status`](absl/status/)\n  <br /> The `status` library contains abstractions for error handling,\n  specifically `absl::Status` and `absl::StatusOr<T>`.\n* [`strings`](absl/strings/)\n  <br /> The `strings` library contains a variety of strings routines and\n  utilities.\n* [`synchronization`](absl/synchronization/)\n  <br /> The `synchronization` library contains concurrency primitives (Abseil's\n  `absl::Mutex` class, an alternative to `std::mutex`) and a variety of\n  synchronization abstractions.\n* [`time`](absl/time/)\n  <br /> The `time` library contains abstractions for computing with absolute\n  points in time, durations of time, and formatting and parsing time within\n  time zones.\n* [`types`](absl/types/)\n  <br /> The `types` library contains non-container utility types.\n* [`utility`](absl/utility/)\n  <br /> The `utility` library contains utility and helper code.\n\n<a name=\"releases\"></a>\n## Releases\n\nAbseil recommends users \"live-at-head\" (update to the latest commit from the\nmaster branch as often as possible). However, we realize this philosophy doesn't\nwork for every project, so we also provide [Long Term Support\nReleases](https://github.com/abseil/abseil-cpp/releases) to which we backport\nfixes for severe bugs. See our [release\nmanagement](https://abseil.io/about/releases) document for more details.\n\n<a name=\"license\"></a>\n## License\n\nThe Abseil C++ library is licensed under the terms of the Apache\nlicense. See [LICENSE](LICENSE) for more information.\n\n<a name=\"links\"></a>\n## Links\n\nFor more information about Abseil:\n\n* Consult our [Abseil Introduction](https://abseil.io/about/intro)\n* Read [Why Adopt Abseil](https://abseil.io/about/philosophy) to understand our\n  design philosophy.\n* Peruse our\n  [Abseil Compatibility Guarantees](https://abseil.io/about/compatibility) to\n  understand both what we promise to you, and what we expect of you in return.\n",
      "stars_today": 6
    },
    {
      "id": 132145189,
      "name": "golangci-lint",
      "full_name": "golangci/golangci-lint",
      "description": "Fast linters runner for Go",
      "html_url": "https://github.com/golangci/golangci-lint",
      "stars": 18365,
      "forks": 1537,
      "language": "Go",
      "topics": [
        "ci",
        "go",
        "golang",
        "golangci-lint",
        "linter"
      ],
      "created_at": "2018-05-04T13:41:15Z",
      "updated_at": "2026-01-25T01:38:28Z",
      "pushed_at": "2026-01-23T19:44:37Z",
      "open_issues": 114,
      "owner": {
        "login": "golangci",
        "avatar_url": "https://avatars.githubusercontent.com/u/35628013?v=4"
      },
      "readme": "<p align=\"center\">\n  <img alt=\"golangci-lint logo\" src=\"assets/go.png\" height=\"150\" />\n  <h3 align=\"center\">golangci-lint</h3>\n  <p align=\"center\">Fast linters runner for Go</p>\n</p>\n\n---\n\n`golangci-lint` is a fast Go linters runner.\n\nIt runs linters in parallel, uses caching, supports YAML configuration,\nintegrates with all major IDEs, and includes over a hundred linters.\n\n## Install `golangci-lint`\n\n- [On my machine](https://golangci-lint.run/docs/welcome/install/local);\n- [On CI/CD systems](https://golangci-lint.run/docs/welcome/install/ci).\n\n## Documentation\n\nDocumentation is hosted at https://golangci-lint.run.\n\n## Social Networks\n\n[![Join Slack](https://img.shields.io/badge/Slack-4285F4?logo=slack&logoColor=white)](https://gophers.slack.com/archives/CS0TBRKPC)\n[![Follow on Mastodon](https://img.shields.io/badge/Mastodon-6364FF?logo=mastodon&logoColor=white)](https://fosstodon.org/@golangcilint)\n[![Follow on Bluesky](https://img.shields.io/badge/Bluesky-0a7aff?logo=bluesky&logoColor=white)](https://bsky.app/profile/golangci-lint.run)\n[![Follow on Twitter](https://img.shields.io/badge/Twitter-1DA1F2?logo=x&logoColor=white)](https://twitter.com/golangci)\n\n## Support Us\n\n`golangci-lint` is a free and open-source project built by volunteers.\n\nIf you value it, consider supporting us, we appreciate it! :heart:\n\n[![Golangci-lint](https://img.shields.io/badge/Support-golangci_lint-blue?style=for-the-badge)](https://donate.golangci.org)\n[![Linter Authors](https://img.shields.io/badge/Support-Linter_Authors-blue?style=for-the-badge)](https://golangci-lint.run/docs/product/thanks/)\n\n## Badges\n\n![Build Status](https://github.com/golangci/golangci-lint/workflows/CI/badge.svg)\n[![License](https://img.shields.io/github/license/golangci/golangci-lint)](/LICENSE)\n[![Release](https://img.shields.io/github/release/golangci/golangci-lint.svg)](https://github.com/golangci/golangci-lint/releases/latest)\n[![Docker](https://img.shields.io/docker/pulls/golangci/golangci-lint)](https://hub.docker.com/r/golangci/golangci-lint)\n[![GitHub Releases Stats of golangci-lint](https://img.shields.io/github/downloads/golangci/golangci-lint/total.svg?logo=github)](https://somsubhra.github.io/github-release-stats/?username=golangci&repository=golangci-lint)\n\n## Contributors\n\nThis project exists thanks to all the people who contribute. [How to contribute](https://golangci-lint.run/docs/contributing/).\n\n<a href=\"https://github.com/golangci/golangci-lint/graphs/contributors\">\n  <img src=\"https://opencollective.com/golangci-lint/contributors.svg?width=890&button=false&skip=golangcidev,CLAassistant,renovate,fossabot,golangcibot,kortschak,golangci-releaser,dependabot%5Bbot%5D\" />\n</a>\n\n## Sponsors\n\n<p>&nbsp;</p>\n<p float=\"left\">\n  <a href=\"https://www.jetbrains.com/go/?utm_source=OSS&utm_medium=referral&utm_campaign=golangci\" target=\"_blank\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"assets/goland-white.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"assets/goland.svg\">\n      <img alt=\"The complete IDE crafted for professional Go developers.\" src=\"assets/goland.svg\" width=\"150\" />\n    </picture>\n  </a>\n</p>\n\n## Stargazers over time\n\n[![Stargazers over time](https://starchart.cc/golangci/golangci-lint.svg?variant=adaptive)](https://starchart.cc/golangci/golangci-lint)\n",
      "stars_today": 6
    },
    {
      "id": 280608729,
      "name": "ORB_SLAM3",
      "full_name": "UZ-SLAMLab/ORB_SLAM3",
      "description": "ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM",
      "html_url": "https://github.com/UZ-SLAMLab/ORB_SLAM3",
      "stars": 8226,
      "forks": 2971,
      "language": "C++",
      "topics": [
        "slam-algorithms"
      ],
      "created_at": "2020-07-18T07:47:46Z",
      "updated_at": "2026-01-24T23:52:13Z",
      "pushed_at": "2024-07-24T08:41:52Z",
      "open_issues": 562,
      "owner": {
        "login": "UZ-SLAMLab",
        "avatar_url": "https://avatars.githubusercontent.com/u/25055183?v=4"
      },
      "readme": "# ORB-SLAM3\n\n### V1.0, December 22th, 2021\n**Authors:** Carlos Campos, Richard Elvira, Juan J. GÃ³mez RodrÃ­guez, [JosÃ© M. M. Montiel](http://webdiis.unizar.es/~josemari/), [Juan D. Tardos](http://webdiis.unizar.es/~jdtardos/).\n\nThe [Changelog](https://github.com/UZ-SLAMLab/ORB_SLAM3/blob/master/Changelog.md) describes the features of each version.\n\nORB-SLAM3 is the first real-time SLAM library able to perform **Visual, Visual-Inertial and Multi-Map SLAM** with **monocular, stereo and RGB-D** cameras, using **pin-hole and fisheye** lens models. In all sensor configurations, ORB-SLAM3 is as robust as the best systems available in the literature, and significantly more accurate. \n\nWe provide examples to run ORB-SLAM3 in the [EuRoC dataset](http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets) using stereo or monocular, with or without IMU, and in the [TUM-VI dataset](https://vision.in.tum.de/data/datasets/visual-inertial-dataset) using fisheye stereo or monocular, with or without IMU. Videos of some example executions can be found at [ORB-SLAM3 channel](https://www.youtube.com/channel/UCXVt-kXG6T95Z4tVaYlU80Q).\n\nThis software is based on [ORB-SLAM2](https://github.com/raulmur/ORB_SLAM2) developed by [Raul Mur-Artal](http://webdiis.unizar.es/~raulmur/), [Juan D. Tardos](http://webdiis.unizar.es/~jdtardos/), [J. M. M. Montiel](http://webdiis.unizar.es/~josemari/) and [Dorian Galvez-Lopez](http://doriangalvez.com/) ([DBoW2](https://github.com/dorian3d/DBoW2)).\n\n<a href=\"https://youtu.be/HyLNq-98LRo\" target=\"_blank\"><img src=\"https://img.youtube.com/vi/HyLNq-98LRo/0.jpg\" \nalt=\"ORB-SLAM3\" width=\"240\" height=\"180\" border=\"10\" /></a>\n\n### Related Publications:\n\n[ORB-SLAM3] Carlos Campos, Richard Elvira, Juan J. GÃ³mez RodrÃ­guez, JosÃ© M. M. Montiel and Juan D. TardÃ³s, **ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM**, *IEEE Transactions on Robotics 37(6):1874-1890, Dec. 2021*. **[PDF](https://arxiv.org/abs/2007.11898)**.\n\n[IMU-Initialization] Carlos Campos, J. M. M. Montiel and Juan D. TardÃ³s, **Inertial-Only Optimization for Visual-Inertial Initialization**, *ICRA 2020*. **[PDF](https://arxiv.org/pdf/2003.05766.pdf)**\n\n[ORBSLAM-Atlas] Richard Elvira, J. M. M. Montiel and Juan D. TardÃ³s, **ORBSLAM-Atlas: a robust and accurate multi-map system**, *IROS 2019*. **[PDF](https://arxiv.org/pdf/1908.11585.pdf)**.\n\n[ORBSLAM-VI] RaÃºl Mur-Artal, and Juan D. TardÃ³s, **Visual-inertial monocular SLAM with map reuse**, IEEE Robotics and Automation Letters, vol. 2 no. 2, pp. 796-803, 2017. **[PDF](https://arxiv.org/pdf/1610.05949.pdf)**. \n\n[Stereo and RGB-D] RaÃºl Mur-Artal and Juan D. TardÃ³s. **ORB-SLAM2: an Open-Source SLAM System for Monocular, Stereo and RGB-D Cameras**. *IEEE Transactions on Robotics,* vol. 33, no. 5, pp. 1255-1262, 2017. **[PDF](https://arxiv.org/pdf/1610.06475.pdf)**.\n\n[Monocular] RaÃºl Mur-Artal, JosÃ© M. M. Montiel and Juan D. TardÃ³s. **ORB-SLAM: A Versatile and Accurate Monocular SLAM System**. *IEEE Transactions on Robotics,* vol. 31, no. 5, pp. 1147-1163, 2015. (**2015 IEEE Transactions on Robotics Best Paper Award**). **[PDF](https://arxiv.org/pdf/1502.00956.pdf)**.\n\n[DBoW2 Place Recognition] Dorian GÃ¡lvez-LÃ³pez and Juan D. TardÃ³s. **Bags of Binary Words for Fast Place Recognition in Image Sequences**. *IEEE Transactions on Robotics,* vol. 28, no. 5, pp. 1188-1197, 2012. **[PDF](http://doriangalvez.com/php/dl.php?dlp=GalvezTRO12.pdf)**\n\n# 1. License\n\nORB-SLAM3 is released under [GPLv3 license](https://github.com/UZ-SLAMLab/ORB_SLAM3/LICENSE). For a list of all code/library dependencies (and associated licenses), please see [Dependencies.md](https://github.com/UZ-SLAMLab/ORB_SLAM3/blob/master/Dependencies.md).\n\nFor a closed-source version of ORB-SLAM3 for commercial purposes, please contact the authors: orbslam (at) unizar (dot) es.\n\nIf you use ORB-SLAM3 in an academic work, please cite:\n  \n    @article{ORBSLAM3_TRO,\n      title={{ORB-SLAM3}: An Accurate Open-Source Library for Visual, Visual-Inertial \n               and Multi-Map {SLAM}},\n      author={Campos, Carlos AND Elvira, Richard AND G\\Â´omez, Juan J. AND Montiel, \n              Jos\\'e M. M. AND Tard\\'os, Juan D.},\n      journal={IEEE Transactions on Robotics}, \n      volume={37},\n      number={6},\n      pages={1874-1890},\n      year={2021}\n     }\n\n# 2. Prerequisites\nWe have tested the library in **Ubuntu 16.04** and **18.04**, but it should be easy to compile in other platforms. A powerful computer (e.g. i7) will ensure real-time performance and provide more stable and accurate results.\n\n## C++11 or C++0x Compiler\nWe use the new thread and chrono functionalities of C++11.\n\n## Pangolin\nWe use [Pangolin](https://github.com/stevenlovegrove/Pangolin) for visualization and user interface. Dowload and install instructions can be found at: https://github.com/stevenlovegrove/Pangolin.\n\n## OpenCV\nWe use [OpenCV](http://opencv.org) to manipulate images and features. Dowload and install instructions can be found at: http://opencv.org. **Required at leat 3.0. Tested with OpenCV 3.2.0 and 4.4.0**.\n\n## Eigen3\nRequired by g2o (see below). Download and install instructions can be found at: http://eigen.tuxfamily.org. **Required at least 3.1.0**.\n\n## DBoW2 and g2o (Included in Thirdparty folder)\nWe use modified versions of the [DBoW2](https://github.com/dorian3d/DBoW2) library to perform place recognition and [g2o](https://github.com/RainerKuemmerle/g2o) library to perform non-linear optimizations. Both modified libraries (which are BSD) are included in the *Thirdparty* folder.\n\n## Python\nRequired to calculate the alignment of the trajectory with the ground truth. **Required Numpy module**.\n\n* (win) http://www.python.org/downloads/windows\n* (deb) `sudo apt install libpython2.7-dev`\n* (mac) preinstalled with osx\n\n## ROS (optional)\n\nWe provide some examples to process input of a monocular, monocular-inertial, stereo, stereo-inertial or RGB-D camera using ROS. Building these examples is optional. These have been tested with ROS Melodic under Ubuntu 18.04.\n\n# 3. Building ORB-SLAM3 library and examples\n\nClone the repository:\n```\ngit clone https://github.com/UZ-SLAMLab/ORB_SLAM3.git ORB_SLAM3\n```\n\nWe provide a script `build.sh` to build the *Thirdparty* libraries and *ORB-SLAM3*. Please make sure you have installed all required dependencies (see section 2). Execute:\n```\ncd ORB_SLAM3\nchmod +x build.sh\n./build.sh\n```\n\nThis will create **libORB_SLAM3.so**  at *lib* folder and the executables in *Examples* folder.\n\n# 4. Running ORB-SLAM3 with your camera\n\nDirectory `Examples` contains several demo programs and calibration files to run ORB-SLAM3 in all sensor configurations with Intel Realsense cameras T265 and D435i. The steps needed to use your own camera are: \n\n1. Calibrate your camera following `Calibration_Tutorial.pdf` and write your calibration file `your_camera.yaml`\n\n2. Modify one of the provided demos to suit your specific camera model, and build it\n\n3. Connect the camera to your computer using USB3 or the appropriate interface\n\n4. Run ORB-SLAM3. For example, for our D435i camera, we would execute:\n\n```\n./Examples/Stereo-Inertial/stereo_inertial_realsense_D435i Vocabulary/ORBvoc.txt ./Examples/Stereo-Inertial/RealSense_D435i.yaml\n```\n\n# 5. EuRoC Examples\n[EuRoC dataset](http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets) was recorded with two pinhole cameras and an inertial sensor. We provide an example script to launch EuRoC sequences in all the sensor configurations.\n\n1. Download a sequence (ASL format) from http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets\n\n2. Open the script \"euroc_examples.sh\" in the root of the project. Change **pathDatasetEuroc** variable to point to the directory where the dataset has been uncompressed. \n\n3. Execute the following script to process all the sequences with all sensor configurations:\n```\n./euroc_examples\n```\n\n## Evaluation\nEuRoC provides ground truth for each sequence in the IMU body reference. As pure visual executions report trajectories centered in the left camera, we provide in the \"evaluation\" folder the transformation of the ground truth to the left camera reference. Visual-inertial trajectories use the ground truth from the dataset.\n\nExecute the following script to process sequences and compute the RMS ATE:\n```\n./euroc_eval_examples\n```\n\n# 6. TUM-VI Examples\n[TUM-VI dataset](https://vision.in.tum.de/data/datasets/visual-inertial-dataset) was recorded with two fisheye cameras and an inertial sensor.\n\n1. Download a sequence from https://vision.in.tum.de/data/datasets/visual-inertial-dataset and uncompress it.\n\n2. Open the script \"tum_vi_examples.sh\" in the root of the project. Change **pathDatasetTUM_VI** variable to point to the directory where the dataset has been uncompressed. \n\n3. Execute the following script to process all the sequences with all sensor configurations:\n```\n./tum_vi_examples\n```\n\n## Evaluation\nIn TUM-VI ground truth is only available in the room where all sequences start and end. As a result the error measures the drift at the end of the sequence. \n\nExecute the following script to process sequences and compute the RMS ATE:\n```\n./tum_vi_eval_examples\n```\n\n# 7. ROS Examples\n\n### Building the nodes for mono, mono-inertial, stereo, stereo-inertial and RGB-D\nTested with ROS Melodic and ubuntu 18.04.\n\n1. Add the path including *Examples/ROS/ORB_SLAM3* to the ROS_PACKAGE_PATH environment variable. Open .bashrc file:\n  ```\n  gedit ~/.bashrc\n  ```\nand add at the end the following line. Replace PATH by the folder where you cloned ORB_SLAM3:\n\n  ```\n  export ROS_PACKAGE_PATH=${ROS_PACKAGE_PATH}:PATH/ORB_SLAM3/Examples/ROS\n  ```\n  \n2. Execute `build_ros.sh` script:\n\n  ```\n  chmod +x build_ros.sh\n  ./build_ros.sh\n  ```\n  \n### Running Monocular Node\nFor a monocular input from topic `/camera/image_raw` run node ORB_SLAM3/Mono. You will need to provide the vocabulary file and a settings file. See the monocular examples above.\n\n  ```\n  rosrun ORB_SLAM3 Mono PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE\n  ```\n\n### Running Monocular-Inertial Node\nFor a monocular input from topic `/camera/image_raw` and an inertial input from topic `/imu`, run node ORB_SLAM3/Mono_Inertial. Setting the optional third argument to true will apply CLAHE equalization to images (Mainly for TUM-VI dataset).\n\n  ```\n  rosrun ORB_SLAM3 Mono PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE [EQUALIZATION]\t\n  ```\n\n### Running Stereo Node\nFor a stereo input from topic `/camera/left/image_raw` and `/camera/right/image_raw` run node ORB_SLAM3/Stereo. You will need to provide the vocabulary file and a settings file. For Pinhole camera model, if you **provide rectification matrices** (see Examples/Stereo/EuRoC.yaml example), the node will recitify the images online, **otherwise images must be pre-rectified**. For FishEye camera model, rectification is not required since system works with original images:\n\n  ```\n  rosrun ORB_SLAM3 Stereo PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE ONLINE_RECTIFICATION\n  ```\n\n### Running Stereo-Inertial Node\nFor a stereo input from topics `/camera/left/image_raw` and `/camera/right/image_raw`, and an inertial input from topic `/imu`, run node ORB_SLAM3/Stereo_Inertial. You will need to provide the vocabulary file and a settings file, including rectification matrices if required in a similar way to Stereo case:\n\n  ```\n  rosrun ORB_SLAM3 Stereo_Inertial PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE ONLINE_RECTIFICATION [EQUALIZATION]\t\n  ```\n  \n### Running RGB_D Node\nFor an RGB-D input from topics `/camera/rgb/image_raw` and `/camera/depth_registered/image_raw`, run node ORB_SLAM3/RGBD. You will need to provide the vocabulary file and a settings file. See the RGB-D example above.\n\n  ```\n  rosrun ORB_SLAM3 RGBD PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE\n  ```\n\n**Running ROS example:** Download a rosbag (e.g. V1_02_medium.bag) from the EuRoC dataset (http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets). Open 3 tabs on the terminal and run the following command at each tab for a Stereo-Inertial configuration:\n  ```\n  roscore\n  ```\n  \n  ```\n  rosrun ORB_SLAM3 Stereo_Inertial Vocabulary/ORBvoc.txt Examples/Stereo-Inertial/EuRoC.yaml true\n  ```\n  \n  ```\n  rosbag play --pause V1_02_medium.bag /cam0/image_raw:=/camera/left/image_raw /cam1/image_raw:=/camera/right/image_raw /imu0:=/imu\n  ```\n  \nOnce ORB-SLAM3 has loaded the vocabulary, press space in the rosbag tab.\n\n**Remark:** For rosbags from TUM-VI dataset, some play issue may appear due to chunk size. One possible solution is to rebag them with the default chunk size, for example:\n  ```\n  rosrun rosbag fastrebag.py dataset-room1_512_16.bag dataset-room1_512_16_small_chunks.bag\n  ```\n\n# 8. Running time analysis\nA flag in `include\\Config.h` activates time measurements. It is necessary to uncomment the line `#define REGISTER_TIMES` to obtain the time stats of one execution which is shown at the terminal and stored in a text file(`ExecTimeMean.txt`).\n\n# 9. Calibration\nYou can find a tutorial for visual-inertial calibration and a detailed description of the contents of valid configuration files at  `Calibration_Tutorial.pdf`\n",
      "stars_today": 6
    },
    {
      "id": 646423,
      "name": "pgbouncer",
      "full_name": "pgbouncer/pgbouncer",
      "description": "lightweight connection pooler for PostgreSQL",
      "html_url": "https://github.com/pgbouncer/pgbouncer",
      "stars": 3841,
      "forks": 532,
      "language": "C",
      "topics": [
        "postgresql"
      ],
      "created_at": "2010-05-04T10:39:40Z",
      "updated_at": "2026-01-24T22:03:28Z",
      "pushed_at": "2025-12-03T18:14:39Z",
      "open_issues": 268,
      "owner": {
        "login": "pgbouncer",
        "avatar_url": "https://avatars.githubusercontent.com/u/11858179?v=4"
      },
      "readme": "PgBouncer\n=========\n\nLightweight connection pooler for PostgreSQL.\n\nHomepage: <https://www.pgbouncer.org/>\n\nSources, bug tracking: <https://github.com/pgbouncer/pgbouncer>\n\nBuilding\n---------\n\nPgBouncer depends on few things to get compiled:\n\n* [GNU Make] 3.81+\n* [Libevent] 2.0+\n* [pkg-config]\n* [OpenSSL] 1.0.1+ for TLS support\n* (optional) [c-ares] as alternative to Libevent's evdns\n* (optional) LDAP libraries\n* (optional) PAM libraries\n\n[GNU Make]: https://www.gnu.org/software/make/\n[Libevent]: http://libevent.org/\n[pkg-config]: https://www.freedesktop.org/wiki/Software/pkg-config/\n[OpenSSL]: https://www.openssl.org/\n[c-ares]: http://c-ares.haxx.se/\n\nWhen dependencies are installed just run:\n\n    $ ./configure --prefix=/usr/local\n    $ make\n    $ make install\n\nIf you are building from Git, or are building for Windows, please see\nseparate build instructions below.\n\nDNS lookup support\n------------------\n\nPgBouncer does host name lookups at connect time instead of just once\nat configuration load time.  This requires an asynchronous DNS\nimplementation.  The following table shows supported backends and\ntheir probing order:\n\n| backend                    | parallel | EDNS0 (1) | /etc/hosts | SOA lookup (2) | note                                  |\n|----------------------------|----------|-----------|------------|----------------|---------------------------------------|\n| c-ares                     | yes      | yes       | yes        | yes            | IPv6+CNAME buggy in <=1.10            |\n| evdns, libevent 2.x        | yes      | no        | yes        | no             | does not check /etc/hosts updates     |\n| getaddrinfo_a, glibc 2.9+  | yes      | yes (3)   | yes        | no             | N/A on non-glibc                      |\n| getaddrinfo, libc          | no       | yes (3)   | yes        | no             | requires pthreads                     |\n\n1. EDNS0 is required to have more than 8 addresses behind one host name.\n2. SOA lookup is needed to re-check host names on zone serial change.\n3. To enable EDNS0, add `options edns0` to `/etc/resolv.conf`.\n\nc-ares is the most fully-featured implementation and is recommended\nfor most uses and binary packaging (if a sufficiently new version is\navailable).  Libevent's built-in evdns is also suitable for many uses,\nwith the listed restrictions.  The other backends are mostly legacy\noptions at this point and don't receive much testing anymore.\n\nBy default, c-ares is used if it can be found.  Its use can be forced\nwith `configure --with-cares` or disabled with `--without-cares`.  If\nc-ares is not used (not found or disabled), then Libevent is used.  Specify\n`--disable-evdns` to disable the use of Libevent's evdns and fall back to a\nlibc-based implementation.\n\nPAM authentication\n------------------\n\nTo enable PAM authentication, `./configure` has a flag `--with-pam`\n(default value is no).  When compiled with PAM support, a new global\nauthentication type `pam` is available to validate users through PAM.\n\nLDAP authentication\n------------------\n\nTo enable LDAP authentication, `./configure` has a flag `--with-ldap`\n(default value is no).  When compiled with LDAP support, a new global\nauthentication type `ldap` is available to validate users through LDAP.\n\nsystemd integration\n-------------------\n\nTo enable systemd integration, use the `configure` option\n`--with-systemd`.  This allows using `Type=notify` (or `Type=notify-reload` if\nyou are using systemd 253 or later) as well as socket activation.  See\n`etc/pgbouncer.service` and `etc/pgbouncer.socket` for examples.\n\nBuilding from Git\n-----------------\n\nBuilding PgBouncer from Git requires that you generate the header and\nconfiguration files before you can run `configure`:\n\n\t$ git clone https://github.com/pgbouncer/pgbouncer.git\n\t$ cd pgbouncer\n\t$ ./autogen.sh\n\t$ ./configure\n\t$ make\n\t$ make install\n\nAll files will be installed under `/usr/local` by default. You can\nsupply one or more command-line options to `configure`. Run\n`./configure --help` to list the available options and the environment\nvariables that customizes the configuration.\n\nAdditional packages required: autoconf, automake, libtool, pandoc\n\nTesting\n-------\n\nSee the [`README.md` file in the test directory][1] on how to run the tests.\n\n[1]: https://github.com/pgbouncer/pgbouncer/blob/master/test/README.md\n\nBuilding on Windows\n-------------------\n\nThe only supported build environment on Windows is MinGW.  Cygwin and\nVisual $ANYTHING are not supported.\n\nTo build on MinGW, do the usual:\n\n\t$ ./configure\n\t$ make\n\nIf cross-compiling from Unix:\n\n\t$ ./configure --host=i586-mingw32msvc\n\nThe LDAP build option is currently not supported on Windows.\n\nRunning on Windows\n------------------\n\nRunning from the command line goes as usual, except that the `-d` (daemonize),\n`-R` (reboot), and `-u` (switch user) switches will not work.\n\nTo run PgBouncer as a Windows service, you need to configure the\n`service_name` parameter to set a name for the service.  Then:\n\n\t$ pgbouncer -regservice config.ini\n\nTo uninstall the service:\n\n\t$ pgbouncer -unregservice config.ini\n\nTo use the Windows event log, set `syslog = 1` in the configuration file.\nBut before that, you need to register `pgbevent.dll`:\n\n\t$ regsvr32 pgbevent.dll\n\nTo unregister it, do:\n\n\t$ regsvr32 /u pgbevent.dll\n",
      "stars_today": 6
    },
    {
      "id": 20008432,
      "name": "orbot-android",
      "full_name": "guardianproject/orbot-android",
      "description": "The Github home of Orbot: Tor on Android (Also available on gitlab!)",
      "html_url": "https://github.com/guardianproject/orbot-android",
      "stars": 2963,
      "forks": 423,
      "language": "Kotlin",
      "topics": [
        "anonymity",
        "anticensorship",
        "censorship-circumvention",
        "security",
        "tor"
      ],
      "created_at": "2014-05-21T05:03:06Z",
      "updated_at": "2026-01-25T01:54:24Z",
      "pushed_at": "2026-01-23T14:45:28Z",
      "open_issues": 169,
      "owner": {
        "login": "guardianproject",
        "avatar_url": "https://avatars.githubusercontent.com/u/218109?v=4"
      },
      "readme": "<div align=\"center\">\n\n# [Orbot](https://orbot.app)\n\n### *Android Onion Routing Robot*\n\n[![Weblate Status](https://hosted.weblate.org/widget/guardianproject/orbot/svg-badge.svg)](https://hosted.weblate.org/engage/guardianproject/)\n[![Play Downloads](https://img.shields.io/github/downloads/guardianproject/orbot/total)](https://play.google.com/store/apps/details?id=org.torproject.android)\n[![Bitrise Status](https://img.shields.io/bitrise/0e76c31b8e7e1801?token=S2weJXueO3AvrDUrrd85SA&logo=bitrise&color=blue)](https://app.bitrise.io/app/0e76c31b8e7e1801) ([CI docs](./docs/info/CI.md))\n\nOrbot is a free VPN and proxy app that empowers other apps to use the internet more securely. Orbot uses Tor to encrypt your Internet traffic and then hides it by bouncing through a series of computers around the world. Tor is free software and an open network that helps you defend against a form of network surveillance that threatens personal freedom and privacy, confidential business activities and relationships, and state security known as traffic analysis.\n\n<img src=./fastlane/metadata/android/en-US/images/phoneScreenshots/A-orbot_connected.png width=\"19%%\"> <img src=./fastlane/metadata/android/en-US/images/phoneScreenshots/B-choose-how.png width=\"20%\">\n<img src=./fastlane/metadata/android/en-US/images/phoneScreenshots/C-Choose_Apps.png width=\"19%\">\n<img src=./fastlane/metadata/android/en-US/images/phoneScreenshots/D-kindness_mode_screen.png width=\"19%\">\n<img src=./fastlane/metadata/android/en-US/images/phoneScreenshots/E-more_screen.png width=\"19%\">\n\n</div>\n\nOrbot is a crucial component of the Guardian Project, an initiative  that leads an effort\nto develop a secure and anonymous smartphone. This platform is designed for use by human rights\nactivists, journalists and others around the world. Learn more: <https://guardianproject.info/>\n\n\nTor protects your privacy on the internet by hiding the connection\nbetween your Internet address and the services you use. We believe that Tor\nis reasonably secure, but please ensure you read the usage instructions and\nlearn to configure it properly. Learn more: <https://torproject.org/>\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td><a href=\"https://github.com/guardianproject/orbot/releases/latest\">Download the Latest Orbot Release</a></td>\n    </tr>\n    <tr>\n      <td><a href=\"https://support.torproject.org/faq/\">Tor FAQ (Frequently Asked Questions)</a></td>\n    </tr>\n    <tr>\n      <td><a href=\"https://hosted.weblate.org/engage/guardianproject/\">Please Contribute Your Translations</a></td>\n    </tr>\n  </table>\n</div>\n\n### Build Instructions\n\nOrbot is built with [hev-socks5-tunnel](https://github.com/heiher/hev-socks5-tunnel). Before you can build Orbot, you'll need to clone the submodule\nfor this dependency. Once cloned, Android Studio + Gradle will take care of building the C code.\n\n```bash\ngit clone --recursive https://github.com/guardianproject/orbot-android\n```\n\nOr, if you already cloned the repo:\n\n```bash\ncd orbot-android\ngit pull\ngit submodule update --init --recursive\n```\n\nIf you pull and see that there are changes to `app/src/main/jni/hev-socks5-tunnel` that means that `hev-socks5-tunnel` was updated. You need to re-run `git submodule update --init --recursive` to fetch the latest changes and then rebuild Orbot.\n\n### Viewing Logs \n\nRecently `tor` was added to be its own Linux process on Android instead of having it run within the primary app process. That measn that you will no longer see logs from `tor`, `OrbotService`, `OrbotVPNManager` etc within Android Studio. In order to see these logs you can use:\n\n\n`adb logcat  --pid=$(adb shell pidof -s \"org.torproject.android.debug\") -v color` to see the app logs in your terminal\n\n`adb logcat  --pid=$(adb shell pidof -s \"org.torproject.android.debug:tor\") -v color` and to see the `tor` process logs.\n\n**There is a helper script to get both of these logs printed side-by-side with `tmux`. From the root directory run:\n\n```bash\n./scripts/view_logs_tmux.sh\n```\n\nYou may need to initially do some configuration to obtain `tmux` and add `adb` to your `PATH`:\n\n```bash\n# on Mac OS \nbrew install tmux \n\n\n# on debian + friends:\nsudo apt intstall tmux \n\n# then make sure adb is in your path in your .bashrc or similar file:\nexport ANDROID_HOME=~/Android/Sdk\nexport PATH=$PATH:$ANDROID_HOME/platform-tools\n\n\n# on mac you do the above or instead get an adb instance from brew...\nbrew install android-platform-tools\n```\n\n**Copyright &#169; 2009-2026, Nathan Freitas, The Guardian Project**\n",
      "stars_today": 6
    },
    {
      "id": 66190491,
      "name": "apkupdater",
      "full_name": "rumboalla/apkupdater",
      "description": "APKUpdater is an open source tool that simplifies the process of finding updates for your installed apps.",
      "html_url": "https://github.com/rumboalla/apkupdater",
      "stars": 3560,
      "forks": 257,
      "language": "Kotlin",
      "topics": [
        "android",
        "apk",
        "apkmirror",
        "aptoide",
        "f-droid",
        "flow",
        "google",
        "gplv3",
        "installer",
        "java",
        "jetpack-compose",
        "kotlin",
        "material-design-3",
        "open-source",
        "play",
        "play-store",
        "updater",
        "workmanager"
      ],
      "created_at": "2016-08-21T09:18:13Z",
      "updated_at": "2026-01-24T20:28:42Z",
      "pushed_at": "2025-07-16T07:25:56Z",
      "open_issues": 29,
      "owner": {
        "login": "rumboalla",
        "avatar_url": "https://avatars.githubusercontent.com/u/21153554?v=4"
      },
      "readme": "# APKUpdater [![](https://github.com/rumboalla/apkupdater/workflows/Android%20Build/badge.svg)](https://github.com/rumboalla/apkupdater/actions?query=workflow%3A%22Android+Build%22)\n**APKUpdater** is an open source tool that simplifies the process of **finding updates** for your installed apps.  \nIt provides similar functionality to an app store, but instead of depending on a single source, it aggregates the results from **APKMirror**, **Aptoide**, **F-Droid**, **IzzyOnDroid**, **APKPure**, **GitLab** and **GitHub**.\n\nThe 3.x branch is a full rewrite using modern technologies like **Jetpack Compose**, **Flow** and **WorkManager**.\n\n# Features\n* **Update Sources**: Find updates from **APKMirror**, **Aptoide**, **F-Droid**, **IzzyOnDroid**, **APKPure**, **GitLab**, **GitHub** and **Google Play**.\n* **Search Sources**: Find new apps to install from **APKMirror**, **Aptoide**, **F-Droid**, **IzzyOnDroid**, **APKPure**, **GitLab**, **GitHub** and **Google Play**.\n* Schedule **background update checks** and receive a **notification** when updates are found.\n* Supports **Android 5** (**21**) to **Android 14** (**34**).\n* Supports **Android TV**.\n* **Material Design 3** with **Dark**, **Light** and **System** theme support.\n* Supports **Material You** on Android 12+.\n* **Direct install** of updates for sources that support it.\n* Supports **installs without user interaction** on Android 12+.\n* **Root install** of updates.\n* No ads. No tracking.\n* **Languages**: Albanian, Arabic, Burmese, Dutch, English, German, Hebrew, Hungarian, Indonesian, Italian, Korean, Malay, Portuguese, Romanian, Russian, Simplified Chinese, Spanish, Traditional Chinese, Turkish.\n\n# Download\n* [Stable Release (3.0.3)](https://github.com/rumboalla/apkupdater/releases/latest/download/com.apkupdater-release.apk)\n* [CI Pre-release Builds](https://github.com/rumboalla/apkupdater/releases?q=CI&expanded=true)\n* [Older releases](https://github.com/rumboalla/apkupdater/releases)\n\n# Translations\nIf you want to help with translations, open a [Pull Request](https://github.com/rumboalla/apkupdater/pulls) or an [Issue](https://github.com/rumboalla/apkupdater/issues) with the translated [strings.xml](https://github.com/rumboalla/apkupdater/blob/3.x/app/src/main/res/values/strings.xml).\n\n* Albanian by [Jvr2022](https://github.com/Jvr2022)\n* Arabic by [Muhammadbahaa2001](https://github.com/Muhammadbahaa2001)\n* Burmese by [kyawlinnthant](https://github.com/kyawlinnthant)\n* Dutch by [AnonymousWP](https://github.com/AnonymousWP)\n* German by [peat80](https://github.com/peat80)\n* Hebrew by [electriquo](https://github.com/electriquo)\n* Hungarian by [gidano](https://github.com/gidano)\n* Indonesian by [HazakuraID](https://github.com/HazakuraID)\n* Italian by [NicKoehler](https://github.com/NicKoehler)\n* Korean by [Apious](https://github.com/Apious)\n* Malay by [HazakuraID](https://github.com/HazakuraID)\n* Portuguese by [zekabra](https://github.com/zekabra)\n* Romanian by [StormProductionsMusic](https://github.com/StormProductionsMusic)\n* Russian by [Xenorant](https://github.com/Xenorant)\n* Simplified Chinese by [Nriver](https://github.com/Nriver)\n* Traditional Chinese by [abc0922001](https://github.com/abc0922001)\n* Turkish by [kyoyacchi](https://github.com/kyoyacchi)\n* Japanese by [anonym499](https://github.com/anonym499)\n\n# Feedback\n- To give feedback and request new features go to [Discussions](https://github.com/rumboalla/apkupdater/discussions).\n- To report bugs, crashes, typos and translations go to [Issues](https://github.com/rumboalla/apkupdater/issues).\n\n# Screenshots\n\n| ![1](https://github.com/rumboalla/apkupdater/assets/21153554/b5b4943b-e12a-43e2-a056-26d6f06f9bc4) | ![2](https://github.com/rumboalla/apkupdater/assets/21153554/c4679c1b-09d4-429d-9160-77d4d33b0a0f) | ![3](https://github.com/rumboalla/apkupdater/assets/21153554/7b89c5a6-672c-44e4-836e-e01f51f33591) | ![4](https://github.com/rumboalla/apkupdater/assets/21153554/7ec15783-e719-4feb-9e07-a14c0f1defcc) |\n|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|\n\n| ![5](https://github.com/rumboalla/apkupdater/assets/21153554/bbf1132a-b0b6-4890-aed7-8fe95c0da11b) | ![6](https://github.com/rumboalla/apkupdater/assets/21153554/32236bfb-b53e-4999-8363-e957fa8f77a9) |\n|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|\n\n# Other Projects\n* [CoolRs](https://github.com/rumboalla/coolrs): A collection of Android RenderScript effects. \n* [KryptoPrefs](https://github.com/rumboalla/KryptoPrefs): Kotlin library for handling encrypted SharedPreferences.\n* [KryptoStore](https://github.com/rumboalla/kryptostore): A thin wrapper around Jetpack Datastore Preferences that provides useful features.\n\n# License\nCopyright &copy; 2016-2024 rumboalla.  \nLicensed under the [GNU General Public License v3](https://www.gnu.org/licenses/gpl-3.0.en.html).\n",
      "stars_today": 6
    },
    {
      "id": 998332835,
      "name": "TizenTubeCobalt",
      "full_name": "reisxd/TizenTubeCobalt",
      "description": "Experience TizenTube on other devices that are not Tizen.",
      "html_url": "https://github.com/reisxd/TizenTubeCobalt",
      "stars": 1437,
      "forks": 69,
      "language": "C++",
      "topics": [],
      "created_at": "2025-06-08T11:43:22Z",
      "updated_at": "2026-01-25T02:05:54Z",
      "pushed_at": "2025-12-20T16:56:20Z",
      "open_issues": 19,
      "owner": {
        "login": "reisxd",
        "avatar_url": "https://avatars.githubusercontent.com/u/29177546?v=4"
      },
      "readme": "# ğŸ’  TizenTube Cobalt\n\n<p align=\"center\">\n    <img width=\"700px\" src=\".github/assets/TizenTube_Cobalt-Official_Banner.png\">\n    <br>\n</p>\n\n**TizenTube Cobalt** is an app based on [Cobalt](https://cobalt.dev) that enhances your favourite streaming website viewing experience by removing ads, adding [SponsorBlock](https://sponsor.ajay.app/) support, and providing useful features like video speed control.\n\n<details>\n<summary><strong>What is Cobalt?</strong></summary>\n\nCobalt is a lightweight, cross-platform application container and runtime for HTML5-based apps, originally developed by Google for embedded and resource-constrained devices (like smart TVs, set-top boxes, and game consoles). It implements a subset of the W3C HTML5 standard and runs web apps with high performance on a wide range of hardware.\n\n</details>\n\n## âœ¨ Features\n\n- ğŸ›‘ **Ad Blocker**: Enjoy your favourite streaming website without interruptions from ads.\n- â— **SponsorBlock Support**: Automatically skip sponsored segments in videos.\n- â­ï¸ **Video Speed Control**: Adjust playback speed to your preference.\n- ğŸ”º **[DeArrow](https://dearrow.ajay.app/) Support**: Remove clickbait and misleading video titles.\n- â• **More to come!** Request features via [issues](https://github.com/reisxd/TizenTube/issues/new).\n\n## â¬‡ï¸ Download\n\nGet the latest release for your platform:\n\n[**Download Latest Release**](https://github.com/reisxd/TizenTubeCobalt/releases/latest)\n\nAFTVNews code: `6366500`\n\nFor a better experience, preferably use TizenTube Cobalt on a [**Google TV certified device.**](https://www.androidtv-guide.com/)\n\n## â” How to Install\n\n1. Download the latest release from the link above.\n2. Sideload or install the app on your device (using a file manager, ADB, or platform-specific method).\n3. Open the app and enjoy an enhanced streaming experience!\n\n## â„¹ï¸ Community & Support\n\n- [Discord Server](https://discord.gg/m2P7v8Y2qR)\n- [Telegram Channel](https://t.me/tizentubecobaltofficial)\n- [Report Issues / Request Features](https://github.com/reisxd/TizenTube/issues)\n",
      "stars_today": 6
    },
    {
      "id": 352933140,
      "name": "ToolJet",
      "full_name": "ToolJet/ToolJet",
      "description": "ToolJet is the open-source foundation of ToolJet AI - the AI-native platform for building internal tools, dashboard, business applications, workflows and AI agents ğŸš€",
      "html_url": "https://github.com/ToolJet/ToolJet",
      "stars": 37336,
      "forks": 4937,
      "language": "JavaScript",
      "topics": [
        "ai-app-builder",
        "docker",
        "hacktoberfest",
        "internal-applications",
        "internal-project",
        "internal-tool",
        "internal-tools",
        "javascript",
        "kubernetes",
        "low-code",
        "low-code-development-platform",
        "low-code-framework",
        "no-code",
        "nodejs",
        "reactjs",
        "self-hosted",
        "typescript",
        "web-development-tools",
        "workflow-automation"
      ],
      "created_at": "2021-03-30T08:51:34Z",
      "updated_at": "2026-01-25T02:13:10Z",
      "pushed_at": "2026-01-24T12:05:31Z",
      "open_issues": 956,
      "owner": {
        "login": "ToolJet",
        "avatar_url": "https://avatars.githubusercontent.com/u/82193554?v=4"
      },
      "readme": "ToolJet is the open-source foundation of ToolJet AI - the AI-native platform for building and deploying internal tools, workflows and AI agents. The community edition provides a powerful visual builder, drag-and-drop UI, and integrations with databases, APIs, SaaS apps, and object storage. For AI-powered UI generation, query building, debugging, and enterprise features, see ToolJet AI.\n\n :star: If you find ToolJet useful, please consider giving us a star on GitHub! Your support helps us continue to innovate and deliver exciting features.\n\n![Docker Cloud Build Status](https://img.shields.io/docker/automated/tooljet/tooljet-ce)\n![Number of GitHub contributors](https://img.shields.io/github/contributors/tooljet/tooljet)\n[![Number of GitHub issues that are open](https://img.shields.io/github/issues/ToolJet/ToolJet)](https://github.com/ToolJet/ToolJet/issues)\n[![Number of GitHub stars](https://img.shields.io/github/stars/ToolJet/ToolJet)](https://github.com/ToolJet/ToolJet/stargazers)\n![Number of GitHub closed issues](https://img.shields.io/github/issues-closed/tooljet/tooljet)\n![Number of GitHub pull requests that are open](https://img.shields.io/github/issues-pr-raw/tooljet/tooljet)\n![GitHub release; latest by date](https://img.shields.io/github/v/release/tooljet/tooljet)\n![GitHub commit activity](https://img.shields.io/github/commit-activity/m/tooljet/tooljet)\n[![GitHub license which is AGPL license](https://img.shields.io/github/license/ToolJet/ToolJet)](https://github.com/ToolJet/ToolJet)\n[![Follow us on X, formerly Twitter](https://img.shields.io/twitter/follow/ToolJet?style=social)](https://twitter.com/ToolJet)\n\n<p align=\"center\">\n    <img src=\"docs/static/img/readme/banner.png\" alt=\"Tooljet dashboard showing inventory and orders\"/>\n</p>\n\n<p align=\"center\">\n    <img src=\"docs/static/img/readme/flowchart.png\"/>\n</p>\n\n## Features  \n\n### Community Edition (CE)  \n- **Visual App Builder:** 60+ responsive components (Tables, Charts, Forms, Lists, Progress Bars, and more).  \n- **ToolJet Database:** Built-in no-code database.  \n- **Multi-page Apps & Multiplayer Editing:** Build complex apps collaboratively.  \n- **75+ Data Sources:** Connect to databases, APIs, cloud storage, and SaaS tools.  \n- **Flexible Deployment:** Self-host with Docker, Kubernetes, AWS, GCP, Azure, and more.  \n- **Collaboration Tools:** Inline comments, mentions, and granular access control.  \n- **Extensibility:** Create plugins and connectors with the [ToolJet CLI](https://www.npmjs.com/package/@tooljet/cli).  \n- **Code Anywhere:** Run JavaScript and Python inside your apps.  \n- **Secure by Design:** AES-256-GCM encryption, proxy-only data flow, SSO support.  \n\n### ToolJet AI (Enterprise)  \nEverything in CE, plus:  \n- **AI App Generation:** Create apps instantly from natural language prompts.  \n- **AI Query Builder:** Generate and transform queries with AI assistance.  \n- **AI Debugging:** Identify and fix issues with one click.  \n- **Agent Builder:** Create intelligent agents to automate workflows and orchestrate processes.  \n- **Enterprise-grade Security & Compliance:** SOC 2 and GDPR readiness, audit logs, and advanced access control.\n- **User Management:** Role-based access (RBAC), custom groups, and granular app/data permissions.  \n- **Multi-environment Management:** Seamless dev/stage/prod environments.  \n- **GitSync & CI/CD:** Integrate with GitHub/GitLab for version control and streamlined deployments.  \n- **Branding & Customization:** White-labeling, and custom theming for organizational branding.  \n- **Fine-Grained Access Control:** Secure data and actions at the row, component, page, and query levels.  \n- **Embedded Apps:** Embed ToolJet apps securely within other applications or portals.  \n- **Enterprise Support:** SLAs, priority bug fixes, and onboarding assistance.  \n\n<hr>\n\n## Quickstart\nThe easiest way to get started with ToolJet is by creating a [ToolJet Cloud](https://tooljet.com) account. ToolJet Cloud offers a hosted solution of ToolJet. If you want to self-host ToolJet, kindly proceed to [deployment documentation](https://docs.tooljet.com/docs/setup/).\n\n### Try using Docker\nWant to give ToolJet a quick spin on your local machine? You can run the following command from your terminal to have ToolJet up and running right away.\n\n\n```bash\ndocker run \\\n  --name tooljet \\\n  --restart unless-stopped \\\n  -p 80:80 \\\n  --platform linux/amd64 \\\n  -v tooljet_data:/var/lib/postgresql/13/main \\\n  tooljet/try:ee-lts-latest\n```\n\n*For users upgrading their ToolJet version, we recommend choosing the LTS version over the latest version. The LTS version ensures stability with production bug fixes, security patches, and performance enhancements.*\n\n## Tutorials and examples\n\n[Time Tracker Application](https://docs.tooljet.com/docs/#quickstart-guide)<br>\n[Build your own CMS using low-code](https://blog.tooljet.com/build-cms-using-lowcode-and-mongodb/)<br>\n[AWS S3 Browser](https://blog.tooljet.com/build-an-aws-s3-broswer-with-tooljet/)<br>\n\n## Documentation\nDocumentation is available at https://docs.tooljet.com.\n\n- [Getting Started](https://docs.tooljet.com)<br>\n- [Data source Reference](https://docs.tooljet.com/docs/data-sources/airtable/)<br>\n- [Component Reference](https://docs.tooljet.com/docs/widgets/button)\n\n## Self-hosted\nYou can use ToolJet Cloud for a fully managed solution. If you want to self-host ToolJet, we have guides on deploying ToolJet on Kubernetes, AWS EC2, Docker, and more.\n\n| Provider  | Documentation |\n| :------------- | :------------- |\n| Digital Ocean | [Link](https://docs.tooljet.com/docs/setup/digitalocean)  |\n| Docker  | [Link](https://docs.tooljet.com/docs/setup/docker)   |\n| AWS EC2 | [Link](https://docs.tooljet.com/docs/setup/ec2)  |\n| AWS ECS | [Link](https://docs.tooljet.com/docs/setup/ecs)   |\n| OpenShift | [Link](https://docs.tooljet.com/docs/setup/openshift)   |\n| Helm | [Link](https://docs.tooljet.com/docs/setup/helm)   |\n| AWS EKS (Kubernetes) | [Link](https://docs.tooljet.com/docs/setup/kubernetes)   |\n| GCP GKE (Kubernetes) | [Link](https://docs.tooljet.com/docs/setup/kubernetes-gke)   |\n| Azure AKS (Kubernetes) | [Link](https://docs.tooljet.com/docs/setup/kubernetes-aks)   |\n| Azure Container | [Link](https://docs.tooljet.com/docs/setup/azure-container)   |\n| Google Cloud Run  | [Link](https://docs.tooljet.com/docs/setup/google-cloud-run)   |\n| Deploying ToolJet client  | [Link](https://docs.tooljet.com/docs/setup/client)   |\n| Deploying ToolJet on a Subpath  | [Link](https://docs.tooljet.com/docs/setup/tooljet-subpath/)   |\n\n## Marketplace \nToolJet can now be found on both AWS and Azure Marketplaces, making it simpler than ever to access and deploy our app-building platform.\n\nFind ToolJet on AWS Marketplace [here](https://aws.amazon.com/marketplace/pp/prodview-fxjto27jkpqfg?sr=0-1&ref_=beagle&applicationId=AWSMPContessa) and explore seamless integration on Azure Marketplace [here](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/tooljetsolutioninc1679496832216.tooljet?tab=Overview).\n\n## Community support\nFor general help using ToolJet, please refer to the official [documentation](https://docs.tooljet.com/docs/). For additional help, you can use one of these channels to ask a question:\n\n- [Slack](https://tooljet.com/slack) - Discussions with the community and the team.\n- [GitHub](https://github.com/ToolJet/ToolJet/issues) - For bug reports and feature requests.\n- [ğ• (Twitter)](https://twitter.com/ToolJet) - Get the product updates quickly.\n\n## Roadmap\nCheck out our [roadmap](https://github.com/orgs/ToolJet/projects/15) to stay updated on recently released features and learn about what's coming next.\n\n## Branching model\nWe use the git-flow branching model. The base branch is `develop`. If you are looking for a stable version, please use the main branch or tags labeled as v1.x.x.\n\n## Contributing\nKindly read our [Contributing Guide](CONTRIBUTING.md) to familiarize yourself with ToolJet's development process, how to suggest bug fixes and improvements, and the steps for building and testing your changes. <br>\n\n## Contributors\n<a href=\"https://github.com/tooljet/tooljet/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=tooljet/tooljet&max=400&columns=20\" />\n  <img src=\"https://us-central1-tooljet-hub.cloudfunctions.net/github\" width=\"0\" height=\"0\" />\n</a>\n\n## License\nToolJet Â© 2023, ToolJet Solutions Inc - Released under the GNU Affero General Public License v3.0.\n",
      "stars_today": 5
    },
    {
      "id": 26038648,
      "name": "spdlog",
      "full_name": "gabime/spdlog",
      "description": "Fast C++ logging library.",
      "html_url": "https://github.com/gabime/spdlog",
      "stars": 28176,
      "forks": 5026,
      "language": "C++",
      "topics": [
        "cpp",
        "cpp11",
        "header-only",
        "logging",
        "spdlog"
      ],
      "created_at": "2014-11-01T01:28:53Z",
      "updated_at": "2026-01-24T23:03:52Z",
      "pushed_at": "2026-01-15T20:54:28Z",
      "open_issues": 54,
      "owner": {
        "login": "gabime",
        "avatar_url": "https://avatars.githubusercontent.com/u/6052198?v=4"
      },
      "readme": "# spdlog\r\n\r\n \r\n[![ci](https://github.com/gabime/spdlog/actions/workflows/linux.yml/badge.svg)](https://github.com/gabime/spdlog/actions/workflows/linux.yml)&nbsp;\r\n[![ci](https://github.com/gabime/spdlog/actions/workflows/windows.yml/badge.svg)](https://github.com/gabime/spdlog/actions/workflows/windows.yml)&nbsp;\r\n[![ci](https://github.com/gabime/spdlog/actions/workflows/macos.yml/badge.svg)](https://github.com/gabime/spdlog/actions/workflows/macos.yml)&nbsp;\r\n[![Build status](https://ci.appveyor.com/api/projects/status/d2jnxclg20vd0o50?svg=true&branch=v1.x)](https://ci.appveyor.com/project/gabime/spdlog) [![Release](https://img.shields.io/github/release/gabime/spdlog.svg)](https://github.com/gabime/spdlog/releases/latest)\r\n\r\nFast C++ logging library\r\n\r\n\r\n## Install\r\n#### Header-only version\r\nCopy the include [folder](include/spdlog) to your build tree and use a C++11 compiler.\r\n\r\n#### Compiled version (recommended - much faster compile times)\r\n```console\r\n$ git clone https://github.com/gabime/spdlog.git\r\n$ cd spdlog && mkdir build && cd build\r\n$ cmake .. && cmake --build .\r\n```\r\nsee example [CMakeLists.txt](example/CMakeLists.txt) on how to use.\r\n\r\n## Platforms\r\n* Linux, FreeBSD, OpenBSD, Solaris, AIX\r\n* Windows (msvc 2013+, cygwin)\r\n* macOS (clang 3.5+)\r\n* Android\r\n\r\n## Package managers:\r\n* Debian: `sudo apt install libspdlog-dev`\r\n* Homebrew: `brew install spdlog`\r\n* MacPorts: `sudo port install spdlog`\r\n* FreeBSD:  `pkg install spdlog`\r\n* Fedora: `dnf install spdlog`\r\n* Gentoo: `emerge dev-libs/spdlog`\r\n* Arch Linux: `pacman -S spdlog`\r\n* openSUSE: `sudo zypper in spdlog-devel`\r\n* ALT Linux: `apt-get install libspdlog-devel`\r\n* vcpkg: `vcpkg install spdlog`\r\n* conan: `conan install --requires=spdlog/[*]`\r\n* conda: `conda install -c conda-forge spdlog`\r\n* build2: ```depends: spdlog ^1.8.2```\r\n\r\n\r\n## Features\r\n* Very fast (see [benchmarks](#benchmarks) below).\r\n* Headers only or compiled\r\n* Feature-rich formatting, using the excellent [fmt](https://github.com/fmtlib/fmt) library.\r\n* Asynchronous mode (optional)\r\n* [Custom](https://github.com/gabime/spdlog/wiki/Custom-formatting) formatting.\r\n* Multi/Single threaded loggers.\r\n* Various log targets:\r\n  * Rotating log files.\r\n  * Daily log files.\r\n  * Console logging (colors supported).\r\n  * syslog.\r\n  * Windows event log.\r\n  * Windows debugger (```OutputDebugString(..)```).\r\n  * Log to Qt widgets ([example](#log-to-qt-with-nice-colors)).\r\n  * Easily [extendable](https://github.com/gabime/spdlog/wiki/Sinks#implementing-your-own-sink) with custom log targets.\r\n* Log filtering - log levels can be modified at runtime as well as compile time.\r\n* Support for loading log levels from argv or environment var.\r\n* [Backtrace](#backtrace-support) support - store debug messages in a ring buffer and display them later on demand.\r\n\r\n## Usage samples\r\n\r\n#### Basic usage\r\n```c++\r\n#include \"spdlog/spdlog.h\"\r\n\r\nint main() \r\n{\r\n    spdlog::info(\"Welcome to spdlog!\");\r\n    spdlog::error(\"Some error message with arg: {}\", 1);\r\n    \r\n    spdlog::warn(\"Easy padding in numbers like {:08d}\", 12);\r\n    spdlog::critical(\"Support for int: {0:d};  hex: {0:x};  oct: {0:o}; bin: {0:b}\", 42);\r\n    spdlog::info(\"Support for floats {:03.2f}\", 1.23456);\r\n    spdlog::info(\"Positional args are {1} {0}..\", \"too\", \"supported\");\r\n    spdlog::info(\"{:<30}\", \"left aligned\");\r\n    \r\n    spdlog::set_level(spdlog::level::debug); // Set *global* log level to debug\r\n    spdlog::debug(\"This message should be displayed..\");    \r\n    \r\n    // change log pattern\r\n    spdlog::set_pattern(\"[%H:%M:%S %z] [%n] [%^---%L---%$] [thread %t] %v\");\r\n    \r\n    // Compile time log levels\r\n    // Note that this does not change the current log level, it will only\r\n    // remove (depending on SPDLOG_ACTIVE_LEVEL) the call on the release code.\r\n    SPDLOG_TRACE(\"Some trace message with param {}\", 42);\r\n    SPDLOG_DEBUG(\"Some debug message\");\r\n}\r\n\r\n```\r\n---\r\n#### Create stdout/stderr logger object\r\n```c++\r\n#include \"spdlog/spdlog.h\"\r\n#include \"spdlog/sinks/stdout_color_sinks.h\"\r\nvoid stdout_example()\r\n{\r\n    // create a color multi-threaded logger\r\n    auto console = spdlog::stdout_color_mt(\"console\");    \r\n    auto err_logger = spdlog::stderr_color_mt(\"stderr\");    \r\n    spdlog::get(\"console\")->info(\"loggers can be retrieved from a global registry using the spdlog::get(logger_name)\");\r\n}\r\n```\r\n\r\n---\r\n#### Basic file logger\r\n```c++\r\n#include \"spdlog/sinks/basic_file_sink.h\"\r\nvoid basic_logfile_example()\r\n{\r\n    try \r\n    {\r\n        auto logger = spdlog::basic_logger_mt(\"basic_logger\", \"logs/basic-log.txt\");\r\n    }\r\n    catch (const spdlog::spdlog_ex &ex)\r\n    {\r\n        std::cout << \"Log init failed: \" << ex.what() << std::endl;\r\n    }\r\n}\r\n```\r\n---\r\n#### Rotating files\r\n```c++\r\n#include \"spdlog/sinks/rotating_file_sink.h\"\r\nvoid rotating_example()\r\n{\r\n    // Create a file rotating logger with 5 MB size max and 3 rotated files\r\n    auto max_size = 1048576 * 5;\r\n    auto max_files = 3;\r\n    auto logger = spdlog::rotating_logger_mt(\"some_logger_name\", \"logs/rotating.txt\", max_size, max_files);\r\n}\r\n```\r\n\r\n---\r\n#### Daily files\r\n```c++\r\n\r\n#include \"spdlog/sinks/daily_file_sink.h\"\r\nvoid daily_example()\r\n{\r\n    // Create a daily logger - a new file is created every day at 2:30 am\r\n    auto logger = spdlog::daily_logger_mt(\"daily_logger\", \"logs/daily.txt\", 2, 30);\r\n}\r\n\r\n```\r\n\r\n---\r\n#### Backtrace support\r\n```c++\r\n// Debug messages can be stored in a ring buffer instead of being logged immediately.\r\n// This is useful to display debug logs only when needed (e.g. when an error happens).\r\n// When needed, call dump_backtrace() to dump them to your log.\r\n\r\nspdlog::enable_backtrace(32); // Store the latest 32 messages in a buffer. \r\n// or my_logger->enable_backtrace(32)..\r\nfor(int i = 0; i < 100; i++)\r\n{\r\n  spdlog::debug(\"Backtrace message {}\", i); // not logged yet..\r\n}\r\n// e.g. if some error happened:\r\nspdlog::dump_backtrace(); // log them now! show the last 32 messages\r\n// or my_logger->dump_backtrace(32)..\r\n```\r\n\r\n---\r\n#### Periodic flush\r\n```c++\r\n// periodically flush all *registered* loggers every 3 seconds:\r\n// warning: only use if all your loggers are thread-safe (\"_mt\" loggers)\r\nspdlog::flush_every(std::chrono::seconds(3));\r\n\r\n```\r\n\r\n---\r\n#### Stopwatch\r\n```c++\r\n// Stopwatch support for spdlog\r\n#include \"spdlog/stopwatch.h\"\r\nvoid stopwatch_example()\r\n{\r\n    spdlog::stopwatch sw;    \r\n    spdlog::debug(\"Elapsed {}\", sw);\r\n    spdlog::debug(\"Elapsed {:.3}\", sw);       \r\n}\r\n\r\n```\r\n\r\n---\r\n#### Log binary data in hex\r\n```c++\r\n// many types of std::container<char> types can be used.\r\n// ranges are supported too.\r\n// format flags:\r\n// {:X} - print in uppercase.\r\n// {:s} - don't separate each byte with space.\r\n// {:p} - don't print the position on each line start.\r\n// {:n} - don't split the output into lines.\r\n// {:a} - show ASCII if :n is not set.\r\n\r\n#include \"spdlog/fmt/bin_to_hex.h\"\r\n\r\nvoid binary_example()\r\n{\r\n    auto console = spdlog::get(\"console\");\r\n    std::array<char, 80> buf;\r\n    console->info(\"Binary example: {}\", spdlog::to_hex(buf));\r\n    console->info(\"Another binary example:{:n}\", spdlog::to_hex(std::begin(buf), std::begin(buf) + 10));\r\n    // more examples:\r\n    // logger->info(\"uppercase: {:X}\", spdlog::to_hex(buf));\r\n    // logger->info(\"uppercase, no delimiters: {:Xs}\", spdlog::to_hex(buf));\r\n    // logger->info(\"uppercase, no delimiters, no position info: {:Xsp}\", spdlog::to_hex(buf));\r\n}\r\n\r\n```\r\n\r\n---\r\n#### Logger with multi sinks - each with a different format and log level\r\n```c++\r\n\r\n// create a logger with 2 targets, with different log levels and formats.\r\n// The console will show only warnings or errors, while the file will log all. \r\nvoid multi_sink_example()\r\n{\r\n    auto console_sink = std::make_shared<spdlog::sinks::stdout_color_sink_mt>();\r\n    console_sink->set_level(spdlog::level::warn);\r\n    console_sink->set_pattern(\"[multi_sink_example] [%^%l%$] %v\");\r\n\r\n    auto file_sink = std::make_shared<spdlog::sinks::basic_file_sink_mt>(\"logs/multisink.txt\", true);\r\n    file_sink->set_level(spdlog::level::trace);\r\n\r\n    spdlog::logger logger(\"multi_sink\", {console_sink, file_sink});\r\n    logger.set_level(spdlog::level::debug);\r\n    logger.warn(\"this should appear in both console and file\");\r\n    logger.info(\"this message should not appear in the console, only in the file\");\r\n}\r\n```\r\n\r\n---\r\n#### Register several loggers - change global level\r\n```c++\r\n\r\n// Creation of loggers. Set levels to all registered loggers. \r\nvoid set_level_example()\r\n{\r\n    auto logger1 = spdlog::basic_logger_mt(\"logger1\", \"logs/logger1.txt\");\r\n    auto logger2 = spdlog::basic_logger_mt(\"logger2\", \"logs/logger2.txt\");\r\n\r\n    spdlog::set_default_logger(logger2);\r\n    spdlog::default_logger()->set_level(spdlog::level::trace); // set level for the default logger (logger2) to trace\r\n\r\n    spdlog::trace(\"trace message to the logger2 (specified as default)\");\r\n\r\n    spdlog::set_level(spdlog::level::off) // (sic!) set level for *all* registered loggers to off (disable)\r\n  \r\n    logger1.warn(\"warn message will not appear because the level set to off\");\r\n    logger2.warn(\"warn message will not appear because the level set to off\");\r\n    spdlog::warn(\"warn message will not appear because the level set to off\");\r\n}\r\n```\r\n\r\n---\r\n#### User-defined callbacks about log events\r\n```c++\r\n\r\n// create a logger with a lambda function callback, the callback will be called\r\n// each time something is logged to the logger\r\nvoid callback_example()\r\n{\r\n    auto callback_sink = std::make_shared<spdlog::sinks::callback_sink_mt>([](const spdlog::details::log_msg &msg) {\r\n         // for example you can be notified by sending an email to yourself\r\n    });\r\n    callback_sink->set_level(spdlog::level::err);\r\n\r\n    auto console_sink = std::make_shared<spdlog::sinks::stdout_color_sink_mt>();\r\n    spdlog::logger logger(\"custom_callback_logger\", {console_sink, callback_sink});\r\n\r\n    logger.info(\"some info log\");\r\n    logger.error(\"critical issue\"); // will notify you\r\n}\r\n```\r\n\r\n---\r\n#### Asynchronous logging\r\n```c++\r\n#include \"spdlog/async.h\"\r\n#include \"spdlog/sinks/basic_file_sink.h\"\r\nvoid async_example()\r\n{\r\n    // default thread pool settings can be modified *before* creating the async logger:\r\n    // spdlog::init_thread_pool(8192, 1); // queue with 8k items and 1 backing thread.\r\n    auto async_file = spdlog::basic_logger_mt<spdlog::async_factory>(\"async_file_logger\", \"logs/async_log.txt\");\r\n    // alternatively:\r\n    // auto async_file = spdlog::create_async<spdlog::sinks::basic_file_sink_mt>(\"async_file_logger\", \"logs/async_log.txt\");   \r\n}\r\n\r\n```\r\n\r\n---\r\n#### Asynchronous logger with multi sinks\r\n```c++\r\n#include \"spdlog/async.h\"\r\n#include \"spdlog/sinks/stdout_color_sinks.h\"\r\n#include \"spdlog/sinks/rotating_file_sink.h\"\r\n\r\nvoid multi_sink_example2()\r\n{\r\n    spdlog::init_thread_pool(8192, 1);\r\n    auto stdout_sink = std::make_shared<spdlog::sinks::stdout_color_sink_mt >();\r\n    auto rotating_sink = std::make_shared<spdlog::sinks::rotating_file_sink_mt>(\"mylog.txt\", 1024*1024*10, 3);\r\n    std::vector<spdlog::sink_ptr> sinks {stdout_sink, rotating_sink};\r\n    auto logger = std::make_shared<spdlog::async_logger>(\"loggername\", sinks.begin(), sinks.end(), spdlog::thread_pool(), spdlog::async_overflow_policy::block);\r\n    spdlog::register_logger(logger);\r\n}\r\n```\r\n \r\n---\r\n#### User-defined types\r\n```c++\r\ntemplate<>\r\nstruct fmt::formatter<my_type> : fmt::formatter<std::string>\r\n{\r\n    auto format(my_type my, format_context &ctx) const -> decltype(ctx.out())\r\n    {\r\n        return fmt::format_to(ctx.out(), \"[my_type i={}]\", my.i);\r\n    }\r\n};\r\n\r\nvoid user_defined_example()\r\n{\r\n    spdlog::info(\"user defined type: {}\", my_type(14));\r\n}\r\n\r\n```\r\n\r\n---\r\n#### User-defined flags in the log pattern\r\n```c++ \r\n// Log patterns can contain custom flags.\r\n// the following example will add new flag '%*' - which will be bound to a <my_formatter_flag> instance.\r\n#include \"spdlog/pattern_formatter.h\"\r\nclass my_formatter_flag : public spdlog::custom_flag_formatter\r\n{\r\npublic:\r\n    void format(const spdlog::details::log_msg &, const std::tm &, spdlog::memory_buf_t &dest) override\r\n    {\r\n        std::string some_txt = \"custom-flag\";\r\n        dest.append(some_txt.data(), some_txt.data() + some_txt.size());\r\n    }\r\n\r\n    std::unique_ptr<custom_flag_formatter> clone() const override\r\n    {\r\n        return spdlog::details::make_unique<my_formatter_flag>();\r\n    }\r\n};\r\n\r\nvoid custom_flags_example()\r\n{    \r\n    auto formatter = std::make_unique<spdlog::pattern_formatter>();\r\n    formatter->add_flag<my_formatter_flag>('*').set_pattern(\"[%n] [%*] [%^%l%$] %v\");\r\n    spdlog::set_formatter(std::move(formatter));\r\n}\r\n\r\n```\r\n\r\n---\r\n#### Custom error handler\r\n```c++\r\nvoid err_handler_example()\r\n{\r\n    // can be set globally or per logger(logger->set_error_handler(..))\r\n    spdlog::set_error_handler([](const std::string &msg) { spdlog::get(\"console\")->error(\"*** LOGGER ERROR ***: {}\", msg); });\r\n    spdlog::get(\"console\")->info(\"some invalid message to trigger an error {}{}{}{}\", 3);\r\n}\r\n\r\n```\r\n\r\n---\r\n#### syslog\r\n```c++\r\n#include \"spdlog/sinks/syslog_sink.h\"\r\nvoid syslog_example()\r\n{\r\n    std::string ident = \"spdlog-example\";\r\n    auto syslog_logger = spdlog::syslog_logger_mt(\"syslog\", ident, LOG_PID);\r\n    syslog_logger->warn(\"This is warning that will end up in syslog.\");\r\n}\r\n```\r\n---\r\n#### Android example\r\n```c++\r\n#include \"spdlog/sinks/android_sink.h\"\r\nvoid android_example()\r\n{\r\n    std::string tag = \"spdlog-android\";\r\n    auto android_logger = spdlog::android_logger_mt(\"android\", tag);\r\n    android_logger->critical(\"Use \\\"adb shell logcat\\\" to view this message.\");\r\n}\r\n```\r\n\r\n---\r\n#### Load log levels from the env variable or argv\r\n\r\n```c++\r\n#include \"spdlog/cfg/env.h\"\r\nint main (int argc, char *argv[])\r\n{\r\n    spdlog::cfg::load_env_levels();\r\n    // or specify the env variable name:\r\n    // MYAPP_LEVEL=info,mylogger=trace && ./example\r\n    // spdlog::cfg::load_env_levels(\"MYAPP_LEVEL\");\r\n    // or from the command line:\r\n    // ./example SPDLOG_LEVEL=info,mylogger=trace\r\n    // #include \"spdlog/cfg/argv.h\" // for loading levels from argv\r\n    // spdlog::cfg::load_argv_levels(argc, argv);\r\n}\r\n```\r\nSo then you can:\r\n\r\n```console\r\n$ export SPDLOG_LEVEL=info,mylogger=trace\r\n$ ./example\r\n```\r\n\r\n\r\n---\r\n#### Log file open/close event handlers\r\n```c++\r\n// You can get callbacks from spdlog before/after a log file has been opened or closed. \r\n// This is useful for cleanup procedures or for adding something to the start/end of the log file.\r\nvoid file_events_example()\r\n{\r\n    // pass the spdlog::file_event_handlers to file sinks for open/close log file notifications\r\n    spdlog::file_event_handlers handlers;\r\n    handlers.before_open = [](spdlog::filename_t filename) { spdlog::info(\"Before opening {}\", filename); };\r\n    handlers.after_open = [](spdlog::filename_t filename, std::FILE *fstream) { fputs(\"After opening\\n\", fstream); };\r\n    handlers.before_close = [](spdlog::filename_t filename, std::FILE *fstream) { fputs(\"Before closing\\n\", fstream); };\r\n    handlers.after_close = [](spdlog::filename_t filename) { spdlog::info(\"After closing {}\", filename); };\r\n    auto my_logger = spdlog::basic_logger_st(\"some_logger\", \"logs/events-sample.txt\", true, handlers);        \r\n}\r\n```\r\n\r\n---\r\n#### Replace the Default Logger\r\n```c++\r\nvoid replace_default_logger_example()\r\n{\r\n    auto new_logger = spdlog::basic_logger_mt(\"new_default_logger\", \"logs/new-default-log.txt\", true);\r\n    spdlog::set_default_logger(new_logger);\r\n    spdlog::info(\"new logger log message\");\r\n}\r\n```\r\n\r\n---\r\n#### Log to Qt with nice colors\r\n```c++\r\n#include \"spdlog/spdlog.h\"\r\n#include \"spdlog/sinks/qt_sinks.h\"\r\nMainWindow::MainWindow(QWidget *parent) : QMainWindow(parent)\r\n{\r\n    setMinimumSize(640, 480);\r\n    auto log_widget = new QTextEdit(this);\r\n    setCentralWidget(log_widget);\r\n    int max_lines = 500; // keep the text widget to max 500 lines. remove old lines if needed.\r\n    auto logger = spdlog::qt_color_logger_mt(\"qt_logger\", log_widget, max_lines);\r\n    logger->info(\"Some info message\");\r\n}\r\n```\r\n---\r\n\r\n#### Mapped Diagnostic Context\r\n```c++\r\n// Mapped Diagnostic Context (MDC) is a map that stores key-value pairs (string values) in thread local storage.\r\n// Each thread maintains its own MDC, which loggers use to append diagnostic information to log outputs.\r\n// Note: it is not supported in asynchronous mode due to its reliance on thread-local storage.\r\n#include \"spdlog/mdc.h\"\r\nvoid mdc_example()\r\n{\r\n    spdlog::mdc::put(\"key1\", \"value1\");\r\n    spdlog::mdc::put(\"key2\", \"value2\");\r\n    // if not using the default format, use the %& formatter to print mdc data\r\n    // spdlog::set_pattern(\"[%H:%M:%S %z] [%^%L%$] [%&] %v\");\r\n}\r\n```\r\n---\r\n## Benchmarks\r\n\r\nBelow are some [benchmarks](bench/bench.cpp) done in Ubuntu 64 bit, Intel i7-4770 CPU @ 3.40GHz\r\n\r\n#### Synchronous mode\r\n```\r\n[info] **************************************************************\r\n[info] Single thread, 1,000,000 iterations\r\n[info] **************************************************************\r\n[info] basic_st         Elapsed: 0.17 secs        5,777,626/sec\r\n[info] rotating_st      Elapsed: 0.18 secs        5,475,894/sec\r\n[info] daily_st         Elapsed: 0.20 secs        5,062,659/sec\r\n[info] empty_logger     Elapsed: 0.07 secs       14,127,300/sec\r\n[info] **************************************************************\r\n[info] C-string (400 bytes). Single thread, 1,000,000 iterations\r\n[info] **************************************************************\r\n[info] basic_st         Elapsed: 0.41 secs        2,412,483/sec\r\n[info] rotating_st      Elapsed: 0.72 secs        1,389,196/sec\r\n[info] daily_st         Elapsed: 0.42 secs        2,393,298/sec\r\n[info] null_st          Elapsed: 0.04 secs       27,446,957/sec\r\n[info] **************************************************************\r\n[info] 10 threads, competing over the same logger object, 1,000,000 iterations\r\n[info] **************************************************************\r\n[info] basic_mt         Elapsed: 0.60 secs        1,659,613/sec\r\n[info] rotating_mt      Elapsed: 0.62 secs        1,612,493/sec\r\n[info] daily_mt         Elapsed: 0.61 secs        1,638,305/sec\r\n[info] null_mt          Elapsed: 0.16 secs        6,272,758/sec\r\n```\r\n#### Asynchronous mode\r\n```\r\n[info] -------------------------------------------------\r\n[info] Messages     : 1,000,000\r\n[info] Threads      : 10\r\n[info] Queue        : 8,192 slots\r\n[info] Queue memory : 8,192 x 272 = 2,176 KB \r\n[info] -------------------------------------------------\r\n[info] \r\n[info] *********************************\r\n[info] Queue Overflow Policy: block\r\n[info] *********************************\r\n[info] Elapsed: 1.70784 secs     585,535/sec\r\n[info] Elapsed: 1.69805 secs     588,910/sec\r\n[info] Elapsed: 1.7026 secs      587,337/sec\r\n[info] \r\n[info] *********************************\r\n[info] Queue Overflow Policy: overrun\r\n[info] *********************************\r\n[info] Elapsed: 0.372816 secs    2,682,285/sec\r\n[info] Elapsed: 0.379758 secs    2,633,255/sec\r\n[info] Elapsed: 0.373532 secs    2,677,147/sec\r\n\r\n```\r\n\r\n## Documentation\r\n\r\nDocumentation can be found in the [wiki](https://github.com/gabime/spdlog/wiki) pages.\r\n\r\n---\r\n\r\n### Powered by\r\n<a href=\"https://jb.gg/OpenSource\">\r\n  <img src=\"https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg\" alt=\"JetBrains logo\" width=\"200\">\r\n</a>\r\n",
      "stars_today": 5
    },
    {
      "id": 70198664,
      "name": "lottie-ios",
      "full_name": "airbnb/lottie-ios",
      "description": "An iOS library to natively render After Effects vector animations",
      "html_url": "https://github.com/airbnb/lottie-ios",
      "stars": 26633,
      "forks": 3828,
      "language": "Swift",
      "topics": [
        "animation",
        "bodymovin",
        "custom-transitions",
        "ios",
        "ios-animation",
        "ios-transition",
        "keyframes",
        "swift",
        "transition-animation"
      ],
      "created_at": "2016-10-06T22:38:38Z",
      "updated_at": "2026-01-24T20:29:03Z",
      "pushed_at": "2026-01-24T16:39:29Z",
      "open_issues": 45,
      "owner": {
        "login": "airbnb",
        "avatar_url": "https://avatars.githubusercontent.com/u/698437?v=4"
      },
      "readme": "# Lottie for iOS\n [![Version](https://img.shields.io/cocoapods/v/lottie-ios.svg?style=flat)](https://cocoapods.org/pods/lottie-ios) [![Carthage Compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage) [![SwiftPM](https://img.shields.io/badge/SPM-supported-DE5C43.svg?style=flat)](https://swift.org/package-manager/) [![License](https://img.shields.io/cocoapods/l/lottie-ios.svg?style=flat)](https://cocoapods.org/pods/lottie-ios) [![Platform](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/airbnb/lottie-ios) [![Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/airbnb/lottie-ios)\n\n**View documentation, FAQ, help, examples, and more at [airbnb.io/lottie](https://airbnb.io/lottie/)**\n\nLottie is a cross-platform library for iOS, macOS, tvOS, visionOS, [Android](https://github.com/airbnb/lottie-android), and [Web](https://github.com/airbnb/lottie-web) that natively renders vector-based animations and art in realtime with minimal code.\n\nLottie loads and renders animations and vectors exported in the bodymovin JSON format. Bodymovin JSON can be created and exported from After Effects with [bodymovin](https://github.com/bodymovin/bodymovin), Sketch with [Lottie Sketch Export](https://github.com/buba447/Lottie-Sketch-Export), and from [Haiku](https://www.haikuanimator.com).\n\nDesigners can create **and ship** beautiful animations without an engineer painstakingly recreating them by hand.\nSince the animations are backed by JSON, they are extremely small in size but can be large in complexity!\nAnimations can be played, resized, looped, sped up, slowed down, reversed, and even interactively scrubbed.\nLottie can play or loop just a portion of the animation as well, the possibilities are endless!\nAnimations can even be ***changed at runtime*** in various ways! Change the color, position, or any keyframable value!\n\nHere is just a small sampling of the power of Lottie\n\n![Example1](_Gifs/Examples1.gif)\n![Example2](_Gifs/Examples2.gif)\n\n<img src=\"_Gifs/Community 2_3.gif\" />\n\n![Example3](_Gifs/Examples3.gif)\n\n![Abcs](_Gifs/Examples4.gif)\n\n## Installing Lottie\nLottie supports [Swift Package Manager](https://www.swift.org/package-manager/), [CocoaPods](https://cocoapods.org/), and [Carthage](https://github.com/Carthage/Carthage) (Both dynamic and static).\n\n### Github Repo\n\nYou can pull the [Lottie Github Repo](https://github.com/airbnb/lottie-ios/) and include the `Lottie.xcodeproj` to build a dynamic or static library.\n\n### Swift Package Manager\n\nTo install Lottie using [Swift Package Manager](https://github.com/swiftlang/swift-package-manager) you can follow the [tutorial published by Apple](https://developer.apple.com/documentation/xcode/adding_package_dependencies_to_your_app) using the URL for the Lottie repo with the current version:\n\n1. In Xcode, select â€œFileâ€ â†’ â€œAdd Packages...â€\n1. Enter https://github.com/airbnb/lottie-spm.git\n\nor you can add the following dependency to your `Package.swift`:\n\n```swift\n.package(url: \"https://github.com/airbnb/lottie-spm.git\", from: \"4.5.2\")\n```\n\nWhen using Swift Package Manager we recommend using the [lottie-spm](https://github.com/airbnb/lottie-spm) repo instead of the main lottie-ios repo.  The main git repository for [lottie-ios](https://github.com/airbnb/lottie-ios) is somewhat large (300+ MB), and Swift Package Manager always downloads the full repository with all git history. The [lottie-spm](https://github.com/airbnb/lottie-spm) repo is much smaller (less than 500kb), so can be downloaded much more quickly. \n\nInstead of downloading the full git history of Lottie and building it from source, the lottie-spm repo just contains a pointer to the precompiled XCFramework included in the [latest lottie-ios release](https://github.com/airbnb/lottie-ios/releases/latest) (typically ~8MB). If you prefer to include Lottie source directly your project, you can directly depend on the main lottie-ios repo by referencing `https://github.com/airbnb/lottie-ios.git` instead.\n\n### CocoaPods\nAdd the pod to your Podfile:\n```ruby\npod 'lottie-ios'\n```\n\nAnd then run:\n```ruby\npod install\n```\nAfter installing the cocoapod into your project import Lottie with\n```swift\nimport Lottie\n```\n\n### Carthage\nAdd Lottie to your Cartfile:\n```\ngithub \"airbnb/lottie-ios\" \"master\"\n```\n\nAnd then run:\n```\ncarthage update\n```\nIn your application targets â€œGeneralâ€ tab under the â€œLinked Frameworks and Librariesâ€ section, drag and drop lottie-ios.framework from the Carthage/Build/iOS directory that `carthage update` produced.\n\n## Swift Version Support\n\nLottie supports Swift / Xcode versions back to the minimum version that is permitted by Apple for submissions to the App Store. You can see the most up-to-date information for which Swift versions Lottie supports on [Swift Package Index](https://swiftpackageindex.com/airbnb/lottie-ios):\n\n[![Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fairbnb%2Flottie-ios%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/airbnb/lottie-ios)\n\n## Privacy\n\nLottie does not collect any data. We provide this notice to help you fill out [App Privacy Details](https://developer.apple.com/app-store/app-privacy-details/). We additionally provide a [privacy manifest](https://github.com/airbnb/lottie-ios/blob/master/Sources/PrivacyInfo.xcprivacy) which can be included in your app.\n\n## Security\n\nWe distribute XCFramework bundles for each release on [GitHub](https://github.com/airbnb/lottie-ios/releases/latest). In Lottie 4.4.0 and later, these XCFramework bundles include a [code signature](https://developer.apple.com/documentation/xcode/verifying-the-origin-of-your-xcframeworks). These bundles are self-signed under the name \"Lottie iOS\" and have the following fingerprint:\n\n```\n89 2F 1B 43 04 7B 50 53 8F 2F 46 EA D9 29 00 DD 3D 48 11 F358 21 78 C0 61 A5 FB 20 F1 11 CB 26\n```\n\nIn Xcode you can verify this by selecting `Lottie.xcframework` and confirming that it shows the following information:\n\n![Code Signature in Xcode](_Gifs/code_signature.png)\n\n## Contributing\n\nWe always appreciate contributions from the community. To make changes to the project, you can clone the repo and open `Lottie.xcworkspace`. This workspace includes:\n - the Lottie framework (for iOS, macOS, and tvOS)\n - unit tests and snapshot tests (for iOS, must be run on an iPhone 8 simulator)\n - an Example iOS app that lets you browse and test over 100 sample animations included in the repo\n\nAll pull requests with new features or bug fixes that affect how animations render should include snapshot test cases that validate the included changes. \n  - To add a new sample animation to the snapshot testing suite, you can add the `.json` file to `Tests/Samples`. Re-run the snapshot tests to generate the new snapshot image files.\n  - To update existing snapshots after making changes, you can set `isRecording = true` in `SnapshotTests.swift` `setUp()` method and then re-run the snapshot tests.\n\nThe project also includes several helpful commands defined in our [Rakefile](https://github.com/airbnb/lottie-ios/blob/master/Rakefile). To use these, you need to install [Bundler](https://bundler.io/):\n\n```bash\n$ sudo gem install bundle\n$ bundle install\n```\n\nFor example, all Swift code should be formatted according to the [Airbnb Swift Style Guide](https://github.com/airbnb/swift). After making changes, you can reformat the code automatically using [SwiftFormat](https://github.com/nicklockwood/SwiftFormat) and [SwiftLint](https://github.com/realm/SwiftLint) by running `bundle exec rake format:swift`. Other helpful commands include:\n\n```bash\n$ bundle exec rake build:all # builds all targets for all platforms\n$ bundle exec rake build:package:iOS # builds the Lottie package for iOS\n$ bundle exec rake test:package # tests the Lottie package\n$ bundle exec rake format:swift # reformat Swift code based on the Airbnb Swift Style Guide\n```\n",
      "stars_today": 5
    },
    {
      "id": 253044228,
      "name": "nuclei-templates",
      "full_name": "projectdiscovery/nuclei-templates",
      "description": "Community curated list of templates for the nuclei engine to find security vulnerabilities.",
      "html_url": "https://github.com/projectdiscovery/nuclei-templates",
      "stars": 11835,
      "forks": 3326,
      "language": "JavaScript",
      "topics": [
        "bugbounty",
        "exploit-development",
        "exploits",
        "fingerprint",
        "hacktoberfest",
        "nuclei",
        "nuclei-checks",
        "nuclei-templates",
        "security",
        "vulnerability-detection"
      ],
      "created_at": "2020-04-04T16:21:34Z",
      "updated_at": "2026-01-25T01:32:09Z",
      "pushed_at": "2026-01-25T00:23:19Z",
      "open_issues": 158,
      "owner": {
        "login": "projectdiscovery",
        "avatar_url": "https://avatars.githubusercontent.com/u/50994705?v=4"
      },
      "readme": "\n\n<h1 align=\"center\">\nNuclei Templates\n</h1>\n<h4 align=\"center\">Community curated list of templates for the nuclei engine to find security vulnerabilities in applications.</h4>\n\n\n<p align=\"center\">\n<a href=\"https://github.com/projectdiscovery/nuclei-templates/issues\"><img src=\"https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat\"></a>\n<a href=\"https://github.com/projectdiscovery/nuclei-templates/releases\"><img src=\"https://img.shields.io/github/release/projectdiscovery/nuclei-templates\"></a>\n<a href=\"https://twitter.com/pdnuclei\"><img src=\"https://img.shields.io/twitter/follow/pdnuclei.svg?logo=twitter\"></a>\n<a href=\"https://discord.gg/projectdiscovery\"><img src=\"https://img.shields.io/discord/695645237418131507.svg?logo=discord\"></a>\n</p>\n      \n<p align=\"center\">\n  <a href=\"https://docs.projectdiscovery.io/templates/introduction\">Documentation</a> â€¢\n  <a href=\"#-contributions\">Contributions</a> â€¢\n  <a href=\"#-discussion\">Discussion</a> â€¢\n  <a href=\"#-community\">Community</a> â€¢\n  <a href=\"https://docs.projectdiscovery.io/templates/faq\">FAQs</a> â€¢\n  <a href=\"https://discord.gg/projectdiscovery\">Join Discord</a>\n</p>\n\n----\n\nTemplates are the core of the [nuclei scanner](https://github.com/projectdiscovery/nuclei) which powers the actual scanning engine.\nThis repository stores and houses various templates for the scanner provided by our team, as well as contributed by the community.\nWe hope that you also contribute by sending templates via **pull requests** or [Github issues](https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&labels=&template=submit-template.md&title=%5Bnuclei-template%5D+) to grow the list.\n\n\n## Nuclei Templates overview\n\n\nAn overview of the nuclei template project, including statistics on unique tags, author, directory, severity, and type of templates. The table below contains the top ten statistics for each matrix; an expanded version of this is [available here](TEMPLATES-STATS.md), and also available in [JSON](TEMPLATES-STATS.json) format for integration.\n\n<table>\n<tr>\n<td>\n\n### ğŸš¨ Known Exploited Vulnerabilities (KEV) Coverage\n\nNuclei templates provide coverage for vulnerabilities actively exploited in the wild:\n\n| **KEV Source** | **Templates** | **Description** |\n|----------------|---------------|-----------------|\n| ğŸ”´ **CISA KEV** | **454** | [CISA Known Exploited Vulnerabilities Catalog](https://www.cisa.gov/known-exploited-vulnerabilities-catalog) |\n| ğŸŸ  **VulnCheck KEV** | **1449** | [VulnCheck KEV](https://vulncheck.com/kev) - Enhanced vulnerability intelligence |\n| ğŸŸ¢ **Both Sources** | **407** | Templates covering vulnerabilities in both catalogs |\n\n> ğŸ’¡ **Total unique KEV templates: 1496** - Use `nuclei -tags kev,vkev` to scan for actively exploited vulnerabilities\n\n---\n\n## Nuclei Templates Top 10 statistics\n\n|    TAG    | COUNT |    AUTHOR     | COUNT | DIRECTORY  | COUNT | SEVERITY | COUNT | TYPE | COUNT |\n|-----------|-------|---------------|-------|------------|-------|----------|-------|------|-------|\n| vuln      |  6468 | dhiyaneshdk   |  1894 | http       |  9281 | info     |  4353 | file |   436 |\n| cve       |  3587 | daffainfo     |   905 | cloud      |   659 | high     |  2552 | dns  |    26 |\n| discovery |  3265 | princechaddha |   854 | file       |   436 | medium   |  2457 |      |       |\n| vkev      |  1394 | dwisiswant0   |   805 | network    |   259 | critical |  1555 |      |       |\n| panel     |  1365 | ritikchaddha  |   678 | code       |   251 | low      |   330 |      |       |\n| xss       |  1269 | pussycat0x    |   675 | dast       |   240 | unknown  |    54 |      |       |\n| wordpress |  1261 | pikpikcu      |   353 | workflows  |   205 |          |       |      |       |\n| exposure  |  1141 | pdteam        |   314 | javascript |    92 |          |       |      |       |\n| wp-plugin |  1103 | pdresearch    |   275 | ssl        |    38 |          |       |      |       |\n| osint     |   848 | iamnoooob     |   263 | dns        |    23 |          |       |      |       |\n\n**873 directories, 11997 files**.\n\n</td>\n</tr>\n</table>\n\nğŸ“– Documentation\n-----\n\nPlease navigate to https://nuclei.projectdiscovery.io for detailed documentation to **build** new or your own **custom** templates.\nWe have also added a set of templates to help you understand how things work.\n\nğŸ’ª Contributions\n-----\n\nNuclei-templates is powered by major contributions from the community.\n[Template contributions ](https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&labels=&template=submit-template.md&title=%5Bnuclei-template%5D+), [Feature Requests](https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&labels=&template=feature_request.md&title=%5BFeature%5D+) and [Bug Reports](https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&labels=&template=bug_report.md&title=%5BBug%5D+) are more than welcome.\n\n![Alt](https://repobeats.axiom.co/api/embed/55ee65543bb9a0f9c797626c4e66d472a517d17c.svg \"Repobeats analytics image\")\n\nğŸ’¬ Discussion\n-----\n\nHave questions / doubts / ideas to discuss?\nFeel free to open a discussion on [Github discussions](https://github.com/projectdiscovery/nuclei-templates/discussions) board.\n\nğŸ‘¨â€ğŸ’» Community\n-----\n\nYou are welcome to join the active [Discord Community](https://discord.gg/projectdiscovery) to discuss directly with project maintainers and share things with others around security and automation.\nAdditionally, you may follow us on [Twitter](https://twitter.com/pdnuclei) to be updated on all the things about Nuclei.\n\n\n<p align=\"center\">\n<a href=\"https://github.com/projectdiscovery/nuclei-templates/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=projectdiscovery/nuclei-templates&max=300\">\n</a>\n</p>\n\n\nThanks again for your contribution and keeping this community vibrant. :heart:\n",
      "stars_today": 5
    },
    {
      "id": 334274271,
      "name": "OpenSearch",
      "full_name": "opensearch-project/OpenSearch",
      "description": "ğŸ” Open source distributed and RESTful search engine.",
      "html_url": "https://github.com/opensearch-project/OpenSearch",
      "stars": 12271,
      "forks": 2377,
      "language": "Java",
      "topics": [
        "analytics",
        "apache2",
        "foss",
        "java",
        "search",
        "search-engine"
      ],
      "created_at": "2021-01-29T22:10:00Z",
      "updated_at": "2026-01-25T00:55:54Z",
      "pushed_at": "2026-01-24T04:09:21Z",
      "open_issues": 2530,
      "owner": {
        "login": "opensearch-project",
        "avatar_url": "https://avatars.githubusercontent.com/u/80134844?v=4"
      },
      "readme": "<a href=\"https://opensearch.org/\">\n  <img src=\"https://opensearch.org/assets/img/opensearch-logo-themed.svg\" height=\"64px\">\n</a>\n\n[![License](https://img.shields.io/badge/license-Apache%20v2-blue.svg)](https://github.com/opensearch-project/OpenSearch/blob/main/LICENSE.txt)\n[![LFX Health Score](https://insights.linuxfoundation.org/api/badge/health-score?project=opensearch-foundation)](https://insights.linuxfoundation.org/project/opensearch-foundation)\n[![LFX Active Contributors](https://insights.linuxfoundation.org/api/badge/active-contributors?project=opensearch-foundation)](https://insights.linuxfoundation.org/project/opensearch-foundation)\n[![Code Coverage](https://codecov.io/gh/opensearch-project/OpenSearch/branch/main/graph/badge.svg)](https://codecov.io/gh/opensearch-project/OpenSearch)\n![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/opensearch-project/OpenSearch?sort=semver)\n[![Linkedin](https://img.shields.io/badge/Follow-Linkedin-blue)](https://www.linkedin.com/company/opensearch-project)\n\n- [Welcome!](#welcome)\n- [Project Resources](#project-resources)\n- [Code of Conduct](#code-of-conduct)\n- [Security](#security)\n- [License](#license)\n- [Copyright](#copyright)\n- [Trademark](#trademark)\n\n## Welcome!\n\nOpenSearch is an open-source, enterprise-grade search and observability suite that brings order to unstructured data at scale.\n\n## Project Resources\n\n* [Project Website](https://opensearch.org/)\n* [Downloads](https://opensearch.org/downloads/)\n* [Documentation](https://docs.opensearch.org/)\n* Need help? Try [Forums](https://discuss.opendistrocommunity.dev/) or [Slack](https://opensearch.org/slack/)\n* [Contributing to OpenSearch](CONTRIBUTING.md)\n* [Maintainer Responsibilities](MAINTAINERS.md)\n* [Release Management](RELEASING.md)\n* [Admin Responsibilities](ADMINS.md)\n* [Testing](TESTING.md)\n* [Security](SECURITY.md)\n\n## Code of Conduct\n\nThe project's [Code of Conduct](CODE_OF_CONDUCT.md) outlines our expectations for all participants in our community, based on the [OpenSearch Code of Conduct](https://opensearch.org/code-of-conduct/). Please contact [conduct@opensearch.foundation](mailto:conduct@opensearch.foundation) with any additional questions or comments.\n\n## Security\nIf you discover a potential security issue in this project we ask that you notify OpenSearch Security directly via email to security@opensearch.org. Please do **not** create a public GitHub issue.\n\n## License\n\nThis project is licensed under the [Apache v2.0 License](LICENSE.txt).\n\n## Copyright\n\nCopyright OpenSearch Contributors. See [NOTICE](NOTICE.txt) for details.\n\n## Trademark\n\nOpenSearch is a registered trademark of LF Projects, LLC.\n\nOpenSearch includes certain Apache-licensed Elasticsearch code from Elasticsearch B.V. and other source code. Elasticsearch B.V. is not the source of that other source code. ELASTICSEARCH is a registered trademark of Elasticsearch B.V.\n\n",
      "stars_today": 5
    },
    {
      "id": 127023441,
      "name": "cuda-samples",
      "full_name": "NVIDIA/cuda-samples",
      "description": "Samples for CUDA Developers which demonstrates features in CUDA Toolkit",
      "html_url": "https://github.com/NVIDIA/cuda-samples",
      "stars": 8750,
      "forks": 2249,
      "language": "C",
      "topics": [
        "cuda",
        "cuda-driver-api",
        "cuda-kernels",
        "cuda-opengl"
      ],
      "created_at": "2018-03-27T17:36:24Z",
      "updated_at": "2026-01-24T21:39:38Z",
      "pushed_at": "2026-01-06T17:29:53Z",
      "open_issues": 101,
      "owner": {
        "login": "NVIDIA",
        "avatar_url": "https://avatars.githubusercontent.com/u/1728152?v=4"
      },
      "readme": "# CUDA Samples\n\nSamples for CUDA Developers which demonstrates features in CUDA Toolkit. This version supports [CUDA Toolkit 13.1](https://developer.nvidia.com/cuda-downloads).\n\n## Release Notes\n\nThis section describes the release notes for the CUDA Samples on GitHub only.\n\n### Change Log\n\n### [Revision History](./CHANGELOG.md)\n\n## Getting Started\n\n### Prerequisites\n\nDownload and install the [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads) for your corresponding platform.\nFor system requirements and installation instructions of cuda toolkit, please refer to the [Linux Installation Guide](http://docs.nvidia.com/cuda/cuda-installation-guide-linux/), and the [Windows Installation Guide](http://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html).\n\n### Getting the CUDA Samples\n\nUsing git clone the repository of CUDA Samples using the command below.\n```\ngit clone https://github.com/NVIDIA/cuda-samples.git\n```\n\nWithout using git the easiest way to use these samples is to download the zip file containing the current version by clicking the \"Download ZIP\" button on the repo page. You can then unzip the entire archive and use the samples.\n\n## Building CUDA Samples\n\n### Building CUDA Samples\n\nThe CUDA Samples are built using CMake. Follow the instructions below for building on Linux, Windows, and for cross-compilation to Tegra devices.\n\n### Linux\n\nEnsure that CMake (version 3.20 or later) is installed. Install it using your package manager if necessary:\n\ne.g.\n```sudo apt install cmake```\n\nNavigate to the root of the cloned repository and create a build directory:\n```\nmkdir build && cd build\n```\nConfigure the project with CMake:\n```\ncmake ..\n```\nBuild the samples:\n```\nmake -j$(nproc)\n```\nRun the samples from their respective directories in the build folder. You can also follow this process from and subdirectory of the samples repo, or from within any individual sample.\n\n### Windows\n\nLanguage services for CMake are available in Visual Studio 2019 version 16.5 or later, and you can directly import the CUDA samples repository from either the root level or from any\nsubdirectory or individual sample.\n\nTo build from the command line, open the `x64 Native Tools Command Prompt for VS` provided with your Visual Studio installation.\n\nNavigate to the root of the cloned repository and create a build directory:\n```\nmkdir build && cd build\n```\nConfigure the project with CMake - for example:\n```\ncmake .. -G \"Visual Studio 16 2019\" -A x64\n```\nOpen the generated solution file CUDA_Samples.sln in Visual Studio. Build the samples by selecting the desired configuration (e.g., Debug or Release) and pressing F7 (Build Solution).\n\nRun the samples from the output directories specified in Visual Studio.\n\n### Enabling On-GPU Debugging\n\nNVIDIA GPUs support on-GPU debugging through cuda-gdb. Enabling this may significantly affect application performance as certain compiler optimizations are disabled\nin this configuration, hence it's not on by default. Enablement of on-device debugging is controlled via the `-G` switch to nvcc.\n\nTo enable cuda-gdb for samples builds, define the `ENABLE_CUDA_DEBUG` flag on the CMake command line. For example:\n\n```\ncmake -DENABLE_CUDA_DEBUG=True ...\n```\n\n### Platform-Specific Samples\n\nSome CUDA samples are specific to certain platforms, and require passing flags into CMake to enable. In particular, we define the following platform-specific flags:\n\n* `BUILD_TEGRA` - for Tegra-specific samples\n\nTo build these samples, set the variables either on the command line or through your CMake GUI. For example:\n\n```\ncmake -DBUILD_TEGRA=True ..\n```\n\n### Cross-Compilation for Tegra Platforms\n\nInstall the NVIDIA toolchain and cross-compilation environment for Tegra devices as described in the Tegra Development Guide.\n\nEnsure that CMake (version 3.20 or later) is installed.\n\nNavigate to the root of the cloned repository and create a build directory:\n```\nmkdir build && cd build\n```\nConfigure the project with CMake, specifying the Tegra toolchain file. And you can use -DTARGET_FS to point to the target file system root path for necessary include and library files:\n```\ncmake .. -DCMAKE_TOOLCHAIN_FILE=../cmake/toolchains/toolchain-aarch64-linux.cmake -DTARGET_FS=/path/to/target/system/file/system\n```\nBuild the samples:\n```\nmake -j$(nproc)\n```\nTransfer the built binaries to the Tegra device and execute them there.\n\n\n### Cross Building for Automotive Linux Platforms from the DriveOS Docker containers\n\nTo build CUDA samples to the target platform from the DriveOS Docker containers, use the following instructions.\n\nMount the target Root Filesystem (RFS) in the container so that the CUDA cmake process has the correct paths to CUDA and other system libraries required to build the samples.\n\nCreate a temporary directory, `<temp>` is any temporary directory of your choosing, for example, you can use `/drive/temp`:\n\n```\n$ mkdir /drive/<temp>\n```\n\nMount the filesystem by running the following command:\n\n```\n$ mount /drive/drive-linux/filesystem/targetfs-images/dev_nsr_desktop_ubuntu-24.04_thor_rfs.img /drive/temp\n```\n\nConfigure the project by running the following cmake command:\n\n```\n$ mkdir build && cd build\n$ cmake .. -DBUILD_TEGRA=True \\\n  -DCMAKE_CUDA_COMPILER=/usr/local/cuda/bin/nvcc \\\n  -DCMAKE_TOOLCHAIN_FILE=../cmake/toolchains/toolchain-aarch64-linux.cmake \\\n  -DTARGET_FS=/drive/temp \\\n  -DCMAKE_LIBRARY_PATH=/drive/temp/usr/local/cuda-13.1/thor/lib64/ \\\n  -DCMAKE_INCLUDE_PATH=/drive/temp/usr/local/cuda-13.1/thor/include/\n```\n\nPlease note that the following libraries are not pre-installed in the DriveOS dev-nsr target filesystem:\n* libdrm-dev\n* Vulkan\n\nThis causes the cmake command to throw errors related to the missing files, and as a result, the related samples will not build in later steps. This issue will be addressed in a future DriveOS release.\n\nTo build the samples with ignore the error mentioned above, you can use `--ignore-errors`/`--keep-going` or comment out the comment out the corresponding `add_subdirectory` command in the CMakeLists.txt in the parent folder for the samples requiring Vulkan and libdrm_dev:\n\n```\n$ make -j$(nproc) --ignore-errors # or --keep-going\n```\n\n```\n# In Samples/5_Domain_Specific/CMakeList.txt\n# add_subdirectory(simpleGL)\n# add_subdirectory(simpleVulkan)\n# add_subdirectory(simpleVulkanMMAP)\n\n# In Samples/8_Platform_Specific/Tegra/CMakeList.txt\n# add_subdirectory(simpleGLES_EGLOutput)\n```\n\n### QNX\n\nCross-compilation for QNX with CMake is supported in the CUDA 13.0 samples release and newer. An example build for\nthe Tegra Thor QNX platform might look like this:\n\n```\n$ mkdir build\n$ cd build\n\nQNX_HOST=/path/to/qnx/host \\\nQNX_TARGET=/path/to/qnx/target \\\ncmake .. \\\n-DBUILD_TEGRA=True \\\n-DCMAKE_CUDA_COMPILER=/usr/local/cuda-safe-13.0/bin/nvcc \\\n-DCMAKE_TOOLCHAIN_FILE=../cmake/toolchains/toolchain-aarch64-qnx.cmake \\\n-DCMAKE_LIBRARY_PATH=/usr/local/cuda-safe-13.0/thor/targets/aarch64-qnx/lib/stubs/ \\\n-DCMAKE_INCLUDE_PATH=/usr/local/cuda-safe-13.0/thor/targets/aarch64-qnx/include/\n```\n\n### Forward Compatibility\n\nTo build samples with new CUDA Toolkit(CUDA 13.0 or later) and UMD(Version 580 or later) and old KMD(Version 550 or earlier)ï¼Œyou need to set the `CMAKE_PREFIX_PATH` for using new driver library, the command might like this:\n\n```\ncmake -DCMAKE_PREFIX_PATH=/usr/local/cuda/lib64/stubs/ ..\n```\n\n## Install Samples\n\n### Installation Path Structure\n\nThe installation system automatically organizes samples into a structured directory layout based on:\n- **Target Architecture**: ${CMAKE_SYSTEM_PROCESSOR}, e.g. `x64`, `aarch64`, `amd64`, etc.\n- **Target OS**: `linux`, `windows`, `darwin`, `qnx`\n- **Build Type**: `release`, `debug`, etc.\n\nThe default installation path is: `build/bin/${TARGET_ARCH}/${TARGET_OS}/${BUILD_TYPE}`\n\n**Examples:**\n- Linux x86_64 Release: `build/bin/x64/linux/release`\n- Linux aarch64 Release: `build/bin/aarch64/linux/release`\n- Windows amd64 Release: `build/bin/amd64/windows/release`\n\n### Customizing Installation Paths\n\nYou can customize the installation location using CMake variables during the configuration step:\n\n- `CMAKE_INSTALL_PREFIX`: Changes the root installation directory (default: `build/bin`)\n  ```\n  cmake -DCMAKE_INSTALL_PREFIX=/custom/path ..\n  ```\n  This will install to: `/custom/path/${TARGET_ARCH}/${TARGET_OS}/${BUILD_TYPE}`\n\n- `CUDA_SAMPLES_INSTALL_DIR`: Specifies the exact final installation directory (overrides the structured path)\n  ```\n  cmake -DCUDA_SAMPLES_INSTALL_DIR=/exact/install/path ..\n  ```\n\n### Install Samples on Linux\n\n**Prerequisites:** You must first configure the project with CMake as described in the [Building CUDA Samples - Linux](#linux) or [Building]section.\n\nAfter configuring and building, install the samples:\n\n```\ncd build/\nmake install\n```\n\n### Install Samples on Windows\n\n**Prerequisites:** You must first configure the project with CMake as described in the [Building CUDA Samples - Windows](#windows) section.\n\n#### Using Command Line\n\nAfter configuring with CMake, build and install from the `x64 Native Tools Command Prompt for VS`:\n\n```cmd\ncd build\ncmake --build . --config Release\ncmake --install . --config Release\n```\n\n**Note:** Replace `Release` with `Debug` if you want to install debug builds. For multi-configuration generators (like Visual Studio), the `--config` flag determines which build type to install.\n\n#### Using Visual Studio IDE\n\nAlternatively, open the generated solution file `CUDA_Samples.sln` in Visual Studio:\n1. Select the desired configuration (`Release` or `Debug`)\n2. Build the solution (F7 or Build > Build Solution)\n3. Right-click on the `INSTALL` target under `CMakePredefinedTargets` in Solution Explorer\n4. Select \"Build\"\n\n## Running All Samples as Tests\n\nIt's important to note that the CUDA samples are _not_ intended as a validation suite for CUDA. They do not cover corner cases, they do not completely cover the\nruntime and driver APIs, are not intended for performance benchmarking, etc. That said, it can sometimes be useful to run all of the samples as a quick sanity check and\nwe provide a script to do so, `run_tests.py`.\n\nThis Python3 script finds all executables in a subdirectory you choose, matching application names with command line arguments specified in `test_args.json`. It accepts\nthe following command line arguments:\n\n| Switch     | Purpose                                                                                                        | Example                 |\n| ---------- | -------------------------------------------------------------------------------------------------------------- | ----------------------- |\n| --dir      | Specify the root directory to search for executables (recursively)                                             | --dir ./build/Samples   |\n| --config   | JSON configuration file for executable arguments                                                               | --config test_args.json |\n| --output   | Output directory for test results (stdout saved to .txt files - directory will be created if it doesn't exist) | --output ./test         |\n| --args     | Global arguments to pass to all executables (not currently used)                                               | --args arg_1 arg_2 ...  |\n| --parallel | Number of applications to execute in parallel.                                                                 | --parallel 8            |\n\n\nApplication configurations are loaded from `test_args.json` and matched against executable names (discarding the `.exe` extension on Windows).\n\nThe script returns 0 on success, or the first non-zero error code encountered during testing on failure. It will also print a condensed list of samples that failed, if any.\n\nThere are three primary modes of configuration:\n\n**Skip**\n\nAn executable configured with \"skip\" will not be executed. These generally rely on having attached graphical displays and are not suited to this kind of automation.\n\nConfiguration example:\n```json\n\"fluidsGL\": {\n    \"skip\": true\n}\n```\n\nYou will see:\n```\nSkipping fluidsGL (marked as skip in config)\n```\n\n**Single Run**\n\nFor executables to run one time only with arguments, specify each argument as a list entry. Each entry in the JSON file will be appended to the command line, separated\nby a space.\n\nAll applications execute from their current directory, so all paths are relative to the application's location.\n\nNote that if an application needs no arguments, this entry is optional. An executable found without a matching entry in the JSON will just run as `./application` from its\ncurrent directory.\n\nConfiguration example:\n```json\n\"ptxgen\": {\n    \"args\": [\n        \"test.ll\",\n        \"-arch=compute_75\"\n    ]\n}\n```\n\nYou will see:\n```\nRunning ptxgen\n    Command: ./ptxgen test.ll -arch=compute_75\n    Test completed with return code 0\n```\n\n**Multiple Runs**\n\nFor executables to run multiple times with different command line arguments, specify any number of sets of args within a \"runs\" list.\n\nAs with single runs, all applications execute from their current directory, so all paths are relative to the application's location.\n\nConfiguration example:\n```json\n\"recursiveGaussian\": {\n    \"runs\": [\n        {\n            \"args\": [\n                \"-sigma=10\",\n                \"-file=data/ref_10.ppm\"\n            ]\n        },\n        {\n            \"args\": [\n                \"-sigma=14\",\n                \"-file=data/ref_14.ppm\"\n            ]\n        },\n        {\n            \"args\": [\n                \"-sigma=18\",\n                \"-file=data/ref_18.ppm\"\n            ]\n        },\n        {\n            \"args\": [\n                \"-sigma=22\",\n                \"-file=data/ref_22.ppm\"\n            ]\n        }\n    ]\n}\n```\n\nYou will see:\n```\nRunning recursiveGaussian (run 1/4)\n    Command: ./recursiveGaussian -sigma=10 -file=data/ref_10.ppm\n    Test completed with return code 0\nRunning recursiveGaussian (run 2/4)\n    Command: ./recursiveGaussian -sigma=14 -file=data/ref_14.ppm\n    Test completed with return code 0\nRunning recursiveGaussian (run 3/4)\n    Command: ./recursiveGaussian -sigma=18 -file=data/ref_18.ppm\n    Test completed with return code 0\nRunning recursiveGaussian (run 4/4)\n    Command: ./recursiveGaussian -sigma=22 -file=data/ref_22.ppm\n    Test completed with return code 0\n```\n\n### Example Usage\n\nHere is an example set of commands to build and test all of the samples.\n\nFirst, build:\n```bash\nmkdir build\ncd build\ncmake ..\nmake -j$(nproc)\n```\n\nNow, return to the samples root directory and run the test script:\n```bash\ncd ..\npython3 run_tests.py --output ./test --dir ./build/Samples --config test_args.json\n```\n\nIf all applications run successfully, you will see something similar to this (the specific number of samples will depend on your build type\nand system configuration):\n\n```\nTest Summary:\nRan 199 test runs for 180 executables.\nAll test runs passed!\n```\n\nIf some samples fail, you will see something like this:\n\n```\nTest Summary:\nRan 199 test runs for 180 executables.\nFailed runs (2):\n  bicubicTexture (run 1/5): Failed (code 1)\n  Mandelbrot (run 1/2): Failed (code 1)\n```\n\nYou can inspect the stdout logs in the output directory (generally `APM_<application_name>.txt` or `APM_<application_name>.run<n>.txt`) to help\ndetermine what may have gone wrong from the output logs. Please file issues against the samples repository if you believe a sample is failing\nincorrectly on your system.\n\n## Samples list\n\n### [0. Introduction](./Samples/0_Introduction/README.md)\nBasic CUDA samples for beginners that illustrate key concepts with using CUDA and CUDA runtime APIs.\n\n### [1. Utilities](./Samples/1_Utilities/README.md)\nUtility samples that demonstrate how to query device capabilities and measure GPU/CPU bandwidth.\n\n### [2. Concepts and Techniques](./Samples/2_Concepts_and_Techniques/README.md)\nSamples that demonstrate CUDA related concepts and common problem solving techniques.\n\n### [3. CUDA Features](./Samples/3_CUDA_Features/README.md)\nSamples that demonstrate CUDA Features (Cooperative Groups, CUDA Dynamic Parallelism, CUDA Graphs etc).\n\n### [4. CUDA Libraries](./Samples/4_CUDA_Libraries/README.md)\nSamples that demonstrate how to use CUDA platform libraries (NPP, NVJPEG, NVGRAPH cuBLAS, cuFFT, cuSPARSE, cuSOLVER and cuRAND).\n\n### [5. Domain Specific](./Samples/5_Domain_Specific/README.md)\nSamples that are specific to domain (Graphics, Finance, Image Processing).\n\n### [6. Performance](./Samples/6_Performance/README.md)\nSamples that demonstrate performance optimization.\n\n### [7. libNVVM](./Samples/7_libNVVM/README.md)\nSamples that demonstrate the use of libNVVVM and NVVM IR.\n\n### [8. Platform Specific](./Samples/8_Platform_Specific/Tegra/README.md)\nSamples that are specific to certain platforms (Tegra, cuDLA, NvMedia, NvSci, OpenGL ES).\n\n## Dependencies\n\nSome CUDA Samples rely on third-party applications and/or libraries, or features provided by the CUDA Toolkit and Driver, to either build or execute. These dependencies are listed below.\n\nIf a sample has a third-party dependency that is available on the system, but is not installed, the sample will waive itself at build time.\n\nEach sample's dependencies are listed in its README's Dependencies section.\n\n### Third-Party Dependencies\n\nThese third-party dependencies are required by some CUDA samples. If available, these dependencies are either installed on your system automatically, or are installable via your system's package manager (Linux) or a third-party website.\n\n#### FreeImage\n\nFreeImage is an open source imaging library. FreeImage can usually be installed on Linux using your distribution's package manager system. FreeImage can also be downloaded from the FreeImage website.\n\nTo set up FreeImage on a Windows system, extract the FreeImage DLL distribution into the folder `./Common/FreeImage/Dist/x64` such that it contains the .h and .lib files. Copy the .dll file to the Release/ Debug/ execution folder or pass the FreeImage folder when cmake configuring with the `-DFreeImage_INCLUDE_DIR` and `-DFreeImage_LIBRARY` options.\n\n#### Message Passing Interface\n\nMPI (Message Passing Interface) is an API for communicating data between distributed processes. A MPI compiler can be installed using your Linux distribution's package manager system. It is also available on some online resources, such as [Open MPI](http://www.open-mpi.org/). On Windows, to build and run MPI-CUDA applications one can install [MS-MPI SDK](https://msdn.microsoft.com/en-us/library/bb524831(v=vs.85).aspx).\n\n#### Only 64-Bit\n\nSome samples can only be run on a 64-bit operating system.\n\n#### DirectX\n\nDirectX is a collection of APIs designed to allow development of multimedia applications on Microsoft platforms. For Microsoft platforms, NVIDIA's CUDA Driver supports DirectX. Several CUDA Samples for Windows demonstrates CUDA-DirectX Interoperability, for building such samples one needs to install Microsoft Visual Studio 2012 or higher which provides Microsoft Windows SDK for Windows 8.\n\n#### DirectX12\n\nDirectX 12 is a collection of advanced low-level programming APIs which can reduce driver overhead, designed to allow development of multimedia applications on Microsoft platforms starting with Windows 10 OS onwards. For Microsoft platforms, NVIDIA's CUDA Driver supports DirectX. Few CUDA Samples for Windows demonstrates CUDA-DirectX12 Interoperability, for building such samples one needs to install [Windows 10 SDK or higher](https://developer.microsoft.com/en-us/windows/downloads/windows-10-sdk), with VS 2015 or VS 2017.\n\n#### OpenGL\n\nOpenGL is a graphics library used for 2D and 3D rendering. On systems which support OpenGL, NVIDIA's OpenGL implementation is provided with the CUDA Driver.\n\n#### OpenGL ES\n\nOpenGL ES is an embedded systems graphics library used for 2D and 3D rendering. On systems which support OpenGL ES, NVIDIA's OpenGL ES implementation is provided with the CUDA Driver.\n\n#### Freeglut\n\nFreeglut is an open-source software library that serves as a replacement for the original OpenGL Utility Toolkit (GLUT). Its primary purpose is to make it easier for developers to create and manage windows containing OpenGL contexts, as well as handle input from devices like the mouse, keyboard, and joystick, across a wide range of platforms. To set up Freeglut on a Windowson on ARM system, you need to download the source from [Freeglut website](https://freeglut.sourceforge.net/), build freeglut on your system, and copy the freeglut.lib into the folder `./Common/lib/x64` and copy the freeglut.dll file into the `./bin/win64/${BUILD_TYPE}` execution folder.\n\n#### Vulkan\n\nVulkan is a low-overhead, cross-platform 3D graphics and compute API. Vulkan targets high-performance realtime 3D graphics applications such as video games and interactive media across all platforms. On systems which support Vulkan, NVIDIA's Vulkan implementation is provided with the CUDA Driver. For building and running Vulkan applications one needs to install the [Vulkan SDK](https://www.lunarg.com/vulkan-sdk/).\n\n#### GLEW\n\nGLEW (OpenGL Extension Wrangler Library) is a cross-platform, open-source C/C++ library designed to simplify the process of using modern OpenGL features and extensions. Its main function is to dynamically load OpenGL function pointers at runtime, allowing developers to access both core OpenGL functions and additional features provided by hardware vendors, known as extensions. To set up GLEW on a Windows on ARM system, you need to download the source from [GLEW website](https://glew.sourceforge.net/), build GLEW on your system, and copy the glew32.lib into the folder `./Common/lib/x64` and the glew32.dll into the `./bin/win64/${BUILD_TYPE}` execution folder.\n\n#### GLFW\n\nGLFW is a lightweight, open-source library designed for managing OpenGL, OpenGL ES, and Vulkan contexts. It simplifies the process of creating and managing windows, handling user input (keyboard, mouse, and joystick), and working with multiple monitors in a cross-platform manner.\n\nTo set up GLFW on a Windows system, Download the pre-built binaries from [GLFW website](https://www.glfw.org/download.html) and extract the zip file into the folder, pass the GLFW include header folder as `-DGLFW_INCLUDE_DIR` and lib folder as `-DGLFW_LIB_DIR` for cmake configuring.\n\n#### OpenMP\n\nOpenMP is an API for multiprocessing programming. OpenMP can be installed using your Linux distribution's package manager system. It usually comes preinstalled with GCC. It can also be found at the [OpenMP website](http://openmp.org/). For compilers such as clang, `libomp.so` and other components for LLVM must be installed separated. You will also need to set additional flags in your CMake configuration files, such as: `-DOpenMP_CXX_FLAGS=\"-fopenmp=libomp\" -DOpenMP_CXX_LIB_NAMES=\"omp\" -DOpenMP_omp_LIBRARY=\"/path/to/libomp.so\"`.\n\n#### Screen\n\nScreen is a windowing system found on the QNX operating system. Screen is usually found as part of the root filesystem.\n\n#### X11\n\nX11 is a windowing system commonly found on *-nix style operating systems. X11 can be installed using your Linux distribution's package manager, and comes preinstalled on Mac OS X systems.\n\n#### EGL\n\nEGL is an interface between Khronos rendering APIs (such as OpenGL, OpenGL ES or OpenVG) and the underlying native platform windowing system.\n\n#### EGLOutput\n\nEGLOutput is a set of EGL extensions which allow EGL to render directly to the display.\n\n#### EGLSync\n\nEGLSync is a set of EGL extensions which provides sync objects that are synchronization primitive, representing events whose completion can be tested or waited upon.\n\n#### NVSCI\n\nNvSci is a set of communication interface libraries out of which CUDA interops with NvSciBuf and NvSciSync. NvSciBuf allows applications to allocate and exchange buffers in memory. NvSciSync allows applications to manage synchronization objects which coordinate when sequences of operations begin and end.\n\n#### NvMedia\n\nNvMedia provides powerful processing of multimedia data for true hardware acceleration across NVIDIA Tegra devices. Applications leverage the NvMedia Application Programming Interface (API) to process the image and video data.\n\n### CUDA Features\n\nThese CUDA features are needed by some CUDA samples. They are provided by either the CUDA Toolkit or CUDA Driver. Some features may not be available on your system.\n\n#### CUFFT Callback Routines\n\nCUFFT Callback Routines are user-supplied kernel routines that CUFFT will call when loading or storing data. These callback routines are only available on Linux x86_64 and ppc64le systems.\n\n#### CUDA Dynamic Parallellism\n\nCDP (CUDA Dynamic Parallellism) allows kernels to be launched from threads running on the GPU. CDP is only available on GPUs with SM architecture of 3.5 or above.\n\n#### Multi-block Cooperative Groups\n\nMulti Block Cooperative Groups(MBCG) extends Cooperative Groups and the CUDA programming model to express inter-thread-block synchronization. MBCG is available on GPUs with Pascal and higher architecture.\n\n#### Multi-Device Cooperative Groups\n\n Multi Device Cooperative Groups extends Cooperative Groups and the CUDA programming model enabling thread blocks executing on multiple GPUs to cooperate and synchronize as they execute. This feature is available on GPUs with Pascal and higher architecture.\n\n#### CUBLAS\n\nCUBLAS (CUDA Basic Linear Algebra Subroutines) is a GPU-accelerated version of the BLAS library.\n\n#### CUDA Interprocess Communication\n\nIPC (Interprocess Communication) allows processes to share device pointers.\n\n#### CUFFT\n\nCUFFT (CUDA Fast Fourier Transform) is a GPU-accelerated FFT library.\n\n#### CURAND\n\nCURAND (CUDA Random Number Generation) is a GPU-accelerated RNG library.\n\n#### CUSPARSE\n\nCUSPARSE (CUDA Sparse Matrix) provides linear algebra subroutines used for sparse matrix calculations.\n\n#### CUSOLVER\n\nCUSOLVER library is a high-level package based on the CUBLAS and CUSPARSE libraries. It combines three separate libraries under a single umbrella, each of which can be used independently or in concert with other toolkit libraries. The intent ofCUSOLVER is to provide useful LAPACK-like features, such as common matrix factorization and triangular solve routines for dense matrices, a sparse least-squares solver and an eigenvalue solver. In addition cuSolver provides a new refactorization library useful for solving sequences of matrices with a shared sparsity pattern.\n\n#### NPP\n\nNPP (NVIDIA Performance Primitives) provides GPU-accelerated image, video, and signal processing functions.\n\n#### NVGRAPH\n\nNVGRAPH is a GPU-accelerated graph analytics library.\n\n#### NVJPEG\n\nNVJPEG library provides high-performance, GPU accelerated JPEG decoding functionality for image formats commonly used in deep learning and hyperscale multimedia applications.\n\n#### NVRTC\n\nNVRTC (CUDA RunTime Compilation) is a runtime compilation library for CUDA C++.\n\n#### Stream Priorities\n\nStream Priorities allows the creation of streams with specified priorities. Stream Priorities is only available on GPUs with SM architecture of 3.5 or above.\n\n#### Unified Virtual Memory\n\nUVM (Unified Virtual Memory) enables memory that can be accessed by both the CPU and GPU without explicit copying between the two. UVM is only available on Linux and Windows systems.\n\n#### 16-bit Floating Point\n\nFP16 is a 16-bit floating-point format. One bit is used for the sign, five bits for the exponent, and ten bits for the mantissa.\n\n#### C++11 CUDA\n\nNVCC support of [C++11 features](https://en.wikipedia.org/wiki/C++11).\n\n#### CMake\n\nThe libNVVM samples are built using [CMake](https://cmake.org/) 3.10 or later.\n\n## Contributors Guide\n\nWe welcome your input on issues and suggestions for samples. At this time we are not accepting contributions from the public, check back here as we evolve our contribution model.\n\nWe use Google C++ Style Guide for all the sources https://google.github.io/styleguide/cppguide.html\n\n## Frequently Asked Questions\n\nAnswers to frequently asked questions about CUDA can be found at http://developer.nvidia.com/cuda-faq and in the [CUDA Toolkit Release Notes](http://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html).\n\n## References\n\n*   [CUDA Programming Guide](http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)\n*   [Accelerated Computing Blog](https://developer.nvidia.com/blog/?tags=accelerated-computing)\n\n## Attributions\n\n*   Teapot image is obtained from [Wikimedia](https://en.wikipedia.org/wiki/File:Original_Utah_Teapot.jpg) and is licensed under the Creative Commons [Attribution-Share Alike 2.0](https://creativecommons.org/licenses/by-sa/2.0/deed.en) Generic license. The image is modified for samples use cases.\n",
      "stars_today": 5
    },
    {
      "id": 112542515,
      "name": "cutlass",
      "full_name": "NVIDIA/cutlass",
      "description": "CUDA Templates and Python DSLs for High-Performance Linear Algebra",
      "html_url": "https://github.com/NVIDIA/cutlass",
      "stars": 9161,
      "forks": 1643,
      "language": "C++",
      "topics": [
        "cpp",
        "cuda",
        "deep-learning",
        "deep-learning-library",
        "gpu",
        "nvidia",
        "python"
      ],
      "created_at": "2017-11-30T00:11:24Z",
      "updated_at": "2026-01-25T01:55:21Z",
      "pushed_at": "2026-01-24T16:46:17Z",
      "open_issues": 537,
      "owner": {
        "login": "NVIDIA",
        "avatar_url": "https://avatars.githubusercontent.com/u/1728152?v=4"
      },
      "readme": "![ALT](./media/images/gemm-hierarchy-with-epilogue-no-labels.png \"Complete CUDA GEMM decomposition\")\n# Overview\n\n# CUTLASS 4.4.0\n\n_CUTLASS 4.4.0 - Jan 2026_\n\nCUTLASS is a collection of abstractions for implementing high-performance matrix-matrix multiplication (GEMM)\nand related computations at all levels and scales within CUDA. It incorporates strategies for\nhierarchical decomposition and data movement. CUTLASS decomposes these \"moving parts\" into reusable, modular\nsoftware components and abstractions.\n\nPrimitives for different levels of a conceptual parallelization hierarchy can be specialized and tuned\nvia custom tiling sizes, data types, and other algorithmic policy. The resulting flexibility simplifies\ntheir use as building blocks within custom kernels and applications.\n\nCUTLASS has been providing CUDA C++ template abstractions for high-performance linear algebra since 2017 and\nthese abstractions provide extensive support for a wide range of computations including\nmixed-precision computations, specialized data-movement (async copy) and\nmultiply-accumulate abstractions for FP64, FP32, TF32, FP16, BF16,\n[FP32 emulation via tensor core instruction](https://github.com/NVIDIA/cutlass/tree/main/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm),\n 8b floating point types (e5m2 and e4m3),\n block scaled data types (NVIDIA NVFP4 and OCP standard MXFP4, MXFP6, MXFP8),\n narrow integer types (4 and 8b signed and unsigned integers),\n and binary 1b data types (where architectures allow for the\nnative support of such data types) across NVIDIA's Volta, Turing, Ampere, Ada, Hopper, and Blackwell architectures.\n\nTo this rich ecosystem of C++ based kernel programming abstractions, CUTLASS 4 adds CUTLASS DSLs. These are Python native interfaces for writing high-performance CUDA kernels based on core CUTLASS and CuTe concepts without any performance compromises. This allows for a much smoother learning curve, orders of magnitude faster compile times, native integration with DL frameworks without writing glue code, and much more intuitive metaprogramming that does not require deep C++ expertise.\n\nOverall we envision CUTLASS DSLs as a family of domain-specific languages (DSLs). With the release of 4.0, we are releasing the first of these in CuTe DSL. This is a low level programming model that is fully consistent with CuTe C++ abstractions â€” exposing core concepts such as layouts, tensors, hardware atoms, and full control over the hardware thread and data hierarchy.\n\nCuTe DSL demonstrates optimal matrix multiply and other linear algebra operations\ntargeting the programmable, high-throughput _Tensor Cores_ implemented by\nNVIDIA's Ampere, Hopper, and Blackwell architectures.\n\nWe believe it will become an indispensable tool for students, researchers, and performance\nengineers alike â€” flattening the learning curve of GPU programming, rapidly prototyping kernel\ndesigns, and bringing optimized solutions into production.\n\nCuTe DSL is currently in public beta and will graduate out of beta by end of summer 2025.\n\nTo get started quickly - please refer :\n  - [CUTLASS C++ Quick Start Guide](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/quickstart.html).\n  - [CuTe DSL Quick Start Guide](https://docs.nvidia.com/cutlass/latest/media/docs/pythonDSL/quick_start.html).\n\n# What's New in CUTLASS 4.4\n\n### CuTe DSL\n* New features\n  - Ahead of Time (AoT) compilation is now available!\n    + Refer to files under https://github.com/NVIDIA/cutlass/tree/main/examples/python/CuTeDSL/cute/export for example usage\n  - JAX support - you can now use CuTeDSL along with JAX\n    + Refer to files under https://github.com/NVIDIA/cutlass/tree/main/examples/python/CuTeDSL/jax for example usage\n  - Introduced versioning support in DSL:\n    + cutlass.__version__ for a string representation of DSL version\n    + cutlass.CUDA_VERSION for a version class to tell the CUDA version used for DSL\n  - Added CopyDsmemStoreOp to store data to distributed shared memory with explicit synchronization.\n\n* Bug fixing and improvements\n  - Fixed `cute.printf` with f-string\n  - Fixed an issue that cutlass.cuda.initialize_cuda_context() silently kills python\n\n* API changes\n  - Deprecate get_num_tmem_alloc_cols from blackwell_helpers.py. Use the one from tmem_allocator.py instead.\n  - Deprecate SM100_TMEM_CAPACITY_COLUMNS and SM100_TMEM_MIN_ALLOC_COLUMNS.\n  - LdMatrix16x16x8bOp and StMatrix16x8x8bOp now require explicit transpose=True when calling __init__, to avoid ambiguity in data transposition.\n  - LdMatrix16x16x8bOp copy traits updated to be faithful to PTX without permutations. Permuted variant is renamed to LdMatrix16x8x8bOp.\n  - group_bulk_copy_modes in async bulk copy example is now deprecated, use group_modes directly instead.\n  - cute.arch.calc_packed_f32x2_op default enable ftz to default disable ftz\n\n### CUTLASS C++\n* Add Hopper e2m1 to fp32 optimized conversion and e2m1 * TF32 tensor core GEMM.\n    - Set MmaType to tfloat32_t for FP32 mode.\n    - TF32 provides FP32 inputs with reduced precision (19-bit vs 32-bit)\n    - Set TileShapeK=64 for TF32 (K must be multiple of 8)\n    - Shuffle optimization enabled via `compute_memory_reordering_atom<tfloat32_t>()`\n    - E2M1 -> FP32 -> TF32 TC path for mixed-precision GEMM\n    - Enable [example 55](https://github.com/NVIDIA/cutlass/tree/main/examples/55_hopper_mixed_dtype_gemm) with TF32 support\n* Add [example 93](https://github.com/NVIDIA/cutlass/tree/main/examples/93_blackwell_low_latency_gqa/) for Blackwell low latency generation phase GQA kernel.\n    - Kernel design details please check [Readme](https://github.com/NVIDIA/cutlass/tree/main/examples/93_blackwell_low_latency_gqa/readme.md).\n* Add [example 94](https://github.com/NVIDIA/cutlass/tree/main/examples/94_ada_fp8_blockwise/) for Ada FP8xFP8 -> BF16 GEMM with blockwise dequantization of input matrices in the MMA loop with FP32 accumulation.\n    - Generate additional device/kernel/threadblock files in CUTLASS include directory that add functionality to carry the scaling tensors + use them in MMA loop.\n    - Add gemm_blockwise to include files in [default_mma_core_sm80](https://github.com/NVIDIA/cutlass/tree/main/include/cutlass/gemm/threadblock/default_mma_core_sm80.h)\n* Add Hopper SM90 State Space Decomposition (SSD) kernel in [example 111](https://github.com/NVIDIA/cutlass/tree/main/examples/111_hopper_ssd).\n* Add Blackwell SM100 State Space Decomposition (SSD) kernel in [example 112](https://github.com/NVIDIA/cutlass/tree/main/examples/112_blackwell_ssd).\n* Add support for arbitrary application-provided strides for block-scale tensors.\n    - Users and applications now must pass valid block-scale strides in all cases, even when the tensor is packed.\n* Support 4x blockscaled public ptx for CUDA 13.1.\n* Allow non-static `TmaGbasis` in `AuxTmaParams`.\n    - Some cases in attention kernel may require non-static `tma_gbasis`.\n    - Relax the restriction on `TmaGbasis` parameter of `AuxTmaParams` and users are allowed to manually construct a dynamic gbasis.\n* Fix some kernel issues:\n    - Fix MSVC pre process issue.\n    - Fix a self assign issue in GEMV kernel.\n    - Fix a TMA descriptor bug where the CUDA driver is not properly setting the OOB address gen mode correctly.\n    - Fix memory fence for clc scheduler in Blackwell SM120 pingpong kernel.\n    - Fix missing SMEM alignment in Blackwell SM120 scale factors.\n* Fix some profiler issues:\n    - Refactor L1 functional test generation logic to reduce the L1 test cases to avoid timeout.\n    - Fix a core dump issue for nvfp4 grouped GEMM kernel.\n    - Fix inconsistent GEMM verification logic.\n    - Rework grouped gemm verification logic for different types.\n* Fix some broken links under `media/docs`.\n\nNote: CUTLASS 4.x builds are known to be down on Windows platforms for all CUDA toolkits.\nCUTLASS team is working on a fix.\n\n**See the [CHANGELOG](https://docs.nvidia.com/cutlass/latest/CHANGELOG.html) for details of all past releases and updates.**\n\n# Performance\n\nCUTLASS primitives are very efficient.  When used to construct device-wide GEMM kernels,\nthey exhibit nearly optimal utilization of peak theoretical throughput. The figure below\nshows CUTLASS 3.8's performance as a % of theoretical peak utilization\non various input and output data types when run on NVIDIA Blackwell SM100 architecture GPU.\n\n![ALT](media/images/cutlass-3.8-blackwell-gemm-peak-performance.svg \"\")\n\nThe two figures below show the continual CUTLASS performance improvements\non an [NVIDIA H100](https://www.nvidia.com/en-us/data-center/h100/) (NVIDIA Hopper architecture) since\nCUTLASS 3.1.\nCUTLASS 3.5.1 was compiled with the [CUDA 12.5u1 Toolkit](https://developer.nvidia.com/cuda-downloads).\nTensor Core operations are implemented using CUDA's\n[mma](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-mma) and\n[wgmma](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-instructions) instructions.\n\n![ALT](media/images/cutlass-3.5.1-gemm-peak-performance.png \"\")\n![ALT](media/images/cutlass-3.5.1-gemm-peak-performance-fp8.png \"\")\n\n# CuTe\n\nCUTLASS 3.0 introduced a new core library, CuTe, to describe and manipulate tensors of threads and data.\nCuTe is a collection of C++ CUDA template abstractions for\ndefining and operating on hierarchically multidimensional layouts of threads and data.\nCuTe provides `Layout` and `Tensor` objects that compactly package the type,\nshape, memory space, and layout of data, while performing the complicated indexing for the user.\nThis lets programmers focus on the logical descriptions of their algorithms while\nCuTe does the mechanical bookkeeping for them. With these tools, we can quickly design,\nimplement, and modify all dense linear algebra operations.\n\nThe core abstractions of CuTe are hierarchically multidimensional layouts\nwhich can be composed with data arrays to represent tensors.\nThe representation of layouts is powerful enough to represent nearly\neverything we need to implement efficient dense linear algebra.\nLayouts can also be combined and manipulated via functional composition, on which we build a large set of common operations such as tiling and partitioning.\n\nCUTLASS 3.0 and beyond adopts CuTe throughout the GEMM hierarchy in its templates.\nThis greatly simplifies the design and improves code composability and readability.\nMore documentation specific to CuTe can be found in its\n[dedicated documentation directory](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/cute/00_quickstart.html).\n\n# Compatibility\n\nMinimum requirements:\n\n- Architecture: Volta (compute capability 7.0)\n- Compiler: Must support at least C++17\n- CUDA Toolkit version: 11.4\n\nCUTLASS requires a C++17 host compiler and\nperforms best when built with the [**CUDA 12.8 Toolkit**](https://developer.nvidia.com/cuda-downloads).\nIt is also compatible with CUDA 11.4, CUDA 11.5, CUDA 11.6, CUDA 11.7, CUDA 11.8, and all other CUDA 12.x versions.\n\n## Operating Systems\n\nWe have tested the following environments.\n\n|**Operating System** | **Compiler** |\n|-----------------|----------|\n| Ubuntu 18.04 | GCC 7.5.0  |\n| Ubuntu 20.04 | GCC 10.3.0 |\n| Ubuntu 22.04 | GCC 11.2.0 |\n\nNote: GCC 8.5.0 has known regressions regarding fold expressions and overloaded operators. Using GCC 7.5.0 or (preferred) GCC >= 9 is recommended.\n\nNote: CUTLASS 3.x builds are known to be down on Windows platforms for all CUDA toolkits.\nCUTLASS team is working on a fix.\n\n## Hardware\n\nCUTLASS runs successfully on the following NVIDIA GPUs, and it is expected to be efficient on Volta, Turing, Ampere, Ada, and Hopper architecture based NVIDIA GPUs.\n\n|**GPU**|**CUDA Compute Capability**|**Minimum CUDA Toolkit Required by CUTLASS-3**|\n|---|---|---|\n|NVIDIA V100 Tensor Core GPU            |7.0|11.4|\n|NVIDIA TitanV                          |7.0|11.4|\n|NVIDIA GeForce RTX 20x0 series         |7.5|11.4|\n|NVIDIA T4                              |7.5|11.4|\n|NVIDIA A100 Tensor Core GPU            |8.0|11.4|\n|NVIDIA A10                             |8.6|11.4|\n|NVIDIA GeForce RTX 30x0 series         |8.6|11.4|\n|NVIDIA GeForce RTX 40x0 series         |8.9|11.8|\n|NVIDIA L40                             |8.9|11.8|\n|NVIDIA H100 Tensor Core GPU            |9.0|11.8|\n|NVIDIA H200 Tensor Core GPU            |9.0|11.8|\n|NVIDIA B200 Tensor Core GPU            |10.0|12.8|\n|NVIDIA B300 Tensor Core GPU            |10.3|13.0|\n|NVIDIA DRIVE Thor                      |11.0|13.0|\n|NVIDIA GeForce RTX 50x0 series         |12.0|12.8|\n|NVIDIA DGX Spark                       |12.1|13.0|\n\n## Target Architecture\n\nIn general, PTX code generated for one target architecture can be run on future architectures\n(i.e., it is forward compatible).\nHowever, CUDA 12.0 introduced the concept of \"architecture-accelerated features\" whose\nPTX does not have forward compatibility guarantees.\nSeveral Hopper and Blackwell PTX instructions fall under this category of\narchitecture-accelerated features, and thus require a `sm_90a` or `sm100a` target architecture\n(note the \"a\" appended). For more details on this and other architecture-accelerated instructions,\nplease refer to the [CUDA Documentation](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#feature-availability).\n\nThe target architecture information is passed on to CUTLASS via the cmake flag\n`CUTLASS_NVCC_ARCHS`. In order to maximize performance on Hopper GH100,\nusers are required to build CUTLASS with `90a` as the target architecture.\nIf a user accidentally builds a kernel which uses SM90a features\n(e.g. Hopper Tensor Core Instructions), using the SM90 target\n(note the lack of \"a\"), with either CUDA Toolkit 12 or 11.8,\nthe kernel is expected to fail with a runtime error.\n\n```\ncmake .. -DCUTLASS_NVCC_ARCHS=\"90a\"\n```\nOr\n\n```\ncmake .. -DCUTLASS_NVCC_ARCHS=\"100a\"\n```\n\nNote: The NVIDIA Blackwell SM100 architecture used in the datacenter\nproducts has a different compute capability than the one underpinning\nNVIDIA Blackwell GeForce RTX 50 series GPUs (SM120). As a result, kernels\ncompiled for Blackwell SM100 architecture with arch conditional features\n(using `sm100a`) are not compatible with RTX 50 series GPUs.\n\nPlease refer to the [functionality documentation](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/functionality.html)\nfor details on which kernels require which target architectures.\n\n# Documentation\n\nCUTLASS is described in the following documents and the accompanying\n[Doxygen documentation](https://nvidia.github.io/cutlass).\n\n- [Quick Start Guide](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/quickstart.html) - basics of building and running CUTLASS\n- [Functionality](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/functionality.html) - summarizes functionality available in CUTLASS\n- [Efficient GEMM in CUDA](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/efficient_gemm.html) - describes how GEMM kernels may be implemented efficiently in CUDA\n- [CUTLASS 3.x Design](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/cutlass_3x_design.html) - describes the CUTLASS 3.x design, its benefits, and how CuTe enables us to write much more composable components\n- [GEMM API 3.x](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/gemm_api_3x.html) - describes the CUTLASS 3.x GEMM model and C++ template concepts\n- [GEMM API 2.x](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/gemm_api.html) - describes the CUTLASS 2.x GEMM model and C++ template concepts\n- [Implicit GEMM Convolution](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/implicit_gemm_convolution.html) - describes 2-D and 3-D convolution in CUTLASS\n- [Code Organization](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/code_organization.html) - describes the organization and contents of the CUTLASS project\n- [Terminology](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/terminology.html) - describes terms used in the code\n- [Programming Guidelines](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/programming_guidelines.html) - guidelines for writing efficient modern CUDA C++\n- [Fundamental types](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/fundamental_types.html) - describes basic C++ classes used in CUTLASS to represent numeric quantities and arrays\n- [Layouts](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/layout.html) - describes layouts of matrices and tensors in memory\n- [Tile Iterators](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/tile_iterator_concept.html) - describes C++ concepts for iterating over tiles of matrices in memory\n- [CUTLASS Profiler](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/profiler.html) - command-line driven profiling application\n- [CUTLASS Utilities](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/utilities.html) - additional templates used to facilitate rapid development\n- [Dependent kernel launch](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/dependent_kernel_launch.html) - describes a new feature in Hopper which allows overlapping dependent\nkernels in the same stream, and how it is used in CUTLASS.\n\n# Resources\nWe have also described the structure of an efficient GEMM in our talk at the\n[GPU Technology Conference 2018](http://on-demand.gputechconf.com/gtc/2018/presentation/s8854-cutlass-software-primitives-for-dense-linear-algebra-at-all-levels-and-scales-within-cuda.pdf).\n\n- [CUTLASS: Software Primitives for Dense Linear Algebra at All Levels and Scales within CUDA](https://www.nvidia.com/en-us/on-demand/session/gtcsiliconvalley2018-s8854/)\n- [Developing CUDA Kernels to Push Tensor Cores to the Absolute Limit on NVIDIA A100](https://www.nvidia.com/en-us/on-demand/session/gtcsj20-s21745/)\n- [Accelerating Convolution with Tensor Cores in CUTLASS](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s31883/)\n- [Accelerating Backward Data Gradient by Increasing Tensor Core Utilization in CUTLASS](https://www.nvidia.com/en-us/on-demand/session/gtcspring22-s41996/)\n- [CUTLASS: Python API, Enhancements, and NVIDIA Hopper](https://www.nvidia.com/en-us/on-demand/session/gtcfall22-a41131/)\n\n# Building CUTLASS\n\nCUTLASS is a header-only template library and does not need to be built to be used by other\nprojects. Client applications should target CUTLASS's `include/` directory in their include\npaths.\n\nCUTLASS unit tests, examples, and utilities can be build with CMake.\nThe minimum version of CMake is given in the [Quickstart guide](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/quickstart.html).\nMake sure the `CUDACXX` environment  variable points to NVCC in the CUDA Toolkit installed\non your system.\n\n```bash\n$ export CUDACXX=${CUDA_INSTALL_PATH}/bin/nvcc\n```\n\nCreate a build directory within the CUTLASS project, then run CMake. By default CUTLASS will build kernels\nfor CUDA architecture versions 5.0, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6, 8.9, and 9.0.\nTo reduce compile time you can specify\nthe architectures to build CUTLASS for by changing the CMake configuration setting\n`CUTLASS_NVCC_ARCHS`.\n\n```bash\n$ mkdir build && cd build\n\n$ cmake .. -DCUTLASS_NVCC_ARCHS=80               # compiles for NVIDIA's Ampere Architecture\n```\n\nFrom the `build/` directory, compile and run the CUTLASS unit tests by building the target `test_unit` with make.\n\nThe unit tests are organized as several binaries mirroring the top-level namespaces of CUTLASS,\nand they may be executed in parallel via make's `-j` command line argument.\n\n```bash\n$ make test_unit -j\n...\n...\n...\n[----------] Global test environment tear-down\n[==========] 946 tests from 57 test cases ran. (10812 ms total)\n[  PASSED  ] 946 tests.\n```\n\nAll tests should pass on supported platforms, though the exact number of tests may vary over time.\n\n\n# Project Structure\n\nCUTLASS is arranged as a header-only library along with Utilities, Tools, Examples, and unit tests.\n[Doxygen documentation](https://nvidia.github.io/cutlass) provides a complete list of files, classes,\nand template concepts defined in the CUTLASS project.\n\nA detailed explanation of the source code organization may be found in the\n[CUTLASS documentation](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/code_organization.html), but several main components are summarized below.\n\n## CUTLASS Template Library\n\n```\ninclude/                     # client applications should target this directory in their build's include paths\n\n  cutlass/                   # CUDA Templates for Linear Algebra Subroutines and Solvers - headers only\n\n    arch/                    # direct exposure of architecture features (including instruction-level GEMMs)\n\n    conv/                    # code specialized for convolution\n\n    epilogue/                # code specialized for the epilogue of gemm/convolution\n\n    gemm/                    # code specialized for general matrix product computations\n\n    layout/                  # layout definitions for matrices, tensors, and other mathematical objects in memory\n\n    platform/                # CUDA-capable Standard Library components\n\n    reduction/               # bandwidth-limited reduction kernels that do not fit the \"gemm\" model\n\n    thread/                  # simt code that can be performed within a CUDA thread\n\n    transform/               # code specialized for layout, type, and domain transformations\n\n    *                        # core vocabulary types, containers, and basic numeric operations\n\n  cute/                      # CuTe Layout, layout algebra, MMA/Copy atoms, tiled MMA/Copy\n\n    algorithm/               # Definitions of core operations such as copy, gemm, and operations on cute::tuples\n\n    arch/                    # Bare bones PTX wrapper structs for copy and math instructions\n\n    atom/                    # Meta-information either link to or built from arch/ operators\n\n      mma_atom.hpp           # cute::Mma_Atom and cute::TiledMma\n\n      copy_atom.hpp          # cute::Copy_Atom and cute::TiledCopy\n\n      *sm*.hpp               # Arch specific meta-information for copy and math operations\n\n    *                        # Core library types such as Shape, Stride, Layout, Tensor, and associated operations\n\n```\n\n### CUTLASS SDK Examples\n\n[CUTLASS SDK examples](https://github.com/NVIDIA/cutlass/tree/main/examples) apply CUTLASS templates to implement basic computations.\n\n### Tools\n\n```\ntools/\n  library/                   # CUTLASS Instance Library - contains instantiations of all supported CUTLASS templates\n    include/\n      cutlass/\n        library/\n\n  profiler/                  # CUTLASS Profiler         - command-line utility for executing operations in the\n                             #                            CUTLASS Library\n\n  util/                      # CUTLASS Utilities        - contains numerous helper classes for\n    include/                 #                            managing tensors in device memory, reference\n      cutlass/               #                            implementations for GEMM, random initialization\n        util/                #                            of tensors, and I/O.\n```\n\n### Test\n\nThe `test/unit/` directory consist of unit tests implemented with Google Test that demonstrate\nbasic usage of Core API components and complete tests of the CUTLASS GEMM computations.\n\nInstructions for building and running the Unit tests are described in the [Quickstart guide](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/quickstart.html).\n\n# Performance Profiling\n\nThe `tools/profiler/` directory contains a command-line utility for launching each of the GEMM kernels.\nIt can be built as follows:\n\n```bash\n$ make cutlass_profiler -j16\n```\n## Building all GEMM and Convolution kernels (_long_ build times)\n\nBy default, only one tile size is instantiated for each data type, math instruction, and layout.\nTo instantiate all, set the following environment variable when running CMake from an empty `build/` directory.\nBeware, this results in *tens of thousands* of kernels and long build times.\nThis would also result in a large binary size and on some platforms linker to fail on building the library.\nTherefore, it's highly recommended to generate only a subset of kernels as demonstrated in the sub-section below.\n```bash\n$ cmake .. -DCUTLASS_NVCC_ARCHS=90a -DCUTLASS_LIBRARY_KERNELS=all\n...\n$ make cutlass_profiler -j16\n```\n\n## Building a subset of GEMM and Convolution kernels (_reduced_ build times)\n\nTo compile strictly one kernel or a small set of kernels, a comma-delimited list of kernel names with\nwildcard characters may be used to reduce the set of kernels. The following examples show building exactly one\nor a subset of kernels for NVIDIA Ampere and Turing architecture:\n\n### Building a subset Tensor Core GEMM kernels\n\nTo compile a subset of Tensor Core GEMM kernels with FP32 accumulation and FP16 input targeting NVIDIA Ampere and Turing architecture,\nuse the below cmake command line:\n```bash\n$ cmake .. -DCUTLASS_NVCC_ARCHS='75;80' -DCUTLASS_LIBRARY_KERNELS=cutlass_tensorop_s*gemm_f16_*_nt_align8\n...\n$ make cutlass_profiler -j16\n```\n\nExample command line for profiling a subset of Tensor Core GEMM kernels is as follows:\n```bash\n./tools/profiler/cutlass_profiler --kernels=cutlass_tensorop_s*gemm_f16_*_nt_align8 --m=3456 --n=4096 --k=4096\n\n...\n=============================\n  Problem ID: 1\n\n        Provider: CUTLASS\n   OperationKind: gemm\n       Operation: cutlass_tensorop_s1688gemm_f16_256x128_32x2_nt_align8\n\n          Status: Success\n    Verification: ON\n     Disposition: Passed\n\nreference_device: Passed\n          cuBLAS: Passed\n\n       Arguments: --gemm_kind=universal --m=3456 --n=4096 --k=4096 --A=f16:column --B=f16:row --C=f32:column --alpha=1  \\\n                  --beta=0 --split_k_slices=1 --batch_count=1 --op_class=tensorop --accum=f32 --cta_m=256 --cta_n=128  \\\n                  --cta_k=32 --stages=2 --warps_m=4 --warps_n=2 --warps_k=1 --inst_m=16 --inst_n=8 --inst_k=8 --min_cc=75  \\\n                  --max_cc=1024\n\n           Bytes: 118489088  bytes\n           FLOPs: 115992428544  flops\n\n         Runtime: 1.55948  ms\n          Memory: 70.7616 GiB/s\n\n            Math: 74378.8 GFLOP/s\n\n\n\n=============================\n...\n```\n\n### Building one CUDA Core GEMM kernel\n\nTo compile one SGEMM kernel targeting NVIDIA Ampere and Turing architecture, use the below cmake command line:\n```bash\n$ cmake .. -DCUTLASS_NVCC_ARCHS='75;80' -DCUTLASS_LIBRARY_KERNELS=cutlass_simt_sgemm_128x128_8x2_nn_align1\n...\n$ make cutlass_profiler -j16\n```\n\nExample command line for profiling single SGEMM CUDA kernel is as follows:\n```bash\n$ ./tools/profiler/cutlass_profiler --kernels=sgemm --m=3456 --n=4096 --k=4096\n\n=============================\n  Problem ID: 1\n\n        Provider: CUTLASS\n   OperationKind: gemm\n       Operation: cutlass_simt_sgemm_128x128_8x2_nn_align1\n\n          Status: Success\n    Verification: ON\n     Disposition: Passed\n\n          cuBLAS: Passed\n\n       Arguments: --m=3456 --n=4096 --k=4096 --A=f32:column --B=f32:column --C=f32:column --alpha=1 --beta=0 --split_k_slices=1  \\\n                  --batch_count=1 --op_class=simt --accum=f32 --cta_m=128 --cta_n=128 --cta_k=8 --stages=2 --warps_m=4  \\\n                  --warps_n=2 --warps_k=1 --inst_m=1 --inst_n=1 --inst_k=1 --min_cc=50 --max_cc=1024\n\n           Bytes: 180355072  bytes\n           FLOPs: 115992428544  flops\n\n         Runtime: 6.73655  ms\n          Memory: 24.934 GiB/s\n\n            Math: 17218.4 GFLOP/s\n\n=============================\n```\n\n### Building a subset of Tensor Core Convolution kernels\n\nTo compile a subset of Tensor core convolution kernels implementing forward propagation (fprop) with FP32 accumulation\nand FP16 input targeting NVIDIA Ampere and Turing architecture, use the below cmake command line:\n```bash\n$ cmake .. -DCUTLASS_NVCC_ARCHS='75;80' -DCUTLASS_LIBRARY_KERNELS=cutlass_tensorop_s*fprop_optimized_f16\n...\n$ make cutlass_profiler -j16\n```\n\nExample command line for profiling a subset of Tensor Core convolution kernels is as follows:\n\n```bash\n$ ./tools/profiler/cutlass_profiler --kernels=cutlass_tensorop_s*fprop_optimized_f16 --n=8 --h=224 --w=224 --c=128 --k=128 --r=3 --s=3\n\n...\n=============================\n  Problem ID: 1\n\n        Provider: CUTLASS\n   OperationKind: conv2d\n       Operation: cutlass_tensorop_s16816fprop_optimized_f16_128x128_32x5_nhwc\n\n          Status: Success\n    Verification: ON\n     Disposition: Passed\n\nreference_device: Passed\n\n       Arguments: --conv_kind=fprop --n=8 --h=224 --w=224 --c=128 --k=128 --r=3 --s=3 --p=224 --q=224 --pad_h=1 --pad_w=1  \\\n                  --stride_h=1 --stride_w=1 --dilation_h=1 --dilation_w=1 --Activation=f16:nhwc --Filter=f16:nhwc --Output=f32:nhwc  \\\n                  --conv_mode=cross --iterator_algorithm=optimized --alpha=1 --beta=0 --split_k_mode=serial --split_k_slices=1  \\\n                  --eq_gemm_provider=none --op_class=tensorop --accum=f32 --cta_m=128 --cta_n=128 --cta_k=32 --stages=5  \\\n                  --warps_m=2 --warps_n=2 --warps_k=1 --inst_m=16 --inst_n=8 --inst_k=16 --min_cc=80 --max_cc=1024\n\n           Bytes: 1130659840  bytes\n           FLOPs: 118482796544  flops\n\n         Runtime: 0.711496  ms\n          Memory: 1479.99 GiB/s\n\n            Math: 166526 GFLOP/s\n\n=============================\n...\n```\n\n\n### Building one Convolution CUDA kernel\n\nTo compile and run one CUDA Core convolution kernel implementing forward propagation (fprop) with F32 accumulation\nand FP32 input targeting NVIDIA Ampere and Turing architecture, use the below cmake command line:\n```bash\n$ cmake .. -DCUTLASS_NVCC_ARCHS='75;80' -DCUTLASS_LIBRARY_KERNELS=cutlass_simt_sfprop_optimized_128x128_8x2_nhwc\n...\n$ make cutlass_profiler -j16\n```\n\nExample command line for profiling one CUDA Core convolution kernel:\n\n```bash\n$ ./tools/profiler/cutlass_profiler --kernels=cutlass_simt_sfprop_optimized_128x128_8x2_nhwc --n=8 --h=224 --w=224 --c=128 --k=128 --r=3 --s=3\n\n\n=============================\n  Problem ID: 1\n\n        Provider: CUTLASS\n   OperationKind: conv2d\n       Operation: cutlass_simt_sfprop_optimized_128x128_8x2_nhwc\n\n          Status: Success\n    Verification: ON\n     Disposition: Passed\n\nreference_device: Passed\n\n       Arguments: --conv_kind=fprop --n=8 --h=224 --w=224 --c=128 --k=128 --r=3 --s=3 --p=224 --q=224 --pad_h=1 --pad_w=1  \\\n                  --stride_h=1 --stride_w=1 --dilation_h=1 --dilation_w=1 --Activation=f32:nhwc --Filter=f32:nhwc --Output=f32:nhwc  \\\n                  --conv_mode=cross --iterator_algorithm=optimized --alpha=1 --beta=0 --split_k_mode=serial --split_k_slices=1  \\\n                  --eq_gemm_provider=none --op_class=simt --accum=f32 --cta_m=128 --cta_n=128 --cta_k=8 --stages=2 --warps_m=4  \\\n                  --warps_n=2 --warps_k=1 --inst_m=1 --inst_n=1 --inst_k=1 --min_cc=50 --max_cc=1024\n\n           Bytes: 2055798784  bytes\n           FLOPs: 118482796544  flops\n\n         Runtime: 7.34266  ms\n          Memory: 260.752 GiB/s\n\n            Math: 16136.2 GFLOP/s\n\n\n=============================\n\n```\n\n## More Details on Compiling CUTLASS Kernels and CUTLASS Profiler\n- Please follow the links for more CMake examples on selectively compiling CUTLASS kernels:\n  - [GEMM CMake Examples](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/quickstart.html#gemm-cmake-examples)\n  - [Implicit GEMM convolution CMake Examples](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/quickstart.html#convolution-cmake-examples)\n- [Further details about the CUTLASS Profiler are described here.](https://docs.nvidia.com/cutlass/latest/media/docs/cpp/profiler.html)\n\n\n# About\n\nCUTLASS is released by NVIDIA Corporation as Open Source software under the\n[3-clause \"New\" BSD license](LICENSE.txt).\n\n# Contributors\n\nThe official list of CUTLASS developers and contributors is available here: [CONTRIBUTORS](CONTRIBUTORS.md).\n\n# Copyright\n\nCopyright (c) 2017 - 2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\nSPDX-License-Identifier: BSD-3-Clause\n\n```\n  Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions are met:\n\n  1. Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n  2. Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n  3. Neither the name of the copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n```\n",
      "stars_today": 5
    },
    {
      "id": 29933948,
      "name": "fluent-bit",
      "full_name": "fluent/fluent-bit",
      "description": "Fast and Lightweight Logs, Metrics and Traces processor for Linux, BSD, OSX and Windows",
      "html_url": "https://github.com/fluent/fluent-bit",
      "stars": 7590,
      "forks": 1856,
      "language": "C",
      "topics": [
        "c",
        "cloudnative",
        "data-collector",
        "fluent-bit",
        "fluentd",
        "forwarder",
        "logging",
        "logs",
        "metrics",
        "opentelemetry",
        "prometheus",
        "sql-queries",
        "stream-processing",
        "traces"
      ],
      "created_at": "2015-01-27T20:41:52Z",
      "updated_at": "2026-01-24T23:54:48Z",
      "pushed_at": "2026-01-23T16:06:01Z",
      "open_issues": 715,
      "owner": {
        "login": "fluent",
        "avatar_url": "https://avatars.githubusercontent.com/u/859518?v=4"
      },
      "readme": "# ![logo](fluentbit_logo.png)\n\n### CI Status\n\n| CI Workflow             | Status                                                                                                                                                     |\n|-------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Unit Tests (`master`)   | [![CI/Unit Tests](https://github.com/fluent/fluent-bit/actions/workflows/unit-tests.yaml/badge.svg?branch=master)](https://github.com/fluent/fluent-bit/actions/workflows/unit-tests.yaml) |\n| Integration Tests       | [![CI/Integration Tests](https://github.com/fluent/fluent-bit/actions/workflows/master-integration-test.yaml/badge.svg)](https://github.com/fluent/fluent-bit/actions/workflows/master-integration-test.yaml) |\n| Arm builds              | <a href=\"https://actuated.dev/\"><img alt=\"Arm CI sponsored by Actuated\" src=\"https://docs.actuated.dev/images/actuated-badge.png\" width=\"120px\"></img></a> |\n| Latest Release Pipeline | [![CI/Build](https://github.com/fluent/fluent-bit/actions/workflows/staging-release.yaml/badge.svg)](https://github.com/fluent/fluent-bit/actions/workflows/staging-release.yaml) |\n\n---\n\n## About\n\n[Fluent Bit](https://fluentbit.io) is a lightweight and high-performance Telemetry Agent designed to collect, process, and forward **Logs**, **Metrics**, and **Traces** from any source to any destination.\n\nIt's part of the Graduated [Fluentd](https://fluentd.org) Ecosystem and a CNCF [Cloud Native Computing Foundation](https://cncf.io) project.\n\nFluent Bit supports a wide array of platforms, including Linux, Windows, MacOS, BSD, and Embedded environments, and is built for maximum efficiency with minimal CPU and memory footprint.\n\n![](documentation/fluentbit_ecosystem.png)\n\n---\n\n## ğŸ“Œ Roadmap & Maintenance\n\nWe follow a fast-paced development cycle, with major releases every 3â€“4 months.\nThe active development branch (`master`) is currently focused on **v5.0** (development).\n\nFor version-specific maintenance timelines and policies, see our [MAINTENANCE.md](https://github.com/fluent/fluent-bit/blob/master/MAINTENANCE.md).\n\nTo track upcoming milestones, visit the [project roadmap](https://github.com/fluent/fluent-bit/wiki/Fluent-Bit-Roadmap).\n\n---\n\n## Key Features\n\n- âš¡ **High Performance** with low memory footprint\n- ğŸ“¦ **Pluggable Architecture**: 70+ built-in plugins for Inputs, Filters, and Outputs\n- ğŸ§  **SQL Stream Processing**: Perform analytics and transformations with SQL queries\n- ğŸ”’ **Secure Networking**: Built-in TLS/SSL support and async I/O\n- ğŸ“Š **Monitoring**: Expose internal metrics over HTTP/Prometheus\n- ğŸ§© **Extensibility**:\n  - Write plugins in **C**, filters in **Lua**, and outputs in **Go**\n- ğŸ”Œ **Supports Logs, Metrics, and Traces** with unified processing and delivery\n\n---\n\n## Documentation\n\nOur official documentation includes installation guides, plugin usage, developer resources, and more:\n\nğŸ“š [https://docs.fluentbit.io](https://docs.fluentbit.io)\n\n---\n\n## Quick Start\n\nBuild from source:\n\n```bash\ncd build\ncmake ..\nmake\nbin/fluent-bit -i cpu -o stdout -f 1\n```\n\nMore details: [Build & Install](https://docs.fluentbit.io/manual/installation/downloads/source/build-and-install)\n\n#### Requirements\n\n- CMake >= 3.0\n- Flex & Bison\n- YAML and OpenSSL headers\n\n---\n\n## Install Fluent Bit\n\n- [Linux packages (Debian, Ubuntu, RHEL, etc.)](https://docs.fluentbit.io/manual/installation/downloads/linux)\n- [Docker images](https://docs.fluentbit.io/manual/installation/downloads/docker)\n- [Windows binaries](https://docs.fluentbit.io/manual/installation/downloads/windows)\n\n---\n\n## Plugins: Inputs, Filters, Outputs\n\nFluent Bit is fully modular. It supports:\n\n- [Input Plugins](https://docs.fluentbit.io/manual/pipeline/inputs): collect logs/metrics/traces\n- [Filter Plugins](https://docs.fluentbit.io/manual/pipeline/filters): enrich and transform data\n- [Output Plugins](https://docs.fluentbit.io/manual/pipeline/outputs): deliver data to external services\n\nSee the full plugin list in our [documentation](https://docs.fluentbit.io/manual/pipeline/inputs).\n\n---\n\n## ğŸš€ Production Usage\n\nFluent Bit is deployed **over 10 million times daily** and has surpassed **15 billion downloads**.\n\nUsed by companies like:\n\n![users](documentation/fluentbit_users.png)\n\n> Want to add your logo? [Open an issue](https://github.com/fluent/fluent-bit/issues).\n\n---\n\n## Contributing\n\nFluent Bit is open to community contributions!\n\n- ğŸ¤ [Join our community](https://fluentbit.io/community/)\n- ğŸ›  [CONTRIBUTING.md](CONTRIBUTING.md)\n- ğŸš€ [Developer Guide](DEVELOPER_GUIDE.md)\n\n---\n\n## Community & Contact\n\n- ğŸ’¬ [Slack](http://slack.fluentd.org) (`#fluent-bit` channel)\n- ğŸ¦ [Twitter](https://twitter.com/fluentbit)\n\n---\n\n## License\n\n[Apache License v2.0](http://www.apache.org/licenses/LICENSE-2.0)\n\n---\n\n## Authors\n\nFluent Bit is a CNCF graduated project, sponsored and maintained by major cloud providers and a growing community of contributors and maintainers from across the Cloud Native ecosystem.\n\nğŸ‘‰ [See Contributors](https://github.com/fluent/fluent-bit/graphs/contributors)\n",
      "stars_today": 5
    },
    {
      "id": 248400799,
      "name": "LibChecker",
      "full_name": "LibChecker/LibChecker",
      "description": "An app to view libraries used in apps in your device.",
      "html_url": "https://github.com/LibChecker/LibChecker",
      "stars": 6492,
      "forks": 407,
      "language": "Kotlin",
      "topics": [
        "android",
        "f-droid",
        "fdroid",
        "kotlin"
      ],
      "created_at": "2020-03-19T03:21:14Z",
      "updated_at": "2026-01-25T01:51:46Z",
      "pushed_at": "2026-01-21T11:23:25Z",
      "open_issues": 27,
      "owner": {
        "login": "LibChecker",
        "avatar_url": "https://avatars.githubusercontent.com/u/116417672?v=4"
      },
      "readme": "# LibChecker\n\n[![Android CI](https://github.com/LibChecker/LibChecker/actions/workflows/android.yml/badge.svg)](https://github.com/LibChecker/LibChecker/actions/workflows/android.yml)\n[![License](https://img.shields.io/github/license/LibChecker/LibChecker?label=License)](https://choosealicense.com/licenses/apache-2.0/)\n[![Discussion](https://img.shields.io/badge/Telegram-Group-blue.svg?logo=telegram)](https://t.me/libcheckerr)\n[![Crowdin](https://badges.crowdin.net/libchecker/localized.svg)](https://crowdin.com/project/libchecker)\n\n![Header](./source/header.png)\n\n## What's this?\nThis app is used to view the third-party libraries used by applications in your device. It can view the ABI architecture of the application's native library (in general, whether the application is 64-bit or 32-bit). It can also view well-known libraries marked by the rules repository on [GitHub](https://github.com/LibChecker/LibChecker-Rules) or [GitLab](https://gitlab.com/zhaobozhen/LibChecker-Rules), and can even sort and view them according to the number of libraries references.\n\n## Supported versions\nAndroid 7.0 ~ 16\n\nAndroid 6 [Marshmallow](https://github.com/LibChecker/LibChecker/tree/marshmallow)\n\n## Document\n[LibChecker-Docs](https://github.com/LibChecker/LibChecker-Docs)\n\n## Download\n<!-- [<img src=\"./source/coolapk-badge.png\" width=\"323\" height=\"125\" />](https://www.coolapk.com/apk/com.absinthe.libchecker) -->\n[<img src=\"https://play.google.com/intl/en_us/badges/static/images/badges/en_badge_web_generic.png\" width=\"323\" height=\"125\" />](https://play.google.com/store/apps/details?id=com.absinthe.libchecker)\n[<img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\" width=\"323\" height=\"125\" />](https://f-droid.org/packages/com.absinthe.libchecker/)\n[<img src=\"https://gitlab.com/IzzyOnDroid/repo/-/raw/master/assets/IzzyOnDroid.png\" width=\"323\" height=\"125\" />](https://apt.izzysoft.de/fdroid/index/apk/com.absinthe.libchecker)\n\n## Discussions\n[Github Discussions](https://github.com/LibChecker/LibChecker/discussions)\n\n### Telegram Group\n<img src=\"./source/tg_group_dark.png#gh-dark-mode-only\" width=\"240\" height=\"240\" />\n<img src=\"./source/tg_group_light.png#gh-light-mode-only\" width=\"240\" height=\"240\" />\n",
      "stars_today": 5
    },
    {
      "id": 992765044,
      "name": "containerization",
      "full_name": "apple/containerization",
      "description": "Containerization is a Swift package for running Linux containers on macOS.",
      "html_url": "https://github.com/apple/containerization",
      "stars": 8259,
      "forks": 246,
      "language": "Swift",
      "topics": [],
      "created_at": "2025-05-29T17:15:44Z",
      "updated_at": "2026-01-24T19:18:58Z",
      "pushed_at": "2026-01-23T04:57:58Z",
      "open_issues": 44,
      "owner": {
        "login": "apple",
        "avatar_url": "https://avatars.githubusercontent.com/u/10639145?v=4"
      },
      "readme": "# Containerization\n\nThe Containerization package allows applications to use Linux containers.\nContainerization is written in [Swift](https://www.swift.org) and uses [Virtualization.framework](https://developer.apple.com/documentation/virtualization) on Apple silicon.\n\n> **Looking for command line binaries for running containers?**\\\n> They are available in the dedicated [apple/container](https://github.com/apple/container) repository.\n\nContainerization provides APIs to:\n\n- [Manage OCI images](./Sources/ContainerizationOCI/).\n- [Interact with remote registries](./Sources/ContainerizationOCI/Client/).\n- [Create and populate ext4 file systems](./Sources/ContainerizationEXT4/).\n- [Interact with the Netlink socket family](./Sources/ContainerizationNetlink/).\n- [Create an optimized Linux kernel for fast boot times](./kernel/).\n- [Spawn lightweight virtual machines and manage the runtime environment](./Sources/Containerization/LinuxContainer.swift).\n- [Spawn and interact with containerized processes](./Sources/Containerization/LinuxProcess.swift).\n- Use Rosetta 2 for running linux/amd64 containers on Apple silicon.\n\nPlease view the [API documentation](https://apple.github.io/containerization/documentation/) for information on the Swift packages that Containerization provides.\n\n## Design\n\nContainerization executes each Linux container inside of its own lightweight virtual machine. Clients can create dedicated IP addresses for every container to remove the need for individual port forwarding. Containers achieve sub-second start times using an optimized [Linux kernel configuration](/kernel) and a minimal root filesystem with a lightweight init system.\n\n[vminitd](/vminitd) is a small init system, which is a subproject within Containerization.\n`vminitd` is spawned as the initial process inside of the virtual machine and provides a GRPC API over vsock.\nThe API allows the runtime environment to be configured and containerized processes to be launched.\n`vminitd` provides I/O, signals, and events to the calling process when a process is run.\n\n## Requirements\n\nTo build the Containerization package, you need:\n\n- Mac with Apple silicon\n- macOS 26\n- Xcode 26\n\nOlder versions of macOS are not supported. \n\n## Example Usage\n\nFor examples of how to use some of the libraries surface, the cctl executable is a good start. This app is a useful playground for exploring the API. It contains commands that exercise some of the core functionality of the various products, such as:\n\n1. [Manipulating OCI images](./Sources/cctl/ImageCommand.swift)\n2. [Logging in to container registries](./Sources/cctl/LoginCommand.swift)\n3. [Creating root filesystem blocks](./Sources/cctl/RootfsCommand.swift)\n4. [Running simple Linux containers](./Sources/cctl/RunCommand.swift)\n\n## Linux kernel\n\nA Linux kernel is required for spawning lightweight virtual machines on macOS.\nContainerization provides an optimized kernel configuration located in the [kernel](./kernel) directory.\n\nThis directory includes a containerized build environment to easily compile a kernel for use with Containerization.\n\nThe kernel configuration is a minimal set of features to support fast start times and a light weight environment.\n\nWhile this configuration will work for the majority of workloads we understand that some will need extra features.\nTo solve this Containerization provides first class APIs to use different kernel configurations and versions on a per container basis.\nThis enables containers to be developed and validated across different kernel versions.\n\nSee the [README](/kernel/README.md) in the kernel directory for instructions on how to compile the optimized kernel.\n\n### Kernel Support\n\nContainerization allows user provided kernels but tests functionality starting with kernel version `6.14.9`.\n\n### Pre-built Kernel\n\nIf you wish to consume a pre-built kernel, make sure it has `VIRTIO` drivers compiled into the kernel (not merely as modules).\n\nThe [Kata Containers](https://github.com/kata-containers/kata-containers) project provides a Linux kernel that is optimized for containers, with all required configuration options enabled. The [releases](https://github.com/kata-containers/kata-containers/releases/) page contains downloadable artifacts, and the image itself (`vmlinux.container`) can be found in the `/opt/kata/share/kata-containers/` directory. \n\n## Prepare to build package\n\nInstall the recommended version of Xcode.\n\nSet the active developer directory to the installed Xcode (replace `<PATH_TO_XCODE>`):\n```bash\nsudo xcode-select -s <PATH_TO_XCODE>\n``` \n\nInstall [Swiftly](https://github.com/swiftlang/swiftly), [Swift](https://www.swift.org), and [Static Linux SDK](https://www.swift.org/documentation/articles/static-linux-getting-started.html):\n\n```bash\nmake cross-prep\n```\n\nIf you use a custom terminal application, you may need to move this command from `.zprofile` to `.zshrc` (replace `<USERNAME>`):\n\n```bash\n# Added by swiftly\n. \"/Users/<USERNAME>/.swiftly/env.sh\"\n```\n\nRestart the terminal application. Ensure this command returns `/Users/<USERNAME>/.swiftly/bin/swift` (replace `<USERNAME>`):\n\n```bash\nwhich swift\n```\n\nIf you've installed or used a Static Linux SDK previously, you may need to remove older SDK versions from the system (replace `<SDK-ID>`):\n\n```bash\nswift sdk list\nswift sdk remove <SDK-ID>\n```\n\n## Build the package\n\nBuild Containerization from sources:\n\n```bash\nmake all\n```\n\n## Test the package\n\nAfter building, run basic and integration tests:\n\n```bash\nmake test integration\n```\n\nA kernel is required to run integration tests.\nIf you do not have a kernel locally for use a default kernel can be fetched using the `make fetch-default-kernel` target.\n\nFetching the default kernel only needs to happen after an initial build or after a `make clean`.\n\n```bash\nmake fetch-default-kernel\nmake all test integration\n```\n\n## Protobufs\n\nContainerization depends on specific versions of `grpc-swift` and `swift-protobuf`. You can install them and re-generate RPC interfaces with:\n\n```bash\nmake protos\n```\n\n## Building a kernel\n\nIf you'd like to build your own kernel please see the instructions in the [kernel directory](./kernel/README.md).\n\n## Pre-commit hook\n\nRun `make pre-commit` to install a pre-commit hook that ensures that your changes have correct formatting and license headers when you run `git commit`.\n\n## Documentation\n\nGenerate the API documentation for local viewing with:\n\n```bash\nmake docs\nmake serve-docs\n```\n\nPreview the documentation by running in another terminal:\n\n```bash\nopen http://localhost:8000/containerization/documentation/\n```\n\n## Contributing\n\nContributions to Containerization are welcomed and encouraged. Please see [CONTRIBUTING.md](/CONTRIBUTING.md) for more information.\n\n## Project Status\n\nVersion 0.1.0 is the first official release of Containerization. Earlier versions have no source stability guarantees.\n\nBecause the Containerization library is under active development, source stability is only guaranteed within minor versions (for example, between 0.1.1 and 0.1.2). If you don't want potentially source-breaking package updates, you can specify your package dependency using .upToNextMinorVersion(from: \"0.1.0\") instead.\n\nFuture minor versions of the package may introduce changes to these rules as needed.\n",
      "stars_today": 5
    },
    {
      "id": 199930808,
      "name": "InviZible",
      "full_name": "Gedsh/InviZible",
      "description": "Android application for online privacy and security",
      "html_url": "https://github.com/Gedsh/InviZible",
      "stars": 2320,
      "forks": 141,
      "language": "Java",
      "topics": [
        "advertising",
        "android",
        "android-application",
        "anonymity",
        "dnscrypt",
        "i2p",
        "internet-privacy",
        "tor"
      ],
      "created_at": "2019-07-31T21:22:01Z",
      "updated_at": "2026-01-24T21:00:16Z",
      "pushed_at": "2026-01-23T13:40:30Z",
      "open_issues": 38,
      "owner": {
        "login": "Gedsh",
        "avatar_url": "https://avatars.githubusercontent.com/u/48843569?v=4"
      },
      "readme": "# InviZible Pro\n\n![GitHub release (latest by date)](https://img.shields.io/github/v/release/gedsh/invizible?style=plastic)\n![GitHub Releases](https://img.shields.io/github/downloads/gedsh/invizible/latest/total?color=blue&style=plastic)\n[![Translation status](https://hosted.weblate.org/widgets/invizible/-/invizible/svg-badge.svg)](https://hosted.weblate.org/engage/invizible/?utm_source=widget)\n\n### [Google Play stable version](https://play.google.com/store/apps/details?id=pan.alexander.tordnscrypt.gp)\n\n### [Download the latest version from GitHub](https://github.com/Gedsh/InviZible/releases/latest)\n\n### [IzzyOnDroid F-Droid beta version](https://apt.izzysoft.de/fdroid/index/apk/pan.alexander.tordnscrypt)\n\n### [F-Droid stable version](https://f-droid.org/packages/pan.alexander.tordnscrypt.stable/)\n\n## Android application for online privacy and security\n\n*Preserves privacy, prevents tracking, and provides access to restricted and hidden online content*\n\n**InviZible Pro** combines the strengths of **Tor**, **DNSCrypt**, and **Purple I2P** to provide a comprehensive solution for online privacy, security, and anonymity.\n\n### Tor\n* Hides user's identity and location\n* Defends against traffic analysis and censorship\n* Protects online activities from surveillance\n* Routes traffic through multiple servers\n* Provides access to \"onion\" websites\n* Open-source\n\n### DNSCrypt\n* Secures DNS traffic with encryption\n* Verifies DNS server legitimacy using cryptographic keys\n* Shields against DNS-based attacks like spoofing\n* Guards against eavesdropping and DNS query logging\n* Can block ads *\n* Can protect against dangerous and malicious sites *\n* Can block \"adult\" sites *\n* Open-source\n\n**Depending on the selected dnscrypt server*\n**(Not available in Google Play version!)**\n\n### Purple I2P\n* Provides anonymous communication network\n* Conceals users' identities and activities\n* Defends against surveillance\n* Ensures secure data transmission\n* Distributed and self-organizing network\n* Provides access to \"i2p\" websites (eepsites)\n* Open-source\n\nTo start using **InviZible Pro**, all you need is an Android phone.\nJust run all three modules and enjoy safe and comfortable internet surfing. However,\nif you want to get full control over the application and your internet connection - no problem!\nThere is access to a large number of both simple and professional settings.\nYou can flexibly configure **InviZible Pro** itself, as well as its modules - **DNSCrypt**,\n**Tor** and **Purple I2P**, to satisfy the most non-standard requirements.\n\n**InviZible Pro** is an all-in-one application. After installation, you can remove all of your VPN applications and ad blockers.\n In most cases, **InviZible Pro** works better, is more stable, and faster than free VPNs.\n It does not contain any ads, bloatware and does not spy upon its users.\n \n### Why InviZible Pro is better than other similar applications:\n* Privacy Protection: Guards your online activities.\n* Anonymous Browsing: Conceals your identity.\n* Secure DNS Encryption: Protects your DNS queries.\n* Anonymity Network Integration: Utilizes Tor, DNSCrypt, and Purple I2P.\n* Firewall: Safeguards against unauthorized access.\n* Access to Restricted Content: Unblocks blocked websites.\n* Anti-Tracking Measures: Prevents tracking of your online behavior.\n* Hidden Network Access: Connects to \"onion\" and \"i2p\" websites.\n* Open-Source: Transparent and community-driven.\n* User-Friendly Design: Simple and intuitive interface.\n\n## Compatibility\n\n**InviZible Pro** can be used both with a rooted or non-rooted device.\n\nPlease visit the [wiki](https://github.com/Gedsh/InviZible/wiki) to find out how to use it.\n\nDepending on the rooting method and device specifics, an application may be incompatible with some android phones.\n\n\n## Support\n\nFor questions, feature requests and bug reports, you can use GitHub.\n\n**Official site: [invizible.net](https://invizible.net)**\n\n### International:\n \nTelegram channel: [InviZiblePro](https://t.me/InviZiblePro)\n\nTelegram group: [InviZiblePro_Group](https://t.me/InviZiblePro_Group)\n\nMatrix group: [Matrix](https://matrix.to/#/#invizible-pro-en:matrix.org)\n\n### For Russian-speaking users:\n\nTelegram channel: [InviZiblePro](https://t.me/InviZibleProRus)\n\nTelegram group: [InviZiblePro_Group](https://t.me/InviZibleProRus_Group)\n\nMatrix group: [Matrix](https://matrix.to/#/#invizible-pro-ru:matrix.org)\n\nThere is support for the latest version of **InviZible Pro** only.\n\nThere is no support for things that are not directly related to **InviZible Pro**.\n\nThere is no support for building and developing things by yourself.\n\n## Contributing\n\n#### Building\nTo clone a project, use the command:\n```bash\ngit clone --recursive https://github.com/Gedsh/InviZible\n```\n\nTo build **InviZible Pro** please use **Android Studio**.\n\nIf you see something like this:\n_Illegal character in opaque part at index 2: C:\\KStore\\keystore.properties_\n\nPlease comment lines of the settings.gradle file in the project root, as shown below:\n\n```bash\ninclude ':tordnscrypt', ':filepicker'\nproject(':filepicker').projectDir = new File('android-filepicker/filepicker')\n//Please comment line below if you are not the project owner\n//project(':tordnscrypt').buildFileName = 'owner.gradle'\n```\n\nIt is expected that you can solve build problems yourself, so there is no support for building. \nIf you cannot build yourself, there are prebuilt versions of **InviZible Pro** available [here](https://github.com/Gedsh/InviZible/releases/latest).\n\n#### Translating\n\n[Translate InviZible on Hosted Weblate](https://hosted.weblate.org/engage/invizible/).\n\n[![Translation status](https://hosted.weblate.org/widgets/invizible/-/multi-auto.svg)](https://hosted.weblate.org/engage/invizible/?utm_source=widget)\n\n## Attribution\n\nInviZible Pro uses:\n\n* [DNSCrypt](https://github.com/jedisct1/dnscrypt-proxy)\n* [Tor](https://www.torproject.org/)\n* [Purple I2P](https://github.com/PurpleI2P/i2pd)\n* [Chainfire/libsuperuser](https://github.com/Chainfire/libsuperuser)\n* [jaredrummler/AndroidShell](https://github.com/jaredrummler/AndroidShell)\n* [NetGuard](https://github.com/M66B/NetGuard)\n* [Angads25/android-filepicker](https://github.com/Angads25/android-filepicker)\n* [meefik/busybox](https://github.com/meefik/busybox)\n\nThis product is produced independently from the **TorÂ®**, **DNSCrypt**, **Purple I2P** software \nand carries no guarantee from The Above Projects about quality, suitability or anything else.\n\n## Donations\n**Patreon**: https://www.patreon.com/inviziblepro\n\n**BTC**: 1GfJwiHG6xKCQCpHeW6fELzFfgsvcSxVUR\n\n**LTC**: MUSAXkcAvnN1Ytauzeo9bwjVjarUdDHGgk\n\n**BCH**: qzl4w4ahh7na2z23056qawwdyuclkgty5gc4q8tw88\n\n**USDT**: 0xdA1Dd53FE6501140E3Dcd5134323dfccF20aD536\n\n**XLM**: GBID6I3VYR4NIFLZWI3MEQH3M2H72COC3HQDI5WMYYQGAC3TE55TSKAX\n\n**XMR** 82WFzofvGUdY52w9zCfrZWaHVqEDcJH7y1FujzvXdGPeU9UpuFNeCvtCKhtpC6pZmMYuCNgFjcw5mHAgEJQ4RTwV9XRhobX\n\n## License\n\n[GNU General Public License version 3](https://www.gnu.org/licenses/gpl-3.0.txt)\n\nCopyright (c) 2019-2025 Garmatin Oleksandr invizible.soft@gmail.com\n\nAll rights reserved\n\nThis file is part of **InviZible Pro**.\n\n**InviZible Pro** is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your discretion) any later version.\n\n**InviZible Pro** is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License along with **InviZible Pro**. If not, see [http://www.gnu.org/licenses/](https://www.gnu.org/licenses/)\n\n\n",
      "stars_today": 5
    },
    {
      "id": 1062297179,
      "name": "agentscope-java",
      "full_name": "agentscope-ai/agentscope-java",
      "description": "AgentScope Java: Agent-Oriented Programming for Building LLM Applications",
      "html_url": "https://github.com/agentscope-ai/agentscope-java",
      "stars": 1074,
      "forks": 230,
      "language": "Java",
      "topics": [
        "agent",
        "agentic",
        "agentic-ai",
        "ai",
        "llm"
      ],
      "created_at": "2025-09-23T04:37:43Z",
      "updated_at": "2026-01-25T02:02:59Z",
      "pushed_at": "2026-01-24T02:13:06Z",
      "open_issues": 129,
      "owner": {
        "login": "agentscope-ai",
        "avatar_url": "https://avatars.githubusercontent.com/u/211762292?v=4"
      },
      "readme": "<p align=\"center\">\n  <img\n    src=\"https://img.alicdn.com/imgextra/i1/O1CN01nTg6w21NqT5qFKH1u_!!6000000001621-55-tps-550-550.svg\"\n    alt=\"AgentScope Logo\"\n    width=\"200\"\n  />\n</p>\n\n<h3 align=\"center\">Build Production-Ready AI Agents in Java</h3>\n\n<p align=\"center\">\n  <a href=\"https://java.agentscope.io/\">ğŸ“– Documentation</a>\n  &nbsp;|&nbsp;\n  <a href=\"README_zh.md\">ä¸­æ–‡</a>\n  &nbsp;|&nbsp;\n  <a href=\"https://discord.gg/eYMpfnkG8h\">Discord</a>\n</p>\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/license-Apache--2.0-blue\" alt=\"License\" />\n  <img src=\"https://img.shields.io/badge/JDK-17%2B-orange\" alt=\"JDK 17+\" />\n  <img src=\"https://img.shields.io/maven-central/v/io.agentscope/agentscope?color=green\" alt=\"Maven Central\" />\n  <a href=\"https://deepwiki.com/agentscope-ai/agentscope-java\"><img src=\"https://deepwiki.com/badge.svg\" alt=\"Ask DeepWiki\"></a>\n</p>\n\n---\n\nAgentScope Java is an agent-oriented programming framework for building LLM-powered applications. It provides everything you need to create intelligent agents: ReAct reasoning, tool calling, memory management, multi-agent collaboration, and more.\n\n## Highlights\n\n### ğŸ¯ Smart Agents, Full Control\n\nAgentScope adopts the ReAct (Reasoning-Acting) paradigm, enabling agents to autonomously plan and execute complex tasks. Unlike rigid workflow-based approaches, ReAct agents dynamically decide which tools to use and when, adapting to changing requirements in real-time.\n\nHowever, autonomy without control is a liability in production. AgentScope provides comprehensive runtime intervention mechanisms:\n\n- **Safe Interruption** - Pause agent execution at any point while preserving full context and tool state, enabling seamless resumption without data loss\n- **Graceful Cancellation** - Terminate long-running or unresponsive tool calls without corrupting agent state, allowing immediate recovery and redirection\n- **Human-in-the-Loop** - Inject corrections, additional context, or guidance at any reasoning step through the Hook system, maintaining human oversight over critical decisions\n\n### ğŸ› ï¸ Built-in Tools\n\nAgentScope includes production-ready tools that address common challenges in agent development:\n\n- **PlanNotebook** - A structured task management system that decomposes complex objectives into ordered, trackable steps. Agents can create, modify, pause, and resume multiple concurrent plans, ensuring systematic execution of multi-step workflows.\n\n- **Structured Output** - A self-correcting output parser that guarantees type-safe responses. When LLM output deviates from the expected format, the system automatically detects errors and guides the model to produce valid output, mapping results directly to Java POJOs without manual parsing.\n\n- **Long-term Memory** - Persistent memory storage with semantic search capabilities across sessions. Supports automatic management, agent-controlled recording, or hybrid modes. Enables multi-tenant isolation for enterprise deployments where agents serve multiple users independently.\n\n- **RAG (Retrieval-Augmented Generation)** - Seamless integration with enterprise knowledge bases. Supports both self-hosted embedding-based retrieval and managed services like Alibaba Cloud Bailian, grounding agent responses in authoritative data sources.\n\n### ğŸ”Œ Seamless Integration\n\nAgentScope is designed to integrate with existing enterprise infrastructure without requiring extensive modifications:\n\n- **MCP Protocol** - Integrate with any MCP-compatible server to instantly extend agent capabilities. Connect to the growing ecosystem of MCP tools and servicesâ€”from file systems and databases to web browsers and code interpretersâ€”without writing custom integration code.\n\n- **A2A Protocol** - Enable distributed multi-agent collaboration through standard service discovery. Register agent capabilities to Nacos or similar registries, allowing agents to discover and invoke each other as naturally as calling microservices.\n\n### ğŸš€ Production Grade\n\nBuilt for enterprise deployment requirements:\n\n- **High Performance** - Reactive architecture based on Project Reactor ensures non-blocking execution. GraalVM native image compilation achieves 200ms cold start times, making AgentScope suitable for serverless and auto-scaling environments.\n\n- **Security Sandbox** - AgentScope Runtime provides isolated execution environments for untrusted tool code. Includes pre-built sandboxes for GUI automation, file system operations, and mobile device interaction, preventing unauthorized access to system resources.\n\n- **Observability** - Native integration with OpenTelemetry for distributed tracing across the entire agent execution pipeline. AgentScope Studio provides visual debugging, real-time monitoring, and comprehensive logging for development and production environments.\n\n## Quick Start\n\n**Requirements:** JDK 17+\n\n```xml\n<dependency>\n    <groupId>io.agentscope</groupId>\n    <artifactId>agentscope</artifactId>\n    <version>1.0.7</version>\n</dependency>\n```\n\n```java\nReActAgent agent = ReActAgent.builder()\n    .name(\"Assistant\")\n    .sysPrompt(\"You are a helpful AI assistant.\")\n    .model(DashScopeChatModel.builder()\n        .apiKey(System.getenv(\"DASHSCOPE_API_KEY\"))\n        .modelName(\"qwen-max\")\n        .build())\n    .build();\n\nMsg response = agent.call(Msg.builder()\n        .textContent(\"Hello!\")\n        .build()).block();\nSystem.out.println(response.getTextContent());\n```\n\nFor more examples, see the [documentation](https://java.agentscope.io/).\n\n## Contributing\n\nWe welcome contributions! Please see [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.\n\n## Community\n\n| [Discord](https://discord.gg/eYMpfnkG8h)                     | DingTalk | WeChat |\n|--------------------------------------------------------------|----------| ---------|\n| <img src=\"./docs/imgs/discord.png\" width=\"100\" height=\"100\"> | <img src=\"./docs/imgs/dingtalk_qr_code.jpg\" width=\"100\" height=\"100\"> | <img src=\"./docs/imgs/wechat.png\" width=\"100\" height=\"100\"> |\n\n## License\n\nApache License 2.0 - see [LICENSE](./LICENSE) for details.\n\n## Publications\n\nIf you find AgentScope helpful, please cite our papers:\n\n- [AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications](https://arxiv.org/abs/2508.16279)\n- [AgentScope: A Flexible yet Robust Multi-Agent Platform](https://arxiv.org/abs/2402.14034)\n\n## Contributors\n\n<a href=\"https://github.com/agentscope-ai/agentscope-java/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=agentscope-ai/agentscope-java&max=999&columns=12&anon=1\" />\n</a>\n",
      "stars_today": 5
    },
    {
      "id": 1046505236,
      "name": "workspace",
      "full_name": "gemini-cli-extensions/workspace",
      "description": "Access Google Workspace when using Gemini CLI",
      "html_url": "https://github.com/gemini-cli-extensions/workspace",
      "stars": 261,
      "forks": 23,
      "language": "TypeScript",
      "topics": [],
      "created_at": "2025-08-28T19:35:17Z",
      "updated_at": "2026-01-25T02:27:15Z",
      "pushed_at": "2026-01-24T01:21:53Z",
      "open_issues": 21,
      "owner": {
        "login": "gemini-cli-extensions",
        "avatar_url": "https://avatars.githubusercontent.com/u/228020938?v=4"
      },
      "readme": "# Google Workspace Extension for Gemini CLI\n\n[![Build Status](https://github.com/gemini-cli-extensions/workspace/actions/workflows/ci.yml/badge.svg)](https://github.com/gemini-cli-extensions/workspace/actions/workflows/ci.yml)\n\nThe Google Workspace extension for Gemini CLI brings the power of your Google Workspace apps to your command line. Manage your documents, spreadsheets, presentations, emails, chat, and calendar events without leaving your terminal.\n\n## Prerequisites\n\nBefore using the Google Workspace extension, you need to be logged into your Google account.\n\n## Installation\n\nInstall the Google Workspace extension by running the following command from your terminal:\n\n```bash\ngemini extensions install https://github.com/gemini-cli-extensions/workspace\n```\n\n## Usage\n\nOnce the extension is installed, you can use it to interact with your Google Workspace apps. Here are a few examples:\n\n**Create a new Google Doc:**\n\n> \"Create a new Google Doc with the title 'My New Doc' and the content '# My New Document\\n\\nThis is a new document created from the command line.'\"\n\n**List your upcoming calendar events:**\n\n> \"What's on my calendar for today?\"\n\n**Search for a file in Google Drive:**\n\n> \"Find the file named 'my-file.txt' in my Google Drive.\"\n\n## Commands\n\nThis extension provides a variety of commands. Here are a few examples:\n\n### Get Schedule\n\n**Command:** `/calendar:get-schedule [date]`\n\nShows your schedule for today or a specified date.\n\n### Search Drive\n\n**Command:** `/drive:search <query>`\n\nSearches your Google Drive for files matching the given query.\n\n## Resources\n\n- [Documentation](docs/index.md): Detailed documentation on all the available tools.\n- [GitHub Issues](https://github.com/gemini-cli-extensions/workspace/issues): Report bugs or request features.\n\n## Important security consideration: Indirect Prompt Injection Risk\n\nWhen exposing any language model to untrusted data, there's a risk of an [indirect prompt injection attack](https://en.wikipedia.org/wiki/Prompt_injection). Agentic tools like Gemini CLI, connected to MCP servers, have access to a wide array of tools and APIs.\n\nThis MCP server grants the agent the ability to read, modify, and delete your Google Account data, as well as other data shared with you.\n\n* Never use this with untrusted tools\n* Never include untrusted inputs into the model context. This includes asking Gemini CLI to process mail, documents, or other resources from unverified sources.\n* Untrusted inputs may contain hidden instructions that could hijack your CLI session. Attackers can then leverage this to modify, steal, or destroy your data.\n* Always carefully review actions taken by Gemini CLI on your behalf to ensure they are correct and align with your intentions.\n\n## Contributing\n\nContributions are welcome! Please read the [CONTRIBUTING.md](CONTRIBUTING.md) file for details on how to contribute to this project.\n\n## ğŸ“„ Legal\n\n- **License**: [Apache License 2.0](LICENSE)\n- **Terms of Service**: [Terms of Service](https://policies.google.com/terms)\n- **Privacy Policy**: [Privacy Policy](https://policies.google.com/privacy)\n- **Security**: [Security Policy](SECURITY.md)\n\n",
      "stars_today": 5
    },
    {
      "id": 20300177,
      "name": "guava",
      "full_name": "google/guava",
      "description": "Google core libraries for Java",
      "html_url": "https://github.com/google/guava",
      "stars": 51440,
      "forks": 11133,
      "language": "Java",
      "topics": [
        "guava",
        "java"
      ],
      "created_at": "2014-05-29T16:23:17Z",
      "updated_at": "2026-01-25T02:26:30Z",
      "pushed_at": "2026-01-24T04:06:17Z",
      "open_issues": 713,
      "owner": {
        "login": "google",
        "avatar_url": "https://avatars.githubusercontent.com/u/1342004?v=4"
      },
      "readme": "# Guava: Google Core Libraries for Java\n\n[![GitHub Release](https://img.shields.io/github/v/release/google/guava)](https://github.com/google/guava/releases/latest)\n[![CI](https://github.com/google/guava/actions/workflows/ci.yml/badge.svg)](https://github.com/google/guava/actions/workflows/ci.yml)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/7197/badge)](https://www.bestpractices.dev/projects/7197)\n\n\n\nGuava is a set of core Java libraries from Google that includes new collection\ntypes (such as multimap and multiset), immutable collections, a graph library,\nand utilities for concurrency, I/O, hashing, primitives, strings, and more! It\nis widely used on most Java projects within Google, and widely used by many\nother companies as well.\n\n\n\nGuava comes in two flavors:\n\n*   The JRE flavor requires JDK 1.8 or higher.\n*   If you need support for Android, use\n    [the Android flavor](https://github.com/google/guava/wiki/Android). You can\n    find the Android Guava source in the [`android` directory].\n\n[`android` directory]: https://github.com/google/guava/tree/master/android\n\n## Adding Guava to your build\n\nGuava's Maven group ID is `com.google.guava`, and its artifact ID is `guava`.\nGuava provides two different \"flavors\": one for use on a (Java 8+) JRE and one\nfor use on Android or by any library that wants to be compatible with Android.\nThese flavors are specified in the Maven version field as either `33.5.0-jre` or\n`33.5.0-android`. For more about depending on Guava, see\n[using Guava in your build].\n\nTo add a dependency on Guava using Maven, use the following:\n\n```xml\n<dependency>\n  <groupId>com.google.guava</groupId>\n  <artifactId>guava</artifactId>\n  <version>33.5.0-jre</version>\n  <!-- or, for Android: -->\n  <version>33.5.0-android</version>\n</dependency>\n```\n\nTo add a dependency using Gradle:\n\n```gradle\ndependencies {\n  // Pick one:\n\n  // 1. Use Guava in your implementation only:\n  implementation(\"com.google.guava:guava:33.5.0-jre\")\n\n  // 2. Use Guava types in your public API:\n  api(\"com.google.guava:guava:33.5.0-jre\")\n\n  // 3. Android - Use Guava in your implementation only:\n  implementation(\"com.google.guava:guava:33.5.0-android\")\n\n  // 4. Android - Use Guava types in your public API:\n  api(\"com.google.guava:guava:33.5.0-android\")\n}\n```\n\nFor more information on when to use `api` and when to use `implementation`,\nconsult the\n[Gradle documentation on API and implementation separation](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_separation).\n\n## Snapshots and Documentation\n\nSnapshots of Guava built from the `master` branch are available through Maven\nusing version `999.0.0-HEAD-jre-SNAPSHOT`, or `999.0.0-HEAD-android-SNAPSHOT`\nfor the Android flavor.\n\n[Snapshot API Javadoc][guava-snapshot-api-docs] as well as\n[Snapshot API Diffs][guava-snapshot-api-diffs] are also available.\n\nAnother easy way to get to the Javadoc is to open\n[guava.dev/api](https://guava.dev/api). You can also jump right to a specific\nclass by appending the class name to guava.dev. For example,\n[guava.dev/ImmutableList](https://guava.dev/ImmutableList)!\n\n## Learn about Guava\n\n-   Our users' guide, [Guava Explained]\n-   [A nice collection](https://www.tfnico.com/presentations/google-guava) of\n    other helpful links\n\n## Links\n\n-   [GitHub project](https://github.com/google/guava)\n-   [Issue tracker: Report a defect or feature request](https://github.com/google/guava/issues/new)\n-   [StackOverflow: Ask \"how-to\" and \"why-didn't-it-work\" questions](https://stackoverflow.com/questions/ask?tags=guava+java)\n-   [guava-announce: Announcements of releases and upcoming significant changes](https://groups.google.com/group/guava-announce)\n-   [guava-discuss: For open-ended questions and discussion](https://groups.google.com/group/guava-discuss)\n\n## IMPORTANT WARNINGS\n\n1.  APIs marked with the `@Beta` annotation at the class or method level are\n    subject to change. They can be modified in any way, or even removed, at any\n    time. If your code is a library itself (i.e., it is used on the CLASSPATH of\n    users outside your own control), you should not use beta APIs unless you\n    [repackage] them. **If your code is a library, we strongly recommend using\n    the [Guava Beta Checker] to ensure that you do not use any `@Beta` APIs!**\n\n2.  APIs without `@Beta` will remain binary-compatible for the indefinite\n    future. (Previously, we sometimes removed such APIs after a deprecation\n    period. The last release to remove non-`@Beta` APIs was Guava 21.0.) Even\n    `@Deprecated` APIs will remain (again, unless they are `@Beta`). We have no\n    plans to start removing things again, but officially, we're leaving our\n    options open in case of surprises (like, say, a serious security problem).\n\n3.  Guava has one dependency that is needed for linkage at runtime:\n    `com.google.guava:failureaccess:1.0.3`. It also has\n    [some annotation-only dependencies][guava-deps], which we discuss in more\n    detail at that link.\n\n4.  Serialized forms of ALL objects are subject to change unless noted\n    otherwise. Do not persist these and assume they can be read by a future\n    version of the library.\n\n5.  Our classes are not designed to protect against a malicious caller. You\n    should not use them for communication between trusted and untrusted code.\n\n6.  For the mainline flavor, we test the libraries using OpenJDK 8, 11, and 17\n    on Linux, with some additional testing on newer JDKs and on Windows. Some\n    features, especially in `com.google.common.io`, may not work correctly in\n    non-Linux environments. For the Android flavor, our unit tests also run on\n    API level 23 (Marshmallow).\n\n[guava-snapshot-api-docs]: https://guava.dev/releases/snapshot-jre/api/docs/\n[guava-snapshot-api-diffs]: https://guava.dev/releases/snapshot-jre/api/diffs/\n[Guava Explained]: https://github.com/google/guava/wiki/Home\n[Guava Beta Checker]: https://github.com/google/guava-beta-checker\n\n<!-- References -->\n\n[using Guava in your build]: https://github.com/google/guava/wiki/UseGuavaInYourBuild\n[repackage]: https://github.com/google/guava/wiki/UseGuavaInYourBuild#what-if-i-want-to-use-beta-apis-from-a-library-that-people-use-as-a-dependency\n[guava-deps]: https://github.com/google/guava/wiki/UseGuavaInYourBuild#what-about-guavas-own-dependencies\n",
      "stars_today": 4
    },
    {
      "id": 1103607,
      "name": "jenkins",
      "full_name": "jenkinsci/jenkins",
      "description": "Jenkins automation server",
      "html_url": "https://github.com/jenkinsci/jenkins",
      "stars": 24947,
      "forks": 9340,
      "language": "Java",
      "topics": [
        "cicd",
        "continuous-delivery",
        "continuous-deployment",
        "continuous-integration",
        "devops",
        "groovy",
        "hacktoberfest",
        "java",
        "jenkins",
        "pipelines-as-code"
      ],
      "created_at": "2010-11-22T21:21:23Z",
      "updated_at": "2026-01-24T22:49:03Z",
      "pushed_at": "2026-01-25T01:05:18Z",
      "open_issues": 3550,
      "owner": {
        "login": "jenkinsci",
        "avatar_url": "https://avatars.githubusercontent.com/u/107424?v=4"
      },
      "readme": "<a href=\"https://jenkins.io\">\n    <img width=\"400\" src=\"https://www.jenkins.io/images/jenkins-logo-title-dark.svg\" alt=\"Jenkins logo\"> \n</a>\n\n[![Jenkins Regular Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog%2Fbadge.json)](https://www.jenkins.io/changelog)\n[![Jenkins LTS Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog-stable%2Fbadge.json)](https://www.jenkins.io/changelog-stable)\n[![Docker Pulls](https://img.shields.io/docker/pulls/jenkins/jenkins.svg)](https://hub.docker.com/r/jenkins/jenkins/)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3538/badge)](https://bestpractices.coreinfrastructure.org/projects/3538)\n[![Reproducible Builds](https://img.shields.io/badge/Reproducible_Builds-ok-green)](https://maven.apache.org/guides/mini/guide-reproducible-builds.html)\n[![Gitter](https://img.shields.io/gitter/room/jenkinsci/jenkins)](https://app.gitter.im/#/room/#jenkinsci_jenkins:gitter.im)\n\n---\n\n# Table of Contents\n\n- [About](#about)\n- [What to Use Jenkins for and When to Use It](#what-to-use-jenkins-for-and-when-to-use-it)\n- [Downloads](#downloads)\n- [Getting Started (Development)](#getting-started-development)\n- [Source](#source)\n- [Contributing to Jenkins](#contributing-to-jenkins)\n- [News and Website](#news-and-website)\n- [Governance](#governance)\n- [Adopters](#adopters)\n- [License](#license)\n\n---\n\n# About\n\nIn a nutshell, Jenkins is the leading open-source automation server.\nBuilt with Java, it provides over 2,000 [plugins](https://plugins.jenkins.io/) to support automating virtually anything,\nso that humans can spend their time doing things machines cannot.\n\n# What to Use Jenkins for and When to Use It\n\nUse Jenkins to automate your development workflow, so you can focus on work that matters most. Jenkins is commonly used for:\n\n- Building projects\n- Running tests to detect bugs and other issues as soon as they are introduced\n- Static code analysis\n- Deployment\n\nExecute repetitive tasks, save time, and optimize your development process with Jenkins.\n\n# Downloads\n\nThe Jenkins project provides official distributions as WAR files, Docker images, native packages and installers for platforms including several Linux distributions and Windows.\nSee the [Downloads](https://www.jenkins.io/download) page for references.\n\nFor all distributions Jenkins offers two release lines:\n\n- [Weekly](https://www.jenkins.io/download/weekly/) -\n  Frequent releases which include all new features, improvements, and bug fixes.\n- [Long-Term Support (LTS)](https://www.jenkins.io/download/lts/) -\n  Older release line which gets periodically updated via bug fix backports.\n\nLatest releases:\n\n[![Jenkins Regular Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog%2Fbadge.json)](https://www.jenkins.io/changelog)\n[![Jenkins LTS Release](https://img.shields.io/endpoint?url=https%3A%2F%2Fwww.jenkins.io%2Fchangelog-stable%2Fbadge.json)](https://www.jenkins.io/changelog-stable)\n\n# Getting Started (Development)\n\nFor more information on setting up your development environment, contributing, and working with Jenkins internals, check the [contributing guide](CONTRIBUTING.md) and the [Jenkins Developer Documentation](https://www.jenkins.io/doc/developer/).\n\n# Source\n\nOur latest and greatest source of Jenkins can be found on [GitHub](https://github.com/jenkinsci/jenkins). Fork us!\n\n# Contributing to Jenkins\n\nNew to open source or Jenkins? Hereâ€™s how to get started:\n\n- Read the [Contribution Guidelines](CONTRIBUTING.md)\n- Check our [good first issues](https://github.com/jenkinsci/jenkins/issues?q=is%3Aissue%20is%3Aopen%20label%3A%22good%20first%20issue%22)\n- Join our [Gitter chat](https://app.gitter.im/#/room/#jenkinsci_newcomer-contributors:gitter.im) for questions and help\n\nFor more information about participating in the community and contributing to the Jenkins project,\nsee [this page](https://www.jenkins.io/participate/).\n\nDocumentation for Jenkins core maintainers is in the [maintainers guidelines](docs/MAINTAINERS.adoc).\n\n# News and Website\n\nAll information about Jenkins can be found on our [official website](https://www.jenkins.io/), including documentation, blog posts, plugin listings, community updates, and more.\n\nStay up-to-date with the latest Jenkins news, tutorials, and release notes:\n\n- [Jenkins Blog](https://www.jenkins.io/blog/)\n- [Documentation](https://www.jenkins.io/doc/)\n- [Plugins Index](https://plugins.jenkins.io/)\n- [Events](https://www.jenkins.io/events/)\n\nFollow Jenkins on social media to stay connected with the community:\n\n- [Twitter / X](https://x.com/jenkinsci)\n- [YouTube](https://www.youtube.com/@jenkinscicd)\n- [LinkedIn](https://www.linkedin.com/company/jenkins-project/)\n\n# Governance\n\nThe Jenkins project is governed by an open source community.\nTo learn more about the governance structure, project leadership, and how decisions are made, visit the [Governance Page](https://www.jenkins.io/project/governance/).\n\n# Adopters\n\nJenkins is trusted by **millions of users** and adopted by **thousands of companies** around the world â€” from startups to enterprises â€” to automate their software delivery pipelines.\n\nExplore the [Adopters Page](https://www.jenkins.io/project/adopters/) and https://stories.jenkins.io to see:\n\n- Companies and organizations using Jenkins\n- Success stories and case studies\n- How Jenkins is used in different industries\n\n> If your company uses Jenkins and you'd like to be featured, feel free to [submit your story](https://www.jenkins.io/project/adopters/contributing/#share-your-story)!\n\n# License\n\nJenkins is **licensed** under the **[MIT License](LICENSE.txt)**.\n",
      "stars_today": 4
    },
    {
      "id": 27729907,
      "name": "grpc-go",
      "full_name": "grpc/grpc-go",
      "description": "The Go language implementation of gRPC. HTTP/2 based RPC",
      "html_url": "https://github.com/grpc/grpc-go",
      "stars": 22732,
      "forks": 4634,
      "language": "Go",
      "topics": [
        "dogs-over-cats",
        "giant-robots",
        "go",
        "golang",
        "grpc",
        "hacktoberfest",
        "microservices",
        "not-nanoservices",
        "proto",
        "rpc"
      ],
      "created_at": "2014-12-08T18:59:34Z",
      "updated_at": "2026-01-25T00:35:26Z",
      "pushed_at": "2026-01-22T06:17:01Z",
      "open_issues": 135,
      "owner": {
        "login": "grpc",
        "avatar_url": "https://avatars.githubusercontent.com/u/7802525?v=4"
      },
      "readme": "# gRPC-Go\n\n[![GoDoc](https://pkg.go.dev/badge/google.golang.org/grpc)][API]\n[![GoReportCard](https://goreportcard.com/badge/grpc/grpc-go)](https://goreportcard.com/report/github.com/grpc/grpc-go)\n[![codecov](https://codecov.io/gh/grpc/grpc-go/graph/badge.svg)](https://codecov.io/gh/grpc/grpc-go)\n\nThe [Go][] implementation of [gRPC][]: A high performance, open source, general\nRPC framework that puts mobile and HTTP/2 first. For more information see the\n[Go gRPC docs][], or jump directly into the [quick start][].\n\n## Prerequisites\n\n- **[Go][]**: any one of the **two latest major** [releases][go-releases].\n\n## Installation\n\nSimply add the following import to your code, and then `go [build|run|test]`\nwill automatically fetch the necessary dependencies:\n\n\n```go\nimport \"google.golang.org/grpc\"\n```\n\n> **Note:** If you are trying to access `grpc-go` from **China**, see the\n> [FAQ](#FAQ) below.\n\n## Learn more\n\n- [Go gRPC docs][], which include a [quick start][] and [API\n  reference][API] among other resources\n- [Low-level technical docs](Documentation) from this repository\n- [Performance benchmark][]\n- [Examples](examples)\n- [Contribution guidelines](CONTRIBUTING.md)\n\n## FAQ\n\n### I/O Timeout Errors\n\nThe `golang.org` domain may be blocked from some countries. `go get` usually\nproduces an error like the following when this happens:\n\n```console\n$ go get -u google.golang.org/grpc\npackage google.golang.org/grpc: unrecognized import path \"google.golang.org/grpc\" (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)\n```\n\nTo build Go code, there are several options:\n\n- Set up a VPN and access google.golang.org through that.\n\n- With Go module support: it is possible to use the `replace` feature of `go\n  mod` to create aliases for golang.org packages.  In your project's directory:\n\n  ```sh\n  go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest\n  go mod tidy\n  go mod vendor\n  go build -mod=vendor\n  ```\n\n  Again, this will need to be done for all transitive dependencies hosted on\n  golang.org as well. For details, refer to [golang/go issue\n  #28652](https://github.com/golang/go/issues/28652).\n\n### Compiling error, undefined: grpc.SupportPackageIsVersion\n\nPlease update to the latest version of gRPC-Go using\n`go get google.golang.org/grpc`.\n\n### How to turn on logging\n\nThe default logger is controlled by environment variables. Turn everything on\nlike this:\n\n```console\n$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99\n$ export GRPC_GO_LOG_SEVERITY_LEVEL=info\n```\n\n### The RPC failed with error `\"code = Unavailable desc = transport is closing\"`\n\nThis error means the connection the RPC is using was closed, and there are many\npossible reasons, including:\n 1. mis-configured transport credentials, connection failed on handshaking\n 1. bytes disrupted, possibly by a proxy in between\n 1. server shutdown\n 1. Keepalive parameters caused connection shutdown, for example if you have\n    configured your server to terminate connections regularly to [trigger DNS\n    lookups](https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779).\n    If this is the case, you may want to increase your\n    [MaxConnectionAgeGrace](https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters),\n    to allow longer RPC calls to finish.\n\nIt can be tricky to debug this because the error happens on the client side but\nthe root cause of the connection being closed is on the server side. Turn on\nlogging on __both client and server__, and see if there are any transport\nerrors.\n\n[API]: https://pkg.go.dev/google.golang.org/grpc\n[Go]: https://golang.org\n[Go module]: https://github.com/golang/go/wiki/Modules\n[gRPC]: https://grpc.io\n[Go gRPC docs]: https://grpc.io/docs/languages/go\n[Performance benchmark]: https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608\n[quick start]: https://grpc.io/docs/languages/go/quickstart\n[go-releases]: https://golang.org/doc/devel/release.html\n",
      "stars_today": 4
    },
    {
      "id": 33352201,
      "name": "grpc-gateway",
      "full_name": "grpc-ecosystem/grpc-gateway",
      "description": "gRPC to JSON proxy generator following the gRPC HTTP spec",
      "html_url": "https://github.com/grpc-ecosystem/grpc-gateway",
      "stars": 19781,
      "forks": 2364,
      "language": "Go",
      "topics": [
        "go",
        "grpc",
        "grpc-gateway",
        "openapi",
        "rest-api",
        "restful-api",
        "swagger"
      ],
      "created_at": "2015-04-03T07:25:13Z",
      "updated_at": "2026-01-24T15:50:34Z",
      "pushed_at": "2026-01-23T20:02:48Z",
      "open_issues": 153,
      "owner": {
        "login": "grpc-ecosystem",
        "avatar_url": "https://avatars.githubusercontent.com/u/19352526?v=4"
      },
      "readme": "<div align=\"center\">\n<h1>gRPC-Gateway</h1>\n<p>\ngRPC to JSON proxy generator following the gRPC HTTP spec\n</p>\n<a href=\"https://github.com/grpc-ecosystem/grpc-gateway/actions/workflows/ci.yml\"><img src=\"https://img.shields.io/github/actions/workflow/status/grpc-ecosystem/grpc-gateway/ci.yml?color=379c9c&label=build&logo=github&logoColor=ffffff&style=flat-square\"/></a>\n<a href=\"https://app.slack.com/client/T029RQSE6/CBATURP1D\"><img src=\"https://img.shields.io/badge/slack-grpc--gateway-379c9c?logo=slack&logoColor=ffffff&style=flat-square\"/></a>\n<a href=\"https://github.com/grpc-ecosystem/grpc-gateway/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/grpc-ecosystem/grpc-gateway?color=379c9c&style=flat-square\"/></a>\n<a href=\"https://github.com/grpc-ecosystem/grpc-gateway/releases\"><img src=\"https://img.shields.io/github/v/release/grpc-ecosystem/grpc-gateway?color=379c9c&logoColor=ffffff&style=flat-square\"/></a>\n<a href=\"https://github.com/grpc-ecosystem/grpc-gateway/stargazers\"><img src=\"https://img.shields.io/github/stars/grpc-ecosystem/grpc-gateway?color=379c9c&style=flat-square\"/></a>\n<a href=\"https://slsa.dev/images/gh-badge-level3.svg\"><img src=\"https://slsa.dev/images/gh-badge-level3.svg\"/></a>\n\n</div>\n\n## About\n\nThe gRPC-Gateway is a plugin of the Google protocol buffers compiler\n[protoc](https://github.com/protocolbuffers/protobuf).\nIt reads protobuf service definitions and generates a reverse-proxy server which\ntranslates a RESTful HTTP API into gRPC. This server is generated according to the\n[`google.api.http`](https://github.com/googleapis/googleapis/blob/master/google/api/http.proto#L46)\nannotations in your service definitions.\n\nThis helps you provide your APIs in both gRPC and RESTful style at the same time.\n\n<div align=\"center\">\n<img src=\"docs/assets/images/architecture_introduction_diagram.svg\" />\n</div>\n\n## Docs\n\nYou can read our docs at:\n\n- https://grpc-ecosystem.github.io/grpc-gateway/\n\n## Testimonials\n\n> We use the gRPC-Gateway to serve millions of API requests per day,\n> and have been since 2018 and through all of that,\n> we have never had any issues with it.\n>\n> _- William Mill, [Ad Hoc](http://adhocteam.us/)_\n\n## Background\n\ngRPC is great -- it generates API clients and server stubs in many programming\nlanguages, it is fast, easy-to-use, bandwidth-efficient and its design is\ncombat-proven by Google. However, you might still want to provide a traditional\nRESTful JSON API as well. Reasons can range from maintaining\nbackward-compatibility, supporting languages or clients that are not well supported by\ngRPC, to simply maintaining the aesthetics and tooling involved with a RESTful\nJSON architecture.\n\nThis project aims to provide that HTTP+JSON interface to your gRPC service.\nA small amount of configuration in your service to attach HTTP semantics is all\nthat's needed to generate a reverse-proxy with this library.\n\n## Installation\n\n### Compile from source\n\nThe following instructions assume you are using\n[Go Modules](https://go.dev/wiki/Modules) for dependency\nmanagement. Use a\n[tool dependency](https://go.dev/wiki/Modules#how-can-i-track-tool-dependencies-for-a-module)\nto track the versions of the following executable packages:\n\n```go\n// +build tools\n\npackage tools\n\nimport (\n    _ \"github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway\"\n    _ \"github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2\"\n    _ \"google.golang.org/grpc/cmd/protoc-gen-go-grpc\"\n    _ \"google.golang.org/protobuf/cmd/protoc-gen-go\"\n)\n```\n\nRun `go mod tidy` to resolve the versions. Install by running\n\n```sh\ngo install \\\n    github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway \\\n    github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2 \\\n    google.golang.org/protobuf/cmd/protoc-gen-go \\\n    google.golang.org/grpc/cmd/protoc-gen-go-grpc\n```\n\nThis will place four binaries in your `$GOBIN`;\n\n- `protoc-gen-grpc-gateway`\n- `protoc-gen-openapiv2`\n- `protoc-gen-go`\n- `protoc-gen-go-grpc`\n\nMake sure that your `$GOBIN` is in your `$PATH`.\n\n### **Using the `tool` Directive in Go 1.24**\n\nStarting from Go 1.24, the `tool` directive in `go.mod` provides a structured way to track and manage executable dependencies. This replaces the previous workaround of using a separate `tools.go` file with blank imports.\n\n#### **Tracking Tools in `go.mod`**\n\nInstead of manually importing tool dependencies in a Go source file, you can now use the `tool` directive in `go.mod` to declare the tools your project depends on. For example:\n\n```go\nmodule tools\n\ngo 1.24\n\ntool (\n\tgithub.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway\n\tgithub.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2\n\tgoogle.golang.org/grpc/cmd/protoc-gen-go-grpc\n\tgoogle.golang.org/protobuf/cmd/protoc-gen-go\n)\n```\n\n#### **Managing Tool Dependencies**\n\nTo add tools to your module, use the `-tool` flag with `go get`:\n\n```sh\ngo get -tool github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway\ngo get -tool github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2\ngo get -tool google.golang.org/protobuf/cmd/protoc-gen-go\ngo get -tool google.golang.org/grpc/cmd/protoc-gen-go-grpc\n```\n\nThis automatically updates `go.mod`, adding the tools under the `tool` directive along with `require` statements to ensure version tracking.\n\n### Install Tools\n\nOnce the tool dependencies are properly recorded in the `go.mod` file, simply execute the following command in the root directory of your project:\n\n```sh\ngo install tool\n```\n\nThis will place four binaries in your `$GOBIN`;\n\n- `protoc-gen-grpc-gateway`\n- `protoc-gen-openapiv2`\n- `protoc-gen-go`\n- `protoc-gen-go-grpc`\n\nMake sure that your `$GOBIN` is in your `$PATH`.\n\n### Download the binaries\n\nYou may alternatively download the binaries from the [GitHub releases page](https://github.com/grpc-ecosystem/grpc-gateway/releases/latest).\nWe generate [SLSA3 signatures](slsa.dev) using the OpenSSF's [slsa-framework/slsa-github-generator](https://github.com/slsa-framework/slsa-github-generator) during the release process. To verify a release binary:\n\n1. Install the verification tool from [slsa-framework/slsa-verifier#installation](https://github.com/slsa-framework/slsa-verifier#installation).\n2. Download the provenance file `attestation.intoto.jsonl` from the [GitHub releases page](https://github.com/grpc-ecosystem/grpc-gateway/releases/latest).\n3. Run the verifier:\n\n```shell\nslsa-verifier -artifact-path <the-binary> -provenance attestation.intoto.jsonl -source github.com/grpc-ecosystem/grpc-gateway -tag <the-tag>\n```\n\nAlternatively, see the section on remotely managed plugin versions below.\n\n## Usage\n\n### 1.Define your [gRPC](https://grpc.io/docs/) service using protocol buffers\n\n`your_service.proto`:\n\n```protobuf\n syntax = \"proto3\";\n package your.service.v1;\n option go_package = \"github.com/yourorg/yourprotos/gen/go/your/service/v1\";\n\n message StringMessage {\n   string value = 1;\n }\n\n service YourService {\n   rpc Echo(StringMessage) returns (StringMessage) {}\n }\n```\n\n### 2. Generate gRPC stubs\n\nThis step generates the gRPC stubs that you can use to implement the service and consume from clients:\n\nHere's an example `buf.gen.yaml` you can use to generate the stubs with [buf](https://github.com/bufbuild/buf):\n\n```yaml\nversion: v2\nplugins:\n  - local: protoc-gen-go\n    out: gen/go\n    opt:\n      - paths=source_relative\n  - local: protoc-gen-go-grpc\n    out: gen/go\n    opt:\n      - paths=source_relative\n```\n\nWith this file in place, you can generate your files using `buf generate`.\n\n> For a complete example of using `buf generate` to generate protobuf stubs, see\n> [the boilerplate repo](https://github.com/johanbrandhorst/grpc-gateway-boilerplate).\n> For more information on generating the stubs with buf, see\n> [the official documentation](https://docs.buf.build/generate-usage).\n\nIf you are using `protoc` to generate stubs, here's an example of what a command\nmight look like:\n\n```sh\nprotoc -I . \\\n    --go_out ./gen/go/ --go_opt paths=source_relative \\\n    --go-grpc_out ./gen/go/ --go-grpc_opt paths=source_relative \\\n    your/service/v1/your_service.proto\n```\n\n### 3. Implement your service in gRPC as usual.\n\n### 4. Generate reverse-proxy using `protoc-gen-grpc-gateway`\n\nAt this point, you have 3 options:\n\n- no further modifications, use the default mapping to HTTP semantics (method, path, etc.)\n  - this will work on any `.proto` file, but will not allow setting HTTP paths, request parameters or similar\n- additional `.proto` modifications to use a custom mapping\n  - relies on parameters in the `.proto` file to set custom HTTP mappings\n- no `.proto` modifications, but use an external configuration file\n  - relies on an external configuration file to set custom HTTP mappings\n  - mostly useful when the source proto file isn't under your control\n\n#### 1. Using the default mapping\n\nThis requires no additional modification to the `.proto` file but does require enabling a specific option when executing the plugin.\nThe `generate_unbound_methods` should be enabled.\n\nHere's what a `buf.gen.yaml` file might look like with this option enabled:\n\n```yaml\nversion: v2\nplugins:\n  - local: protoc-gen-go\n    out: gen/go\n    opt:\n      - paths=source_relative\n  - local: protoc-gen-go-grpc\n    out: gen/go\n    opt:\n      - paths=source_relative\n  - local: protoc-gen-grpc-gateway\n    out: gen/go\n    opt:\n      - paths=source_relative\n      - generate_unbound_methods=true\n```\n\nWith `protoc` (just the grpc-gateway stubs):\n\n```sh\nprotoc -I . --grpc-gateway_out ./gen/go \\\n    --grpc-gateway_opt paths=source_relative \\\n    --grpc-gateway_opt generate_unbound_methods=true \\\n    your/service/v1/your_service.proto\n```\n\n#### 2. With custom annotations\n\nAdd a [`google.api.http`](https://github.com/googleapis/googleapis/blob/master/google/api/http.proto#L46)\nannotation to your .proto file\n\n`your_service.proto`:\n\n```diff\n syntax = \"proto3\";\n package your.service.v1;\n option go_package = \"github.com/yourorg/yourprotos/gen/go/your/service/v1\";\n+\n+import \"google/api/annotations.proto\";\n+\n message StringMessage {\n   string value = 1;\n }\n\n service YourService {\n-  rpc Echo(StringMessage) returns (StringMessage) {}\n+  rpc Echo(StringMessage) returns (StringMessage) {\n+    option (google.api.http) = {\n+      post: \"/v1/example/echo\"\n+      body: \"*\"\n+    };\n+  }\n }\n```\n\n> You will need to provide the required third party protobuf files to the protobuf compiler.\n> If you are using [buf](https://github.com/bufbuild/buf), this dependency can\n> be added to the `deps` array in your `buf.yaml` under the name\n> `buf.build/googleapis/googleapis`:\n>\n> ```yaml\n> version: v2\n> name: buf.build/yourorg/myprotos\n> deps:\n>   - buf.build/googleapis/googleapis\n> ```\n>\n> Always run `buf dep update` after adding a dependency to your `buf.yaml`.\n\nSee [a_bit_of_everything.proto](examples/internal/proto/examplepb/a_bit_of_everything.proto)\nfor examples of more annotations you can add to customize gateway behavior\nand generated OpenAPI output.\n\nHere's what a `buf.gen.yaml` file might look like:\n\n```yaml\nversion: v2\nplugins:\n  - local: protoc-gen-go\n    out: gen/go\n    opt:\n      - paths=source_relative\n  - local: protoc-gen-go-grpc\n    out: gen/go\n    opt:\n      - paths=source_relative\n  - local: protoc-gen-grpc-gateway\n    out: gen/go\n    opt:\n      - paths=source_relative\n```\n\nIf you are using `protoc` to generate stubs, you need to ensure the required\ndependencies are available to the compiler at compile time. These can be found\nby manually cloning and copying the relevant files from the\n[googleapis repository](https://github.com/googleapis/googleapis), and providing\nthem to `protoc` when running. The files you will need are:\n\n```\ngoogle/api/annotations.proto\ngoogle/api/field_behavior.proto\ngoogle/api/http.proto\ngoogle/api/httpbody.proto\n```\n\nHere's what a `protoc` execution might look like:\n\n```sh\nprotoc -I . --grpc-gateway_out ./gen/go \\\n    --grpc-gateway_opt paths=source_relative \\\n    your/service/v1/your_service.proto\n```\n\n#### 3. External configuration\n\nIf you do not want to (or cannot) modify the proto file for use with gRPC-Gateway you can\nalternatively use an external\n[gRPC Service Configuration](https://cloud.google.com/endpoints/docs/grpc/grpc-service-config) file.\n[Check our documentation](https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/grpc_api_configuration/)\nfor more information. This is best combined with the `standalone=true` option\nto generate a file that can live in its own package, separate from the files\ngenerated by the source protobuf file.\n\nHere's what a `buf.gen.yaml` file might look like with this option enabled:\n\n```yaml\nversion: v2\nplugins:\n  - local: protoc-gen-go\n    out: gen/go\n    opt:\n      - paths=source_relative\n  - local: protoc-gen-go-grpc\n    out: gen/go\n    opt:\n      - paths=source_relative\n  - local: protoc-gen-grpc-gateway\n    out: gen/go\n    opt:\n      - paths=source_relative\n      - grpc_api_configuration=path/to/config.yaml\n      - standalone=true\n```\n\nWith `protoc` (just the grpc-gateway stubs):\n\n```sh\nprotoc -I . --grpc-gateway_out ./gen/go \\\n    --grpc-gateway_opt paths=source_relative \\\n    --grpc-gateway_opt grpc_api_configuration=path/to/config.yaml \\\n    --grpc-gateway_opt standalone=true \\\n    your/service/v1/your_service.proto\n```\n\n### 5. Write an entrypoint for the HTTP reverse-proxy server\n\n```go\npackage main\n\nimport (\n  \"context\"\n  \"flag\"\n  \"net/http\"\n\n  \"github.com/grpc-ecosystem/grpc-gateway/v2/runtime\"\n  \"google.golang.org/grpc\"\n  \"google.golang.org/grpc/credentials/insecure\"\n  \"google.golang.org/grpc/grpclog\"\n\n  gw \"github.com/yourorg/yourrepo/proto/gen/go/your/service/v1/your_service\"  // Update\n)\n\nvar (\n  // command-line options:\n  // gRPC server endpoint\n  grpcServerEndpoint = flag.String(\"grpc-server-endpoint\",  \"localhost:9090\", \"gRPC server endpoint\")\n)\n\nfunc run() error {\n  ctx := context.Background()\n  ctx, cancel := context.WithCancel(ctx)\n  defer cancel()\n\n  // Register gRPC server endpoint\n  // Note: Make sure the gRPC server is running properly and accessible\n  mux := runtime.NewServeMux()\n  opts := []grpc.DialOption{grpc.WithTransportCredentials(insecure.NewCredentials())}\n  err := gw.RegisterYourServiceHandlerFromEndpoint(ctx, mux,  *grpcServerEndpoint, opts)\n  if err != nil {\n    return err\n  }\n\n  // Start HTTP server (and proxy calls to gRPC server endpoint)\n  return http.ListenAndServe(\":8081\", mux)\n}\n\nfunc main() {\n  flag.Parse()\n\n  if err := run(); err != nil {\n    grpclog.Fatal(err)\n  }\n}\n```\n\n### 6. (Optional) Generate OpenAPI definitions using `protoc-gen-openapiv2`\n\nHere's what a `buf.gen.yaml` file might look like:\n\n```yaml\nversion: v2\nplugins:\n  - local: protoc-gen-go\n    out: gen/go\n    opt:\n      - paths=source_relative\n  - local: protoc-gen-go-grpc\n    out: gen/go\n    opt:\n      - paths=source_relative\n  - local: protoc-gen-grpc-gateway\n    out: gen/go\n    opt:\n      - paths=source_relative\n      - generate_unbound_methods=true\n  - local: protoc-gen-openapiv2\n    out: gen/go\n```\n\nTo use the custom protobuf annotations supported by `protoc-gen-openapiv2`, we need\nanother dependency added to our protobuf generation step. If you are using\n`buf`, you can add the `buf.build/grpc-ecosystem/grpc-gateway` dependency\nto your `deps` array:\n\n```yaml\nversion: v2\nname: buf.build/yourorg/myprotos\ndeps:\n  - buf.build/googleapis/googleapis\n  - buf.build/grpc-ecosystem/grpc-gateway\n```\n\nWith `protoc` (just the swagger file):\n\n```sh\nprotoc -I . --openapiv2_out ./gen/openapiv2 \\\n    your/service/v1/your_service.proto\n```\n\nIf you are using `protoc` to generate stubs, you will need to copy the protobuf\nfiles from the `protoc-gen-openapiv2/options` directory of this repository,\nand providing them to `protoc` when running.\n\nNote that this plugin also supports generating OpenAPI definitions for unannotated methods;\nuse the `generate_unbound_methods` option to enable this.\n\nIt is possible with the HTTP mapping for a gRPC service method to create duplicate mappings\nwith the only difference being constraints on the path parameter.\n\n`/v1/{name=projects/*}` and `/v1/{name=organizations/*}` both become `/v1/{name}`. When\nthis occurs the plugin will rename the path parameter with a \"\\_1\" (or \"\\_2\" etc) suffix\nto differentiate the different operations. So in the above example, the 2nd path would become\n`/v1/{name_1=organizations/*}`. This can also cause OpenAPI clients to URL encode the \"/\" that is\npart of the path parameter as that is what OpenAPI defines in the specification. To allow gRPC gateway to\naccept the URL encoded slash and still route the request, use the UnescapingModeAllCharacters or\nUnescapingModeLegacy (which is the default currently though may change in future versions). See\n[Customizing Your Gateway](https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/customizing_your_gateway/)\nfor more information.\n\n## Usage with remote plugins\n\nAs an alternative to all of the above, you can use `buf` with\n[remote plugins](https://buf.build/docs/bsr/remote-plugins/usage)\nto manage plugin versions and generation. An example `buf.gen.yaml` using remote\nplugin generation looks like this:\n\n```yaml\nversion: v2\nplugins:\n  - remote: buf.build/protocolbuffers/go:v1.31.0\n    out: gen/go\n    opt:\n      - paths=source_relative\n  - remote: buf.build/grpc/go:v1.3.0\n    out: gen/go\n    opt:\n      - paths=source_relative\n  - remote: buf.build/grpc-ecosystem/gateway:v2.16.2\n    out: gen/go\n    opt:\n      - paths=source_relative\n  - remote: buf.build/grpc-ecosystem/openapiv2:v2.16.2\n    out: gen/openapiv2\n```\n\nThis requires no local installation of any plugins. Be careful to use the same\nversion of the generator as the runtime library, i.e. if using `v2.16.2`, run\n\n```shell\n$ go get github.com/grpc-ecosystem/grpc-gateway/v2@v2.16.2\n```\n\nTo get the same version of the runtime in your `go.mod`.\n\nNote that usage of remote plugins is incompatible with usage of external configuration files like [grpc_api_configuration](https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/grpc_api_configuration/#using-an-external-configuration-file).\n\n## Video intro\n\nThis GopherCon UK 2019 presentation from our maintainer [@JohanBrandhorst](https://github.com/johanbrandhorst) provides a good intro to using the gRPC-Gateway. It uses the following boilerplate repo as a base: https://github.com/johanbrandhorst/grpc-gateway-boilerplate.\n\n<div align=\"center\">\n<a href=\"https://www.youtube.com/watch?v=Pq1paKC-fXk\">\n<img src=\"https://img.youtube.com/vi/Pq1paKC-fXk/0.jpg\" />\n</a>\n</div>\n\n## Parameters and flags\n\nWhen using `buf` to generate stubs, flags and parameters are passed through\nthe `opt` field in your `buf.gen.yaml` file, for example:\n\n```yaml\nversion: v2\nplugins:\n  - local: protoc-gen-grpc-gateway\n    out: gen/go\n    opt:\n      - paths=source_relative\n      - grpc_api_configuration=path/to/config.yaml\n      - standalone=true\n```\n\nDuring code generation with `protoc`, flags to gRPC-Gateway tools must be passed\nthrough `protoc` using one of 2 patterns:\n\n- as part of the `--<tool_suffix>_out` `protoc` parameter: `--<tool_suffix>_out=<flags>:<path>`\n\n```sh\n--grpc-gateway_out=repeated_path_param_separator=ssv:.\n--openapiv2_out=repeated_path_param_separator=ssv:.\n```\n\n- using additional `--<tool_suffix>_opt` parameters: `--<tool_suffix>_opt=<flag>[,<flag>]*`\n\n```sh\n--grpc-gateway_opt repeated_path_param_separator=ssv\n--openapiv2_opt repeated_path_param_separator=ssv\n```\n\n## More examples\n\nMore examples are available under the `examples` directory.\n\n- `proto/examplepb/echo_service.proto`, `proto/examplepb/a_bit_of_everything.proto`, `proto/examplepb/unannotated_echo_service.proto`: service definition\n  - `proto/examplepb/echo_service.pb.go`, `proto/examplepb/a_bit_of_everything.pb.go`, `proto/examplepb/unannotated_echo_service.pb.go`: [generated] stub of the service\n  - `proto/examplepb/echo_service.pb.gw.go`, `proto/examplepb/a_bit_of_everything.pb.gw.go`, `proto/examplepb/uannotated_echo_service.pb.gw.go`: [generated] reverse proxy for the service\n  - `proto/examplepb/unannotated_echo_service.yaml`: gRPC API Configuration for `unannotated_echo_service.proto`\n- `server/main.go`: service implementation\n- `main.go`: entrypoint of the generated reverse proxy\n\nTo use the same port for custom HTTP handlers (e.g. serving `swagger.json`),\ngRPC-Gateway, and a gRPC server, see\n[this example by CoreOS](https://github.com/philips/grpc-gateway-example/blob/master/cmd/serve.go)\n(and its accompanying [blog post](https://web.archive.org/web/20201112010739/https://coreos.com/blog/grpc-protobufs-swagger.html)).\n\n[This example by neiro.ai](https://github.com/mynalabsai/grpc_gateway_media_example) (and its accompanying [blog post](https://medium.com/neiro-ai/grpc-gateway-for-media-api-by-neiro-9033caab12c8)) shows how mediafiles using `multipart/form-data` can be integrated into rpc messages using a middleware.\n\n## Features\n\n### Supported\n\n- Generating JSON API handlers.\n- Method parameters in the request body.\n- Method parameters in the request path.\n- Method parameters in the query string.\n- Enum fields in the path parameter (including repeated enum fields).\n- Mapping streaming APIs to newline-delimited JSON streams.\n- Mapping HTTP headers with `Grpc-Metadata-` prefix to gRPC metadata (prefixed with `grpcgateway-`)\n- Optionally emitting API definitions for\n  [OpenAPI (Swagger) v2](https://swagger.io/docs/specification/2-0/basic-structure/).\n- Setting [gRPC timeouts](https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md#requests)\n  through inbound HTTP `Grpc-Timeout` header.\n- Partial support for [gRPC API Configuration](https://cloud.google.com/endpoints/docs/grpc/grpc-service-config)\n  files as an alternative to annotation.\n- Automatically translating PATCH requests into Field Mask gRPC requests. See\n  [the docs](https://grpc-ecosystem.github.io/grpc-gateway/docs/mapping/patch_feature/)\n  for more information.\n- [Protobuf Editions](https://protobuf.dev/editions/overview/) support (edition 2023).\n- Go [Opaque API](https://go.dev/blog/protobuf-opaque) support.\n\n### No plan to support\n\nBut patches are welcome.\n\n- Method parameters in HTTP headers.\n- Handling trailer metadata.\n- Encoding request/response body in XML.\n- True bi-directional streaming.\n\n## Mapping gRPC to HTTP\n\n- [How gRPC error codes map to HTTP status codes in the response](https://github.com/grpc-ecosystem/grpc-gateway/blob/main/runtime/errors.go#L15).\n- HTTP request source IP is added as `X-Forwarded-For` gRPC request header.\n- HTTP request host is added as `X-Forwarded-Host` gRPC request header.\n- HTTP `Authorization` header is added as `authorization` gRPC request header.\n- Remaining Permanent HTTP header keys (as specified by the IANA\n  [here](http://www.iana.org/assignments/message-headers/message-headers.xhtml))\n  are prefixed with `grpcgateway-` and added with their values to gRPC request\n  header.\n- HTTP headers that start with 'Grpc-Metadata-' are mapped to gRPC metadata\n  (prefixed with `grpcgateway-`).\n- While configurable, the default {un,}marshaling uses\n  [protojson](https://pkg.go.dev/google.golang.org/protobuf/encoding/protojson).\n- The path template used to map gRPC service methods to HTTP endpoints supports the [google.api.http](https://github.com/googleapis/googleapis/blob/master/google/api/http.proto)\n  path template syntax. For example, `/api/v1/{name=projects/*/topics/*}` or `/prefix/{path=organizations/**}`.\n\n## Contribution\n\nSee [CONTRIBUTING.md](http://github.com/grpc-ecosystem/grpc-gateway/blob/main/CONTRIBUTING.md).\n\n## License\n\ngRPC-Gateway is licensed under the BSD 3-Clause License.\nSee [LICENSE](https://github.com/grpc-ecosystem/grpc-gateway/blob/main/LICENSE) for more details.\n",
      "stars_today": 4
    },
    {
      "id": 66841911,
      "name": "excelize",
      "full_name": "qax-os/excelize",
      "description": "Go language library for reading and writing Microsoft Excelâ„¢ (XLAM / XLSM / XLSX / XLTM / XLTX) spreadsheets",
      "html_url": "https://github.com/qax-os/excelize",
      "stars": 20227,
      "forks": 1865,
      "language": "Go",
      "topics": [
        "agent",
        "ai",
        "analytics",
        "chart",
        "ecma-376",
        "excel",
        "excelize",
        "formula",
        "go",
        "mcp",
        "microsoft",
        "office",
        "ooxml",
        "spreadsheet",
        "statistics",
        "table",
        "vba",
        "visualization",
        "xlsx",
        "xml"
      ],
      "created_at": "2016-08-29T12:32:12Z",
      "updated_at": "2026-01-25T01:33:17Z",
      "pushed_at": "2026-01-24T05:12:20Z",
      "open_issues": 115,
      "owner": {
        "login": "qax-os",
        "avatar_url": "https://avatars.githubusercontent.com/u/29733149?v=4"
      },
      "readme": "<p align=\"center\"><img width=\"650\" src=\"./excelize.svg\" alt=\"Excelize logo\"></p>\n\n<p align=\"center\">\n    <a href=\"https://github.com/xuri/excelize/actions/workflows/go.yml\"><img src=\"https://github.com/xuri/excelize/actions/workflows/go.yml/badge.svg\" alt=\"Build Status\"></a>\n    <a href=\"https://codecov.io/gh/qax-os/excelize\"><img src=\"https://codecov.io/gh/qax-os/excelize/branch/master/graph/badge.svg\" alt=\"Code Coverage\"></a>\n    <a href=\"https://goreportcard.com/report/github.com/xuri/excelize/v2\"><img src=\"https://goreportcard.com/badge/github.com/xuri/excelize/v2\" alt=\"Go Report Card\"></a>\n    <a href=\"https://pkg.go.dev/github.com/xuri/excelize/v2\"><img src=\"https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&logoColor=white\" alt=\"go.dev\"></a>\n    <a href=\"https://opensource.org/licenses/BSD-3-Clause\"><img src=\"https://img.shields.io/badge/license-bsd-orange.svg\" alt=\"Licenses\"></a>\n    <a href=\"https://www.paypal.com/paypalme/xuri\"><img src=\"https://img.shields.io/badge/Donate-PayPal-green.svg\" alt=\"Donate\"></a>\n</p>\n\n# Excelize\n\n## Introduction\n\nExcelize is a library written in pure Go providing a set of functions that allow you to write to and read from XLAM / XLSM / XLSX / XLTM / XLTX files. Supports reading and writing spreadsheet documents generated by Microsoft Excel&trade; 2007 and later. Supports complex components by high compatibility, and provided streaming API for generating or reading data from a worksheet with huge amounts of data. This library needs Go version 1.24.0 or later. The full docs can be seen using go's built-in documentation tool, or online at [go.dev](https://pkg.go.dev/github.com/xuri/excelize/v2) and [docs reference](https://xuri.me/excelize/).\n\n## Basic Usage\n\n### Installation\n\n```bash\ngo get github.com/xuri/excelize\n```\n\n- If your packages are managed using [Go Modules](https://go.dev/blog/using-go-modules), please install with following command.\n\n```bash\ngo get github.com/xuri/excelize/v2\n```\n\n### Create spreadsheet\n\nHere is a minimal example usage that will create spreadsheet file.\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n\n    \"github.com/xuri/excelize/v2\"\n)\n\nfunc main() {\n    f := excelize.NewFile()\n    defer func() {\n        if err := f.Close(); err != nil {\n            fmt.Println(err)\n        }\n    }()\n    // Create a new sheet.\n    index, err := f.NewSheet(\"Sheet2\")\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    // Set value of a cell.\n    f.SetCellValue(\"Sheet2\", \"A2\", \"Hello world.\")\n    f.SetCellValue(\"Sheet1\", \"B2\", 100)\n    // Set active sheet of the workbook.\n    f.SetActiveSheet(index)\n    // Save spreadsheet by the given path.\n    if err := f.SaveAs(\"Book1.xlsx\"); err != nil {\n        fmt.Println(err)\n    }\n}\n```\n\n### Reading spreadsheet\n\nThe following constitutes the bare to read a spreadsheet document.\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n\n    \"github.com/xuri/excelize/v2\"\n)\n\nfunc main() {\n    f, err := excelize.OpenFile(\"Book1.xlsx\")\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    defer func() {\n        // Close the spreadsheet.\n        if err := f.Close(); err != nil {\n            fmt.Println(err)\n        }\n    }()\n    // Get value from cell by given worksheet name and cell reference.\n    cell, err := f.GetCellValue(\"Sheet1\", \"B2\")\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    fmt.Println(cell)\n    // Get all the rows in the Sheet1.\n    rows, err := f.GetRows(\"Sheet1\")\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    for _, row := range rows {\n        for _, colCell := range row {\n            fmt.Print(colCell, \"\\t\")\n        }\n        fmt.Println()\n    }\n}\n```\n\n### Add chart to spreadsheet file\n\nWith Excelize chart generation and management is as easy as a few lines of code. You can build charts based on data in your worksheet or generate charts without any data in your worksheet at all.\n\n<p align=\"center\"><img width=\"650\" src=\"./test/images/chart.png\" alt=\"Excelize\"></p>\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n\n    \"github.com/xuri/excelize/v2\"\n)\n\nfunc main() {\n    f := excelize.NewFile()\n    defer func() {\n        if err := f.Close(); err != nil {\n            fmt.Println(err)\n        }\n    }()\n    for idx, row := range [][]interface{}{\n        {nil, \"Apple\", \"Orange\", \"Pear\"}, {\"Small\", 2, 3, 3},\n        {\"Normal\", 5, 2, 4}, {\"Large\", 6, 7, 8},\n    } {\n        cell, err := excelize.CoordinatesToCellName(1, idx+1)\n        if err != nil {\n            fmt.Println(err)\n            return\n        }\n        f.SetSheetRow(\"Sheet1\", cell, &row)\n    }\n    if err := f.AddChart(\"Sheet1\", \"E1\", &excelize.Chart{\n        Type: excelize.Col3DClustered,\n        Series: []excelize.ChartSeries{\n            {\n                Name:       \"Sheet1!$A$2\",\n                Categories: \"Sheet1!$B$1:$D$1\",\n                Values:     \"Sheet1!$B$2:$D$2\",\n            },\n            {\n                Name:       \"Sheet1!$A$3\",\n                Categories: \"Sheet1!$B$1:$D$1\",\n                Values:     \"Sheet1!$B$3:$D$3\",\n            },\n            {\n                Name:       \"Sheet1!$A$4\",\n                Categories: \"Sheet1!$B$1:$D$1\",\n                Values:     \"Sheet1!$B$4:$D$4\",\n            }},\n        Title: []excelize.RichTextRun{\n            {\n                Text: \"Fruit 3D Clustered Column Chart\",\n            },\n        },\n    }); err != nil {\n        fmt.Println(err)\n        return\n    }\n    // Save spreadsheet by the given path.\n    if err := f.SaveAs(\"Book1.xlsx\"); err != nil {\n        fmt.Println(err)\n    }\n}\n```\n\n### Add picture to spreadsheet file\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    _ \"image/gif\"\n    _ \"image/jpeg\"\n    _ \"image/png\"\n\n    \"github.com/xuri/excelize/v2\"\n)\n\nfunc main() {\n    f, err := excelize.OpenFile(\"Book1.xlsx\")\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    defer func() {\n        // Close the spreadsheet.\n        if err := f.Close(); err != nil {\n            fmt.Println(err)\n        }\n    }()\n    // Insert a picture.\n    if err := f.AddPicture(\"Sheet1\", \"A2\", \"image.png\", nil); err != nil {\n        fmt.Println(err)\n    }\n    // Insert a picture to worksheet with scaling.\n    if err := f.AddPicture(\"Sheet1\", \"D2\", \"image.jpg\",\n        &excelize.GraphicOptions{ScaleX: 0.5, ScaleY: 0.5}); err != nil {\n        fmt.Println(err)\n    }\n    // Insert a picture offset in the cell with printing support.\n    enable, disable := true, false\n    if err := f.AddPicture(\"Sheet1\", \"H2\", \"image.gif\",\n        &excelize.GraphicOptions{\n            PrintObject:     &enable,\n            LockAspectRatio: false,\n            OffsetX:         15,\n            OffsetY:         10,\n            Locked:          &disable,\n        }); err != nil {\n        fmt.Println(err)\n    }\n    // Save the spreadsheet with the origin path.\n    if err = f.Save(); err != nil {\n        fmt.Println(err)\n    }\n}\n```\n\n## Contributing\n\nContributions are welcome! Open a pull request to fix a bug, or open an issue to discuss a new feature or change. XML is compliant with [part 1 of the 5th edition of the ECMA-376 Standard for Office Open XML](https://www.ecma-international.org/publications-and-standards/standards/ecma-376/).\n\n## Licenses\n\nThis program is under the terms of the BSD 3-Clause License. See [https://opensource.org/licenses/BSD-3-Clause](https://opensource.org/licenses/BSD-3-Clause).\n\nThe Excel logo is a trademark of [Microsoft Corporation](https://aka.ms/trademarks-usage). This artwork is an adaptation.\n\nThe Go gopher was created by [Renee French](https://go.dev/doc/gopher/README). Licensed under the [Creative Commons 4.0 Attributions license](http://creativecommons.org/licenses/by/4.0/).\n\n## Gold Sponsors\n\n<a href=\"https://www.gravityclimate.com\" alt=\"Gravity\"><img width=\"120\" src=\"https://xuri.me/excelize/images/vendor/gravityclimate.com.svg\" alt=\"Gravity\"></a>\n",
      "stars_today": 4
    },
    {
      "id": 136938012,
      "name": "vendure",
      "full_name": "vendurehq/vendure",
      "description": "The most customizable commerce platform built with TypeScript, NestJS and GraphQL. ",
      "html_url": "https://github.com/vendurehq/vendure",
      "stars": 7846,
      "forks": 1310,
      "language": "TypeScript",
      "topics": [
        "ecommerce",
        "ecommerce-api",
        "ecommerce-framework",
        "ecommerce-platform",
        "graphql",
        "graphql-commerce",
        "headless",
        "headless-commerce",
        "nestjs",
        "nodejs",
        "nodejs-ecommerce",
        "shopping-cart"
      ],
      "created_at": "2018-06-11T14:29:20Z",
      "updated_at": "2026-01-25T01:14:41Z",
      "pushed_at": "2026-01-23T22:13:08Z",
      "open_issues": 356,
      "owner": {
        "login": "vendurehq",
        "avatar_url": "https://avatars.githubusercontent.com/u/39629390?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://vendure.io\">\n    <img alt=\"Vendure logo\" height=\"60\" width=\"auto\" src=\"https://a.storyblok.com/f/328257/699x480/8dbb4c7a3c/logo-icon.png\">\n  </a>\n</p>\n\n<h1 align=\"center\">\n  Vendure\n</h1>\n<h3 align=\"center\">\n    Own Your Commerce. Build Without Workarounds. Ship Faster.\n</h3>\n<h4 align=\"center\">\n  <a href=\"https://docs.vendure.io\">Documentation</a> |\n  <a href=\"https://vendure.io\">Website</a>\n</h4>\n\n<p align=\"center\">\n  <a href=\"https://github.com/vendurehq/vendure/blob/master/LICENSE.md\">\n    <img src=\"https://img.shields.io/badge/license-GPL-blue.svg\" alt=\"Vendure is released under the GPLv3 license.\" />\n  </a>\n  <a href=\"https://twitter.com/intent/follow?screen_name=vendure_io\">\n    <img src=\"https://img.shields.io/twitter/follow/vendure_io\" alt=\"Follow @vendure_io\" />\n  </a>\n  <a href=\"https://vendure.io/community\">\n    <img src=\"https://img.shields.io/badge/join-our%20discord-7289DA.svg\" alt=\"Join our Discord\" />\n  </a>\n  <a href=\"https://github.com/vendurehq/vendure/blob/master/CONTRIBUTING.md\">\n    <img src=\"https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat\" alt=\"PRs welcome!\" />\n  </a>\n</p>\n\n## What is Vendure \n\nVendure is an open-source headless commerce platform built with _TypeScript_ and _Node.js_. It provides a robust foundation for building enterprise-grade digital commerce applications with exceptional scalability and maintainability.\n\n- **Built for heavy customization**: Extensible plugin architecture allows you to tailor every aspect of your commerce solution\n- **Modern, AI-optimized tech stack**: Built on TypeScript, Node.js, NestJS, and GraphQL for outstanding performance and developer experience\n- **Headless architecture**: API-first design enables seamless multichannel commerce across any frontend\n- **Enterprise-ready**: Trusted by thousands of teams worldwide, from startups to Fortune 500 companies\n- **Rich feature set**: Comprehensive out-of-the-box functionality with customizable admin dashboard and commerce framework\n\nWhether you're building a B2B platform, multi-vendor marketplace, or D2C storefront, Vendure provides the flexible foundation to create unique commerce experiences tailored to your business needs.\n\n## Getting Started\n\nVisit our [Getting Started guide](https://docs.vendure.io/guides/getting-started/installation/) to get Vendure up and running locally in _less than 2 minutes_ with a single command.\n\n**Need Help?** Our community is here to help, join [our Discord](https://www.vendure.io/community) for support and discussions!\n\n## Upgrades & Plugins \n\nNew updates get released on a bi-weekly cadence, check out our [release notes](https://github.com/vendurehq/vendure/releases) to keep up-to-date with the latest releases.\n\nHave a look at all of our [ready-made Vendure plugins](https://vendure.io/plugins?page=1).\n\n## Contribution\n\nContributions to Vendure are welcome and highly appreciated! Whether you're fixing bugs, adding features, or improving documentation, your help makes Vendure better for everyone.\n\nOur **[Contribution Guide](./CONTRIBUTING.md)** is covering everything from setting up your development environment to submitting your first pull request.\n\n**Ready to get started?** Check out [these issues](https://github.com/vendurehq/vendure/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22%F0%9F%91%8B%20contributions%20welcome%22) for a good first task to start!\n\n## License\n\nLicensed under the [GPLv3 license](./LICENSE.md). Commercial license (VCL) [available](https://vendure.io/pricing).\n",
      "stars_today": 4
    },
    {
      "id": 37205440,
      "name": "axe-core",
      "full_name": "dequelabs/axe-core",
      "description": "Accessibility engine for automated Web UI testing",
      "html_url": "https://github.com/dequelabs/axe-core",
      "stars": 6828,
      "forks": 857,
      "language": "JavaScript",
      "topics": [
        "a11y",
        "accessibility",
        "axe"
      ],
      "created_at": "2015-06-10T15:26:45Z",
      "updated_at": "2026-01-24T21:20:56Z",
      "pushed_at": "2026-01-23T17:08:29Z",
      "open_issues": 424,
      "owner": {
        "login": "dequelabs",
        "avatar_url": "https://avatars.githubusercontent.com/u/4094299?v=4"
      },
      "readme": "# axe-core\n\n[![License](https://img.shields.io/npm/l/axe-core.svg?color=c41)](LICENSE)\n[![Version](https://img.shields.io/npm/v/axe-core.svg)](https://www.npmjs.com/package/axe-core)\n[![NPM downloads](https://img.shields.io/npm/dw/axe-core.svg?color=080)![](https://img.shields.io/npm/dy/axe-core.svg?color=080&label=)](https://npm-stat.com/charts.html?package=axe-core&from=2017-01-01)\n[![Commits](https://img.shields.io/github/commit-activity/y/dequelabs/axe-core.svg)](https://github.com/dequelabs/axe-core/commits/develop)\n[![GitHub contributors](https://img.shields.io/github/contributors/dequelabs/axe-core.svg?color=080)](https://github.com/dequelabs/axe-core/graphs/contributors)\n[![Join our Slack chat](https://img.shields.io/badge/slack-chat-purple.svg?logo=slack)](https://accessibility.deque.com/axe-community)\n[![Package Quality](https://npm.packagequality.com/shield/axe-core.svg)](https://packagequality.com/#?package=axe-core)\n\nAxe is an accessibility testing engine for websites and other HTML-based user interfaces. It's fast, secure, lightweight, and was built to seamlessly integrate with any existing test environment so you can automate accessibility testing alongside your regular functional testing.\n\n[Sign up for axe news](https://hubs.ly/H0fsN0b0) to get the latest on axe features, future releases, and events.\n\n## The Accessibility Rules\n\nAxe-core has different types of rules, for WCAG 2.0, 2.1, 2.2 on level A, AA and AAA as well as a number of best practices that help you identify common accessibility practices like ensuring every page has an `h1` heading, and to help you avoid \"gotchas\" in ARIA like where an ARIA attribute you used will get ignored. The complete list of rules, grouped WCAG level and best practice, can be found in [doc/rule-descriptions.md](./doc/rule-descriptions.md).\n\nWith axe-core, you can find **on average 57% of WCAG issues automatically**. Additionally, axe-core will return elements as \"incomplete\" where axe-core could not be certain, and manual review is needed.\n\nTo catch bugs earlier in the development cycle we recommend using the [axe-linter vscode extension](https://marketplace.visualstudio.com/items?itemName=deque-systems.vscode-axe-linter). To improve test coverage even further we recommend the [intelligent guided tests](https://www.youtube.com/watch?v=AtsX0dPCG_4&feature=youtu.be&ab_channel=DequeSystems) in the [axe Extension](https://www.deque.com/axe/browser-extensions/).\n\n## Getting started\n\nFirst download the package:\n\n```console\nnpm install axe-core --save-dev\n```\n\nNow include the javascript file in each of your iframes in your fixtures or test systems:\n\n```html\n<script src=\"node_modules/axe-core/axe.min.js\"></script>\n```\n\nNow insert calls at each point in your tests where a new piece of UI becomes visible or exposed:\n\n```js\naxe\n  .run()\n  .then(results => {\n    if (results.violations.length) {\n      throw new Error('Accessibility issues found');\n    }\n  })\n  .catch(err => {\n    console.error('Something bad happened:', err.message);\n  });\n```\n\n## Philosophy\n\nThe web can only become an accessible, inclusive space if developers are empowered to take responsibility for accessibility testing and accessible coding practices.\n\nAutomated accessibility testing is a huge timesaver, it doesn't require special expertise, and it allows teams to focus expert resources on the accessibility issues that really need them. Unfortunately, most accessibility tools are meant to be run on sites and applications that have reached the end of the development process and often don't give clear or consistent results, causing frustration and delays just when you thought your product was ready to ship.\n\nAxe was built to reflect how web development actually works. It works with all modern browsers, tools, and testing environments a dev team might use. With axe, accessibility testing can be performed as part of your unit testing, integration testing, browser testing, and any other functional testing your team already performs on a day-to-day basis. Building accessibility testing into the early development process saves time, resources, and all kinds of frustration.\n\n## About axe - our Manifesto\n\n- Axe is open source.\n- It returns zero false positives (bugs notwithstanding).\n- It's designed to work on all modern browsers and with whatever tools, frameworks, libraries and environments you use today.\n- It's actively supported by [Deque Systems](https://www.deque.com), a major accessibility vendor.\n- It integrates with your existing functional/acceptance automated tests.\n- It automatically determines which rules to run based on the evaluation context.\n- Axe supports in-memory fixtures, static fixtures, integration tests, and iframes of infinite depth.\n- Axe is highly configurable.\n\n## Supported Browsers\n\nThe [axe-core API](doc/API.md) fully supports the following browsers:\n\n- Microsoft Edge v40 and above\n- Google Chrome v42 and above\n- Mozilla Firefox v38 and above\n- Apple Safari v7 and above\n- Internet Explorer v11 (DEPRECATED)\n\nSupport means that we will fix bugs and attempt to test each browser regularly. Only Chrome and Firefox are currently tested on every pull request.\n\nThere is limited support for JSDOM. We will attempt to make all rules compatible with JSDOM but where this is not possible, we recommend turning those rules off. Currently the `color-contrast` rule is known not to work with JSDOM.\n\nWe can only support environments where features are either natively supported or polyfilled correctly. We do not support the deprecated v0 Shadow DOM implementation.\n\n## Contents of the API Package\n\nThe [axe-core API](doc/API.md) package consists of:\n\n- `axe.js` - the JavaScript file that should be included in your web site under test (API)\n- `axe.min.js` - a minified version of the above file\n\n## Localization\n\nAxe can be built using your local language. To do so, a localization file must be added to the `./locales` directory. This file must be named in the following manner: `<langcode>.json`. To build axe using this locale, instead of the default, run axe with the `--lang` flag, like so:\n\n`grunt build --lang=nl`\n\nor equivalently:\n\n`npm run build -- --lang=nl`\n\nThis will create a new build for axe, called `axe.<lang>.js` and `axe.<lang>.min.js`. If you want to build all localized versions, simply pass in `--all-lang` instead. If you want to build multiple localized versions (but not all of them), you can pass in a comma-separated list of languages to the `--lang` flag, like `--lang=nl,ja`.\n\nTo create a new translation for axe, start by running `grunt translate --lang=<langcode>`. This will create a json file in the `./locales` directory, with the default English text in it for you to translate. Alternatively, you could copy `./locales/_template.json`. We welcome any localization for axe-core. For details on how to contribute, see the Contributing section below. For details on the message syntax, see [Check Message Template](/doc/check-message-template.md).\n\nTo update an existing translation file, re-run `grunt translate --lang=<langcode>`. This will add new messages used in English and remove messages which were not used in English.\n\nAdditionally, locale can be applied at runtime by passing a `locale` object to `axe.configure()`. The locale object must be of the same shape as existing locales in the `./locales` directory. For example:\n\n```js\naxe.configure({\n  locale: {\n    lang: 'de',\n    rules: {\n      accesskeys: {\n        help: 'Der Wert des accesskey-Attributes muss einzigartig sein.'\n      }\n      // ...\n    },\n    checks: {\n      abstractrole: {\n        fail: 'Abstrakte ARIA-Rollen dÃ¼rfen nicht direkt verwendet werden.'\n      },\n      'aria-errormessage': {\n        // Note: doT (https://github.com/olado/dot) templates are supported here.\n        fail: 'Der Wert der aria-errormessage ${data.values}` muss eine Technik verwenden, um die Message anzukÃ¼ndigen (z. B., aria-live, aria-describedby, role=alert, etc.).'\n      }\n      // ...\n    }\n  }\n});\n```\n\n### Supported Locales\n\nAxe-core supports the following locales. Do note that since locales are contributed by our community, they are not guaranteed to include all translations needed in a release.\n\n- Basque\n- Chinese (Simplified)\n- Chinese (Traditional)\n- Danish\n- Dutch\n- French\n- German\n- Greek\n- Hebrew\n- Italian\n- Japanese\n- Korean\n- Norwegian (BokmÃ¥l)\n- Polish\n- Portuguese (Brazilian)\n- Spanish\n\n## Updates & Security\n\nAxe-core has a new minor release every 3 to 5 months, which usually introduces new rules and features. We recommend scheduling time to upgrade to these versions. Security updates will be made available for minor version lines up to **18 months old**.\n\n- See [release and support](doc/release-and-support.md) for details on the frequency of releases, long-term support and recommendations on upgrading axe-core.\n- See [backward compatibility](doc/backwards-compatibility-doc.md) for details on the types of changes different releases may introduce.\n\n## Deque Trademarks Policy\n\nDEQUE, DEQUELABS, AXEÂ®, and AXE-COREÂ® are trademarks of Deque Systems, Inc. Use of the Deque trademarks must be in accordance with [Deque's trademark policy](https://www.deque.com/legal/trademarks/).\n\n## Supported ARIA Roles and Attributes.\n\nRefer [axe-core ARIA support](./doc/aria-supported.md) for a complete list of ARIA supported roles and attributes by axe.\n\n## Contributing\n\nRead the [Proposing Axe-core Rules guide](./doc/rule-proposal.md)\n\nRead the [documentation on the architecture](./doc/developer-guide.md)\n\nRead the [documentation on contributing](CONTRIBUTING.md)\n\n## Projects using axe-core\n\n[List of projects using axe-core](doc/projects.md)\n\n## Acknowledgements\n\nThanks to Marat Dulin for his [css-selector-parser](https://www.npmjs.com/package/css-selector-parser) implementation which is included for shadow DOM support. Another thank you to the [Slick Parser](https://github.com/mootools/slick/blob/master/Source/Slick.Parser.js) implementers for their contribution, we have used some of their algorithms in our shadow DOM support code. Thanks to Lea Verou and Chris Lilley for their [colorjs.io](https://colorjs.io/) library which we have used for converting between color formats.\n\n## Licenses\n\nAxe-core is distributed under the [Mozilla Public License, version 2.0](LICENSE). It comes bundled with several dependencies which are distributed under their own terms. (See [LICENSE-3RD-PARTY.txt](LICENSE-3RD-PARTY.txt))\n",
      "stars_today": 4
    },
    {
      "id": 746689243,
      "name": "kafka-ui",
      "full_name": "kafbat/kafka-ui",
      "description": "Open-Source Web UI for managing Apache Kafka clusters",
      "html_url": "https://github.com/kafbat/kafka-ui",
      "stars": 1955,
      "forks": 243,
      "language": "Java",
      "topics": [
        "apache-kafka",
        "big-data",
        "cluster-management",
        "event-streaming",
        "foss",
        "hacktoberfest",
        "kafka",
        "kafka-brokers",
        "kafka-client",
        "kafka-cluster",
        "kafka-connect",
        "kafka-manager",
        "kafka-producer",
        "kafka-streams",
        "kafka-ui",
        "opensource",
        "streaming-data",
        "streams",
        "web-ui"
      ],
      "created_at": "2024-01-22T13:38:08Z",
      "updated_at": "2026-01-24T11:46:53Z",
      "pushed_at": "2026-01-23T23:11:56Z",
      "open_issues": 257,
      "owner": {
        "login": "kafbat",
        "avatar_url": "https://avatars.githubusercontent.com/u/98461227?v=4"
      },
      "readme": "<div align=\"center\">\n<img src=\"documentation/images/logo_new.png\" alt=\"logo\"/>\n<h3>Kafbat UI</h3>\n\nVersatile, fast and lightweight web UI for managing Apache KafkaÂ® clusters.\n</div>\n\n<div align=\"center\">\n<a href=\"https://github.com/kafbat/kafka-ui/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\" alt=\"License\"/></a>\n<img src=\"documentation/images/free-open-source.svg\" alt=\"price free\"/>\n<a href=\"https://github.com/kafbat/kafka-ui/releases\"><img src=\"https://img.shields.io/github/v/release/kafbat/kafka-ui\" alt=\"latest release version\"/></a>\n<a href=\"https://discord.gg/4DWzD7pGE5\"><img src=\"https://img.shields.io/discord/897805035122077716\" alt=\"discord online number count\"/></a>\n<a href=\"https://github.com/sponsors/kafbat\"><img src=\"https://img.shields.io/github/sponsors/kafbat?style=flat&logo=githubsponsors&logoColor=%23EA4AAA&label=Support%20us\" alt=\"\" /></a>\n</div>\n\n<p align=\"center\">\n    <a href=\"https://ui.docs.kafbat.io/\">Documentation</a> â€¢ \n    <a href=\"https://ui.docs.kafbat.io/quick-start/demo-run\">Quick Start</a> â€¢ \n    <a href=\"https://discord.gg/4DWzD7pGE5\">Community</a>\n    <br/>\n    <a href=\"https://aws.amazon.com/marketplace/pp/prodview-6tdqqzzjwmejq\">AWS Marketplace</a>  â€¢\n    <a href=\"https://www.producthunt.com/products/ui-for-apache-kafka/reviews/new\">ProductHunt</a>\n</p>\n\n<p align=\"center\">\n  <img src=\"https://repobeats.axiom.co/api/embed/88d2bd9887380c7d86e2f986725d9af52ebad7f4.svg\" alt=\"stats\"/>\n</p>\n\n#### Kafbat UI is a free, open-source web UI to monitor and manage Apache Kafka clusters.\n\n[Kafbat UI](https://kafbat.io/) is a simple tool that makes your data flows observable, helps find and troubleshoot issues faster and deliver optimal performance. Its lightweight dashboard makes it easy to track key metrics of your Kafka clusters - Brokers, Topics, Partitions, Production, and Consumption.\n\n<i>\nKafbat UI, developed by <b>Kafbat</b>*, proudly carries forward the legacy of the UI Apache Kafka project.\nOur dedication is reflected in the continuous evolution of the project, ensuring adherence to its foundational vision while adapting to meet modern demands.\nWe extend our gratitude to Provectus for their past support in groundbreaking work, which serves as a cornerstone for our ongoing innovation and dedication.\n\n<b>*</b> - The <b>Kafbat</b> team comprises key contributors from the project's inception, bringing a wealth of experience and insight to this renewed endeavor.\n</i>\n\n# Interface\n\n![Interface](https://raw.githubusercontent.com/kafbat/kafka-ui/images/overview.gif)\n\n# Features\n\n* **Topic Insights** â€“ View essential topic details including partition count, replication status, and custom configurations.\n* **Configuration Wizard** â€“ Set up and configure your Kafka clusters directly through the UI.\n* **Multi-Cluster Management** â€“ Monitor and manage all your Kafka clusters in one unified interface.\n* **Metrics Dashboard** â€“ Track key Kafka metrics in real time with a streamlined, lightweight dashboard.\n* **Kafka Brokers Overview** â€“ Inspect brokers, including partition assignments and controller status.\n* **Consumer Group Details** â€“ Analyze parked offsets per partition, and monitor both combined and partition-specific lag.\n* **Message Browser** â€“ Explore messages in JSON, plain text, or Avro encoding formats. Live view is supported, enriched with user-defined CEL message filters.\n* **Dynamic Topic Management** â€“ Create and configure new topics with flexible, real-time settings.\n* **Pluggable Authentication** â€“ Secure your UI using OAuth 2.0 (GitHub, GitLab, Google), LDAP, or basic authentication.\n* **Cloud IAM Support** â€“ Integrate with **GCP IAM**, **Azure IAM**, and **AWS IAM** for cloud-native identity and access management.\n* **Managed Kafka Service Support** â€“ Full support for **Azure EventHub**, **Google Cloud Managed Service for Apache Kafka**, and **AWS Managed Streaming for Apache Kafka (MSK)**â€”both server-based and serverless.\n* **Custom SerDe Plugin Support** â€“ Use built-in serializers/deserializers like AWS Glue and Smile, or create your own custom plugins.\n* **Role-Based Access Control** â€“ [Manage granular UI permissions](https://ui.docs.kafbat.io/configuration/rbac-role-based-access-control) with RBAC.\n* **Data Masking** â€“ [Obfuscate sensitive data](https://ui.docs.kafbat.io/configuration/data-masking) in topic messages to enhance privacy and compliance.\n* **MCP Server** - [Model Context Protocol](https://ui.docs.kafbat.io/faq/mcp) Server\n\n\n## Feature overview\n\n<details>\n    <summary>Click here for the feature overview</summary>\n\n# The Interface\nKafbat UI wraps major functions of Apache Kafka with an intuitive user interface.\n\n![Interface](documentation/images/Interface.gif)\n\n## Topics\nKafbat UI makes it easy for you to create topics in your browser with just a few clicks, by pasting your own parameters, and viewing topics in the list.\n\n![Create Topic](documentation/images/Create_topic_kafka-ui.gif)\n\nYou can jump from the connectors view to corresponding topics and from a topic to consumers (back and forth) for more convenient navigation, including connectors and overview topic settings.\n\n![Connector_Topic_Consumer](documentation/images/Connector_Topic_Consumer.gif)\n\n### Messages\nSuppose you want to produce messages for your topic. With Kafbat UI, you can easily send or write data/messages to Kafka topics by specifying parameters and viewing messages in the list.\n\n![Produce Message](documentation/images/Create_message_kafka-ui.gif)\n\n## Schema registry\nThere are three supported types of schemas: AvroÂ®, JSON Schema, and Protobuf schemas.\n\n![Create Schema Registry](documentation/images/Create_schema.gif)\n\nBefore producing Avro/Protobuf encoded messages, you need to add a schema for the topic in the Schema Registry. All these steps are now easy to do with just a few clicks in a user-friendly interface.\n\n![Avro Schema Topic](documentation/images/Schema_Topic.gif)\n\n</details>\n\n# Getting Started\n\nTo run Kafbat UI, you can use either a pre-built Docker image or build it (or a jar file) yourself.\n\n## Quick start (Demo run)\n\n```bash\ndocker run -it -p 8080:8080 -e DYNAMIC_CONFIG_ENABLED=true ghcr.io/kafbat/kafka-ui\n```\n\nThen access the web UI at [http://localhost:8080](http://localhost:8080)\n\nThis command is sufficient to try things out. When you're done, you can proceed with a [persistent installation](https://ui.docs.kafbat.io/quick-start/persistent-start).\n\n## Persistent installation\n\n```yml\nservices:\n  kafbat-ui:\n    container_name: kafbat-ui\n    image: ghcr.io/kafbat/kafka-ui:latest\n    ports:\n      - 8080:8080\n    environment:\n      DYNAMIC_CONFIG_ENABLED: 'true'\n    volumes:\n      - ~/kui/config.yml:/etc/kafkaui/dynamic_config.yaml\n```\n\nPlease refer to our [configuration](https://ui.docs.kafbat.io/configuration/configuration-file) page to proceed with further app configuration.\n\n## Some useful configuration related links\n\n[Web UI Cluster Configuration Wizard](https://ui.docs.kafbat.io/configuration/configuration-wizard)\n\n[Configuration file explanation](https://ui.docs.kafbat.io/configuration/configuration-file)\n\n[Docker Compose examples](https://ui.docs.kafbat.io/configuration/compose-examples)\n\n[Misc configuration properties](https://ui.docs.kafbat.io/configuration/misc-configuration-properties)\n\n## Helm charts\n\n[Quick start](https://ui.docs.kafbat.io/configuration/helm-charts/quick-start)\n\n## Building from sources\n\n[Quick start](https://ui.docs.kafbat.io/development/building/prerequisites) for building from source\n\n## Liveliness and readiness probes\nThe liveness and readiness endpoint is at `/actuator/health`.<br/>\nThe info endpoint (build info) is located at `/actuator/info`.\n\n# Configuration options\n\nAll environment variables and configuration properties can be found [here](https://ui.docs.kafbat.io/configuration/misc-configuration-properties).\n\n# Contributing\n\nPlease refer to the [contributing guide](https://ui.docs.kafbat.io/development/contributing); we'll guide you from there.\n\n# Support\n\nAs we're fully independent, team members contribute in their free time.\nYour support is crucial for us, if you wish to sponsor us, take a look [here](https://github.com/sponsors/kafbat)\n\n# Powered by\n\n[![JetBrains logo.](https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg)](https://jb.gg/OpenSourceSupport)\n",
      "stars_today": 4
    },
    {
      "id": 556894297,
      "name": "nRFBox",
      "full_name": "cifertech/nRFBox",
      "description": "Open-source ESP32-powered tool to scan, jam, spoof, and master BLE, Wi-Fi, and 2.4GHz networks.",
      "html_url": "https://github.com/cifertech/nRFBox",
      "stars": 1451,
      "forks": 208,
      "language": "C++",
      "topics": [
        "arduino",
        "ble-jammer",
        "ble-spoof",
        "ble-spoofer",
        "cybersecurity",
        "deauther",
        "esp32",
        "hack",
        "hacktoberfest",
        "jammer",
        "nrf-scanner",
        "nrf24l01",
        "sour-apple"
      ],
      "created_at": "2022-10-24T18:07:26Z",
      "updated_at": "2026-01-24T23:03:53Z",
      "pushed_at": "2025-06-22T19:59:58Z",
      "open_issues": 65,
      "owner": {
        "login": "cifertech",
        "avatar_url": "https://avatars.githubusercontent.com/u/62047147?v=4"
      },
      "readme": "<div align=\"center\">\n\n  <img src=\"https://user-images.githubusercontent.com/62047147/195847997-97553030-3b79-4643-9f2c-1f04bba6b989.png\" alt=\"logo\" width=\"100\" height=\"auto\" />\n  \n  <h1> nRFBOX </h1>\n  <p> All-in-One Gadget for BLE and 2.4GHz Networks </p>\n\n\n<!-- Badges -->\n<a href=\"https://github.com/cifertech/nrfbox\" title=\"Go to GitHub repo\"><img src=\"https://img.shields.io/static/v1?label=cifertech&message=nrfbox&color=purple&logo=github\" alt=\"cifertech - nrfbox\"></a>\n![GitHub Downloads (all assets, all releases)](https://img.shields.io/github/downloads/cifertech/nrfbox/total)\n<a href=\"https://github.com/cifertech/nrfbox\"><img src=\"https://img.shields.io/github/stars/cifertech/nrfbox?style=social\" alt=\"stars - nrfbox\"></a>\n<a href=\"https://github.com/cifertech/nrfbox\"><img src=\"https://img.shields.io/github/forks/cifertech/nrfbox?style=social\" alt=\"forks - nrfbox\"></a>\n\n   \n<h4>\n    <a href=\"https://twitter.com/techcifer\">TWITTER</a>\n  <span> Â· </span>\n    <a href=\"https://www.instagram.com/cifertech/\">INSTAGRAM</a>\n  <span> Â· </span>\n    <a href=\"https://www.youtube.com/@techcifer\">YOUTUBE</a>\n  <span> Â· </span>\n    <a href=\"https://cifertech.net/\">WEBSITE</a>\n  </h4>\n</div>\n<br/>\n\n## ğŸ“– Explore the nRFBox Wiki\n\nComplete project story, in-depth tutorials, and all the features in [Wiki](https://github.com/cifertech/nRFBox/wiki)! From Wi-Fi deauthentication attacks to Sub-GHz signal replay, the Wiki covers everything you need to get started. [Click here to explore now!](https://github.com/cifertech/nRFBox/wiki)\n  \n<div>&nbsp;</div>\n\n<h2>ğŸ›  Functionality Status and Reliability</h2>\n\n<table>\n  <thead>\n    <tr>\n      <th>Feature</th>\n      <th>Status</th>\n      <th>Reliability</th>\n      <th>Notes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><strong>Scanner</strong></td>\n      <td>Stable</td>\n      <td>High</td>\n      <td>Reliably scans the 2.4 GHz band to detect active channels and nearby devices. Occasional misses in high-interference environments.</td>\n    </tr>\n    <tr>\n      <td><strong>Analyzer</strong></td>\n      <td>Stable</td>\n      <td>High</td>\n      <td>Provides useful insights into detected signals, but additional updates are needed for improved accuracy and detailed analysis.</td>\n    </tr>\n    <tr>\n      <td><strong>Jammer</strong></td>\n      <td>Stable</td>\n      <td>High</td>\n      <td>Basic jamming works but effectiveness varies by device type and signal strength. Testing on select channels is recommended.</td>\n    </tr>\n    <tr>\n      <td><strong>BLE Jammer</strong></td>\n      <td>Stable</td>\n      <td>High</td>\n      <td>Disrupts BLE devices inconsistently. Further improvements are needed to ensure stability and effectiveness across BLE variants.</td>\n    </tr>\n    <tr>\n      <td><strong>BLE Spoofer</strong></td>\n      <td>Stable</td>\n      <td>Low</td>\n      <td>Capable of simulating basic BLE signals but has limited compatibility. Best for controlled testing scenarios.</td>\n    </tr>\n    <tr>\n      <td><strong>Sour Apple</strong></td>\n      <td>Stable</td>\n      <td>Low</td>\n      <td>Specialized attack method with limited reliability; effective only under specific conditions. Further tuning is required.</td>\n    </tr>\n  </tbody>\n</table>\n\n> [!NOTE]\n> - When using **multiple NRF24** modules, the power demands can exceed the capabilities of the onboard power supply or regulator. Running three NRF modules simultaneously may cause instability, leading to intermittent failures or causing the nRFBox to stop functioning altogether.\n> - **Range Limitations**: The jammer is most effective at short range. Beyond a certain distance, the signal weakens, making it harder to consistently disrupt communication.\n> - **Device Variability**: Different devices react to jamming signals in varying ways. Some may be more resistant.\n\n\n\n<div>&nbsp;</div>\n\n<!-- About the Project -->\n## :star2: About the Project\nnRFBOX is a wireless toolkit designed to explore, analyze, and interact with various wireless communication protocols. It combines the ESP32 Wroom32U, NRF24 modules, an OLED display, and other components to create a multifunctional device that can act as a scanner, analyzer, jammer, BLE jammer, BLE spoofer, and perform advanced tasks such as the \"Sour Apple\" attack.\n\n\n\n<div align=\"center\"> \n  <img src=\"https://github.com/user-attachments/assets/1d49f15d-45be-4ed4-b92a-842d628c8695\" alt=\"screenshot\" width=\"Auto\" height=\"Auto\" />\n</div>\n\n\n\n<!-- Features -->\n### ğŸ¯ Features\n\n- **Scanner** - Scans the 2.4GHz frequency band to detect active channels and devices.\n- **Analyzer** - Analyzes the detected signals and provides detailed information about the activity.\n- **Jammer** - Jams wireless communication on selected channels to test network robustness.\n- **BLE Jammer** - Specifically targets Bluetooth Low Energy (BLE) devices to disrupt their communication.\n- **BLE Spoofer** - Spoofs BLE devices to simulate various BLE signals for testing and research.\n- **Sour Apple** - A specialized attack for testing security measures against specific wireless vulnerabilities.\n- **Proto Kill Mode** - Proto Kill has evolved into a powerful tool for disrupting various protocols.\n- **WiFi Scanner** - Scan for hidden and visible BLE devices\n- **BLE Scanner** - List nearby Wi-Fi networks with extended details\n- **Wi-Fi Deauthentication Attack** - Send deauthentication frames to disrupt client connections\n\n> Explore the nRFBOX's features in detail at the [nRFBOX Wiki](https://github.com/cifertech/nRFBox/wiki/Features)! \n\n\n<div>&nbsp;</div>\n\n<!-- nRFBOX V2 -->\n## :eyes: nRFBox Versions: Then and Now\n\n<table>\n  <tr>\n    <td style=\"text-align: center;\">\n      <img src=\"https://github.com/user-attachments/assets/b121fe84-c789-409a-85f5-21f6d5854347\" alt=\"nRFBOX V1\" style=\"width: 400px; border: 1px solid #ccc; border-radius: 5px;\">\n      <p style=\"font-style: italic; font-size: 14px; margin-top: 5px;\">nRFBox-v1 based on Arduino</p>\n    </td>    \n    <td style=\"text-align: center;\">\n      <img src=\"https://github.com/user-attachments/assets/a044ab5e-346c-415f-b1fb-f65aa04c520a\" alt=\"nRFBOX V2\" style=\"width: 400px; border: 1px solid #ccc; border-radius: 5px;\">\n      <p style=\"font-style: italic; font-size: 14px; margin-top: 5px;\">nRFBox-v2 based on ESP32</p>\n    </td>\n    </td>    \n    <td style=\"text-align: center;\">\n      <img src=\"https://github.com/user-attachments/assets/bee71205-64b0-4f40-bf15-2675d3468bc1\" alt=\"nRFBOX V3\" style=\"width: 400px; border: 1px solid #ccc; border-radius: 5px;\">\n      <p style=\"font-style: italic; font-size: 14px; margin-top: 5px;\">nRFBox-v3 based on ESP32</p>\n    </td>\n  </tr>\n</table>\n\n\n<div>&nbsp;</div>\n\n<!-- License -->\n## :warning: License\n\nDistributed under the MIT License. See LICENSE.txt for more information.\n\n<div>&nbsp;</div>\n\n<!-- Contact -->\n## :handshake: Contact\n\nâ–¶ Support me on Patreon [patreon.com/cifertech](https://www.patreon.com/cifertech)\n\nCiferTech - [@twitter](https://twitter.com/techcifer) - CiferTech@gmali.com\n\nProject Link: [https://github.com/cifertech/nRFBOX](https://github.com/cifertech/nrfbox)\n\n<div>&nbsp;</div>\n\n<!-- Acknowledgments -->\n## :gem: Acknowledgements \n\n**The libraries and projects listed below are used in the nRFBox Project:**\n - [Poor Manâ€™s 2.4 GHz Scanner](https://forum.arduino.cc/t/poor-mans-2-4-ghz-scanner/54846)\n - [arduino_oled_menu](https://github.com/upiir/arduino_oled_menu)\n - [nRF24L01-WiFi-Jammer](https://github.com/hugorezende/nRF24L01-WiFi-Jammer)\n - [Universal-RC-system](https://github.com/alexbeliaev/Universal-RC-system/tree/master)\n - [AppleJuice](https://github.com/ECTO-1A/AppleJuice)\n - [ESP32-Sour-Apple](https://github.com/RapierXbox/ESP32-Sour-Apple)\n\n**Community Contributors**: Thanks to everyone who helped improve nRFBox! Your support is much appreciated!\n\n",
      "stars_today": 4
    },
    {
      "id": 815904141,
      "name": "ReVancedXposed",
      "full_name": "chsbuffer/ReVancedXposed",
      "description": "ReVanced LSPosed module. YouTube & YT Music Remove ads, Background playback",
      "html_url": "https://github.com/chsbuffer/ReVancedXposed",
      "stars": 2013,
      "forks": 85,
      "language": "Kotlin",
      "topics": [
        "android",
        "revanced",
        "xposed-module",
        "youtube",
        "youtube-music"
      ],
      "created_at": "2024-06-16T13:36:30Z",
      "updated_at": "2026-01-24T21:55:45Z",
      "pushed_at": "2026-01-22T23:45:19Z",
      "open_issues": 15,
      "owner": {
        "login": "chsbuffer",
        "avatar_url": "https://avatars.githubusercontent.com/u/33744752?v=4"
      },
      "readme": "<div align=\"center\">\n  <h1>ReVanced Xposed</h1>\n  <a href=\"https://discord.gg/QWUrAA2mKq\"><img alt=\"Discord Server\" src=\"https://img.shields.io/badge/Discord%20Server-5865F2.svg?logo=discord&logoColor=white\"></a>\n  <a href=\"https://t.me/revancedxposed\"><img alt=\"Telegram Channel\" src=\"https://img.shields.io/badge/Telegram_Channel-blue.svg?logo=telegram&logoColor=white\"></a>\n  <a href=\"https://github.com/chsbuffer/ReVancedXposed/releases/latest\"><img alt=\"GitHub Downloads\" src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fshields.chsbuffer.workers.dev%2F%3Frepos%3Dchsbuffer%2FReVancedXposed%2CXposed-Modules-Repo%2Fio.github.chsbuffer.revancedxposed&cacheSeconds=3600\"></a>\n  <a href=\"https://github.com/chsbuffer/ReVancedXposed\"><img alt=\"GitHub Stars\" src=\"https://img.shields.io/github/stars/chsbuffer/ReVancedXposed\"></a>  \n  <br>\n</div>\n\n**ReVanced LSPosed module by ChsBuffer.**  \n>[!IMPORTANT]  \n> - This is **NOT an official ReVanced project**, do not ask the ReVanced developers for help.  \n> - **Root access** is strictly **required** to use this module!\n> - **Spotify is no longer supported!** Get the new module [here](https://github.com/chsbuffer/ReVancedXposed_Spotify)\n> - **Having issues?** Check the **[FAQ](https://github.com/chsbuffer/ReVancedXposed/wiki/Frequently-Asked-Questions)** before reporting.\n\n## Downloads\n- **Release build**: [Download](https://github.com/chsbuffer/ReVancedXposed/releases/latest)\n- **Nightly build**: [Download](https://nightly.link/chsbuffer/ReVancedXposed/workflows/android/main)\n\n<sub>If you've joined the YouTube beta program, please try the nightly build before reporting an issue.</sub>\n\n## Patches\n\n### Youtube\n- Remove ads\n- SponsorBlock\n- Remove background playback restrictions\n- Remove share links tracking query parameter\n- Hide and change navigation buttons\n- Swipe controls\n- Remember video quality changes\n- Show video quality button\n- Show advanced video quality menu\n- Copy video url video player button\n- Open external downloader app\n- Custom playback speed\n- Remember playback speed\n- Playback speed dialog button\n- Hide layout components\n- Hide video action buttons\n- Disable resuming Shorts on startup\n- Disable video codecs\n- Disable auto captions\n- Alternative thumbnails\n- Bypass image region restrictions\n\n### Spotify (Moved to Dedicated Repository)\n\n[ReVancedXposed_Spotify](https://github.com/chsbuffer/ReVancedXposed_Spotify)\n\n### Google Photos\n- Spoof Pixel XL\n\n### Youtube Music\n- Remove music video ads\n- Remove background playback restrictions\n- Hide upgrade button\n- Hide 'Get Music Premium' label\n- Enable exclusive audio playback\n\n### Instagram\n- Hide ads\n\n### Threads\n- Hide ads\n\n### Reddit\n- Hide ads\n- Sanitize sharing links\n\n### Strava\n- Unlock subscription features\n- Disable subscription suggestions\n\n### Photomath\n- Unlock plus\n\n## Supports\n[![Discord Server](https://img.shields.io/badge/Join-Discord-5865F2.svg?logo=discord)](https://discord.gg/QWUrAA2mKq)  \n[![FAQ](https://img.shields.io/badge/Read-FAQ-orange.svg?logo=github)](https://github.com/chsbuffer/ReVancedXposed/wiki/Frequently-Asked-Questions)  \nor [Create an issue](https://github.com/chsbuffer/ReVancedXposed/issues/new/choose)\n\n## â­ Credits\n\n[DexKit](https://luckypray.org/DexKit/en/): a high-performance dex runtime parsing library.  \n[ReVanced](https://revanced.app): Continuing the legacy of Vanced at [revanced.app](https://revanced.app)  \n",
      "stars_today": 4
    },
    {
      "id": 47023603,
      "name": "xxl-job",
      "full_name": "xuxueli/xxl-job",
      "description": "A distributed task scheduling framework.ï¼ˆåˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦å¹³å°XXL-JOBï¼‰",
      "html_url": "https://github.com/xuxueli/xxl-job",
      "stars": 29853,
      "forks": 11443,
      "language": "Java",
      "topics": [
        "cron",
        "distributed",
        "glue",
        "java",
        "job",
        "quartz",
        "restful",
        "schedule",
        "scheduler",
        "task",
        "xxl-job"
      ],
      "created_at": "2015-11-28T12:59:34Z",
      "updated_at": "2026-01-24T16:09:56Z",
      "pushed_at": "2026-01-04T08:44:34Z",
      "open_issues": 240,
      "owner": {
        "login": "xuxueli",
        "avatar_url": "https://avatars.githubusercontent.com/u/10633817?v=4"
      },
      "readme": "<p align=\"center\" >\n    <img src=\"https://www.xuxueli.com/doc/static/xxl-job/images/xxl-logo.jpg\" width=\"150\">\n    <h3 align=\"center\">XXL-JOB</h3>\n    <p align=\"center\">\n        XXL-JOB, a distributed task scheduling framework.\n        <br>\n        <a href=\"https://www.xuxueli.com/xxl-job/\"><strong>-- Home Page --</strong></a>\n        <br>\n        <br>\n        <a href=\"https://github.com/xuxueli/xxl-job/actions\">\n            <img src=\"https://github.com/xuxueli/xxl-job/workflows/Java%20CI/badge.svg\" >\n        </a>\n        <a href=\"https://central.sonatype.com/artifact/com.xuxueli/xxl-job-core\">\n            <img src=\"https://img.shields.io/maven-central/v/com.xuxueli/xxl-job-core\" >\n        </a>\n        <a href=\"https://github.com/xuxueli/xxl-job/releases\">\n         <img src=\"https://img.shields.io/github/release/xuxueli/xxl-job.svg\" >\n        </a>\n        <a href=\"https://github.com/xuxueli/xxl-job/\">\n            <img src=\"https://img.shields.io/github/stars/xuxueli/xxl-job\" >\n        </a>\n        <a href=\"https://hub.docker.com/r/xuxueli/xxl-job-admin/\">\n            <img src=\"https://img.shields.io/docker/pulls/xuxueli/xxl-job-admin\" >\n        </a>\n        <a href=\"http://www.gnu.org/licenses/gpl-3.0.html\">\n         <img src=\"https://img.shields.io/badge/license-GPLv3-blue.svg\" >\n        </a>\n        <a href=\"https://www.xuxueli.com/page/donate.html\">\n           <img src=\"https://img.shields.io/badge/%24-donate-ff69b4.svg?style=flat\" >\n        </a>\n    </p>\n</p>\n\n\n## Introduction\nXXL-JOB is a distributed task scheduling framework. \nIt's core design goal is to develop quickly and learn simple, lightweight, and easy to expand. \nNow, it's already open source, and many companies use it in production environments, real \"out-of-the-box\".\n\nXXL-JOBæ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦å¹³å°ï¼Œå…¶æ ¸å¿ƒè®¾è®¡ç›®æ ‡æ˜¯å¼€å‘è¿…é€Ÿã€å­¦ä¹ ç®€å•ã€è½»é‡çº§ã€æ˜“æ‰©å±•ã€‚ç°å·²å¼€æ”¾æºä»£ç å¹¶æ¥å…¥å¤šå®¶å…¬å¸çº¿ä¸Šäº§å“çº¿ï¼Œå¼€ç®±å³ç”¨ã€‚\n\n\n## Sponsor\nXXL-JOB is an open source and free project, with its ongoing development made possible entirely by the support of these awesome backers.\n\nXXL-JOB æ˜¯ä¸€ä¸ªå¼€æºä¸”å…è´¹é¡¹ç›®ï¼Œå…¶æ­£åœ¨è¿›è¡Œçš„å¼€å‘å®Œå…¨å¾—ç›Šäºæ”¯æŒè€…çš„æ”¯æŒã€‚å¼€æºä¸æ˜“ï¼Œ[å‰å¾€èµåŠ©é¡¹ç›®å¼€å‘](https://www.xuxueli.com/page/donate.html )\n\n<!-- supporter start -->\n<h3 style=\"color: #E6BE8A;\" >é‡‘ç‰ŒèµåŠ©æ–¹</h3>\n<table>\n<tr>\n    <td>\n        <a href=\"https://www.aliyun.com/product/aliware/mse?utm_content=g_1000401794\" title=\"\" target=\"_blank\" >\n            <img width=\"150px\" src=\"http://www.xuxueli.com/page/static/images/logo_aliyun2.png\" >\n            <br>\n            <span style=\"text-decoration:underline;color: #E6BE8A;\" >é˜¿é‡Œäº‘ æä¾›äº‘ä¸Šæ‰˜ç®¡ XXL-JOB</span>\n        </a>\n    </td>\n    <td>\n        <a href=\"https://www.mall4j.com/cn/?statId=10\" title=\"\" target=\"_blank\" >\n            <img width=\"150px\" src=\"http://www.xuxueli.com/page/static/images/logo_mail4j.png\" >\n        </a>\n    </td>\n</tr>\n</table>\n<!-- supporter end -->\n\n\n## Documentation\n- [ä¸­æ–‡æ–‡æ¡£](https://www.xuxueli.com/xxl-job/)\n- [English Documentation](https://www.xuxueli.com/xxl-job/en/)\n\n\n## Communication    \n- [ç¤¾åŒºäº¤æµ](https://www.xuxueli.com/page/community.html)\n\n\n## Features\n- 1ã€ç®€å•ï¼šæ”¯æŒé€šè¿‡Webé¡µé¢å¯¹ä»»åŠ¡è¿›è¡ŒCRUDæ“ä½œï¼Œæ“ä½œç®€å•ï¼Œä¸€åˆ†é’Ÿä¸Šæ‰‹ï¼›\n- 2ã€åŠ¨æ€ï¼šæ”¯æŒåŠ¨æ€ä¿®æ”¹ä»»åŠ¡çŠ¶æ€ã€å¯åŠ¨/åœæ­¢ä»»åŠ¡ï¼Œä»¥åŠç»ˆæ­¢è¿è¡Œä¸­ä»»åŠ¡ï¼Œå³æ—¶ç”Ÿæ•ˆï¼›\n- 3ã€è°ƒåº¦ä¸­å¿ƒHAï¼ˆä¸­å¿ƒå¼ï¼‰ï¼šè°ƒåº¦é‡‡ç”¨ä¸­å¿ƒå¼è®¾è®¡ï¼Œâ€œè°ƒåº¦ä¸­å¿ƒâ€è‡ªç ”è°ƒåº¦ç»„ä»¶å¹¶æ”¯æŒé›†ç¾¤éƒ¨ç½²ï¼Œå¯ä¿è¯è°ƒåº¦ä¸­å¿ƒHAï¼›\n- 4ã€æ‰§è¡Œå™¨HAï¼ˆåˆ†å¸ƒå¼ï¼‰ï¼šä»»åŠ¡åˆ†å¸ƒå¼æ‰§è¡Œï¼Œä»»åŠ¡\"æ‰§è¡Œå™¨\"æ”¯æŒé›†ç¾¤éƒ¨ç½²ï¼Œå¯ä¿è¯ä»»åŠ¡æ‰§è¡ŒHAï¼›\n- 5ã€æ³¨å†Œä¸­å¿ƒ: æ‰§è¡Œå™¨ä¼šå‘¨æœŸæ€§è‡ªåŠ¨æ³¨å†Œä»»åŠ¡, è°ƒåº¦ä¸­å¿ƒå°†ä¼šè‡ªåŠ¨å‘ç°æ³¨å†Œçš„ä»»åŠ¡å¹¶è§¦å‘æ‰§è¡Œã€‚åŒæ—¶ï¼Œä¹Ÿæ”¯æŒæ‰‹åŠ¨å½•å…¥æ‰§è¡Œå™¨åœ°å€ï¼›\n- 6ã€å¼¹æ€§æ‰©å®¹ç¼©å®¹ï¼šä¸€æ—¦æœ‰æ–°æ‰§è¡Œå™¨æœºå™¨ä¸Šçº¿æˆ–è€…ä¸‹çº¿ï¼Œä¸‹æ¬¡è°ƒåº¦æ—¶å°†ä¼šé‡æ–°åˆ†é…ä»»åŠ¡ï¼›\n- 7ã€è§¦å‘ç­–ç•¥ï¼šæä¾›ä¸°å¯Œçš„ä»»åŠ¡è§¦å‘ç­–ç•¥ï¼ŒåŒ…æ‹¬ï¼šCronè§¦å‘ã€å›ºå®šé—´éš”è§¦å‘ã€å›ºå®šå»¶æ—¶è§¦å‘ã€APIï¼ˆäº‹ä»¶ï¼‰è§¦å‘ã€äººå·¥è§¦å‘ã€çˆ¶å­ä»»åŠ¡è§¦å‘ï¼›\n- 8ã€è°ƒåº¦è¿‡æœŸç­–ç•¥ï¼šè°ƒåº¦ä¸­å¿ƒé”™è¿‡è°ƒåº¦æ—¶é—´çš„è¡¥å¿å¤„ç†ç­–ç•¥ï¼ŒåŒ…æ‹¬ï¼šå¿½ç•¥ã€ç«‹å³è¡¥å¿è§¦å‘ä¸€æ¬¡ç­‰ï¼›\n- 9ã€é˜»å¡å¤„ç†ç­–ç•¥ï¼šè°ƒåº¦è¿‡äºå¯†é›†æ‰§è¡Œå™¨æ¥ä¸åŠå¤„ç†æ—¶çš„å¤„ç†ç­–ç•¥ï¼Œç­–ç•¥åŒ…æ‹¬ï¼šå•æœºä¸²è¡Œï¼ˆé»˜è®¤ï¼‰ã€ä¸¢å¼ƒåç»­è°ƒåº¦ã€è¦†ç›–ä¹‹å‰è°ƒåº¦ï¼›\n- 10ã€ä»»åŠ¡è¶…æ—¶æ§åˆ¶ï¼šæ”¯æŒè‡ªå®šä¹‰ä»»åŠ¡è¶…æ—¶æ—¶é—´ï¼Œä»»åŠ¡è¿è¡Œè¶…æ—¶å°†ä¼šä¸»åŠ¨ä¸­æ–­ä»»åŠ¡ï¼›\n- 11ã€ä»»åŠ¡å¤±è´¥é‡è¯•ï¼šæ”¯æŒè‡ªå®šä¹‰ä»»åŠ¡å¤±è´¥é‡è¯•æ¬¡æ•°ï¼Œå½“ä»»åŠ¡å¤±è´¥æ—¶å°†ä¼šæŒ‰ç…§é¢„è®¾çš„å¤±è´¥é‡è¯•æ¬¡æ•°ä¸»åŠ¨è¿›è¡Œé‡è¯•ï¼›å…¶ä¸­åˆ†ç‰‡ä»»åŠ¡æ”¯æŒåˆ†ç‰‡ç²’åº¦çš„å¤±è´¥é‡è¯•ï¼›\n- 12ã€ä»»åŠ¡å¤±è´¥å‘Šè­¦ï¼›é»˜è®¤æä¾›é‚®ä»¶æ–¹å¼å¤±è´¥å‘Šè­¦ï¼ŒåŒæ—¶é¢„ç•™æ‰©å±•æ¥å£ï¼Œå¯æ–¹ä¾¿çš„æ‰©å±•çŸ­ä¿¡ã€é’‰é’‰ç­‰å‘Šè­¦æ–¹å¼ï¼›\n- 13ã€è·¯ç”±ç­–ç•¥ï¼šæ‰§è¡Œå™¨é›†ç¾¤éƒ¨ç½²æ—¶æä¾›ä¸°å¯Œçš„è·¯ç”±ç­–ç•¥ï¼ŒåŒ…æ‹¬ï¼šç¬¬ä¸€ä¸ªã€æœ€åä¸€ä¸ªã€è½®è¯¢ã€éšæœºã€ä¸€è‡´æ€§HASHã€æœ€ä¸ç»å¸¸ä½¿ç”¨ã€æœ€è¿‘æœ€ä¹…æœªä½¿ç”¨ã€æ•…éšœè½¬ç§»ã€å¿™ç¢Œè½¬ç§»ç­‰ï¼›\n- 14ã€åˆ†ç‰‡å¹¿æ’­ä»»åŠ¡ï¼šæ‰§è¡Œå™¨é›†ç¾¤éƒ¨ç½²æ—¶ï¼Œä»»åŠ¡è·¯ç”±ç­–ç•¥é€‰æ‹©\"åˆ†ç‰‡å¹¿æ’­\"æƒ…å†µä¸‹ï¼Œä¸€æ¬¡ä»»åŠ¡è°ƒåº¦å°†ä¼šå¹¿æ’­è§¦å‘é›†ç¾¤ä¸­æ‰€æœ‰æ‰§è¡Œå™¨æ‰§è¡Œä¸€æ¬¡ä»»åŠ¡ï¼Œå¯æ ¹æ®åˆ†ç‰‡å‚æ•°å¼€å‘åˆ†ç‰‡ä»»åŠ¡ï¼›\n- 15ã€åŠ¨æ€åˆ†ç‰‡ï¼šåˆ†ç‰‡å¹¿æ’­ä»»åŠ¡ä»¥æ‰§è¡Œå™¨ä¸ºç»´åº¦è¿›è¡Œåˆ†ç‰‡ï¼Œæ”¯æŒåŠ¨æ€æ‰©å®¹æ‰§è¡Œå™¨é›†ç¾¤ä»è€ŒåŠ¨æ€å¢åŠ åˆ†ç‰‡æ•°é‡ï¼ŒååŒè¿›è¡Œä¸šåŠ¡å¤„ç†ï¼›åœ¨è¿›è¡Œå¤§æ•°æ®é‡ä¸šåŠ¡æ“ä½œæ—¶å¯æ˜¾è‘—æå‡ä»»åŠ¡å¤„ç†èƒ½åŠ›å’Œé€Ÿåº¦ã€‚\n- 16ã€æ•…éšœè½¬ç§»ï¼šä»»åŠ¡è·¯ç”±ç­–ç•¥é€‰æ‹©\"æ•…éšœè½¬ç§»\"æƒ…å†µä¸‹ï¼Œå¦‚æœæ‰§è¡Œå™¨é›†ç¾¤ä¸­æŸä¸€å°æœºå™¨æ•…éšœï¼Œå°†ä¼šè‡ªåŠ¨Failoveråˆ‡æ¢åˆ°ä¸€å°æ­£å¸¸çš„æ‰§è¡Œå™¨å‘é€è°ƒåº¦è¯·æ±‚ã€‚\n- 17ã€ä»»åŠ¡è¿›åº¦ç›‘æ§ï¼šæ”¯æŒå®æ—¶ç›‘æ§ä»»åŠ¡è¿›åº¦ï¼›\n- 18ã€Rollingå®æ—¶æ—¥å¿—ï¼šæ”¯æŒåœ¨çº¿æŸ¥çœ‹è°ƒåº¦ç»“æœï¼Œå¹¶ä¸”æ”¯æŒä»¥Rollingæ–¹å¼å®æ—¶æŸ¥çœ‹æ‰§è¡Œå™¨è¾“å‡ºçš„å®Œæ•´çš„æ‰§è¡Œæ—¥å¿—ï¼›\n- 19ã€GLUEï¼šæä¾›Web IDEï¼Œæ”¯æŒåœ¨çº¿å¼€å‘ä»»åŠ¡é€»è¾‘ä»£ç ï¼ŒåŠ¨æ€å‘å¸ƒï¼Œå®æ—¶ç¼–è¯‘ç”Ÿæ•ˆï¼Œçœç•¥éƒ¨ç½²ä¸Šçº¿çš„è¿‡ç¨‹ã€‚æ”¯æŒ30ä¸ªç‰ˆæœ¬çš„å†å²ç‰ˆæœ¬å›æº¯ã€‚\n- 20ã€è„šæœ¬ä»»åŠ¡ï¼šæ”¯æŒä»¥GLUEæ¨¡å¼å¼€å‘å’Œè¿è¡Œè„šæœ¬ä»»åŠ¡ï¼ŒåŒ…æ‹¬Shellã€Pythonã€NodeJSã€PHPã€PowerShellç­‰ç±»å‹è„šæœ¬;\n- 21ã€å‘½ä»¤è¡Œä»»åŠ¡ï¼šåŸç”Ÿæä¾›é€šç”¨å‘½ä»¤è¡Œä»»åŠ¡Handlerï¼ˆBeanä»»åŠ¡ï¼Œ\"CommandJobHandler\"ï¼‰ï¼›ä¸šåŠ¡æ–¹åªéœ€è¦æä¾›å‘½ä»¤è¡Œå³å¯ï¼›\n- 22ã€ä»»åŠ¡ä¾èµ–ï¼šæ”¯æŒé…ç½®å­ä»»åŠ¡ä¾èµ–ï¼Œå½“çˆ¶ä»»åŠ¡æ‰§è¡Œç»“æŸä¸”æ‰§è¡ŒæˆåŠŸåå°†ä¼šä¸»åŠ¨è§¦å‘ä¸€æ¬¡å­ä»»åŠ¡çš„æ‰§è¡Œ, å¤šä¸ªå­ä»»åŠ¡ç”¨é€—å·åˆ†éš”ï¼›\n- 23ã€ä¸€è‡´æ€§ï¼šâ€œè°ƒåº¦ä¸­å¿ƒâ€é€šè¿‡DBé”ä¿è¯é›†ç¾¤åˆ†å¸ƒå¼è°ƒåº¦çš„ä¸€è‡´æ€§, ä¸€æ¬¡ä»»åŠ¡è°ƒåº¦åªä¼šè§¦å‘ä¸€æ¬¡æ‰§è¡Œï¼›\n- 24ã€è‡ªå®šä¹‰ä»»åŠ¡å‚æ•°ï¼šæ”¯æŒåœ¨çº¿é…ç½®è°ƒåº¦ä»»åŠ¡å…¥å‚ï¼Œå³æ—¶ç”Ÿæ•ˆï¼›\n- 25ã€è°ƒåº¦çº¿ç¨‹æ± ï¼šè°ƒåº¦ç³»ç»Ÿå¤šçº¿ç¨‹è§¦å‘è°ƒåº¦è¿è¡Œï¼Œç¡®ä¿è°ƒåº¦ç²¾ç¡®æ‰§è¡Œï¼Œä¸è¢«å µå¡ï¼›\n- 26ã€æ•°æ®åŠ å¯†ï¼šè°ƒåº¦ä¸­å¿ƒå’Œæ‰§è¡Œå™¨ä¹‹é—´çš„é€šè®¯è¿›è¡Œæ•°æ®åŠ å¯†ï¼Œæå‡è°ƒåº¦ä¿¡æ¯å®‰å…¨æ€§ï¼›\n- 27ã€é‚®ä»¶æŠ¥è­¦ï¼šä»»åŠ¡å¤±è´¥æ—¶æ”¯æŒé‚®ä»¶æŠ¥è­¦ï¼Œæ”¯æŒé…ç½®å¤šé‚®ä»¶åœ°å€ç¾¤å‘æŠ¥è­¦é‚®ä»¶ï¼›\n- 28ã€æ¨é€mavenä¸­å¤®ä»“åº“: å°†ä¼šæŠŠæœ€æ–°ç¨³å®šç‰ˆæ¨é€åˆ°mavenä¸­å¤®ä»“åº“, æ–¹ä¾¿ç”¨æˆ·æ¥å…¥å’Œä½¿ç”¨;\n- 29ã€è¿è¡ŒæŠ¥è¡¨ï¼šæ”¯æŒå®æ—¶æŸ¥çœ‹è¿è¡Œæ•°æ®ï¼Œå¦‚ä»»åŠ¡æ•°é‡ã€è°ƒåº¦æ¬¡æ•°ã€æ‰§è¡Œå™¨æ•°é‡ç­‰ï¼›ä»¥åŠè°ƒåº¦æŠ¥è¡¨ï¼Œå¦‚è°ƒåº¦æ—¥æœŸåˆ†å¸ƒå›¾ï¼Œè°ƒåº¦æˆåŠŸåˆ†å¸ƒå›¾ç­‰ï¼›\n- 30ã€å…¨å¼‚æ­¥ï¼šä»»åŠ¡è°ƒåº¦æµç¨‹å…¨å¼‚æ­¥åŒ–è®¾è®¡å®ç°ï¼Œå¦‚å¼‚æ­¥è°ƒåº¦ã€å¼‚æ­¥è¿è¡Œã€å¼‚æ­¥å›è°ƒç­‰ï¼Œæœ‰æ•ˆå¯¹å¯†é›†è°ƒåº¦è¿›è¡Œæµé‡å‰Šå³°ï¼Œç†è®ºä¸Šæ”¯æŒä»»æ„æ—¶é•¿ä»»åŠ¡çš„è¿è¡Œï¼›\n- 31ã€è·¨è¯­è¨€/OpenAPIï¼šè°ƒåº¦ä¸­å¿ƒä¸æ‰§è¡Œå™¨æä¾›è¯­è¨€æ— å…³çš„ OpenApiï¼ˆRESTful æ ¼å¼ï¼‰ï¼Œç¬¬ä¸‰æ–¹ä»»æ„è¯­è¨€å¯æ®æ­¤å¯¹æ¥è°ƒåº¦ä¸­å¿ƒæˆ–è€…å®ç°æ‰§è¡Œå™¨ï¼Œå®ç°å¤šè¯­è¨€æ”¯æŒã€‚é™¤æ­¤ä¹‹å¤–ï¼Œè¿˜æä¾›äº† â€œå¤šä»»åŠ¡æ¨¡å¼â€å’Œâ€œhttpJobHandlerâ€ç­‰å…¶ä»–è·¨è¯­è¨€æ–¹æ¡ˆï¼›\n- 32ã€å›½é™…åŒ–ï¼šè°ƒåº¦ä¸­å¿ƒæ”¯æŒå›½é™…åŒ–è®¾ç½®ï¼Œæä¾›ä¸­æ–‡ã€è‹±æ–‡ä¸¤ç§å¯é€‰è¯­è¨€ï¼Œé»˜è®¤ä¸ºä¸­æ–‡ï¼›\n- 33ã€å®¹å™¨åŒ–ï¼šæä¾›å®˜æ–¹dockeré•œåƒï¼Œå¹¶å®æ—¶æ›´æ–°æ¨é€dockerhubï¼Œè¿›ä¸€æ­¥å®ç°äº§å“å¼€ç®±å³ç”¨ï¼›\n- 34ã€çº¿ç¨‹æ± éš”ç¦»ï¼šè°ƒåº¦çº¿ç¨‹æ± è¿›è¡Œéš”ç¦»æ‹†åˆ†ï¼Œæ…¢ä»»åŠ¡è‡ªåŠ¨é™çº§è¿›å…¥\"Slow\"çº¿ç¨‹æ± ï¼Œé¿å…è€—å°½è°ƒåº¦çº¿ç¨‹ï¼Œæé«˜ç³»ç»Ÿç¨³å®šæ€§ï¼›\n- 35ã€ç”¨æˆ·ç®¡ç†ï¼šæ”¯æŒåœ¨çº¿ç®¡ç†ç³»ç»Ÿç”¨æˆ·ï¼Œå­˜åœ¨ç®¡ç†å‘˜ã€æ™®é€šç”¨æˆ·ä¸¤ç§è§’è‰²ï¼›\n- 36ã€æƒé™æ§åˆ¶ï¼šæ‰§è¡Œå™¨ç»´åº¦è¿›è¡Œæƒé™æ§åˆ¶ï¼Œç®¡ç†å‘˜æ‹¥æœ‰å…¨é‡æƒé™ï¼Œæ™®é€šç”¨æˆ·éœ€è¦åˆ†é…æ‰§è¡Œå™¨æƒé™åæ‰å…è®¸ç›¸å…³æ“ä½œï¼›\n- 37ã€AIä»»åŠ¡ï¼šåŸç”Ÿæä¾›AIæ‰§è¡Œå™¨ï¼Œå¹¶å†…ç½®å¤šä¸ªAIä»»åŠ¡Handlerï¼Œä¸spring-aiã€ollamaã€difyç­‰é›†æˆæ‰“é€šï¼Œæ”¯æŒå¿«é€Ÿå¼€å‘AIç±»ä»»åŠ¡ã€‚\n- 38ã€å®¡è®¡æ—¥å¿—ï¼šè®°å½•ä»»åŠ¡æ“ä½œæ•æ„Ÿä¿¡æ¯ï¼Œç”¨äºç³»ç»Ÿç›‘æ§ã€å®¡è®¡å’Œå®‰å…¨åˆ†æï¼Œå¯å¿«é€Ÿè¿½æº¯å¼‚å¸¸è¡Œä¸ºä»¥åŠå®šä½æ’æŸ¥é—®é¢˜ã€‚\n- 39ã€ä¼˜é›…åœæœºï¼šè°ƒåº¦ä¸­å¿ƒåœæœºï¼Œæ£€æµ‹æ—¶é—´è½®éç©ºæ—¶ä¸»åŠ¨ç­‰å¾…è°ƒåº¦å®Œæˆï¼›å®¢æˆ·ç«¯åœæœºï¼Œæ£€æµ‹å­˜åœ¨è¿è¡Œä¸­ä»»åŠ¡æ—¶ï¼Œåœæ­¢æ¥æ”¶æ–°ä»»åŠ¡å¹¶ä¸»åŠ¨ç­‰å¾…ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼›\n\n## Development\näº2015å¹´ä¸­ï¼Œæˆ‘åœ¨githubä¸Šåˆ›å»ºXXL-JOBé¡¹ç›®ä»“åº“å¹¶æäº¤ç¬¬ä¸€ä¸ªcommitï¼Œéšä¹‹è¿›è¡Œç³»ç»Ÿç»“æ„è®¾è®¡ï¼ŒUIé€‰å‹ï¼Œäº¤äº’è®¾è®¡â€¦â€¦\n\näº2015-11æœˆï¼ŒXXL-JOBç»ˆäºRELEASEäº†ç¬¬ä¸€ä¸ªå¤§ç‰ˆæœ¬V1.0ï¼Œ éšåæˆ‘å°†ä¹‹å‘å¸ƒåˆ°OSCHINAï¼ŒXXL-JOBåœ¨OSCHINAä¸Šè·å¾—äº†@çº¢è–¯çš„çƒ­é—¨æ¨èï¼ŒåŒæœŸåˆ†åˆ«è¾¾åˆ°äº†OSCHINAçš„â€œçƒ­é—¨åŠ¨å¼¹â€æ’è¡Œç¬¬ä¸€å’Œgit.oschinaçš„å¼€æºè½¯ä»¶æœˆçƒ­åº¦æ’è¡Œç¬¬ä¸€ï¼Œåœ¨æ­¤ç‰¹åˆ«æ„Ÿè°¢çº¢è–¯ï¼Œæ„Ÿè°¢å¤§å®¶çš„å…³æ³¨å’Œæ”¯æŒã€‚\n\näº2015-12æœˆï¼Œæˆ‘å°†XXL-JOBå‘è¡¨åˆ°æˆ‘å¸å†…éƒ¨çŸ¥è¯†åº“ï¼Œå¹¶ä¸”å¾—åˆ°å†…éƒ¨åŒäº‹è®¤å¯ã€‚\n\näº2016-01æœˆï¼Œæˆ‘å¸å±•å¼€XXL-JOBçš„å†…éƒ¨æ¥å…¥å’Œå®šåˆ¶å·¥ä½œï¼Œåœ¨æ­¤æ„Ÿè°¢è¢æŸå’Œå°¹æŸä¸¤ä½åŒäº‹çš„è´¡çŒ®ï¼ŒåŒæ—¶ä¹Ÿæ„Ÿè°¢å†…éƒ¨å…¶ä»–ç»™ä¸å…³æ³¨ä¸æ”¯æŒçš„åŒäº‹ã€‚\n\näº2017-05-13ï¼Œåœ¨ä¸Šæµ·ä¸¾åŠçš„ \"[ç¬¬62æœŸå¼€æºä¸­å›½æºåˆ›ä¼š](https://www.oschina.net/event/2236961)\" çš„ \"æ”¾ç è¿‡æ¥\" ç¯èŠ‚ï¼Œæˆ‘ç™»å°å¯¹XXL-JOBåšäº†æ¼”è®²ï¼Œå°ä¸‹äº”ç™¾ä½åœ¨åœºè§‚ä¼—åå“çƒ­çƒˆï¼ˆ[å›¾æ–‡å›é¡¾](https://www.oschina.net/question/2686220_2242120) ï¼‰ã€‚\n\näº2017-10-22ï¼Œåˆæ‹äº‘ Open Talk è”åˆ Spring Cloud ä¸­å›½ç¤¾åŒºä¸¾åŠçš„ \"[è¿›å‡»çš„å¾®æœåŠ¡å®æˆ˜æ´¾ä¸Šæµ·ç«™](https://opentalk.upyun.com/303.html)\"ï¼Œæˆ‘ç™»å°å¯¹XXL-JOBåšäº†æ¼”è®²ï¼Œç°åœºè§‚ä¼—åå“çƒ­çƒˆå¹¶åœ¨ä¼šåä¸XXL-JOBç”¨æˆ·çƒ­çƒˆè®¨è®ºäº¤æµã€‚\n\näº2017-12-11ï¼ŒXXL-JOBæœ‰å¹¸å‚ä¼šã€Š[InfoQ ArchSummitå…¨çƒæ¶æ„å¸ˆå³°ä¼š](http://bj2017.archsummit.com/)ã€‹ï¼Œå¹¶è¢«æ‹æ‹è´·æ¶æ„æ€»ç›‘\"æ¨æ³¢è€å¸ˆ\"åœ¨ä¸“é¢˜ \"[å¾®æœåŠ¡åŸç†ã€åŸºç¡€æ¶æ„å’Œå¼€æºå®è·µ](http://bj2017.archsummit.com/training/2)\" ä¸­ç°åœºä»‹ç»ã€‚\n\näº2017-12-18ï¼ŒXXL-JOBå‚ä¸\"[2017å¹´åº¦æœ€å—æ¬¢è¿ä¸­å›½å¼€æºè½¯ä»¶](http://www.oschina.net/project/top_cn_2017?sort=1)\"è¯„æ¯”ï¼Œåœ¨å½“æ—¶å·²å½•å…¥çš„çº¦ä¹åƒä¸ªå›½äº§å¼€æºé¡¹ç›®ä¸­è§’é€ï¼Œæœ€ç»ˆè¿›å…¥äº†å‰30å¼ºã€‚\n\näº2018-01-15ï¼ŒXXL-JOBå‚ä¸\"[2017ç äº‘æœ€ç«å¼€æºé¡¹ç›®](https://www.oschina.net/news/92438/2017-mayun-top-50)\"è¯„æ¯”ï¼Œåœ¨å½“æ—¶å·²å½•å…¥çš„çº¦å…­åƒäº”ç™¾ä¸ªç äº‘é¡¹ç›®ä¸­è§’é€ï¼Œæœ€ç»ˆè¿›å»äº†å‰20å¼ºã€‚\n\näº2018-04-14ï¼ŒiTechPlusåœ¨ä¸Šæµ·ä¸¾åŠçš„ \"[2018äº’è”ç½‘å¼€å‘è€…å¤§ä¼š](http://www.itdks.com/eventlist/detail/2065)\"ï¼Œæˆ‘ç™»å°å¯¹XXL-JOBåšäº†æ¼”è®²ï¼Œç°åœºè§‚ä¼—åå“çƒ­çƒˆå¹¶åœ¨ä¼šåä¸XXL-JOBç”¨æˆ·çƒ­çƒˆè®¨è®ºäº¤æµã€‚\n\näº2018-05-27ï¼Œåœ¨ä¸Šæµ·ä¸¾åŠçš„ \"[ç¬¬75æœŸå¼€æºä¸­å›½æºåˆ›ä¼š](https://www.oschina.net/event/2278742)\" çš„ \"æ¶æ„\" ä¸»é¢˜ä¸“åœºï¼Œæˆ‘ç™»å°è¿›è¡Œâ€œåŸºç¡€æ¶æ„ä¸ä¸­é—´ä»¶å›¾è°±â€ä¸»é¢˜æ¼”è®²ï¼Œå°ä¸‹ä¸Šåƒä½åœ¨åœºè§‚ä¼—åå“çƒ­çƒˆï¼ˆ[å›¾æ–‡å›é¡¾](https://www.oschina.net/question/3802184_2280606) ï¼‰ã€‚\n\näº2018-12-05ï¼ŒXXL-JOBå‚ä¸\"[2018å¹´åº¦æœ€å—æ¬¢è¿ä¸­å›½å¼€æºè½¯ä»¶](https://www.oschina.net/project/top_cn_2018?sort=1)\"è¯„æ¯”ï¼Œåœ¨å½“æ—¶å·²å½•å…¥çš„ä¸€ä¸‡å¤šä¸ªå¼€æºé¡¹ç›®ä¸­è§’é€ï¼Œæœ€ç»ˆæ’åç¬¬19åã€‚\n\näº2019-12-10ï¼ŒXXL-JOBå‚ä¸\"[2019å¹´åº¦æœ€å—æ¬¢è¿ä¸­å›½å¼€æºè½¯ä»¶](https://www.oschina.net/project/top_cn_2019)\"è¯„æ¯”ï¼Œåœ¨å½“æ—¶å·²å½•å…¥çš„ä¸€ä¸‡å¤šä¸ªå¼€æºé¡¹ç›®ä¸­è§’é€ï¼Œæœ€ç»ˆæ’å\"å¼€å‘æ¡†æ¶å’ŒåŸºç¡€ç»„ä»¶ç±»\"ç¬¬9åã€‚\n\näº2020-11-16ï¼ŒXXL-JOBå‚ä¸\"[2020å¹´åº¦æœ€å—æ¬¢è¿ä¸­å›½å¼€æºè½¯ä»¶](https://www.oschina.net/project/top_cn_2020)\"è¯„æ¯”ï¼Œåœ¨å½“æ—¶å·²å½•å…¥çš„ä¸€ä¸‡å¤šä¸ªå¼€æºé¡¹ç›®ä¸­è§’é€ï¼Œæœ€ç»ˆæ’å\"å¼€å‘æ¡†æ¶å’ŒåŸºç¡€ç»„ä»¶ç±»\"ç¬¬8åã€‚\n\näº2021-12-06ï¼ŒXXL-JOBå‚ä¸\"[2021å¹´åº¦OSCä¸­å›½å¼€æºé¡¹ç›®è¯„é€‰](https://www.oschina.net/project/top_cn_2021) \"è¯„æ¯”ï¼Œåœ¨å½“æ—¶å·²å½•å…¥çš„ä¸€ä¸‡å¤šä¸ªå¼€æºé¡¹ç›®ä¸­è§’é€ï¼Œæœ€ç»ˆå½“é€‰\"æœ€å—æ¬¢è¿é¡¹ç›®\"ã€‚\n\näº2024-11-06ï¼ŒXXL-JOBç» GitCode å®˜æ–¹è¯„å®¡ï¼Œè·å¾— â€œG-Staré¡¹ç›®æ¯•ä¸šè®¤è¯â€ã€‚\n\n> æˆ‘å¸å¤§ä¼—ç‚¹è¯„ç›®å‰å·²æ¥å…¥XXL-JOBï¼Œå†…éƒ¨åˆ«åã€ŠFerrariã€‹ï¼ˆFerrariåŸºäºXXL-JOBçš„V1.1ç‰ˆæœ¬å®šåˆ¶è€Œæˆï¼Œæ–°æ¥å…¥åº”ç”¨æ¨èå‡çº§æœ€æ–°ç‰ˆæœ¬ï¼‰ã€‚\næ®æœ€æ–°ç»Ÿè®¡, è‡ª2016-01-21æ¥å…¥è‡³2017-12-01æœŸé—´ï¼Œè¯¥ç³»ç»Ÿå·²è°ƒåº¦çº¦100ä¸‡æ¬¡ï¼Œè¡¨ç°ä¼˜å¼‚ã€‚æ–°æ¥å…¥åº”ç”¨æ¨èä½¿ç”¨æœ€æ–°ç‰ˆæœ¬ï¼Œå› ä¸ºç»è¿‡æ•°åä¸ªç‰ˆæœ¬çš„æ›´æ–°ï¼Œç³»ç»Ÿçš„ä»»åŠ¡æ¨¡å‹ã€UIäº¤äº’æ¨¡å‹ä»¥åŠåº•å±‚è°ƒåº¦é€šè®¯æ¨¡å‹éƒ½æœ‰äº†è¾ƒå¤§çš„ä¼˜åŒ–å’Œæå‡ï¼Œæ ¸å¿ƒåŠŸèƒ½æ›´åŠ ç¨³å®šé«˜æ•ˆã€‚\n\nè‡³ä»Šï¼ŒXXL-JOBå·²æ¥å…¥å¤šå®¶å…¬å¸çš„çº¿ä¸Šäº§å“çº¿ï¼Œæ¥å…¥åœºæ™¯å¦‚ç”µå•†ä¸šåŠ¡ï¼ŒO2Oä¸šåŠ¡å’Œå¤§æ•°æ®ä½œä¸šç­‰ï¼Œæˆªæ­¢æœ€æ–°ç»Ÿè®¡æ—¶é—´ä¸ºæ­¢ï¼ŒXXL-JOBå·²æ¥å…¥çš„å…¬å¸åŒ…æ‹¬ä¸é™äºï¼š\n    \n\t- 1ã€å¤§ä¼—ç‚¹è¯„ã€ç¾å›¢ç‚¹è¯„ã€‘\n\t- 2ã€å±±ä¸œå­¦è€Œç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸ï¼›\n\t- 3ã€å®‰å¾½æ…§é€šäº’è”ç§‘æŠ€æœ‰é™å…¬å¸ï¼›\n\t- 4ã€äººäººèšè´¢é‡‘æœï¼›\n\t- 5ã€ä¸Šæµ·æ£ æ££ä¿¡æ¯ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n\t- 6ã€è¿æ»¡æ»¡ã€è¿æ»¡æ»¡ã€‘\n\t- 7ã€ç±³å…¶æ— (ä¸­å›½åŒº)ã€ç±³å…¶æ—ã€‘\n\t- 8ã€å¦ˆå¦ˆè”ç›Ÿ\n\t- 9ã€ä¹æ¨±å¤©ä¸‹ï¼ˆåŒ—äº¬ï¼‰ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n\t- 10ã€ä¸‡æ™®æ‹‰æ–¯ç§‘æŠ€æœ‰é™å…¬å¸ã€ä¸€åŠ æ‰‹æœºã€‘\n\t- 11ã€ä¸Šæµ·äº¿ä¿å¥åº·ç®¡ç†æœ‰é™å…¬å¸\n\t- 12ã€æµ·å°”é¦¨å¨ã€æµ·å°”ã€‘\n\t- 13ã€æ²³å—å¤§çº¢åŒ…ç”µå­å•†åŠ¡æœ‰é™å…¬å¸\n\t- 14ã€æˆéƒ½é¡ºç‚¹ç§‘æŠ€æœ‰é™å…¬å¸\n\t- 15ã€æ·±åœ³å¸‚æ€¡äºšé€š\n\t- 16ã€æ·±åœ³éº¦äºšä¿¡ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n\t- 17ã€ä¸Šæµ·åšè¹ç§‘æŠ€ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n\t- 18ã€ä¸­å›½å¹³å®‰ç§‘æŠ€æœ‰é™å…¬å¸ã€ä¸­å›½å¹³å®‰ã€‘\n\t- 19ã€æ­å·çŸ¥æ—¶ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n\t- 20ã€åšè¹ç§‘æŠ€ï¼ˆä¸Šæµ·ï¼‰æœ‰é™å…¬å¸\n\t- 21ã€æˆéƒ½ä¾èƒ½è‚¡ä»½æœ‰é™è´£ä»»å…¬å¸\n\t- 22ã€æ¹–å—é«˜é˜³é€šè”ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n\t- 23ã€æ·±åœ³å¸‚é‚¦å¾·æ–‡åŒ–å‘å±•æœ‰é™å…¬å¸\n\t- 24ã€ç¦å»ºé˜¿æ€å¯ç½‘ç»œæ•™è‚²æœ‰é™å…¬å¸\n\t- 25ã€ä¼˜ä¿¡äºŒæ‰‹è½¦ã€ä¼˜ä¿¡ã€‘\n\t- 26ã€ä¸Šæµ·æ‚ æ¸¸å ‚æŠ•èµ„å‘å±•è‚¡ä»½æœ‰é™å…¬å¸ã€æ‚ æ¸¸å ‚ã€‘\n\t- 27ã€åŒ—äº¬ç²‰ç¬”è“å¤©ç§‘æŠ€æœ‰é™å…¬å¸\n\t- 28ã€ä¸­ç§€ç§‘æŠ€(æ— é”¡)æœ‰é™å…¬å¸\n\t- 29ã€æ­¦æ±‰ç©ºå¿ƒç§‘æŠ€æœ‰é™å…¬å¸\n\t- 30ã€åŒ—äº¬èš‚èšé£æš´ç§‘æŠ€æœ‰é™å…¬å¸\n\t- 31ã€å››å·äº’å®œè¾¾ç§‘æŠ€æœ‰é™å…¬å¸\n\t- 32ã€é’±åŒ…è¡Œäº‘ï¼ˆåŒ—äº¬ï¼‰ç§‘æŠ€æœ‰é™å…¬å¸\n\t- 33ã€é‡åº†æ¬£æ‰é›†å›¢\n    - 34ã€å’ªå’•äº’åŠ¨å¨±ä¹æœ‰é™å…¬å¸ã€ä¸­å›½ç§»åŠ¨ã€‘\n    - 35ã€åŒ—äº¬è¯ºäº¦è…¾ç§‘æŠ€æœ‰é™å…¬å¸\n    - 36ã€å¢é•¿å¼•æ“(åŒ—äº¬)ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 37ã€åŒ—äº¬è‹±è´æ€ç§‘æŠ€æœ‰é™å…¬å¸\n    - 38ã€åˆšæ³°é›†å›¢\n    - 39ã€æ·±åœ³æ³°ä¹…ä¿¡æ¯ç³»ç»Ÿè‚¡ä»½æœ‰é™å…¬å¸\n    - 40ã€éšè¡Œä»˜æ”¯ä»˜æœ‰é™å…¬å¸\n    - 41ã€å¹¿å·ç€šå†œç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 42ã€äº«ç‚¹ç§‘æŠ€æœ‰é™å…¬å¸\n    - 43ã€æ­å·æ¯”æ™ºç§‘æŠ€æœ‰é™å…¬å¸\n    - 44ã€åœ³ä¸´ç•Œçº¿ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 45ã€å¹¿å·çŸ¥è¯†åœˆç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 46ã€å›½èª‰å•†ä¸šä¸Šæµ·æœ‰é™å…¬å¸\n    - 47ã€æµ·å°”æ¶ˆè´¹é‡‘èæœ‰é™å…¬å¸ï¼Œå—¨ä»˜ã€å¤ŸèŠ±ã€æµ·å°”ã€‘\n    - 48ã€å¹¿å·å·´å›¾é²ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 49ã€æ·±åœ³å¸‚é¹æµ·è¿ç”µå­æ•°æ®äº¤æ¢æœ‰é™å…¬å¸\n    - 50ã€æ·±åœ³å¸‚äºšé£ç”µå­å•†åŠ¡æœ‰é™å…¬å¸\n    - 51ã€ä¸Šæµ·è¶£åŒ»ç½‘ç»œæœ‰é™å…¬å¸\n    - 52ã€èšé‡‘èµ„æœ¬\n    - 53ã€åŒ—äº¬çˆ¶æ¯é‚¦ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 54ã€ä¸­å±±å…ƒèµ«è½¯ä»¶ç§‘æŠ€æœ‰é™å…¬å¸\n    - 55ã€ä¸­å•†æƒ æ°‘(åŒ—äº¬)ç”µå­å•†åŠ¡æœ‰é™å…¬å¸\n    - 56ã€å‡¯äº¬é›†å›¢\n    - 57ã€åå¤ç¥¨è”ï¼ˆåŒ—äº¬ï¼‰ç§‘æŠ€æœ‰é™å…¬å¸\n    - 58ã€æ‹æ‹è´·ã€æ‹æ‹è´·ã€‘\n    - 59ã€åŒ—äº¬å°šå¾·æœºæ„åœ¨çº¿æ•™è‚²æœ‰é™å…¬å¸\n    - 60ã€ä»»å­è¡Œè‚¡ä»½æœ‰é™å…¬å¸\n    - 61ã€åŒ—äº¬æ—¶æ€ç”µå­å•†åŠ¡æœ‰é™å…¬å¸\n    - 62ã€æ·±åœ³å·çš®ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 63ã€åŒ—äº¬å®‰åšé€šç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 64ã€æœªæ¥æ— çº¿ç½‘\n    - 65ã€å¦é—¨ç“·ç¦§ç½‘ç»œæœ‰é™å…¬å¸\n    - 66ã€åŒ—äº¬é€’è“ç§‘è½¯ä»¶è‚¡ä»½æœ‰é™å…¬å¸\n    - 67ã€éƒ‘å·åˆ›æµ·è½¯ä»¶ç§‘æŠ€å…¬å¸\n    - 68ã€åŒ—äº¬å›½æ§ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 69ã€æµªæ½®è½¯ä»¶é›†å›¢\n    - 70ã€å¤šç«‹æ’(åŒ—äº¬)ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 71ã€å¹¿å·æè¿…å®¢ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 72ã€èµ«åŸºï¼ˆä¸­å›½ï¼‰é›†å›¢è‚¡ä»½æœ‰é™å…¬å¸\n    - 73ã€æµ·æŠ•æ±‡\n    - 74ã€ä¸Šæµ·æ¶¦ç›Šåˆ›ä¸šå­µåŒ–å™¨ç®¡ç†è‚¡ä»½æœ‰é™å…¬å¸\n    - 75ã€æ±‰çº³æ£®ï¼ˆå¦é—¨ï¼‰æ•°æ®è‚¡ä»½æœ‰é™å…¬å¸\n    - 76ã€å®‰ä¿¡ä¿¡æ‰˜\n    - 77ã€å²šå„’è´¢å¯Œ\n    - 78ã€æ·é“è½¯ä»¶\n    - 79ã€æ¹–åŒ—äº«ä¸ƒç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 80ã€æ¹–å—åˆ›å‘ç§‘æŠ€è´£ä»»æœ‰é™å…¬å¸\n    - 81ã€æ·±åœ³å°å®‰æ—¶ä»£äº’è”ç½‘é‡‘èæœåŠ¡æœ‰é™å…¬å¸\n    - 82ã€æ¹–åŒ—äº«ä¸ƒç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 83ã€é’±åŒ…è¡Œäº‘(åŒ—äº¬)ç§‘æŠ€æœ‰é™å…¬å¸\n    - 84ã€360é‡‘èã€360ã€‘\n    - 85ã€æ˜“ä¼ç§€\n    - 86ã€æ‘©è´ï¼ˆä¸Šæµ·ï¼‰ç”Ÿç‰©ç§‘æŠ€æœ‰é™å…¬å¸\n    - 87ã€å¹¿ä¸œèŠ¯æ™ºæ…§ç§‘æŠ€æœ‰é™å…¬å¸\n    - 88ã€è”æƒ³é›†å›¢ã€è”æƒ³ã€‘\n    - 89ã€æ€ªå…½å……ç”µ\n    - 90ã€è¡Œåœ†æ±½è½¦\n    - 91ã€æ·±åœ³åº—åº—é€šç§‘æŠ€é‚®ç®±å…¬å¸\n    - 92ã€äº¬ä¸œã€äº¬ä¸œã€‘\n    - 93ã€ç±³åº„ç†è´¢\n    - 94ã€å’–å•¡æ˜“è\n    - 95ã€æ¢§æ¡è¯šé€‰\n    - 96ã€æ’å¤§åœ°äº§ã€æ’å¤§ã€‘\n    - 97ã€æ˜†æ˜é¾™æ…§\n    - 98ã€ä¸Šæµ·æ¶©ç‘¶è½¯ä»¶\n    - 99ã€æ˜“ä¿¡ã€ç½‘æ˜“ã€‘\n    - 100ã€é“œæ¿è¡—\n    - 101ã€æ­å·äº‘è‹¥ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 102ã€ç‰¹ç™¾æƒ ï¼ˆä¸­å›½ï¼‰æœ‰é™å…¬å¸\n    - 103ã€å¸¸å±±ä¼—å¡è¿åŠ›ä¾›åº”é“¾ç®¡ç†æœ‰é™å…¬å¸\n    - 104ã€æ·±åœ³ç«‹åˆ›ç”µå­å•†åŠ¡æœ‰é™å…¬å¸\n    - 105ã€æ­å·æ™ºè¯ºç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 106ã€åŒ—äº¬äº‘æ¼¾ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 107ã€æ·±åœ³å¸‚å¤šé“¶ç§‘æŠ€æœ‰é™å…¬å¸\n    - 108ã€äº²å®å®\n    - 109ã€ä¸Šæµ·åšå¡è½¯ä»¶ç§‘æŠ€æœ‰é™å…¬å¸\n    - 110ã€æ™ºæ…§æ ‘åœ¨çº¿æ•™è‚²å¹³å°\n    - 111ã€ç±³æ—é‡‘è\n    - 112ã€åŒ—äº¬è¾°æ£®ä¸–çºª\n    - 113ã€äº‘å—æ»‡åŒ»é€š\n    - 114ã€å¹¿å·å¸‚åˆ†é¢†ç½‘ç»œç§‘æŠ€æœ‰é™è´£ä»»å…¬å¸\n    - 115ã€æµ™æ±Ÿå¾®èƒ½ç§‘æŠ€æœ‰é™å…¬å¸\n    - 116ã€ä¸Šæµ·é¦¨é£ç”µå­å•†åŠ¡æœ‰é™å…¬å¸\n    - 117ã€ä¸Šæµ·å®å°Šç”µå­å•†åŠ¡æœ‰é™å…¬å¸\n    - 118ã€ç›´å®¢é€šç§‘æŠ€æŠ€æœ¯æœ‰é™å…¬å¸\n    - 119ã€ç§‘åº¦ç§‘æŠ€æœ‰é™å…¬å¸\n    - 120ã€ä¸Šæµ·æ•°æ…§ç³»ç»ŸæŠ€æœ¯æœ‰é™å…¬å¸\n    - 121ã€æˆ‘çš„åŒ»è¯ç½‘\n    - 122ã€å¤šç²‰å¹³å°\n    - 123ã€é“ç”²äºŒæ‰‹æœº\n    - 124ã€ä¸Šæµ·æµ·æ–°å¾—æ•°æ®æŠ€æœ¯æœ‰é™å…¬å¸\n    - 125ã€æ·±åœ³å¸‚ççˆ±ç½‘ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸ã€ççˆ±ç½‘ã€‘\n    - 126ã€å°èœœèœ‚\n    - 127ã€å‰è£æ•°ç§‘æŠ€\n    - 128ã€ä¸Šæµ·æºåŸŸä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 129ã€å¹¿å·è”æ”¯ç½‘ç»œæœ‰é™å…¬å¸ã€è”æFMã€‘\n    - 130ã€æ­å·é—ªå®ç§‘æŠ€æœ‰é™å…¬å¸\n    - 131ã€åŒ—äº¬äº’è”æ–°ç½‘ç§‘æŠ€å‘å±•æœ‰é™å…¬å¸\n    - 132ã€èª‰é“ç§‘æŠ€\n    - 133ã€å±±è¥¿å…†ç››æˆ¿åœ°äº§å¼€å‘æœ‰é™å…¬å¸\n    - 134ã€åŒ—äº¬è“ç¿é€šè¾¾ç§‘æŠ€æœ‰é™å…¬å¸\n    - 135ã€æœˆäº®å°å±‹ï¼ˆä¸­å›½ï¼‰æœ‰é™å…¬å¸ã€è“æœˆäº®ã€‘\n    - 136ã€é’å²›å›½ç‘ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 137ã€åšé›…äº‘è®¡ç®—ï¼ˆåŒ—äº¬ï¼‰æœ‰é™å…¬å¸\n    - 138ã€åæ³°è¯åˆ¸é¦™æ¸¯å­å…¬å¸\n    - 139ã€æ­å·ä¸œæ–¹é€šä¿¡è½¯ä»¶æŠ€æœ¯æœ‰é™å…¬å¸\n    - 140ã€æ­¦æ±‰åšæ™Ÿå®‰å…¨æŠ€æœ¯è‚¡ä»½æœ‰é™å…¬å¸\n    - 141ã€æ·±åœ³å¸‚å…­åº¦äººå’Œç§‘æŠ€æœ‰é™å…¬å¸\n    - 142ã€æ­å·è¶£ç»´ç§‘æŠ€æœ‰é™å…¬å¸ï¼ˆå°å½±ï¼‰\n    - 143ã€å®æ³¢å•è½¦ä¾ ä¹‹å®¶ç§‘æŠ€æœ‰é™å…¬å¸ã€å•è½¦ä¾ ã€‘\n    - 144ã€ä¸ä¸äº‘åº·ä¿¡æ¯ç§‘æŠ€ï¼ˆåŒ—äº¬ï¼‰æœ‰é™å…¬å¸\n    - 145ã€äº‘é’±è¢‹\n    - 146ã€å—äº¬ä¸­å…´åŠ›ç»´\n    - 147ã€ä¸Šæµ·çŸ½æ˜Œé€šä¿¡æŠ€æœ¯æœ‰é™å…¬å¸\n    - 148ã€æ·±åœ³è¨ç§‘ç§‘æŠ€\n    - 149ã€ä¸­é€šæœåˆ›ç«‹ç§‘æŠ€æœ‰é™è´£ä»»å…¬å¸\n    - 150ã€æ·±åœ³å¸‚å¯¹åº„ç§‘æŠ€æœ‰é™å…¬å¸\n    - 151ã€ä¸Šè¯æ‰€ä¿¡æ¯ç½‘ç»œæœ‰é™å…¬å¸\n    - 152ã€æ­å·ç«çƒ§äº‘ç§‘æŠ€æœ‰é™å…¬å¸ã€å©šç¤¼çºªã€‘\n    - 153ã€å¤©æ´¥é’èŠ’æœç§‘æŠ€æœ‰é™å…¬å¸ã€èŠ’æœå¤´æ¡ã€‘\n    - 154ã€é•¿é£å…‰çº¤å…‰ç¼†è‚¡ä»½æœ‰é™å…¬å¸\n    - 155ã€ä¸–çºªå‡¯æ­Œï¼ˆåŒ—äº¬ï¼‰åŒ»ç–—ç§‘æŠ€æœ‰é™å…¬å¸\n    - 156ã€æµ™æ±Ÿéœ–æ¢“æ§è‚¡æœ‰é™å…¬å¸\n    - 157ã€æ±Ÿè¥¿è…¾é£ç½‘ç»œæŠ€æœ¯æœ‰é™å…¬å¸\n    - 158ã€å®‰è¿…ç‰©æµæœ‰é™å…¬å¸\n    - 159ã€è‚‰è”ç½‘\n    - 160ã€åŒ—äº¬åŒ—å¹¿æ¢¯å½±å¹¿å‘Šä¼ åª’æœ‰é™å…¬å¸\n    - 161ã€ä¸Šæµ·æ•°æ…§ç³»ç»ŸæŠ€æœ¯æœ‰é™å…¬å¸\n    - 162ã€å¤§å¿—å¤©æˆ\n    - 163ã€ä¸Šæµ·äº‘é¹ŠåŒ»\n    - 164ã€ä¸Šæµ·äº‘é¹ŠåŒ»\n    - 165ã€å¢¨è¿¹å¤©æ°”ã€å¢¨è¿¹å¤©æ°”ã€‘\n    - 166ã€ä¸Šæµ·é€¸æ©™ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 167ã€æ²…æœ‹ç‰©è”\n    - 168ã€æ­å·æ’ç”Ÿäº‘èç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 169ã€ç»¿ç±³è”åˆ›\n    - 170ã€é‡åº†æ˜“å® ç§‘æŠ€æœ‰é™å…¬å¸\n    - 171ã€å®‰å¾½å¼•èˆªç§‘æŠ€æœ‰é™å…¬å¸ï¼ˆä¹èŒç½‘ï¼‰\n    - 172ã€ä¸Šæµ·æ•°è”åŒ»ä¿¡ä¼ä¸šå‘å±•æœ‰é™å…¬å¸\n    - 173ã€è‰¯å½¬å»ºæ\n    - 174ã€æ­å·æ±‚æ˜¯åŒåˆ›ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 175ã€è·é©¬å›½é™…\n    - 176ã€ç‚¹é›‡ç½‘\n    - 177ã€æ·±åœ³å¸‚åæ˜Ÿå…‰ç”µæŠ€æœ¯æœ‰é™å…¬å¸\n    - 178ã€å¦é—¨ç¥å·é¹°è½¯ä»¶ç§‘æŠ€æœ‰é™å…¬å¸\n    - 179ã€æ·±åœ³å¸‚æ‹›å•†ä¿¡è¯ºäººå¯¿ä¿é™©æœ‰é™å…¬å¸\n    - 180ã€ä¸Šæµ·å¥½å±‹ç½‘ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 181ã€æµ·ä¿¡é›†å›¢ã€æµ·ä¿¡ã€‘\n    - 182ã€ä¿¡å‡Œå¯ä¿¡æ¯ç§‘æŠ€ï¼ˆä¸Šæµ·ï¼‰æœ‰é™å…¬å¸\n    - 183ã€é•¿æ˜¥å¤©æˆç§‘æŠ€å‘å±•æœ‰é™å…¬å¸\n    - 184ã€ç”¨å‹é‡‘èä¿¡æ¯æŠ€æœ¯è‚¡ä»½æœ‰é™å…¬å¸ã€ç”¨å‹ã€‘\n    - 185ã€åŒ—äº¬å’–å•¡æ˜“èæœ‰é™å…¬å¸\n    - 186ã€å›½æŠ•ç‘é“¶åŸºé‡‘ç®¡ç†æœ‰é™å…¬å¸\n    - 187ã€æ™‹æ¾(ä¸Šæµ·)ç½‘ç»œä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 188ã€æ·±åœ³å¸‚éšæ‰‹ç§‘æŠ€æœ‰é™å…¬å¸ã€éšæ‰‹è®°ã€‘\n    - 189ã€æ·±åœ³æ°´åŠ¡ç§‘æŠ€æœ‰é™å…¬å¸\n    - 190ã€æ˜“ä¼ç§€ã€æ˜“ä¼ç§€ã€‘\n    - 191ã€åŒ—äº¬ç£äº‘ç§‘æŠ€\n    - 192ã€å—äº¬èœ‚æ³°äº’è”ç½‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 193ã€ç« é±¼ç›´æ’­\n    - 194ã€å¥–å¤šå¤šç§‘æŠ€\n    - 195ã€å¤©æ´¥å¸‚ç¥å·å•†é¾™ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 196ã€å²©å¿ƒç§‘æŠ€\n    - 197ã€è½¦ç ç§‘æŠ€ï¼ˆåŒ—äº¬ï¼‰æœ‰é™å…¬å¸\n    - 198ã€è´µé˜³å¸‚æŠ•èµ„æ§è‚¡é›†å›¢\n    - 199ã€åº·æ——è‚¡ä»½\n    - 200ã€é¾™è…¾å‡ºè¡Œ\n    - 201ã€æ­å·åé‡è½¯ä»¶\n    - 202ã€åˆè‚¥é¡¶å²­åŒ»ç–—ç§‘æŠ€æœ‰é™å…¬å¸\n    - 203ã€é‡åº†è¡¨è¾¾å¼ç§‘æŠ€æœ‰é™å…¬å¸\n    - 204ã€ä¸Šæµ·ç±³é“ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 205ã€åŒ—äº¬ç›Šå‹ä¼šç§‘æŠ€æœ‰é™å…¬å¸\n    - 206ã€åŒ—äº¬èè´¯ç”µå­å•†åŠ¡æœ‰é™å…¬å¸\n    - 207ã€ä¸­å›½å¤–æ±‡äº¤æ˜“ä¸­å¿ƒ\n    - 208ã€ä¸­å›½å¤–è¿è‚¡ä»½æœ‰é™å…¬å¸\n    - 209ã€ä¸­å›½ä¸Šæµ·æ™“åœˆæ•™è‚²ç§‘æŠ€æœ‰é™å…¬å¸\n    - 210ã€æ™®è”è½¯ä»¶è‚¡ä»½æœ‰é™å…¬å¸\n    - 211ã€åŒ—äº¬ç§‘è“è½¯ä»¶è‚¡ä»½æœ‰é™å…¬å¸\n    - 212ã€æ±Ÿè‹æ–¯è¯ºç‰©è”ç§‘æŠ€æœ‰é™å…¬å¸\n    - 213ã€åŒ—äº¬æœç‹-ç‹å‹ã€æœç‹ã€‘\n    - 214ã€æ–°å¤§é™†ç½‘å•†é‡‘è\n    - 215ã€å±±ä¸œç¥ç ä¸­ç¨ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 216ã€æ²³å—æ±‡é¡ºç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 217ã€åŒ—äº¬åå¤æ€æºç§‘æŠ€å‘å±•æœ‰é™å…¬å¸\n    - 218ã€ä¸Šæµ·ä¸œæ™®ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 219ã€ä¸Šæµ·é¸£å‹ƒç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 220ã€å¹¿ä¸œå­¦è‹‘æ•™è‚²å‘å±•æœ‰é™å…¬å¸\n    - 221ã€æ·±åœ³å¼ºæ—¶ç§‘æŠ€æœ‰é™å…¬å¸\n    - 222ã€ä¸Šæµ·äº‘ç ºä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 223ã€é‡åº†æ„‰å®¢è¡Œç½‘ç»œæœ‰é™å…¬å¸\n    - 224ã€æ•°äº‘\n    - 225ã€å›½å®¶ç”µç½‘è¿æ£€éƒ¨\n    - 226ã€æ­å·æ‰¾è¶£\n    - 227ã€æµ©é²¸äº‘è®¡ç®—ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 228ã€ç§‘å¤§è®¯é£ã€ç§‘å¤§è®¯é£ã€‘\n    - 229ã€æ­å·è¡Œè£…ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 230ã€å³æœ‰åˆ†æœŸé‡‘è\n    - 231ã€æ·±åœ³æ³•å¸å¾·ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 232ã€ä¸Šæµ·åšå¤ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 233ã€æ­å·äº‘å˜‰äº‘è®¡ç®—æœ‰é™å…¬å¸\n    - 234ã€æœ‰å®¶æ°‘å®¿(æœ‰å®¶ç¾å®¿)\n    - 235ã€åŒ—äº¬èµ¢é”€é€šè½¯ä»¶æŠ€æœ¯æœ‰é™å…¬å¸\n    - 236ã€æµ™æ±Ÿèšæœ‰è´¢é‡‘èæœåŠ¡å¤–åŒ…æœ‰é™å…¬å¸\n    - 237ã€æ˜“æ—æ™ºæ±‡(åŒ—äº¬)ç§‘æŠ€æœ‰é™å…¬å¸\n    - 238ã€åˆè‚¥é¡¶å²­åŒ»ç–—ç§‘æŠ€å¼€å‘æœ‰é™å…¬å¸\n    - 239ã€è½¦èˆ¹å®(æ·±åœ³)æ—­ç©ç§‘æŠ€æœ‰é™å…¬å¸)\n    - 240ã€å¹¿å·å¯ŒåŠ›åœ°äº§æœ‰é™å…¬å¸\n    - 241ã€æ°¢è¯¾ï¼ˆä¸Šæµ·ï¼‰æ•™è‚²ç§‘æŠ€æœ‰é™å…¬å¸\n    - 242ã€æ­¦æ±‰æ°ªç»†èƒç½‘ç»œæŠ€æœ¯æœ‰é™å…¬å¸\n    - 243ã€æ­å·æœ‰äº‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 244ã€ä¸Šæµ·ä»™è±†æ™ºèƒ½æœºå™¨äººæœ‰é™å…¬å¸\n    - 245ã€æ‹‰å¡æ‹‰æ”¯ä»˜è‚¡ä»½æœ‰é™å…¬å¸ã€æ‹‰å¡æ‹‰ã€‘\n    - 246ã€è™å½©å°è‰ºè‚¡ä»½æœ‰é™å…¬å¸\n    - 247ã€åŒ—äº¬æ•°å¾®ç§‘æŠ€æœ‰é™å…¬å¸\n    - 248ã€å¹¿ä¸œæ™ºç‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 249ã€æ‰¾é’¢ç½‘\n    - 250ã€ä¹æœºç½‘\n    - 251ã€æ­å·è·‘è·‘ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 252ã€æ·±åœ³æœªæ¥äº‘é›†\n    - 253ã€æ­å·æ¯æ—¥ç»™åŠ›ç§‘æŠ€æœ‰é™å…¬å¸\n    - 254ã€ä¸Šæµ·é½çŠ‡ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 255ã€æ»´æ»´å‡ºè¡Œã€æ»´æ»´ã€‘\n    - 256ã€åˆè‚¥äº‘è¯Šä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 257ã€äº‘çŸ¥å£°æ™ºèƒ½ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 258ã€å—äº¬å¦é“ç§‘æŠ€æœ‰é™å…¬å¸\n    - 259ã€çˆ±ä¹ä¼˜ï¼ˆäºŒæ‰‹å¹³å°ï¼‰\n    - 260ã€çŒ«çœ¼ç”µå½±ï¼ˆç§æœ‰åŒ–éƒ¨ç½²ï¼‰ã€çŒ«çœ¼ç”µå½±ã€‘\n    - 261ã€ç¾å›¢å¤§è±¡ï¼ˆç§æœ‰åŒ–éƒ¨ç½²ï¼‰ã€ç¾å›¢å¤§è±¡ã€‘\n    - 262ã€ä½œä¸šå¸®æ•™è‚²ç§‘æŠ€ï¼ˆåŒ—äº¬ï¼‰æœ‰é™å…¬å¸ã€ä½œä¸šå¸®ã€‘\n    - 263ã€åŒ—äº¬å°å¹´ç³•äº’è”ç½‘æŠ€æœ¯æœ‰é™å…¬å¸\n    - 264ã€å±±ä¸œçŸ©é˜µè½¯ä»¶å·¥ç¨‹è‚¡ä»½æœ‰é™å…¬å¸\n    - 265ã€é™•è¥¿å›½é©¿è½¯ä»¶ç§‘æŠ€æœ‰é™å…¬å¸\n    - 266ã€å›å¼€ä¿¡æ¯ç§‘æŠ€\n    - 267ã€æ‘é¸Ÿç½‘ç»œç§‘æŠ€æœ‰é™è´£ä»»å…¬å¸\n    - 268ã€äº‘å—å›½é™…ä¿¡æ‰˜æœ‰é™å…¬å¸\n    - 269ã€é‡‘æ™ºæ•™è‚²\n    - 270ã€ç æµ·å¸‚ç­‘å·¢ç§‘æŠ€æœ‰é™å…¬å¸\n    - 271ã€ä¸Šæµ·ç™¾èƒœè½¯ä»¶è‚¡ä»½æœ‰é™å…¬å¸\n    - 272ã€æ·±åœ³å¸‚ç§‘ç›¾ç§‘æŠ€æœ‰é™å…¬å¸\n    - 273ã€å“ˆå•°å‡ºè¡Œã€å“ˆå•°ã€‘\n    - 274ã€é€”è™å…»è½¦ã€é€”è™ã€‘\n    - 275ã€å¡æ€ä¼˜æ´¾äººåŠ›èµ„æºé›†å›¢\n    - 276ã€å—äº¬è§‚ä¸ºæ™ºæ…§è½¯ä»¶ç§‘æŠ€æœ‰é™å…¬å¸\n    - 277ã€æ­å·åŸå¸‚å¤§è„‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 278ã€çŒ¿è¾…å¯¼ã€çŒ¿è¾…å¯¼ã€‘\n    - 279ã€æ´›é˜³å¥åˆ›ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 280ã€é­”åŠ›è€³æœµ\n    - 281ã€äº¿é˜³ä¿¡é€š\n    - 282ã€ä¸Šæµ·æ‹›é²¤ç§‘æŠ€æœ‰é™å…¬å¸\n    - 283ã€å››å·å•†æ—…æ— å¿§ç§‘æŠ€æœåŠ¡æœ‰é™å…¬å¸\n    - 284ã€UUè·‘è…¿\n    - 285ã€åŒ—äº¬è€è™è¯åˆ¸ã€è€è™è¯åˆ¸ã€‘\n    - 286ã€æ‚ æ´»çœå§ï¼ˆåŒ—äº¬ï¼‰ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 287ã€F5æœªæ¥å•†åº—\n    - 288ã€æ·±åœ³ç¯é˜³é€šä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 289ã€é å‚³é›»ä¿¡\n    - 290ã€ä½œä¸šå¸®ï¼ˆåŒ—äº¬ï¼‰æ•™è‚²ç§‘æŠ€æœ‰é™å…¬å¸ã€ä½œä¸šå¸®ã€‘\n    - 291ã€æˆéƒ½ç§‘é¸¿æ™ºä¿¡ç§‘æŠ€æœ‰é™å…¬å¸\n    - 292ã€åŒ—äº¬æœ¨å±‹æ—¶ä»£ç§‘æŠ€æœ‰é™å…¬å¸\n    - 293ã€å¤§å­¦é€šï¼ˆå“ˆå°”æ»¨ï¼‰ç§‘æŠ€æœ‰é™è´£ä»»å…¬å¸\n    - 294ã€æµ™æ±Ÿåå¤é“å¨æ•°æ®ç§‘æŠ€æœ‰é™å…¬å¸\n    - 295ã€å‰ç¥¥èˆªç©ºã€å‰ç¥¥èˆªç©ºã€‘\n    - 296ã€å—äº¬åœ†å‘¨ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 297ã€å¹¿å·å¸‚æ´‹è‘±omallç”µå­å•†åŠ¡\n    - 298ã€å¤©æ´¥è”ç‰©ç§‘æŠ€æœ‰é™å…¬å¸\n    - 299ã€è·‘å“ªå„¿ç§‘æŠ€ï¼ˆåŒ—äº¬ï¼‰æœ‰é™å…¬å¸\n    - 300ã€æ·±åœ³å¸‚ç¾è¥¿è¥¿é¤é¥®æœ‰é™å…¬å¸(å–œèŒ¶)\n    - 301ã€å¹³å®‰ä¸åŠ¨äº§æœ‰é™å…¬å¸ã€å¹³å®‰ã€‘\n    - 302ã€æ±Ÿè‹ä¸­æµ·æ˜‡ç‰©è”ç§‘æŠ€æœ‰é™å…¬å¸\n    - 303ã€æ¹–å—ç‰™åŒ»å¸®ç§‘æŠ€æœ‰é™å…¬å¸\n    - 304ã€é‡åº†æ°‘èˆªå‡¯äºšä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸ï¼ˆæ˜“é€šèˆªï¼‰\n    - 305ã€é€’æ˜“ï¼ˆä¸Šæµ·ï¼‰æ™ºèƒ½ç§‘æŠ€æœ‰é™å…¬å¸\n    - 306ã€äºšæœµ\n    - 307ã€æµ™æ±Ÿæ–°è¯¾å ‚æ•™è‚²è‚¡ä»½æœ‰é™å…¬å¸\n    - 308ã€åŒ—äº¬èœ‚åˆ›ç§‘æŠ€æœ‰é™å…¬å¸\n    - 309ã€å¾·ä¸€æ™ºæ…§åŸå¸‚ä¿¡æ¯ç³»ç»Ÿæœ‰é™å…¬å¸\n    - 310ã€åŒ—äº¬ç¿¼ç‚¹ç§‘æŠ€æœ‰é™å…¬å¸\n    - 311ã€æ¹–å—æ™ºæ•°æ–°ç»´åº¦ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 312ã€åŒ—äº¬ç–æ‰¬åšæ–‡æ–‡åŒ–å‘å±•æœ‰é™å…¬å¸\n    - 313ã€ä¸Šæµ·å®‡ç©ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 314ã€å…¨æ™¯æ™ºè”ï¼ˆæ­¦æ±‰ï¼‰ç§‘æŠ€æœ‰é™å…¬å¸\n    - 315ã€å¤©æ´¥æ˜“å®¢æ»¡å›½é™…ç‰©æµæœ‰é™å…¬å¸\n    - 316ã€å—äº¬çˆ±ç¦è·¯æ±½è½¦ç§‘æŠ€æœ‰é™å…¬å¸\n    - 317ã€æˆ‘æˆ¿æ—…å±…é›†å›¢\n    - 318ã€æ¹›æ±Ÿäº²é‚»ç§‘æŠ€æœ‰é™å…¬å¸\n    - 319ã€æ·±åœ³å¸‚å§œç§‘ç½‘ç»œæœ‰é™å…¬å¸\n    - 320ã€é’å²›æ—¥æ—¥é¡ºç‰©æµæœ‰é™å…¬å¸\n    - 321ã€å—äº¬å¤ªå·ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 322ã€ç¾å›¾ä¹‹å®¶ç§‘æŠ€æœ‰é™å…¬å¸ã€ç¾å›¾ã€‘\n    - 323ã€å—äº¬å¤ªå·ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 324ã€ä¼—è–ªç§‘æŠ€ï¼ˆåŒ—äº¬ï¼‰æœ‰é™å…¬å¸\n    - 325ã€æ­¦æ±‰å®‰å®‰ç‰©è”ç§‘æŠ€æœ‰é™å…¬å¸\n    - 326ã€åŒ—äº¬æ™ºå®¢æœ—é“ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 327ã€æ·±åœ³å¸‚è¶…çº§çŒ©çŒ©å¥èº«ç®¡ç†ç®¡ç†æœ‰é™å…¬å¸\n    - 328ã€é‡åº†è¾¾å¿—ç§‘æŠ€æœ‰é™å…¬å¸\n    - 329ã€ä¸Šæµ·äº«è¯„ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 330ã€è–ªå¾—ä»˜ä¿¡æ¯ç§‘æŠ€\n    - 331ã€è·Ÿè°å­¦\n    - 332ã€ä¸­é“ï¼ˆè‹å·ï¼‰æ—…æ¸¸ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 333ã€å¹¿å·å°å«ç§‘æŠ€æœ‰é™å…¬å¸\n    - 334ã€ä¸Šæµ·éç ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 335ã€é€”å®¶ç½‘ç½‘ç»œæŠ€æœ¯ï¼ˆåŒ—äº¬ï¼‰æœ‰é™å…¬å¸ã€é€”å®¶ã€‘\n    - 336ã€å¹¿å·è¾‰å‡¡ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 337ã€å¤©ç»´å°”ä¿¡æ¯ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 338ã€ä¸Šæµ·æè±†ç§‘æŠ€æœ‰é™å…¬å¸\n    - 339ã€è‹å·è§¦è¾¾ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 340ã€åŒ—äº¬çƒ­äº‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 341ã€ä¸­æ™ºä¼æœï¼ˆåŒ—äº¬ï¼‰ç§‘æŠ€æœ‰é™å…¬å¸\n    - 342ã€æ˜“è”äº‘è®¡ç®—ï¼ˆæ­å·ï¼‰æœ‰é™è´£ä»»å…¬å¸\n    - 343ã€é’å²›èˆªç©ºè‚¡ä»½æœ‰é™å…¬å¸ã€é’å²›èˆªç©ºã€‘\n    - 344ã€å±±è¥¿åšç¿é€šç§‘æŠ€æœ‰é™å…¬å¸\n    - 345ã€ç½‘æ˜“æ­å·ç½‘ç»œæœ‰é™å…¬å¸ã€ç½‘æ˜“ã€‘\n    - 346ã€åŒ—äº¬æœæœä¹å­¦ç§‘æŠ€æœ‰é™å…¬å¸\n    - 347ã€ç™¾æœ›è‚¡ä»½æœ‰é™å…¬å¸\n    - 348ã€ä¸­ä¿é‡‘æœï¼ˆæ·±åœ³ï¼‰ç§‘æŠ€æœ‰é™å…¬å¸\n    - 349ã€å¤©æ´¥è¿å‹ç‰©æµç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 350ã€å¹¿ä¸œåˆ›èƒ½ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 351ã€ä¸Šæµ·å€šåšä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 352ã€æ·±åœ³ç™¾æœå›­å®ä¸šï¼ˆé›†å›¢ï¼‰è‚¡ä»½æœ‰é™å…¬å¸\n    - 353ã€å¹¿å·ç»†åˆ»ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 354ã€æ­¦æ±‰é¸¿ä¸šä¼—åˆ›ç§‘æŠ€æœ‰é™å…¬å¸\n    - 355ã€é‡‘é”¡ç§‘æŠ€ï¼ˆå¹¿å·ï¼‰æœ‰é™å…¬å¸\n    - 356ã€æ˜“ç‘å›½é™…ç”µå­å•†åŠ¡æœ‰é™å…¬å¸\n    - 357ã€å¥‡ç‚¹äº‘\n    - 358ã€ä¸­è§†ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 359ã€å¼€æºé¡¹ç›®:datax-web\n    - 360ã€äº‘çŸ¥å£°æ™ºèƒ½ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 361ã€å¼€æºé¡¹ç›®:bboss\n    - 362ã€æˆéƒ½æ·±é©¾ç§‘æŠ€æœ‰é™å…¬å¸\n    - 363ã€FunPlusã€è¶£åŠ ã€‘\n    - 364ã€æ­å·åˆ›åŒ ä¿¡ç§‘æŠ€æœ‰é™å…¬å¸\n    - 365ã€é¾™åŒ ï¼ˆåŒ—äº¬ï¼‰ç§‘æŠ€å‘å±•æœ‰é™å…¬å¸\n    - 366ã€å¹¿å·ä¸€é“¾é€šäº’è”ç½‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 367ã€ä¸Šæµ·æ˜Ÿè‰¾ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 368ã€è™åšç½‘ç»œæŠ€æœ¯(ä¸Šæµ·)æœ‰é™å…¬å¸\n    - 369ã€é’å²›ä¼˜ç±³ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 370ã€å…«ç»´é€šç§‘æŠ€æœ‰é™å…¬å¸\n    - 371ã€çƒŸå°åˆäº«æ™ºæ˜Ÿæ•°æ®ç§‘æŠ€æœ‰é™å…¬å¸\n    - 372ã€ä¸œå´è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸\n    - 373ã€ä¸­é€šäº‘ä»“è‚¡ä»½æœ‰é™å…¬å¸ã€ä¸­é€šã€‘\n    - 374ã€åŒ—äº¬åŠ è²çŒ«ç§‘æŠ€æœ‰é™å…¬å¸\n    - 375ã€åŒ—äº¬åŒ å¿ƒæ¼”ç»ç§‘æŠ€æœ‰é™å…¬å¸\n    - 376ã€å®è´èµ°å¤©ä¸‹\n    - 377ã€å¦é—¨ä¼—åº“ç§‘æŠ€æœ‰é™å…¬å¸\n    - 378ã€æµ·é€šè¯åˆ¸æ•°æ®ä¸­å¿ƒ\n    - 389ã€æ¹–å—å¿«ä¹é€šå®å°é¢è´·æ¬¾æœ‰é™å…¬å¸\n    - 380ã€æµ™æ±Ÿå¤§åæŠ€æœ¯è‚¡ä»½æœ‰é™å…¬å¸\n    - 381ã€æ­å·é­”ç­·ç§‘æŠ€æœ‰é™å…¬å¸\n    - 382ã€é’å²›æŒè®¯é€šåŒºå—é“¾ç§‘æŠ€æœ‰é™å…¬å¸\n    - 383ã€æ–°å¤§é™†é‡‘èç§‘æŠ€\n    - 384ã€å¸¸å·çºæ‹“è½¯ä»¶ç§‘æŠ€æœ‰é™å…¬å¸\n    - 385ã€åŒ—äº¬æ­£ä¿ç½‘æ ¼æ•™è‚²ç§‘æŠ€æœ‰é™å…¬å¸\n    - 386ã€ç»Ÿä¸€ä¼ä¸šï¼ˆä¸­å›½ï¼‰æŠ•èµ„æœ‰é™å…¬å¸ã€ç»Ÿä¸€ã€‘\n    - 387ã€å¾®é©ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 388ã€æ­å·èæ˜“ç®—ç§‘æŠ€æœ‰é™å…¬å¸\n    - 399ã€é’å²›ä¸Šå•¥ç­ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 390ã€äº¬ä¸œé…’ä¸–ç•Œ\n    - 391ã€æ­å·çˆ±åšä»•ç§‘æŠ€æœ‰é™å…¬å¸\n    - 392ã€äº”æ˜Ÿé‡‘æœæ§è‚¡æœ‰é™å…¬å¸\n    - 393ã€ç¦å»ºä¹æ‘©ç‰©è”ç§‘æŠ€æœ‰é™å…¬å¸\n    - 394ã€ç™¾ç‚¼æ™ºèƒ½ç§‘æŠ€æœ‰é™å…¬å¸\n    - 395ã€å±±ä¸œèƒ½æºæ•°æ™ºäº‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 396ã€æ‹›å•†å±€èƒ½æºè¿è¾“è‚¡ä»½æœ‰é™å…¬å¸\n    - 397ã€ä¸‰ä¸€é›†å›¢ã€ä¸‰ä¸€ã€‘\n    - 398ã€ä¸œå·´æ–‡ï¼ˆæ·±åœ³ï¼‰å¥åº·ç®¡ç†æœ‰é™å…¬å¸\n    - 399ã€ç´¢æ˜“è½¯ä»¶\n    - 400ã€æ·±åœ³å¸‚å®è¿œç§‘æŠ€æœ‰é™å…¬å¸\n    - 401ã€ç†™ç‰›åŒ»ç–—\n    - 402ã€å—äº¬æ™ºé¹¤ç”µå­ç§‘æŠ€æœ‰é™å…¬å¸\n    - 403ã€å˜€å—’å‡ºè¡Œã€å˜€å—’å‡ºè¡Œã€‘\n    - 404ã€å¹¿å·è™ç‰™ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸ã€è™ç‰™ã€‘\n    - 405ã€å¹¿å·æ¬§è±é›…ç™¾åº“ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸ã€æ¬§è±é›…ã€‘\n    - 406ã€å¾®å¾®ç§‘æŠ€æœ‰é™å…¬å¸\n    - 407ã€æˆ‘çˆ±æˆ‘å®¶æˆ¿åœ°äº§ç»çºªæœ‰é™å…¬å¸ã€æˆ‘çˆ±æˆ‘å®¶ã€‘\n    - 408ã€ä¹å·å‘ç°\n    - 409ã€è–ªäººè–ªäº‹\n    - 410ã€æ­¦æ±‰æ°ªç»†èƒç½‘ç»œæŠ€æœ¯æœ‰é™å…¬å¸\n    - 411ã€å¹¿å·å¸‚æ–¯å‡¯å¥‡å•†ä¸šæœ‰é™å…¬å¸\n    - 412ã€å¾®æ·¼å•†å­¦é™¢\n    - 413ã€æ­å·è½¦ç››ç§‘æŠ€æœ‰é™å…¬å¸\n    - 414ã€æ·±å…°ç§‘æŠ€ï¼ˆä¸Šæµ·ï¼‰æœ‰é™å…¬å¸\n    - 415ã€å®‰å¾½ä¸­ç§‘ç¾ç»œä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 416ã€æ¯”äºšè¿ªæ±½è½¦å·¥ä¸šæœ‰é™å…¬å¸ã€æ¯”äºšè¿ªã€‘\n    - 417ã€æ¹–å—å°æ¡”ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 418ã€å®‰å¾½ç§‘å¤§å›½åˆ›è½¯ä»¶ç§‘æŠ€æœ‰é™å…¬å¸\n    - 419ã€å…‹è€Œç‘\n    - 420ã€é™•è¥¿äº‘åŸºåæµ·ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 421ã€å®‰å¾½æ·±å®ç§‘æŠ€æœ‰é™å…¬å¸\n    - 422ã€å¹¿ä¸œåº·çˆ±å¤šæ•°å­—å¥åº·æœ‰é™å…¬å¸\n    - 423ã€å˜‰é‡Œç”µå­å•†åŠ¡\n    - 424ã€ä¸Šæµ·æ—¶ä»£å…‰åæ•™è‚²å‘å±•æœ‰é™å…¬å¸\n    - 425ã€CityDo\n    - 426ã€ä¸Šæµ·ç¦¹çŸ¥ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 427ã€å¹¿ä¸œæ™ºç‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 428ã€è¥¿å®‰çˆ±é“­ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 429ã€å¿ƒåŒ»å›½é™…æ•°å­—åŒ»ç–—ç³»ç»Ÿ(å¤§è¿)æœ‰é™å…¬å¸\n    - 430ã€ä¹å…¶ç”µå•†\n    - 431ã€é”è¾¾ç§‘æŠ€\n    - 432ã€å¤©æ´¥é•¿åŸæ»¨é“¶æ±½è½¦é‡‘èæœ‰é™å…¬å¸\n    - 433ã€ä»£ç ç½‘\n    - 434ã€ä¸œèå¸‚ä¸œåŸä¹”ä¼¦è½¯ä»¶å¼€å‘å·¥ä½œå®¤\n    - 435ã€æµ™æ±Ÿç™¾åº”ç§‘æŠ€æœ‰é™å…¬å¸\n    - 436ã€ä¸Šæµ·åŠ›çˆ±å¸ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸(Red E)\n    - 437ã€äº‘å¾™ç§‘æŠ€æœ‰é™å…¬å¸\n    - 438ã€åŒ—äº¬åº·æ™ºä¹æ€ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸ã€å¤§å§¨å—APPã€‘\n    - 439ã€å®‰å¾½å¼€å…ƒç¬è§†ç§‘æŠ€æœ‰é™å…¬å¸\n    - 440ã€ç«‹æ–¹\n    - 441ã€å¦é—¨çºµè¡Œç§‘æŠ€\n    - 442ã€ä¹å±±-è²å°¼å…‹æ–¯åŠå¯¼ä½“æœ‰é™å…¬å¸\n    - 443ã€æ­¦æ±‰å…‰è°·è”åˆé›†å›¢æœ‰é™å…¬å¸\n    - 444ã€ä¸Šæµ·é‡‘ä»•è¾¾è½¯ä»¶ç§‘æŠ€æœ‰é™å…¬å¸\n    - 445ã€æ·±åœ³æ˜“ä¸–é€šè¾¾ç§‘æŠ€æœ‰é™å…¬å¸\n    - 446ã€çˆ±åŠ¨è¶…è¶Šäººå·¥æ™ºèƒ½ç§‘æŠ€ï¼ˆåŒ—äº¬ï¼‰æœ‰é™è´£ä»»å…¬å¸\n    - 447ã€è¿ªæ™®ä¿¡ï¼ˆåŒ—äº¬ï¼‰ç§‘æŠ€æœ‰é™å…¬å¸\n    - 448ã€æŒç«™ç§‘æŠ€ï¼ˆåŒ—äº¬ï¼‰æœ‰é™å…¬å¸\n    - 449ã€æ·±åœ³å¸‚åäº‘ä¸­ç››è‚¡ä»½æœ‰é™å…¬å¸\n    - 450ã€ä¸Šæµ·åŸåœˆç§‘æŠ€æœ‰é™å…¬å¸\n    - 451ã€å¹¿å·èµèµä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 452ã€Amber Group\n    - 453ã€å¾·å¨å›½é™…è´§è¿ä»£ç†ï¼ˆä¸Šæµ·ï¼‰å…¬å¸\n    - 454ã€æµ™æ±Ÿæ°å¤«å…„å¼Ÿæ™ºæ…§ç§‘æŠ€æœ‰é™å…¬å¸\n    - 455ã€ä¿¡ä¹Ÿç§‘æŠ€\n    - 456ã€å¼€æ€æ—¶ä»£ç§‘æŠ€ï¼ˆæ·±åœ³ï¼‰æœ‰é™å…¬å¸\n    - 457ã€å¤§è¿æ§å¾·ç§‘æŠ€æœ‰é™å…¬å¸\n    - 458ã€åŒç¨‹ç”Ÿæ´»\n    - 459ã€æ¾æœå‡ºè¡Œ\n    - 460ã€ä¼é¹…æä»é›†å›¢\n    - 461ã€å®æ³¢ç§‘äº‘ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 462ã€ä¸Šæµ·æ ¼è“å¨é©°ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 463ã€æ­å·è¶£æ·˜é²¸ç§‘æŠ€æœ‰é™å…¬å¸\n    - 464ã€æ¹–å·å¸‚æ•°å­—æƒ æ°‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 465ã€ä¹æ™®ï¼ˆåŒ—äº¬ï¼‰åŒ»ç–—å™¨æ¢°è‚¡ä»½æœ‰é™å…¬å¸\n    - 466ã€å¹¿å·å¸‚æ™´å·é«˜æ–°æŠ€æœ¯å¼€å‘æœ‰é™å…¬å¸\n    - 467ã€å±±è¥¿ç¼‡å®¢ç§‘æŠ€æœ‰é™å…¬å¸\n    - 468ã€å¾å·å¡è¥¿ç©†ç”µå­å•†åŠ¡æœ‰é™å…¬å¸\n    - 469ã€æ ¼åˆ›ä¸œæ™ºç§‘æŠ€æœ‰é™å…¬å¸\n    - 470ã€ä¸–çºªé¾™ä¿¡æ¯ç½‘ç»œæœ‰é™è´£ä»»å…¬å¸\n    - 471ã€é‚¦é“ç§‘æŠ€æœ‰é™å…¬å¸\n    - 472ã€æ²³å—ä¸­ç›Ÿæ–°äº‘ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 473ã€æ¨ªç´äººå¯¿ä¿é™©æœ‰é™å…¬å¸\n    - 474ã€ä¸Šæµ·æµ·éš†åé’Ÿä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 475ã€ä¸Šæµ·ä¹…æ¹›\n    - 476ã€ä¸Šæµ·ä»™è±†æ™ºèƒ½æœºå™¨äººæœ‰é™å…¬å¸\n    - 477ã€å¹¿å·æ±‡å°šç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 478ã€æ·±åœ³å¸‚é˜¿å¡ç´¢èµ„è®¯è‚¡ä»½æœ‰é™å…¬å¸\n    - 479ã€é’å²›ä½³å®¶åº·å¥åº·ç®¡ç†æœ‰é™è´£ä»»å…¬å¸\n    - 480ã€è“åŸå…„å¼Ÿ\n    - 481ã€æˆéƒ½å¤©åºœé€šé‡‘èæœåŠ¡è‚¡ä»½æœ‰é™å…¬å¸\n    - 482ã€æ·±åœ³äº‘é•–ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 483ã€ä¸Šæµ·å½±åˆ›ç§‘æŠ€\n    - 484ã€æˆéƒ½è‰¾æ‹‰ç‰©è”\n    - 485ã€åŒ—äº¬å®¢é‚»å°šå“ç½‘ç»œæŠ€æœ¯æœ‰é™å…¬å¸\n    - 486ã€ITå®æˆ˜è”ç›Ÿ\n    - 487ã€æ­å·å°¤æ‹‰å¤«ç§‘æŠ€æœ‰é™å…¬å¸\n    - 488ã€ä¸­å¤§æ£€æµ‹(æ¹–å—)è‚¡ä»½æœ‰é™å…¬å¸\n    - 489ã€æ±Ÿè‹ç”µè€è™å·¥ä¸šäº’è”ç½‘è‚¡ä»½æœ‰é™å…¬å¸\n    - 490ã€ä¸Šæµ·åŠ©é€šä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 491ã€åŒ—äº¬ç¬¦èŠ‚ç§‘æŠ€æœ‰é™å…¬å¸\n    - 492ã€æ­å·è‹±ç¥ç§‘æŠ€æœ‰é™å…¬å¸\n    - 493ã€æ±Ÿè‹ç”µè€è™å·¥ä¸šäº’è”ç½‘è‚¡ä»½æœ‰é™å…¬å¸\n    - 494ã€æ·±åœ³å¸‚ç‚¹çŒ«ç§‘æŠ€æœ‰é™å…¬å¸\n    - 495ã€æ­å·å¤©éŸ³\n    - 496ã€æ·±åœ³å¸‚äºŒåä¸€ç§‘æŠ€äº’è”ç½‘æœ‰é™å…¬å¸\n    - 497ã€æµ·å—æµ·å£ç¿åº¦ç§‘æŠ€\n    - 498ã€åŒ—äº¬å°è¶£æ™ºå“ç§‘æŠ€æœ‰é™å…¬å¸\n    - 499ã€å¹¿å·çŸ³ç«¹è®¡ç®—æœºè½¯ä»¶æœ‰é™å…¬å¸\n    - 500ã€æ·±åœ³å¸‚æƒŸå®¢æ•°æ®ç§‘æŠ€æœ‰é™å…¬å¸\n    - 501ã€ä¸­å›½åŒ»ç–—å™¨æ¢°æœ‰é™å…¬å¸\n    - 502ã€ä¸Šæµ·äº‘è°¦ç§‘æŠ€æœ‰é™å…¬å¸\n    - 503ã€ä¸Šæµ·ç£å†œä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 504ã€å¹¿å·é¢†èˆªé£Ÿå“æœ‰é™å…¬å¸\n    - 505ã€é’å²›æŒè®¯é€šåŒºå—é“¾ç§‘æŠ€æœ‰é™å…¬å¸\n    - 506ã€åŒ—äº¬æ–°ç½‘æ•°ç ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 507ã€è¶…ä½“ä¿¡æ¯ç§‘æŠ€(æ·±åœ³)æœ‰é™å…¬å¸\n    - 508ã€é•¿æ²™åº—å¸®æ‰‹ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 509ã€ä¸Šæµ·åŠ©å¼“è£…é¥°å·¥ç¨‹æœ‰é™å…¬å¸\n    - 510ã€æ­å·å¯»è”ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 511ã€æˆéƒ½å¤§æ·˜å®¢ç§‘æŠ€æœ‰é™å…¬å¸\n    - 512ã€æ¾æœå‡ºè¡Œ\n    - 513ã€æ·±åœ³å¸‚å”¤æ¢¦ç§‘æŠ€æœ‰é™å…¬å¸\n    - 514ã€ä¸Šæ±½é›†å›¢å•†ç”¨è½¦æŠ€æœ¯ä¸­å¿ƒ\n    - 515ã€åŒ—äº¬ä¸­èˆªè®¯ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 516ã€åŒ—é¾™ä¸­ç½‘(åŒ—äº¬)ç§‘æŠ€æœ‰é™è´£ä»»å…¬å¸\n    - 517ã€å‰æµ·è¶…çº§å‰å°(æ·±åœ³)ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 518ã€ä¸Šæµ·ä¸­å•†ç½‘ç»œè‚¡ä»½æœ‰é™å…¬å¸\n    - 519ã€ä¸Šæµ·åŠ©é€šä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 520ã€å®æ³¢èšè‡»æ™ºèƒ½ç§‘æŠ€æœ‰é™å…¬å¸\n    - 521ã€ä¸Šæµ·é›¶åŠ¨æ•°ç ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 522ã€æµ™æ±Ÿå­¦æµ·æ•™è‚²ç§‘æŠ€æœ‰é™å…¬å¸\n    - 523ã€èšå­¦äº‘(å±±ä¸œ)ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 524ã€å¤šæ°Ÿå¤šæ–°ææ–™è‚¡ä»½æœ‰é™å…¬å¸\n    - 525ã€æ™ºæ…§çœ¼ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 526ã€å¹¿ä¸œæ™ºé€šäººæ‰è¿é”è‚¡ä»½æœ‰é™å…¬å¸\n    - 527ã€ä¸–çºªå¼€å…ƒæ™ºå°äº’è”ç§‘æŠ€é›†å›¢è‚¡ä»½æœ‰é™å…¬å¸\n    - 528ã€åŒ—äº¬ç†æƒ³æ±½è½¦ã€ç†æƒ³æ±½è½¦ã€‘\n    - 529ã€å·½é€¸ç§‘æŠ€(é‡åº†)æœ‰é™å…¬å¸\n    - 530ã€ä¹‰ä¹Œè´­ç”µå­å•†åŠ¡æœ‰é™å…¬å¸\n    - 531ã€æ·±åœ³å¸‚ç‚è±è’‚å°”æœé¥°æœ‰é™å…¬å¸\n    - 532ã€æ±Ÿè¥¿å›½æ³°åˆ©æ°‘ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 533ã€å¹¿è¥¿å¹¿ç”µå¤§æ•°æ®ç§‘æŠ€æœ‰é™å…¬å¸\n    - 534ã€æ­å·è‰¾éº¦ç§‘æŠ€æœ‰é™å…¬å¸\n    - 535ã€å¹¿å·å°æ»´ç§‘æŠ€æœ‰é™å…¬å¸\n    - 536ã€ä½³ç¼˜ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 537ã€ä¸Šæµ·æ·±æ“ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 538ã€æ­¦å•†ç½‘\n    - 539ã€ç¦å»ºæ°‘æœ¬ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 540ã€æ­å·æƒ åˆä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 541ã€å¦é—¨çˆ±ç«‹å¾—ç§‘æŠ€æœ‰é™å…¬å¸\n    - 542ã€æˆéƒ½æ‹Ÿåˆæœªæ¥ç§‘æŠ€æœ‰é™å…¬å¸\n    - 543ã€å®æ³¢èšè‡»æ™ºèƒ½ç§‘æŠ€æœ‰é™å…¬å¸\n    - 544ã€å¹¿ä¸œç™¾æ…§ç§‘æŠ€æœ‰é™å…¬å¸\n    - 545ã€ç¬¨é©¬ç½‘ç»œ\n    - 546ã€æ·±åœ³å¸‚ä¿¡å®‰æ•°å­—ç§‘æŠ€æœ‰é™å…¬å¸\n    - 547ã€æ·±åœ³å¸‚æ€ä¹æ•°æ®æŠ€æœ¯æœ‰é™å…¬å¸\n    - 548ã€å››å·ç»¿æºé›†ç§‘æŠ€æœ‰é™å…¬å¸\n    - 549ã€æ¹–å—äº‘åŒ»é“¾ç”Ÿç‰©ç§‘æŠ€æœ‰é™å…¬å¸\n    - 550ã€æ­å·æºè¯šç§‘æŠ€æœ‰é™å…¬å¸\n    - 551ã€åŒ—äº¬å¼€è¯¾å§ç§‘æŠ€æœ‰é™å…¬å¸\n    - 552ã€åŒ—äº¬å¤šæ¥ç‚¹ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 553ã€JEECG BOOTä½ä»£ç å¼€å‘å¹³å°\n    - 554ã€è‹å·åŒå…ƒè½¯æ§ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 555ã€æ±Ÿè‹å¤§æ³°ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 556ã€åŒ—äº¬å¤§ç¦¹æ±‡æ™º\n    - 557ã€åŒ—äº¬ç››å“²ç§‘æŠ€æœ‰é™å…¬å¸\n    - 558ã€å¹¿å·é’›åŠ¨ç§‘æŠ€æœ‰é™å…¬å¸\n    - 559ã€åŒ—äº¬å¤§ç¦¹æ±‡æ™ºç§‘æŠ€æœ‰é™å…¬å¸\n    - 560ã€æ¹–å—é¼ç¿°æ–‡åŒ–è‚¡ä»½æœ‰é™å…¬å¸\n    - 561ã€è‹å·å®‰è½¯ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 562ã€èŠ’æœtv\n    - 563ã€ä¸Šæµ·è‰ºèµ›æ——è½¯ä»¶è‚¡ä»½æœ‰é™å…¬å¸\n    - 564ã€ä¸­ç›ˆä¼˜åˆ›èµ„è®¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 565ã€ä¹ä¹å…¬å¯“\n    - 566ã€å¯æ˜ä¿¡æ¯\n    - 567ã€è‹å·å®‰è½¯\n    - 568ã€å—äº¬å¯Œé‡‘çš„è½¯ä»¶ç§‘æŠ€æœ‰é™å…¬å¸\n    - 569ã€æ·±åœ³å¸‚æ–°ç§‘èšåˆç½‘ç»œæŠ€æœ¯æœ‰é™å…¬å¸\n    - 570ã€ä½ å¥½ç°åœ¨(åŒ—äº¬)ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 571ã€360è€ƒè¯•å®å…¸\n    - 572ã€åŒ—äº¬ä¸€é›¶ç§‘æŠ€æœ‰é™å…¬å¸\n    - 573ã€å¦é—¨æ˜Ÿçºµä¿¡æ¯\n    - 574ã€Dalligent Solusi Indonesia\n    - 575ã€æ·±åœ³åæ™®ç‰©è”ç§‘æŠ€æœ‰é™å…¬å¸\n    - 576ã€æ·±åœ³è¡Œå¥è‡ªåŠ¨åŒ–è‚¡ä»½æœ‰é™å…¬å¸\n    - 577ã€æ·±åœ³å¸‚å¯Œèä¿¡æ¯ç§‘æŠ€æœåŠ¡æœ‰é™å…¬å¸\n    - 578ã€è“é¸Ÿäº‘\n    - 579ã€ä¸Šæµ·æ¾åšè´¢ç»èµ„è®¯æœ‰é™å…¬å¸\n    - 580ã€åŒ—äº¬å°é¸¦ç§‘æŠ€æœ‰é™å…¬å¸\n    - 581ã€æ­å·ç›ˆæ³‰äº‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 582ã€æƒŸå®¢æ•°æ®\n    - 583ã€GOSOé¦™èœœé—ºç§€\n    - 584ã€æ™®ä¹å¸ˆï¼ˆä¸Šæµ·ï¼‰æ•°å­—ç§‘æŠ€æœ‰é™å…¬å¸\n    - 585ã€è¥¿å®‰å¸‚é›å¡”åŒºå’–åŒ—å ‚ç½‘ç»œç§‘æŠ€éƒ¨\n    - 586ã€å®æ³¢èšè‡»æ™ºèƒ½ç§‘æŠ€æœ‰é™å…¬å¸\n    - 587ã€æ™®ä¹å¸ˆæ•°å­—ç§‘æŠ€æœ‰é™å…¬å¸\n    - 588ã€æ±Ÿè‹èŸ¹è”ç½‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 589ã€æ­å·æœªæ™ºç§‘æŠ€æœ‰é™å…¬å¸\n    - 590ã€å®‰å‰æ™ºè¡Œç‰©æµæœ‰é™å…¬å¸\n    - 591ã€åç”Ÿå¤§å®¶å±…é›†å›¢æœ‰é™å…¬å¸\n    - 592ã€ç¾å¿ƒé£Ÿå“ï¼ˆå¹¿å·ï¼‰æœ‰é™å…¬å¸\n    - 593ã€è´§æ‹‰æ‹‰ã€è´§æ‹‰æ‹‰APPã€‘\n    - 594ã€æ­å·æ€éŸ¬ç‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 595ã€æ­å·ç–èç§‘æŠ€æœ‰é™å…¬å¸\n    - 596ã€åŒ—äº¬ä¼˜æµ·ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 597ã€æµ™æ±Ÿå¤§ç»´é«˜æ–°æŠ€æœ¯è‚¡ä»½æœ‰é™å…¬å¸\n    - 598ã€ç²¤æ¸¯æ¾³å¤§æ¹¾åŒºæ•°å­—ç»æµç ”ç©¶é™¢\n    - 599ã€æ™®åº·ï¼ˆæ­å·ï¼‰å¥åº·ç§‘æŠ€æœ‰é™å…¬å¸\n    - 600ã€åè¥¿è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸ã€åè¥¿è¯åˆ¸ã€‘\n    - 601ã€æ­å·æµ·åº·æœºå™¨äººè‚¡ä»½æœ‰é™å…¬å¸ã€æµ·åº·ã€‘\n    - 602ã€æ²³å—å®¸é‚¦ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 603ã€æˆéƒ½æ¬¡å…ƒèŠ‚ç‚¹ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 604ã€å¯Œå£«åº·ç§‘æŠ€é›†å›¢ã€å¯Œå£«åº·ã€‘\n    - 605ã€é’å²›ä¸œè½¯è½½æ³¢ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 606ã€å°èŠå¿«è·‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 607ã€è§†æºè‚¡ä»½\n    - 608ã€å®æ³¢èšè‡»æ™ºèƒ½ç§‘æŠ€æœ‰é™å…¬å¸\n    - 609ã€é˜”å¤©ç§‘æŠ€æœ‰é™å…¬å¸\n    - 610ã€ç½‘å®¿ç§‘æŠ€æœ‰é™å…¬å¸\n    - 611ã€å—äº¬æ¢µé¼ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 612ã€æˆ¿å¤©ä¸‹ã€æˆ¿å¤©ä¸‹ã€‘\n    - 613ã€ç‰¹ç“¦ç‰¹èƒ½æºç§‘æŠ€æœ‰é™å…¬å¸\n    - 614ã€æ‹“è¿ªæ™ºèƒ½ç§‘æŠ€æœ‰é™å…¬å¸\n    - 615ã€ä¸œè½¯é›†å›¢ã€ä¸œè½¯ã€‘\n    - 616ã€å¼€æ™®äº‘\n    - 617ã€é¢†è¯¾ç½‘ç»œ\n    - 618ã€å—äº¬ç‰¹ç»´è½¯ä»¶æœ‰é™å…¬å¸\n    - 619ã€ç¦å»ºæ˜“è”ä¼—ä¿ç¿é€šä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 620ã€æµ™æ±Ÿæ ¸å¿ƒåŒèŠ±é¡ºé‡‘èç§‘æŠ€æœ‰é™å…¬å¸ã€åŒèŠ±é¡ºã€‘\n    - 621ã€æµ™æ±Ÿåšè§‚ç‘æ€ç§‘æŠ€æœ‰é™å…¬å¸\n    - 622ã€åŒ—äº¬æ–°ç¾äº’é€šç§‘æŠ€æœ‰é™å…¬å¸\n    - 623ã€åŒ—äº¬æœ‰ç”Ÿåšå¤§è½¯ä»¶è‚¡ä»½æœ‰é™å…¬å¸\n    - 624ã€æ—¶ä»£ä¸­å›½\n    - 625ã€é±¼æ³¡ç½‘\n    - 626ã€ä¸€ç²’æ–¹ç³–ï¼ˆå®‰å¾½ï¼‰ç§‘æŠ€æœ‰é™å…¬å¸\n    - 627ã€åŒ—äº¬å¤–ç ”åœ¨çº¿æ•°å­—ç§‘æŠ€æœ‰é™å…¬å¸\n    - 628ã€å¾·ç”µï¼ˆä¸­å›½ï¼‰é€šä¿¡æŠ€æœ¯æœ‰é™å…¬å¸\n    - 629ã€æ­å·å¯»è”ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 630ã€æ©™è”ï¼ˆä¸­å›½ï¼‰æœ‰é™å…¬å¸\n    - 631ã€åŒ—äº¬æ‰¿å¯é€šç§‘æŠ€æœ‰é™å…¬å¸\n    - 632ã€é“¶è”æ•°æ®æœåŠ¡æœ‰é™å…¬å¸ã€é“¶è”ã€‘\n    - 633ã€ä¸Šæµ·æ™¶ç¡®ç§‘æŠ€æœ‰é™å…¬å¸\n    - 634ã€äºšä¿¡ç§‘æŠ€æœ‰é™å…¬å¸\n    - 635ã€ç¦å»ºæ–°èˆªç‰©è”ç½‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 636ã€ä¸Šæ‰¬è½¯ä»¶\n    - 637ã€æ·±è“æ±½è½¦ç§‘æŠ€æœ‰é™å…¬å¸\n    - 638ã€å—æ˜ŒèŠ‚ç‚¹æ±‡æ™ºç§‘æŠ€æœ‰é™å…¬å¸\n    - 639ã€é”æ˜æŠ€æœ¯\n    - 640ã€å†é€ å†ç”Ÿå¥åº·ç§‘æŠ€æœ‰é™å…¬å¸\n    - 641ã€åå®è¯åˆ¸\n    - 642ã€å“æ­£åŒ»ç–—\n    - 643ã€æ·±åœ³æ¹›ä¿¡ç§‘æŠ€\n    - 644ã€é™•è¥¿é‘«ä¼—ä¸ºè½¯ä»¶æœ‰é™å…¬å¸\n    - 645ã€æ·±åœ³å¸‚æ¶¦å†œç§‘æŠ€æœ‰é™å…¬å¸\n    - 646ã€åºšå•†æ•™è‚²æ™ºèƒ½ç§‘æŠ€æœ‰é™å…¬å¸\n    - 647ã€æ­å·ç¥å£°ç§‘æŠ€\n    - 648ã€å››å·ä¹…è¿œé“¶æµ·è½¯ä»¶è‚¡ä»½æœ‰é™å…¬å¸\n    - 649ã€GeeFoxæç‹ä½ä»£ç \n    - 650ã€æµ™æ±Ÿå’Œä»ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 651ã€å®æ³¢èšè‡»æ™ºèƒ½ç§‘æŠ€æœ‰é™å…¬å¸\n    - 652ã€ç¦å»ºç¦æ˜•è½¯ä»¶å¼€å‘è‚¡ä»½æœ‰é™å…¬å¸ã€ç¦æ˜•ã€‘\n    - 653ã€å¹¿å·ä¸­é•¿åº·è¾¾ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 654ã€æ­¦æ±‰è¶£æ”¹ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 655ã€åŒ—äº¬åå¤æ€æºç§‘æŠ€å‘å±•æœ‰é™å…¬å¸\n    - 656ã€å®æ³¢å…³å…³é€šç§‘æŠ€æœ‰é™å…¬å¸\n    - 657ã€é’å²›å•æ°é¤é¥®æœ‰é™å…¬å¸\n    - 658ã€æ­å·ä¹åˆ»ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 659ã€ä¸Šæµ·çº¢ç“¦ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 660ã€é™•è¥¿æ—…å°å®ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 661ã€ä¸­ç§‘å“æ’(å¤§è¿)ç§‘æŠ€æœ‰é™å…¬å¸\n    - 662ã€åŒ—äº¬åç›Šç²¾ç‚¹ç”Ÿç‰©æŠ€æœ¯æœ‰é™å…¬å¸\n    - 663ã€é©¬å£«åŸºï¼ˆä¸­å›½ï¼‰èˆªè¿æœ‰é™å…¬å¸ã€é©¬å£«åŸºã€‘\n    - 664ã€é™•è¥¿ç¾å’šç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 665ã€å±±ä¸œæ–°åŒ—æ´‹ä¿¡æ¯æŠ€æœ¯è‚¡ä»½æœ‰é™å…¬å¸ \n    - 666ã€ç¦å»ºä¸­ç‘æ–‡åŒ–å‘å±•é›†å›¢æœ‰é™å…¬å¸\n    - 667ã€é»‘é¾™æ±Ÿçœå»ºå·¥é›†å›¢æœ‰é™è´£ä»»å…¬å¸ã€é»‘é¾™æ±Ÿçœå»ºå·¥ã€‘\n    - 668ã€å¿—ä¿¡èƒ½è¾¾å®‰å…¨ç§‘æŠ€(å¹¿å·)æœ‰é™å…¬å¸\n    - 669ã€é‡åº†å¼€æºå…±åˆ›ç§‘æŠ€æœ‰é™å…¬å¸\n    - 670ã€åæ³°äººå¯¿ä¿é™©è‚¡ä»½æœ‰é™å…¬å¸ã€åæ³°äººå¯¿ã€‘\n    - 671ã€æˆéƒ½ç›˜å¤çºµæ¨ªé›†å›¢\n    - 672ã€åŒ—äº¬æœæœä¹å­¦ç§‘æŠ€æœ‰é™å…¬å¸\n    - 673ã€åŒ—äº¬å‡Œäº‘ç©ºé—´ç§‘æŠ€æœ‰é™å…¬å¸\n    - 674ã€ä¸´å·¥é‡æœºè‚¡ä»½æœ‰é™å…¬å¸\n    - 675ã€ä¸Šæµ·çƒ­é£æ—¶å°šç®¡ç†é›†å›¢ã€çƒ­é£ã€‘\n    - 676ã€HashKey Exchange\n    - 677ã€å‚²åŸºï¼ˆæ·±åœ³ï¼‰è·¨å¢ƒå•†åŠ¡è‚¡ä»½æœ‰é™å…¬å¸\n    - 678ã€é’å²›æ–‡è¾¾é€šç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 679ã€æ­å·æ™®ç½—äº‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 680ã€æµ™æ±Ÿäº‘é¹­ç§‘æŠ€æœ‰é™å…¬å¸\n    - 681ã€ä¸­å±±å¸‚èŠ¯å®æŸ¿ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 682ã€æ·±åœ³å¸‚å®¶å®¶é¡ºç‰©è”ç§‘æŠ€\n    - 683ã€é‡åº†æ–‘è¥¿ç§‘æŠ€æœ‰é™å…¬å¸\n    - 684ã€ç¦å»ºçœæ³°å¤ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 685ã€è´µé˜³æ°¸é’ä»ªç”µç§‘æŠ€æœ‰é™å…¬å¸\n    - 686ã€å¹¿å·åšä¾ç‰¹æ™ºèƒ½ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 687ã€æ²³å—å® å‘¦å‘¦ä¿¡æ¯æŠ€æœ¯æœ‰é™å…¬å¸\n    - 688ã€é™•è¥¿æ˜Ÿé‚‘ç©ºé—´æŠ€æœ¯æœ‰é™å…¬å¸\n    - 689ã€å¹¿ä¸œè¥¿æ¬§å…‹å®ä¸šæœ‰é™å…¬å¸\n    - 690ã€å”±å§éº¦é¢‚KTV\n    - 691ã€è”é€šäº‘\n    - 692ã€åŒ—äº¬çˆ±è¯æœ¬ç§‘æŠ€æœ‰é™å…¬å¸\n    - 693ã€åŒ—äº¬èµ·åˆ›ç§‘æŠ€æœ‰é™å…¬å¸\n    - 694ã€å¹³å®‰è¯åˆ¸ã€å¹³å®‰è¯åˆ¸ã€‘\n    - 695ã€åˆè‚¥ä¸­ç§‘ç±»è„‘æ™ºèƒ½æŠ€æœ¯æœ‰é™å…¬å¸\n    - 696ã€å—äº¬åŒä»å ‚å¥åº·äº§ä¸šæœ‰é™å…¬å¸ã€åŒä»å ‚ã€‘\n    - 697ã€é“œä»å¸‚ç¢§æ±ŸåŒºæ™ºæƒ åŠ æ²¹ç«™\n    - 698ã€æƒŸå®¢æ•°æ®\n    - 699ã€å‡¤å‡°æ–°é—»ã€å‡¤å‡°æ–°é—»ã€‘\n    - 700ã€æ·±åœ³ç‹åŠ›æ™ºèƒ½\n    - 701ã€è¿”åˆ©ç½‘æ•°å­—ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸\n    - 702ã€ä¸Šæµ·é˜œèƒ½ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 703ã€æ·±åœ³å¸‚æèƒ½è¶…ç”µæ•°å­—ç§‘æŠ€æœ‰é™å…¬å¸\n    - 704ã€æµ·ç›®æ˜Ÿæ¿€å…‰ç§‘æŠ€é›†å›¢è‚¡ä»½æœ‰é™å…¬å¸\n    - 705ã€å®‰å…‹åˆ›æ–°ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸ã€å®‰å…‹ã€‘\n    - 706ã€å¤§åº†ç‚¹ç¥ç§‘æŠ€æœ‰é™å…¬å¸\n    - 707ã€æµ™æ±Ÿé›¶è·‘ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸ã€é›¶è·‘ã€‘\n    - 708ã€æˆéƒ½æˆç”µé‡‘ç›˜å¥åº·æ•°æ®æŠ€æœ¯æœ‰é™å…¬å¸\n    - 709ã€æˆéƒ½æç±³ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸ã€æç±³ã€‘\n    - 710ã€é¡ºå¾·èŒä¸šæŠ€æœ¯å¤§å­¦\n    - 711ã€ä¸­é‚®è¯åˆ¸æœ‰é™è´£ä»»å…¬å¸ã€ä¸­é‚®è¯åˆ¸ã€‘\n    - 712ã€å¿—è±ªé“¾äº‘ç§‘æŠ€æœ‰é™å…¬å¸\n    - 713ã€æ¹–å—ä¸‡é²¸ç§‘æŠ€æœ‰é™å…¬å¸\n    - 714ã€å¹¿å·ä¸‡è¡¨\n    - 715ã€å†æƒ ï¼ˆä¸Šæµ·ï¼‰ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - 716ã€ä¸Šæµ·çˆ±è¯šè£•ä¿¡æ¯ç§‘æŠ€æœ‰é™å…¬å¸\n    - 717ã€æ­å·è¿ˆç‘æ•°å­—ç§‘æŠ€æœ‰é™å…¬å¸\n    - 718ã€å¹¿å·ä¸²è”ç½‘ç»œç§‘æŠ€æœ‰é™å…¬å¸\n    - â€¦â€¦\n\n> æ›´å¤šæ¥å…¥çš„å…¬å¸ï¼Œæ¬¢è¿åœ¨ [ç™»è®°åœ°å€](https://github.com/xuxueli/xxl-job/issues/1 ) ç™»è®°ï¼Œç™»è®°ä»…ä»…ä¸ºäº†äº§å“æ¨å¹¿ã€‚\n\næ¬¢è¿å¤§å®¶çš„å…³æ³¨å’Œä½¿ç”¨ï¼ŒXXL-JOBä¹Ÿå°†æ‹¥æŠ±å˜åŒ–ï¼ŒæŒç»­å‘å±•ã€‚\n\n\n## Contributing\nContributions are welcome! Open a pull request to fix a bug, or open an [Issue](https://github.com/xuxueli/xxl-job/issues/) to discuss a new feature or change.\n\næ¬¢è¿å‚ä¸é¡¹ç›®è´¡çŒ®ï¼æ¯”å¦‚æäº¤PRä¿®å¤ä¸€ä¸ªbugï¼Œæˆ–è€…æ–°å»º [Issue](https://github.com/xuxueli/xxl-job/issues/) è®¨è®ºæ–°ç‰¹æ€§æˆ–è€…å˜æ›´ã€‚\n\n\n## Copyright and License\nThis product is open source and free, and will continue to provide free community technical support. Individual or enterprise users are free to access and use.\n\n- Licensed under the GNU General Public License (GPL) v3.\n- Copyright (c) 2015-present, xuxueli.\n\näº§å“å¼€æºå…è´¹ï¼Œå¹¶ä¸”å°†æŒç»­æä¾›å…è´¹çš„ç¤¾åŒºæŠ€æœ¯æ”¯æŒã€‚ä¸ªäººæˆ–ä¼ä¸šå†…éƒ¨å¯è‡ªç”±çš„æ¥å…¥å’Œä½¿ç”¨ã€‚å¦‚æœ‰éœ€è¦å¯ [é‚®ä»¶è”ç³»](https://www.xuxueli.com/page/community.html) ä½œè€…å…è´¹è·å–é¡¹ç›®æˆæƒã€‚\n",
      "stars_today": 3
    },
    {
      "id": 15583310,
      "name": "SoftEtherVPN",
      "full_name": "SoftEtherVPN/SoftEtherVPN",
      "description": "Cross-platform multi-protocol VPN software. Pull requests are welcome. The stable version is available at https://github.com/SoftEtherVPN/SoftEtherVPN_Stable.",
      "html_url": "https://github.com/SoftEtherVPN/SoftEtherVPN",
      "stars": 12915,
      "forks": 2736,
      "language": "C",
      "topics": [
        "etherip",
        "ike",
        "ipsec",
        "l2tp",
        "l2tpv3",
        "openvpn",
        "softether-vpn",
        "softethervpn",
        "ssl-vpn",
        "sstp",
        "tls",
        "vpn",
        "vpn-protocols",
        "vpn-server",
        "vpn-tunnel",
        "wfh",
        "wireguard",
        "work-from-home"
      ],
      "created_at": "2014-01-02T12:40:57Z",
      "updated_at": "2026-01-25T00:56:34Z",
      "pushed_at": "2026-01-24T21:44:29Z",
      "open_issues": 281,
      "owner": {
        "login": "SoftEtherVPN",
        "avatar_url": "https://avatars.githubusercontent.com/u/6303100?v=4"
      },
      "readme": "# SoftEther VPN\r\n\r\n||Badges|\r\n|---|---|\r\n|GitLab CI|[![GitLab CI build status](https://gitlab.com/SoftEther/SoftEtherVPN/badges/master/pipeline.svg)](https://gitlab.com/SoftEther/SoftEtherVPN/pipelines)|\r\n|Coverity Scan|[![Coverity Scan build status](https://scan.coverity.com/projects/16304/badge.svg)](https://scan.coverity.com/projects/softethervpn-softethervpn)|\r\n|Cirrus CI|[![Cirrus CI build status](https://api.cirrus-ci.com/github/SoftEtherVPN/SoftEtherVPN.svg)](https://cirrus-ci.com/github/SoftEtherVPN/SoftEtherVPN)|\r\n\r\n- [SoftEther VPN](#softether-vpn)\r\n- [BOARD MEMBERS OF THIS REPOSITORY](#board-members-of-this-repository)\r\n- [SOFTETHER VPN ADVANTAGES](#softether-vpn-advantages)\r\n- [Installation](#installation)\r\n  * [For FreeBSD](#for-freebsd)\r\n  * [For Windows](#for-windows)\r\n  * [From binary installers (stable channel)](#from-binary-installers-stable-channel)\r\n  * [Build from Source code](#build-from-source-code)\r\n- [Antivirus False Positive Detection](ANTIVIRUS.md)\r\n- [About HTML5-based Modern Admin Console and JSON-RPC API Suite](#about-html5-based-modern-admin-console-and-json-rpc-api-suite)\r\n  * [Built-in SoftEther VPN Server HTML5 Ajax-based Web Administration Console](#built-in-softether-vpn-server-html5-ajax-based-web-administration-console)\r\n  * [Built-in SoftEther Server VPN JSON-RPC API Suite](#built-in-softether-server-vpn-json-rpc-api-suite)\r\n- [TO CIRCUMVENT YOUR GOVERNMENT'S FIREWALL RESTRICTION](#to-circumvent-your-governments-firewall-restriction)\r\n- [SOURCE CODE CONTRIBUTION](#source-code-contribution)\r\n- [DEAR SECURITY EXPERTS](#dear-security-experts)\r\n\r\nSoftEther VPN (Developer Edition Master Repository)\r\n- An Open-Source Cross-platform Multi-protocol VPN Program\r\nhttps://www.softether.org/\r\n\r\n\r\nThis repository has experimental codes. Pull requests are welcome.\r\n\r\nStable Edition is available on\r\nhttps://github.com/SoftEtherVPN/SoftEtherVPN_Stable\r\nwhich the non-developer user can stable use.\r\n\r\nPlease note that [some features](#comparison-with-stable-edition) are not available in Stable Edition.\r\n\r\nSource code packages (.zip and .tar.gz) and binary files of Stable Edition are also available:  \r\nhttps://www.softether-download.com/\r\n\r\nCopyright (c) all contributors on SoftEther VPN project in GitHub.\r\nCopyright (c) Daiyuu Nobori, SoftEther Project at University of Tsukuba, and SoftEther Corporation.\r\n\r\n---\r\n\r\nThe development of SoftEther VPN was supported by the MITOH Project,\r\na research and development project by Japanese Government,\r\nsubsidized by Ministry of Economy, Trade and Industry of Japan,\r\nadministrated by Information Promotion Agency.\r\nhttps://www.ipa.go.jp/english/humandev/\r\n\r\n---\r\n\r\n![https://icons8.com](resources/icons8.png \"Icons8\")\r\n\r\n[Icons8](https://icons8.com) kindly supported the project by gifting a license which allows to edit and redistribute their icons.\r\n\r\nPlease note that you are not allowed to redistribute those icons outside of this repository.\r\n\r\nThe developers of SoftEther VPN love Icons8's work and kindly ask the users to support them as much as possible.\r\n\r\n---\r\n\r\nLicensed under the Apache License, Version 2.0 (the \"License\");\r\nyou may not use this file except in compliance with the License.\r\nYou may obtain a copy of the License at\r\n\r\n   http://www.apache.org/licenses/LICENSE-2.0\r\n\r\nSoftEther VPN (\"SoftEther\" means \"Software Ethernet\") is one of the\r\nworld's most powerful and easy-to-use multi-protocol VPN software.\r\n\r\nSoftEther VPN runs on Windows, Linux, Mac, FreeBSD and Solaris.\r\n\r\nSoftEther VPN supports most of widely-used VPN protocols\r\nincluding SSL-VPN, WireGuard, OpenVPN, IPsec, L2TP, MS-SSTP, L2TPv3 and EtherIP\r\nby the single SoftEther VPN Server program.\r\n\r\nMore details on https://www.softether.org/.\r\n\r\n\r\n# BOARD MEMBERS OF THIS REPOSITORY\r\n\r\n\r\nDaiyuu Nobori (Since Jan 2, 2014)\r\nhttps://github.com/dnobori\r\n\r\nMoataz Elmasry (Since Nov 6, 2017)\r\nhttps://github.com/moatazelmasry2\r\n\r\nZulyandri Zardi (Since Nov 6, 2017)\r\nhttps://github.com/zulzardi\r\n\r\nAlex Maslakov (Since Nov 6, 2017)\r\nhttps://github.com/GildedHonour\r\n\r\nDavide Beatrici (Since Jul 21, 2018)\r\nhttps://github.com/davidebeatrici\r\n\r\nIlya Shipitsin (Since Jul 21, 2018)\r\nhttps://github.com/chipitsine\r\n\r\n\r\n# SOFTETHER VPN ADVANTAGES\r\n\r\n\r\n- Supporting all popular VPN protocols by the single VPN server:\r\n  SSL-VPN (HTTPS)\r\n  WireGuard\r\n  OpenVPN\r\n  IPsec\r\n  L2TP\r\n  MS-SSTP\r\n  L2TPv3\r\n  EtherIP\r\n- Free and open-source software.\r\n- Easy to establish both remote-access and site-to-site VPN.\r\n- SSL-VPN Tunneling on HTTPS to pass through NATs and firewalls.\r\n- Revolutionary VPN over ICMP and VPN over DNS features.\r\n- Resistance to highly-restricted firewall.\r\n- Ethernet-bridging (L2) and IP-routing (L3) over VPN.\r\n- Embedded dynamic-DNS and NAT-traversal so that no static nor\r\n  fixed IP address is required.\r\n- AES 256-bit and RSA 4096-bit encryptions.\r\n- Sufficient security features such as logging and firewall inner\r\n  VPN tunnel.\r\n- User authentication with RADIUS and NT domain controllers.\r\n- User authentication with X.509 client certificate.\r\n- Packet logging.\r\n- 1Gbps-class high-speed throughput performance with low memory and\r\n  CPU usage.\r\n- Windows, Linux, Mac, Android, iPhone, iPad and Windows Phone are\r\n  supported.\r\n- The OpenVPN clone function supports legacy OpenVPN clients.\r\n- IPv4 / IPv6 dual-stack.\r\n- The VPN server runs on Windows, Linux, FreeBSD, Solaris and Mac OS X.\r\n- Configure All settings on GUI.\r\n- Multi-languages (English, Japanese and Simplified-Chinese).\r\n- No memory leaks. High quality stable codes, intended for long-term runs.\r\n  We always verify that there are no memory or resource leaks before\r\n  releasing the build.\r\n- More details at https://www.softether.org/.\r\n\r\n# Comparison with Stable Edition\r\n\r\n| Protocol | Stable Edition (SE) | Developer Edition (DE) | Comment |\r\n| --- | --- | --- | --- |\r\n| SSL-VPN | âœ… | âœ… | |\r\n| OpenVPN | âœ… | âœ… | AEAD mode is supported in DE only. |\r\n| IPsec | âœ… | âœ… | |\r\n| L2TP | âœ… | âœ… | |\r\n| MS-SSTP | âœ… | âœ… | |\r\n| L2TPv3 | âœ… | âœ… | |\r\n| EtherIP | âœ… | âœ… | |\r\n| WireGuard | âŒ | âœ… | |\r\n| IKEv2 | âŒ | âŒ | |\r\n\r\n| Feature | Stable Edition (SE) | Developer Edition (DE) | Comment |\r\n| --- | --- | --- | --- |\r\n| Password Authentication | âœ… | âœ… | |\r\n| RADIUS / NT Authentication | âœ… | âœ… | |\r\n| Certificate Authentication | âš ï¸ | âœ… | SE supports the feature in SSL-VPN only. |\r\n| IPv6-capable VPN Tunnel | âš ï¸ | âœ… | SE supports IPv6 in L2 VPN tunnels only. |\r\n| IPv4 Route Management | âœ… | âœ… | Windows clients only |\r\n| IPv6 Route Management | âŒ | âœ… | Windows clients only |\r\n| TLS Server Verification | âš ï¸ | âœ… | In SE you need to specify the exact certificate or CA to verify. DE can perform standard TLS verification and use the system CA store. |\r\n| Dual-stack Name Resolution | âš ï¸ | âœ… | SE attempts in IPv6 only after IPv4 has failed. |\r\n| ECDSA Certificates Import | âŒ | âœ… | |\r\n| Runs on Windows XP and Earlier | âœ… | âŒ | |\r\n| Compatible with SoftEther VPN 1.0 | âœ… | âŒ | |\r\n| AES-NI Hardware Acceleration | âš ï¸ |  âœ… | SE requires [intel_aes_lib](https://software.intel.com/sites/default/files/article/181731/intel-aesni-sample-library-v1.2.zip) to enable AES-NI, so x86 only. In DE, enabled by default as long as processor supports it (at least x86 and ARM). |\r\n\r\n# Installation\r\n\r\n## For FreeBSD\r\n\r\nSoftEther VPN in FreeBSD Ports Collection is maintained by\r\n[Koichiro Iwao](https://people.FreeBSD.org/~meta/) ([@metalefty](https://github.com/metalefty)).\r\n\r\nBinary package can be installed by pkg:\r\n```\r\npkg install softether5\r\n```\r\n\r\nAlternatively, it can be built & installed by ports:\r\n```\r\nmake install -C /usr/ports/security/softether5\r\n```\r\n\r\nTo run SoftEther VPN Server:\r\n```\r\nservice softether_server start\r\n```\r\n\r\nTo configure SoftEther VPN Server startup on boot:\r\n```\r\nsysrc softether_server_enable=yes\r\n```\r\n\r\nAlso SoftEther VPN [Stable Edition](https://www.freshports.org/security/softether-devel/) and\r\n[RTM version](https://www.freshports.org/security/softether/) are available on FreeBSD.\r\n\r\n## For Windows\r\n\r\n[Releases](https://github.com/SoftEtherVPN/SoftEtherVPN/releases)\r\n\r\n[Nightly builds](https://github.com/SoftEtherVPN/SoftEtherVPN/actions/workflows/windows.yml)\r\n(choose appropriate platform, then find binaries or installers as artifacts)\r\n\r\n**âš ï¸ Important for Windows Users**: Some antivirus software (including Microsoft Defender) may incorrectly flag SoftEther VPN as malicious. This is a **false positive**. See [ANTIVIRUS.md](ANTIVIRUS.md) for detailed information and solutions.\r\n\r\n## From binary installers (stable channel)\r\n\r\nThose can be found under https://www.softether-download.com/\r\nThere you can also find SoftEtherVPN source code in zip and tar formats.\r\n\r\n## Docker Container Image\r\n\r\nPlease look at the [ContainerREADME.md](ContainerREADME.md)\r\n\r\n## Build from Source code\r\n\r\nsee [BUILD_UNIX](src/BUILD_UNIX.md) or [BUILD_WINDOWS](src/BUILD_WINDOWS.md)\r\n\r\nThere are two flavours of SoftEtherVPN source code:\r\n\r\n1. Unstable. Found under https://github.com/SoftEtherVPN/SoftEtherVPN\r\n2. Stable. Found under https://github.com/SoftEtherVPN/SoftEtherVPN_Stable\r\n\r\n\r\n# About HTML5-based Modern Admin Console and JSON-RPC API Suite\r\n\r\n## Built-in SoftEther VPN Server HTML5 Ajax-based Web Administration Console\r\nWe are developing the HTML5 Ajax-based Web Administration Console (currently very limited, under construction) in the embedded HTTPS server on the SoftEther VPN Server.\r\n\r\nAccess to the following URL from your favorite web browser.\r\n\r\n```\r\nhttps://<vpn_server_hostname>:<port>/admin/\r\n```\r\n\r\nFor example if your VPN Server is running as the port 5555 on the host at 192.168.0.1, you can access to the web console by:\r\n\r\n```\r\nhttps://192.168.0.1:5555/admin/\r\n```\r\n\r\nNote: Your HTML5 development contribution is very appreciated. The current HTML5 pages are written by Daiyuu Nobori (the core developer of SoftEther VPN). He is obviously lack of HTML5 development ability. Please kindly consider to contribute for SoftEther VPN's development on GitHub. Your code will help every people running SoftEther VPN Server.\r\n\r\n\r\n## Built-in SoftEther Server VPN JSON-RPC API Suite\r\nThe API Suite allows you to easily develop your original SoftEther VPN Server management application to control the VPN Server (e.g. creating users, adding Virtual Hubs, disconnecting a specified VPN sessions).\r\n\r\nYou can access to the [latest SoftEther VPN Server JSON-RPC Document on GitHub.](https://github.com/SoftEtherVPN/SoftEtherVPN/tree/master/developer_tools/vpnserver-jsonrpc-clients/)\r\n\r\n- Almost all control APIs, which the VPN Server provides, are available as JSON-RPC API.\r\nYou can write your own VPN Server management application in your favorite languages (JavaScript, TypeScript, Java, Python, Ruby, C#, ... etc.)\r\n- If you are planning to develop your own VPN cloud service, the JSON-RPC API is the best choice to realize the automated operations for the VPN Server.\r\n- No need to use any specific API client library since all APIs are provided on the JSON-RPC 2.0 Specification. You can use your favorite JSON and HTTPS client library to call any of all APIs in your pure runtime environment.\r\n- Also, the SoftEther VPN Project provides high-quality JSON-RPC client stub libraries which define all of the API client stub codes. These libraries are written in C#, JavaScript and TypeScript. The Node.js Client Library for VPN Server RPC (vpnrpc) package is also available.\r\n\r\n\r\n# TO CIRCUMVENT YOUR GOVERNMENT'S FIREWALL RESTRICTION\r\n\r\nBecause SoftEther VPN is overly strong tool to build a VPN tunnel,\r\nsome censorship governments want to block your access to the source code\r\nof SoftEther VPN, by abusing their censorship firewalls.\r\n\r\nTo circumvent your censor's unjust restriction,\r\nSoftEther VPN Project distributes the up-to-date source code\r\non all the following open-source repositories:\r\n\r\n  - GitHub\r\n    https://github.com/SoftEtherVPN/SoftEtherVPN\r\n\r\n        $ git clone https://github.com/SoftEtherVPN/SoftEtherVPN.git\r\n\r\n  - GitLab (mirrored from GitHub)\r\n    https://gitlab.com/SoftEther/VPN\r\n\r\n        $ git clone https://gitlab.com/SoftEther/VPN.git\r\n\r\n  - OneDev (mirrored from GitHub)\r\n    https://code.onedev.io/SoftEther/VPN\r\n\r\n        $ git clone https://code.onedev.io/SoftEther/VPN.git\r\n\r\nWe hope that you can reach one of the above URLs at least!\r\n\r\n\r\n# SOURCE CODE CONTRIBUTION\r\n\r\nYour contribution to SoftEther VPN Project is much appreciated.\r\nPlease send patches to us through GitHub.\r\n\r\nHere you find how to submit new translation: [TRANSLATION_GUIDE.md](TRANSLATION_GUIDE.md)\r\n\r\n\r\n# DEAR SECURITY EXPERTS\r\n\r\nIf you find a bug or a security vulnerability please [kindly inform](https://github.com/SoftEtherVPN/SoftEtherVPN/security/advisories/new) us\r\nabout the problem immediately so that we can fix the security problem\r\nto protect a lot of users around the world as soon as possible.\r\n\r\nOur e-mail address for security reports is:\r\n**softether-vpn-security at softether.org**\r\n\r\nPlease note that the above e-mail address is not a technical support\r\ninquiry address. If you need technical assistance, please visit\r\nhttps://www.softether.org/ and ask your question on the users forum.\r\n",
      "stars_today": 3
    },
    {
      "id": 21306961,
      "name": "fsnotify",
      "full_name": "fsnotify/fsnotify",
      "description": "Cross-platform filesystem notifications for Go.",
      "html_url": "https://github.com/fsnotify/fsnotify",
      "stars": 10527,
      "forks": 961,
      "language": "Go",
      "topics": [],
      "created_at": "2014-06-28T16:47:01Z",
      "updated_at": "2026-01-24T17:20:31Z",
      "pushed_at": "2025-12-04T14:32:34Z",
      "open_issues": 35,
      "owner": {
        "login": "fsnotify",
        "avatar_url": "https://avatars.githubusercontent.com/u/8013877?v=4"
      },
      "readme": "fsnotify is a Go library to provide cross-platform filesystem notifications on\nWindows, Linux, macOS, BSD, and illumos.\n\nGo 1.17 or newer is required; the full documentation is at\nhttps://pkg.go.dev/github.com/fsnotify/fsnotify\n\n---\n\nPlatform support:\n\n| Backend               | OS         | Status                                                                    |\n| :-------------------- | :--------- | :------------------------------------------------------------------------ |\n| inotify               | Linux      | Supported                                                                 |\n| kqueue                | BSD, macOS | Supported                                                                 |\n| ReadDirectoryChangesW | Windows    | Supported                                                                 |\n| FEN                   | illumos    | Supported                                                                 |\n| fanotify              | Linux 5.9+ | [Not yet](https://github.com/fsnotify/fsnotify/issues/114)                |\n| FSEvents              | macOS      | [Needs support in x/sys/unix][fsevents]                                   |\n| USN Journals          | Windows    | [Needs support in x/sys/windows][usn]                                     |\n| Polling               | *All*      | [Not yet](https://github.com/fsnotify/fsnotify/issues/9)                  |\n\nLinux and illumos should include Android and Solaris, but these are currently\nuntested.\n\n[fsevents]:   https://github.com/fsnotify/fsnotify/issues/11#issuecomment-1279133120\n[usn]:        https://github.com/fsnotify/fsnotify/issues/53#issuecomment-1279829847\n\nUsage\n-----\nA basic example:\n\n```go\npackage main\n\nimport (\n    \"log\"\n\n    \"github.com/fsnotify/fsnotify\"\n)\n\nfunc main() {\n    // Create new watcher.\n    watcher, err := fsnotify.NewWatcher()\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer watcher.Close()\n\n    // Start listening for events.\n    go func() {\n        for {\n            select {\n            case event, ok := <-watcher.Events:\n                if !ok {\n                    return\n                }\n                log.Println(\"event:\", event)\n                if event.Has(fsnotify.Write) {\n                    log.Println(\"modified file:\", event.Name)\n                }\n            case err, ok := <-watcher.Errors:\n                if !ok {\n                    return\n                }\n                log.Println(\"error:\", err)\n            }\n        }\n    }()\n\n    // Add a path.\n    err = watcher.Add(\"/tmp\")\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    // Block main goroutine forever.\n    <-make(chan struct{})\n}\n```\n\nSome more examples can be found in [cmd/fsnotify](cmd/fsnotify), which can be\nrun with:\n\n    % go run ./cmd/fsnotify\n\nFurther detailed documentation can be found in godoc:\nhttps://pkg.go.dev/github.com/fsnotify/fsnotify\n\nFAQ\n---\n### Will a file still be watched when it's moved to another directory?\nNo, not unless you are watching the location it was moved to.\n\n### Are subdirectories watched?\nNo, you must add watches for any directory you want to watch (a recursive\nwatcher is on the roadmap: [#18]).\n\n[#18]: https://github.com/fsnotify/fsnotify/issues/18\n\n### Do I have to watch the Error and Event channels in a goroutine?\nYes. You can read both channels in the same goroutine using `select` (you don't\nneed a separate goroutine for both channels; see the example).\n\n### Why don't notifications work with NFS, SMB, FUSE, /proc, or /sys?\nfsnotify requires support from underlying OS to work. The current NFS and SMB\nprotocols does not provide network level support for file notifications, and\nneither do the /proc and /sys virtual filesystems.\n\nThis could be fixed with a polling watcher ([#9]), but it's not yet implemented.\n\n[#9]: https://github.com/fsnotify/fsnotify/issues/9\n\n### Why do I get many Chmod events?\nSome programs may generate a lot of attribute changes; for example Spotlight on\nmacOS, anti-virus programs, backup applications, and some others are known to do\nthis. As a rule, it's typically best to ignore Chmod events. They're often not\nuseful, and tend to cause problems.\n\nSpotlight indexing on macOS can result in multiple events (see [#15]). A\ntemporary workaround is to add your folder(s) to the *Spotlight Privacy\nsettings* until we have a native FSEvents implementation (see [#11]).\n\n[#11]: https://github.com/fsnotify/fsnotify/issues/11\n[#15]: https://github.com/fsnotify/fsnotify/issues/15\n\n### Watching a file doesn't work well\nWatching individual files (rather than directories) is generally not recommended\nas many programs (especially editors) update files atomically: it will write to\na temporary file which is then moved to a destination, overwriting the original\n(or some variant thereof). The watcher on the original file is now lost, as that\nno longer exists.\n\nThe upshot of this is that a power failure or crash won't leave a half-written\nfile.\n\nWatch the parent directory and use `Event.Name` to filter out files you're not\ninterested in. There is an example of this in `cmd/fsnotify/file.go`.\n\nPlatform-specific notes\n-----------------------\n### Linux\nWhen a file is removed a REMOVE event won't be emitted until all file\ndescriptors are closed; it will emit a CHMOD instead:\n\n    fp := os.Open(\"file\")\n    os.Remove(\"file\")        // CHMOD\n    fp.Close()               // REMOVE\n\nThis is the event that inotify sends, so not much can be changed about this.\n\nThe `fs.inotify.max_user_watches` sysctl variable specifies the upper limit for\nthe number of watches per user, and `fs.inotify.max_user_instances` specifies\nthe maximum number of inotify instances per user. Every Watcher you create is an\n\"instance\", and every path you add is a \"watch\". Reaching the limit will result\nin a \"no space left on device\" or \"too many open files\" error.\n\nThese are also exposed in `/proc` as `/proc/sys/fs/inotify/max_user_watches` and\n`/proc/sys/fs/inotify/max_user_instances`. The default values differ per distro\nand available memory.\n\nTo increase them you can use `sysctl` or write the value to proc file:\n\n    sysctl fs.inotify.max_user_watches=200000\n    sysctl fs.inotify.max_user_instances=256\n\nTo make the changes persist on reboot edit `/etc/sysctl.conf` or\n`/usr/lib/sysctl.d/50-default.conf` (details differ per Linux distro; check your\ndistro's documentation):\n\n    fs.inotify.max_user_watches=200000\n    fs.inotify.max_user_instances=256\n\n\n### kqueue (macOS, all BSD systems)\nkqueue requires opening a file descriptor for every file that's being watched;\nso if you're watching a directory with five files then that's six file\ndescriptors. You will run in to your system's \"max open files\" limit faster on\nthese platforms.\n\nThe sysctl variables `kern.maxfiles` and `kern.maxfilesperproc` can be used to\ncontrol the maximum number of open files.\n",
      "stars_today": 3
    },
    {
      "id": 83160811,
      "name": "littlefs",
      "full_name": "littlefs-project/littlefs",
      "description": "A little fail-safe filesystem designed for microcontrollers",
      "html_url": "https://github.com/littlefs-project/littlefs",
      "stars": 6384,
      "forks": 961,
      "language": "C",
      "topics": [
        "embedded",
        "filesystem",
        "microcontroller"
      ],
      "created_at": "2017-02-25T20:33:13Z",
      "updated_at": "2026-01-24T21:02:03Z",
      "pushed_at": "2026-01-09T06:51:19Z",
      "open_issues": 603,
      "owner": {
        "login": "littlefs-project",
        "avatar_url": "https://avatars.githubusercontent.com/u/60944974?v=4"
      },
      "readme": "## littlefs\n\nA little fail-safe filesystem designed for microcontrollers.\n\n```\n   | | |     .---._____\n  .-----.   |          |\n--|o    |---| littlefs |\n--|     |---|          |\n  '-----'   '----------'\n   | | |\n```\n\n**Power-loss resilience** - littlefs is designed to handle random power\nfailures. All file operations have strong copy-on-write guarantees and if\npower is lost the filesystem will fall back to the last known good state.\n\n**Dynamic wear leveling** - littlefs is designed with flash in mind, and\nprovides wear leveling over dynamic blocks. Additionally, littlefs can\ndetect bad blocks and work around them.\n\n**Bounded RAM/ROM** - littlefs is designed to work with a small amount of\nmemory. RAM usage is strictly bounded, which means RAM consumption does not\nchange as the filesystem grows. The filesystem contains no unbounded\nrecursion and dynamic memory is limited to configurable buffers that can be\nprovided statically.\n\n## Example\n\nHere's a simple example that updates a file named `boot_count` every time\nmain runs. The program can be interrupted at any time without losing track\nof how many times it has been booted and without corrupting the filesystem:\n\n``` c\n#include \"lfs.h\"\n\n// variables used by the filesystem\nlfs_t lfs;\nlfs_file_t file;\n\n// configuration of the filesystem is provided by this struct\nconst struct lfs_config cfg = {\n    // block device operations\n    .read  = user_provided_block_device_read,\n    .prog  = user_provided_block_device_prog,\n    .erase = user_provided_block_device_erase,\n    .sync  = user_provided_block_device_sync,\n\n    // block device configuration\n    .read_size = 16,\n    .prog_size = 16,\n    .block_size = 4096,\n    .block_count = 128,\n    .cache_size = 16,\n    .lookahead_size = 16,\n    .block_cycles = 500,\n};\n\n// entry point\nint main(void) {\n    // mount the filesystem\n    int err = lfs_mount(&lfs, &cfg);\n\n    // reformat if we can't mount the filesystem\n    // this should only happen on the first boot\n    if (err) {\n        lfs_format(&lfs, &cfg);\n        lfs_mount(&lfs, &cfg);\n    }\n\n    // read current count\n    uint32_t boot_count = 0;\n    lfs_file_open(&lfs, &file, \"boot_count\", LFS_O_RDWR | LFS_O_CREAT);\n    lfs_file_read(&lfs, &file, &boot_count, sizeof(boot_count));\n\n    // update boot count\n    boot_count += 1;\n    lfs_file_rewind(&lfs, &file);\n    lfs_file_write(&lfs, &file, &boot_count, sizeof(boot_count));\n\n    // remember the storage is not updated until the file is closed successfully\n    lfs_file_close(&lfs, &file);\n\n    // release any resources we were using\n    lfs_unmount(&lfs);\n\n    // print the boot count\n    printf(\"boot_count: %d\\n\", boot_count);\n}\n```\n\n## Usage\n\nDetailed documentation (or at least as much detail as is currently available)\ncan be found in the comments in [lfs.h](lfs.h).\n\nlittlefs takes in a configuration structure that defines how the filesystem\noperates. The configuration struct provides the filesystem with the block\ndevice operations and dimensions, tweakable parameters that tradeoff memory\nusage for performance, and optional static buffers if the user wants to avoid\ndynamic memory.\n\nThe state of the littlefs is stored in the `lfs_t` type which is left up\nto the user to allocate, allowing multiple filesystems to be in use\nsimultaneously. With the `lfs_t` and configuration struct, a user can\nformat a block device or mount the filesystem.\n\nOnce mounted, the littlefs provides a full set of POSIX-like file and\ndirectory functions, with the deviation that the allocation of filesystem\nstructures must be provided by the user.\n\nAll POSIX operations, such as remove and rename, are atomic, even in event\nof power-loss. Additionally, file updates are not actually committed to\nthe filesystem until sync or close is called on the file.\n\n## Other notes\n\nLittlefs is written in C, and specifically should compile with any compiler\nthat conforms to the `C99` standard.\n\nAll littlefs calls have the potential to return a negative error code. The\nerrors can be either one of those found in the `enum lfs_error` in\n[lfs.h](lfs.h), or an error returned by the user's block device operations.\n\nIn the configuration struct, the `prog` and `erase` function provided by the\nuser may return a `LFS_ERR_CORRUPT` error if the implementation already can\ndetect corrupt blocks. However, the wear leveling does not depend on the return\ncode of these functions, instead all data is read back and checked for\nintegrity.\n\nIf your storage caches writes, make sure that the provided `sync` function\nflushes all the data to memory and ensures that the next read fetches the data\nfrom memory, otherwise data integrity can not be guaranteed. If the `write`\nfunction does not perform caching, and therefore each `read` or `write` call\nhits the memory, the `sync` function can simply return 0.\n\n## Design\n\nAt a high level, littlefs is a block based filesystem that uses small logs to\nstore metadata and larger copy-on-write (COW) structures to store file data.\n\nIn littlefs, these ingredients form a sort of two-layered cake, with the small\nlogs (called metadata pairs) providing fast updates to metadata anywhere on\nstorage, while the COW structures store file data compactly and without any\nwear amplification cost.\n\nBoth of these data structures are built out of blocks, which are fed by a\ncommon block allocator. By limiting the number of erases allowed on a block\nper allocation, the allocator provides dynamic wear leveling over the entire\nfilesystem.\n\n```\n                    root\n                   .--------.--------.\n                   | A'| B'|         |\n                   |   |   |->       |\n                   |   |   |         |\n                   '--------'--------'\n                .----'   '--------------.\n       A       v                 B       v\n      .--------.--------.       .--------.--------.\n      | C'| D'|         |       | E'|new|         |\n      |   |   |->       |       |   | E'|->       |\n      |   |   |         |       |   |   |         |\n      '--------'--------'       '--------'--------'\n      .-'   '--.                  |   '------------------.\n     v          v              .-'                        v\n.--------.  .--------.        v                       .--------.\n|   C    |  |   D    |   .--------.       write       | new E  |\n|        |  |        |   |   E    |        ==>        |        |\n|        |  |        |   |        |                   |        |\n'--------'  '--------'   |        |                   '--------'\n                         '--------'                   .-'    |\n                         .-'    '-.    .-------------|------'\n                        v          v  v              v\n                   .--------.  .--------.       .--------.\n                   |   F    |  |   G    |       | new F  |\n                   |        |  |        |       |        |\n                   |        |  |        |       |        |\n                   '--------'  '--------'       '--------'\n```\n\nMore details on how littlefs works can be found in [DESIGN.md](DESIGN.md) and\n[SPEC.md](SPEC.md).\n\n- [DESIGN.md](DESIGN.md) - A fully detailed dive into how littlefs works.\n  I would suggest reading it as the tradeoffs at work are quite interesting.\n\n- [SPEC.md](SPEC.md) - The on-disk specification of littlefs with all the\n  nitty-gritty details. May be useful for tooling development.\n\n## Testing\n\nThe littlefs comes with a test suite designed to run on a PC using the\n[emulated block device](bd/lfs_testbd.h) found in the `bd` directory.\nThe tests assume a Linux environment and can be started with make:\n\n``` bash\nmake test\n```\n\nTests are implemented in C in the .toml files found in the `tests` directory.\nWhen developing a feature or fixing a bug, it is frequently useful to run a\nsingle test case or suite of tests:\n\n``` bash\n./scripts/test.py -l runners/test_runner  # list available test suites\n./scripts/test.py -L runners/test_runner test_dirs  # list available test cases\n./scripts/test.py runners/test_runner test_dirs  # run a specific test suite\n```\n\nIf an assert fails in a test, test.py will try to print information about the\nfailure:\n\n``` bash\ntests/test_dirs.toml:1:failure: test_dirs_root:1g12gg2 (PROG_SIZE=16, ERASE_SIZE=512) failed\ntests/test_dirs.toml:5:assert: assert failed with 0, expected eq 42\n    lfs_mount(&lfs, cfg) => 42;\n```\n\nThis includes the test id, which can be passed to test.py to run only that\nspecific test permutation:\n\n``` bash\n./scripts/test.py runners/test_runner test_dirs_root:1g12gg2  # run a specific test permutation\n./scripts/test.py runners/test_runner test_dirs_root:1g12gg2 --gdb  # drop into gdb on failure\n```\n\nSome other flags that may be useful:\n\n```bash\n./scripts/test.py runners/test_runner -b -j  # run tests in parallel\n./scripts/test.py runners/test_runner -v -O-  # redirect stdout to stdout\n./scripts/test.py runners/test_runner -ddisk  # capture resulting disk image\n```\n\nSee `-h/--help` for a full list of available flags:\n\n``` bash\n./scripts/test.py --help\n```\n\n## License\n\nThe littlefs is provided under the [BSD-3-Clause] license. See\n[LICENSE.md](LICENSE.md) for more information. Contributions to this project\nare accepted under the same license.\n\nIndividual files contain the following tag instead of the full license text.\n\n    SPDX-License-Identifier:    BSD-3-Clause\n\nThis enables machine processing of license information based on the SPDX\nLicense Identifiers that are here available: http://spdx.org/licenses/\n\n## Related projects\n\n- [littlefs-fuse] - A [FUSE] wrapper for littlefs. The project allows you to\n  mount littlefs directly on a Linux machine. Can be useful for debugging\n  littlefs if you have an SD card handy.\n\n- [littlefs-js] - A javascript wrapper for littlefs. I'm not sure why you would\n  want this, but it is handy for demos.  You can see it in action\n  [here][littlefs-js-demo].\n  \n- [littlefs-python] - A Python wrapper for littlefs. The project allows you\n  to create images of the filesystem on your PC. Check if littlefs will fit\n  your needs, create images for a later download to the target memory or\n  inspect the content of a binary image of the target memory.\n\n- [littlefs-toy] - A command-line tool for creating and working with littlefs\n  images. Uses syntax similar to tar command for ease of use. Supports working\n  on littlefs images embedded inside another file (firmware image, etc).\n\n- [littlefs2-rust] - A Rust wrapper for littlefs. This project allows you\n  to use littlefs in a Rust-friendly API, reaping the benefits of Rust's memory\n  safety and other guarantees.\n\n- [nim-littlefs] - A Nim wrapper and API for littlefs. Includes a fuse\n  implementation based on [littlefs-fuse]\n\n- [chamelon] - A pure-OCaml implementation of (most of) littlefs, designed for\n  use with the MirageOS library operating system project. It is interoperable\n  with the reference implementation, with some caveats.\n\n- [littlefs-disk-img-viewer] - A memory-efficient web application for viewing\n  littlefs disk images in your web browser.\n\n- [mklfs] - A command line tool for creating littlefs images. Used in the Lua\n  RTOS ecosystem.\n\n- [mklittlefs] - A command line tool for creating littlefs images. Used in the\n  ESP8266 and RP2040 ecosystem.\n\n- [pico-littlefs-usb] - An interface for littlefs that emulates a FAT12\n  filesystem over USB. Allows mounting littlefs on a host PC without additional\n  drivers.\n\n- [ramcrc32bd] - An example block device using littlefs's 32-bit CRC for\n  error-correction.\n\n- [ramrsbd] - An example block device using Reed-Solomon codes for\n  error-correction.\n\n- [Mbed OS] - The easiest way to get started with littlefs is to jump into Mbed\n  which already has block device drivers for most forms of embedded storage.\n  littlefs is available in Mbed OS as the [LittleFileSystem] class.\n\n- [SPIFFS] - Another excellent embedded filesystem for NOR flash. As a more\n  traditional logging filesystem with full static wear-leveling, SPIFFS will\n  likely outperform littlefs on small memories such as the internal flash on\n  microcontrollers.\n\n- [Dhara] - An interesting NAND flash translation layer designed for small\n  MCUs. It offers static wear-leveling and power-resilience with only a fixed\n  _O(|address|)_ pointer structure stored on each block and in RAM.\n\n- [ChaN's FatFs] - A lightweight reimplementation of the infamous FAT filesystem\n  for microcontroller-scale devices. Due to limitations of FAT it can't provide\n  power-loss resilience, but it does allow easy interop with PCs.\n\n[BSD-3-Clause]: https://spdx.org/licenses/BSD-3-Clause.html\n[littlefs-fuse]: https://github.com/geky/littlefs-fuse\n[FUSE]: https://github.com/libfuse/libfuse\n[littlefs-js]: https://github.com/geky/littlefs-js\n[littlefs-js-demo]:http://littlefs.geky.net/demo.html\n[littlefs-python]: https://pypi.org/project/littlefs-python/\n[littlefs-toy]: https://github.com/tjko/littlefs-toy\n[littlefs2-rust]: https://crates.io/crates/littlefs2\n[nim-littlefs]: https://github.com/Graveflo/nim-littlefs\n[chamelon]: https://github.com/yomimono/chamelon\n[littlefs-disk-img-viewer]: https://github.com/tniessen/littlefs-disk-img-viewer\n[mklfs]: https://github.com/whitecatboard/Lua-RTOS-ESP32/tree/master/components/mklfs/src\n[mklittlefs]: https://github.com/earlephilhower/mklittlefs\n[pico-littlefs-usb]: https://github.com/oyama/pico-littlefs-usb\n[ramcrc32bd]: https://github.com/geky/ramcrc32bd\n[ramrsbd]: https://github.com/geky/ramrsbd\n[Mbed OS]: https://github.com/armmbed/mbed-os\n[LittleFileSystem]: https://os.mbed.com/docs/mbed-os/latest/apis/littlefilesystem.html\n[SPIFFS]: https://github.com/pellepl/spiffs\n[Dhara]: https://github.com/dlbeer/dhara\n[ChaN's FatFs]: http://elm-chan.org/fsw/ff/00index_e.html\n",
      "stars_today": 3
    },
    {
      "id": 681215919,
      "name": "APatch",
      "full_name": "bmax121/APatch",
      "description": "The patching of Android kernel and Android system",
      "html_url": "https://github.com/bmax121/APatch",
      "stars": 6971,
      "forks": 644,
      "language": "Kotlin",
      "topics": [
        "android",
        "inline-hook",
        "kernel",
        "magisk",
        "magisk-module",
        "patch",
        "root"
      ],
      "created_at": "2023-08-21T14:20:01Z",
      "updated_at": "2026-01-24T22:14:08Z",
      "pushed_at": "2026-01-23T19:21:02Z",
      "open_issues": 88,
      "owner": {
        "login": "bmax121",
        "avatar_url": "https://avatars.githubusercontent.com/u/12316019?v=4"
      },
      "readme": "<div align=\"center\">\n<a href=\"https://github.com/bmax121/APatch/releases/latest\"><img src=\"https://images.weserv.nl/?url=https://raw.githubusercontent.com/bmax121/APatch/main/app/src/main/ic_launcher-playstore.png&mask=circle\" style=\"width: 128px;\" alt=\"logo\"></a>\n\n<h1 align=\"center\">APatch</h1>\n\n[![Latest Release](https://img.shields.io/github/v/release/bmax121/APatch?label=Release&logo=github)](https://github.com/bmax121/APatch/releases/latest)\n[![Nightly Release](https://img.shields.io/badge/Nightly%20release-gray?logo=hackthebox&logoColor=fff)](https://nightly.link/bmax121/APatch/workflows/build/main/APatch)\n[![Weblate](https://img.shields.io/badge/Localization-Weblate-teal?logo=weblate)](https://hosted.weblate.org/engage/APatch)\n[![Channel](https://img.shields.io/badge/Follow-Telegram-blue.svg?logo=telegram)](https://t.me/APatchGroup)\n[![GitHub License](https://img.shields.io/github/license/bmax121/APatch?logo=gnu)](/LICENSE)\n\n</div>\n\nThe patching of Android kernel and Android system.\n\n- A new kernel-based root solution for Android devices.\n- APM: Support for modules similar to Magisk.\n- KPM: Support for modules that allow you to inject any code into the kernel (Provides kernel function `inline-hook` and `syscall-table-hook`).\n- APatch relies on [KernelPatch](https://github.com/bmax121/KernelPatch/).\n- The APatch UI and the APModule source code have been derived and modified from [KernelSU](https://github.com/tiann/KernelSU).\n\n[<img src=\"https://fdroid.gitlab.io/artwork/badge/get-it-on.png\"\n     alt=\"Get it on F-Droid\"\n     height=\"80\">](https://f-droid.org/packages/me.bmax.apatch/)\n\nOr download the latest APK from the [Releases Section](https://github.com/bmax121/APatch/releases/latest).\n\n## Supported Versions\n\n- Only supports the ARM64 architecture.\n- Only supports Android kernel versions 3.18 - 6.12\n\nSupport for Samsung devices with security protection: Planned\n\n## Requirement\n\nKernel configs:\n\n- `CONFIG_KALLSYMS=y` and `CONFIG_KALLSYMS_ALL=y`\n\n- `CONFIG_KALLSYMS=y` and `CONFIG_KALLSYMS_ALL=n`: Initial support\n\n## Security Alert\n\nThe **SuperKey** has higher privileges than root access.  \nWeak or compromised keys can lead to unauthorized control of your device.  \nIt is critical to use robust keys and safeguard them from exposure to maintain the security of your device.\n\n## Translation\n\nTo help translate APatch or improve existing translations, please use [Weblate](https://hosted.weblate.org/engage/apatch/). PR of APatch translation is no longer accepted, because it will conflict with Weblate.\n\n<div align=\"center\">\n\n[![Translation Status](https://hosted.weblate.org/widget/APatch/open-graph.png)](https://hosted.weblate.org/engage/APatch/)\n\n</div>\n\n## Get Help\n\n### Usage\n\nFor usage, please refer to [our official documentation](https://apatch.dev).  \nIt's worth noting that the documentation is currently not quite complete, and the content may change at any time.  \nFurthermore, we need more volunteers to [contribute to the documentation](https://github.com/AndroidPatch/APatchDocs) in other languages.\n\n### Updates\n\n- Telegram Channel: [@APatchUpdates](https://t.me/APatchChannel)\n\n### Discussions\n\n- Telegram Group: [@APatchDiscussions(EN/CN)](https://t.me/Apatch_discuss)\n- Telegram Group: [ä¸­æ–‡](https://t.me/APatch_CN_Group)\n\n### More Information\n\n- [Documents](docs/)\n\n## Credits\n\n- [KernelPatch](https://github.com/bmax121/KernelPatch/): The core.\n- [Magisk](https://github.com/topjohnwu/Magisk): magiskboot and magiskpolicy.\n- [KernelSU](https://github.com/tiann/KernelSU): App UI, and Magisk module like support.\n\n## License\n\nAPatch is licensed under the GNU General Public License v3 [GPL-3](http://www.gnu.org/copyleft/gpl.html).\n",
      "stars_today": 3
    },
    {
      "id": 39964628,
      "name": "CANopenNode",
      "full_name": "CANopenNode/CANopenNode",
      "description": "CANopen protocol stack",
      "html_url": "https://github.com/CANopenNode/CANopenNode",
      "stars": 1798,
      "forks": 760,
      "language": "C",
      "topics": [
        "canopen",
        "canopennode",
        "embedded",
        "iot",
        "stack"
      ],
      "created_at": "2015-07-30T17:56:14Z",
      "updated_at": "2026-01-24T14:06:24Z",
      "pushed_at": "2025-11-22T11:40:52Z",
      "open_issues": 93,
      "owner": {
        "login": "CANopenNode",
        "avatar_url": "https://avatars.githubusercontent.com/u/13575344?v=4"
      },
      "readme": "CANopenNode\n===========\n\nCANopenNode is free and open source CANopen protocol stack.\n\nCANopen is the internationally standardized (EN 50325-4) ([CiA301](https://www.can-cia.org/cia-groups/technical-documents)) higher-layer protocol for embedded control system built on top of CAN. For more information on CANopen see http://www.can-cia.org/\n\nCANopenNode is written in ANSI C in object-oriented way. It runs on different microcontrollers, as standalone application or with RTOS.\n\nVariables (communication, device, custom) are collected in CANopen Object Dictionary and are accessible from both: C code and from CANopen network.\n\nCANopenNode homepage is https://github.com/CANopenNode/CANopenNode\n\nThis is version 4 of CANopenNode with new Object Dictionary implementation. For older versions `git checkout` branches `v1.3-master` or `v2.0-master`.\n\n\nCharacteristics\n---------------\n### CANopen\n - [Object Dictionary](https://www.can-cia.org/can-knowledge/canopen-internal-device-architecture/) offers clear and flexible organisation of any variables. Variables can be accessed directly or via read/write functions.\n - [NMT](https://www.can-cia.org/can-knowledge/network-management/) slave to start, stop, reset device. Simple NMT master.\n - [Heartbeat](https://www.can-cia.org/can-knowledge/error-control-protocols) producer/consumer error control for monitoring of CANopen devices. An older alternative, 'node guarding', is also available.\n - [PDO](https://www.can-cia.org/can-knowledge/pdo-protocol/) for broadcasting process data with high priority and no protocol overhead. Variables from Object Dictionary can be dynamically mapped to the TPDO, which is then transmitted according to communication rules and received as RPDO by another device. Bitwise mapping is available.\n - [SDO](https://www.can-cia.org/can-knowledge/sdo-protocol/) server enables expedited, segmented and block transfer access to all Object Dictionary variables inside CANopen device.\n - [SDO](https://www.can-cia.org/can-knowledge/sdo-protocol/) client can access any Object Dictionary variable on any CANopen device inside the network.\n - [Emergency](https://www.can-cia.org/can-knowledge/special-function-protocols/) message producer/consumer.\n - [Sync](https://www.can-cia.org/can-knowledge/special-function-protocols/) producer/consumer enables network synchronized transmission of the PDO objects, etc.\n - [Time-stamp](https://www.can-cia.org/can-knowledge/special-function-protocols/) producer/consumer enables date and time synchronization in millisecond resolution.\n - [LSS](https://www.can-cia.org/can-knowledge/cia-305-layer-setting-services-lss/) CANopen node-id and bitrate setup, master and slave, LSS fastscan.\n - [CANopen gateway](https://www.can-cia.org/can-knowledge/cia-309-series-accessing-canopen-via-tcp/), CiA309-3 Ascii command interface for NMT master, LSS master and SDO client.\n - [CANopen Safety](https://standards.globalspec.com/std/1284438/en-50325-5), EN 50325-5, CiA304, \"PDO like\" communication in safety-relevant networks\n - [CANopen Conformance Test Tool](https://www.can-cia.org/services/canopen-conformance-test-tool/) passed.\n\n### Other\n - [Suitable for 16-bit microcontrollers and above](#device-support)\n - [Multithreaded, real-time](#canopenNode-flowchart)\n - [Object Dictionary editor](#object-dictionary-editor)\n - Non-volatile storage for Object Dictionary or other variables. Automatic or controlled by standard CANopen commands, configurable.\n - [Power saving possible](#power-saving)\n - [Bootloader possible](https://github.com/CANopenNode/CANopenNode/issues/111) (for firmware update)\n\n\nRelated projects\n----------------\n - [CANopenNode](https://github.com/CANopenNode/CANopenNode) (this project): CANopen protocol stack, base for CANopen device. It contains no device specific code (drivers), which must be added separately for each target system. An example shows the basic principles, compiles on any system, but does not connect to any CAN hardware.\n - [CANopenDemo](https://github.com/CANopenNode/CANopenDemo): Demo device with CANopenNode and different target systems, tutorial and testing tools.\n - [CANopenNode.github.io](https://github.com/CANopenNode/CANopenNode.github.io): Html documentation, compiled by doxygen, for CANopenDemo, CANopenNode and other devices, available also online: https://canopennode.github.io\n - [CANopenEditor](https://github.com/CANopenNode/CANopenEditor): Object Dictionary editor, external GUI tool for editing CANopen Object Dictionary for custom device. It generates C source code, electronic data sheet and documentation for the device. It is a fork from [libedssharp](https://github.com/robincornelius/libedssharp).\n - [CANopenLinux](https://github.com/CANopenNode/CANopenLinux): CANopenNode on Linux devices. It can be a basic CANopen device or more advanced with commander functionalities.\n - [CANopenSTM32](https://github.com/CANopenNode/CanOpenSTM32): CANopenNode on STM32 microcontrollers.\n - [Analog Devices Inc.](https://github.com/Analog-Devices-MSDK/CANopenADI): CANopenNode on Analog Devices Inc. MAX32xx microcontrollers.\n - [CANopenPIC](https://github.com/CANopenNode/CANopenPIC): CANopenNode on PIC microcontrollers from Microchip. Works with 16-bit and 32 bit devices. Includes example for Arduino style [Max32](https://reference.digilentinc.com/reference/microprocessor/max32/start) board.\n - [doc/deviceSupport.md](doc/deviceSupport.md): List of other implementations of CANopenNode on different devices.\n\n\nDocumentation, support and contributions\n----------------------------------------\nAll code is documented in the source header files. Some additional documents are in `doc` directory.\n\nTo generate complete html documentation, run [doxygen](https://www.doxygen.nl/index.html) in the project base directory: `sudo apt install doxygen graphviz pdf2svg; doxygen > /dev/null`\n\nComplete generated documentation is also available online: https://canopennode.github.io\n\nTutorial, demo device and tests are available in [CANopenDemo](https://github.com/CANopenNode/CANopenDemo) repository.\n\nReport issues on https://github.com/CANopenNode/CANopenNode/issues\n\nContributions are welcome. Best way to contribute your code is to fork a project, modify it and then send a pull request. Please follow the [Recommended C style and coding rules](https://github.com/MaJerle/c-code-style), use .clang-format file for automatic code formatting.\n\nThe CANopenNode files conform to the [MISRA C:2012](https://www.misra.org.uk) guidelines, with some noted exceptions, as indicated in [MISRA.md](MISRA.md).\n\nCANopenNode flowchart\n---------------------\nFlowchart of a typical CANopenNode implementation:\n~~~\n                            -----------------------\n                           |     Program start     |\n                            -----------------------\n                                       |\n                            -----------------------\n                           |     CANopen init      |\n                            -----------------------\n                                       |\n                            -----------------------\n                           |     Start threads     |\n                            -----------------------\n                                 |     |     |\n             --------------------      |      --------------------\n            |                          |                          |\n ----------------------    ------------------------    -----------------------\n| CAN receive thread   |  | Timer interval thread  |  | Mainline thread       |\n|                      |  |                        |  |                       |\n| - Fast response.     |  | - Realtime thread with |  | - Processing of time  |\n| - Detect CAN ID.     |  |   constant interval,   |  |   consuming tasks     |\n| - Partially process  |  |   typically 1ms.       |  |   in CANopen objects: |\n|   messages and copy  |  | - Network synchronized |  |    - SDO server,      |\n|   data to target     |  | - Copy inputs (RPDOs,  |  |    - Emergency,       |\n|   CANopen objects.   |  |   HW) to Object Dict.  |  |    - Network state,   |\n|                      |  | - May call application |  |    - Heartbeat.       |\n|                      |  |   for some processing. |  |    - LSS slave        |\n|                      |  | - Copy variables from  |  | - Gateway (optional): |\n|                      |  |   Object Dictionary to |  |    - NMT master       |\n|                      |  |   outputs (TPDOs, HW). |  |    - SDO client       |\n|                      |  |                        |  |    - LSS master       |\n|                      |  |                        |  | - May cyclically call |\n|                      |  |                        |  |   application code.   |\n ----------------------    ------------------------    -----------------------\n~~~\n\nAll code of the CANopenNode is non-blocking. Code in source files is collected into objects. Parts of the code can be enabled/disabled, so only files and parts of code can be used, which are required for the project. See stack configuration in 301/CO_config.h file.\n\nFor most efficiency code can run in different thread as seen in above flowchart. This is suitable for microcontrollers. It is also possible to run everything from single thread, as available on Linux devices. Code includes mechanisms, which triggers processing of OD objects when necessary.\n\nIn CANopen initialization section all CANopen objects are initialized. In run time CANopen objects are processed cyclically.\n\nFiles CANopen.h and CANopen.c is a joint of all CANopen objects. It may seems complex, but offers some flexibility and is suitable for most common configurations of the CANopen objects. CANopen objects can be defined in global space or can be dynamically allocated. Object dictionary can be used default (OD.h/.c files), but configuration with multiple object dictionaries is also possible by using the #CO_config_t structure. CANopen.h and CANopen.c files can also be only a reference for more customized implementation of CANopenNode based device.\n\nObject Dictionary is a collection of all network accessible variables and offers most flexible usage. OD variables can be initialized by object dictionary or application can specify own read/write access functions for specific OD variables. Groups of OD variables are also able to be stored to non-volatile memory, either on command or automatically.\n\n\nFile structure\n--------------\n - **301/** - CANopen application layer and communication profile.\n   - **CO_config.h** - Configuration macros for CANopenNode.\n   - **CO_driver.h** - Interface between CAN hardware and CANopenNode.\n   - **CO_ODinterface.h/.c** - CANopen Object Dictionary interface.\n   - **CO_Emergency.h/.c** - CANopen Emergency protocol.\n   - **CO_HBconsumer.h/.c** - CANopen Heartbeat consumer protocol.\n   - **CO_NMT_Heartbeat.h/.c** - CANopen Network management and Heartbeat producer protocol.\n   - **CO_PDO.h/.c** - CANopen Process Data Object protocol.\n   - **CO_SDOclient.h/.c** - CANopen Service Data Object - client protocol (master functionality).\n   - **CO_SDOserver.h/.c** - CANopen Service Data Object - server protocol.\n   - **CO_SYNC.h/.c** - CANopen Synchronisation protocol (producer and consumer).\n   - **CO_TIME.h/.c** - CANopen Time-stamp protocol.\n   - **CO_fifo.h/.c** - Fifo buffer for SDO and gateway data transfer.\n   - **crc16-ccitt.h/.c** - Calculation of CRC 16 CCITT polynomial.\n - **303/** - CANopen Recommendation\n   - **CO_LEDs.h/.c** - CANopen LED Indicators\n - **304/** - CANopen Safety Related Data Object, as specified by EN 50325-5:2010\n   - **CO_SRDO.h/.c** - CANopen Safety-relevant Data Object protocol.\n   - **CO_GFC.h/.c** - CANopen Global Failsafe Command (producer and consumer).\n - **305/** - CANopen layer setting services (LSS) and protocols.\n   - **CO_LSS.h** - CANopen Layer Setting Services protocol (common).\n   - **CO_LSSmaster.h/.c** - CANopen Layer Setting Service - master protocol.\n   - **CO_LSSslave.h/.c** - CANopen Layer Setting Service - slave protocol.\n - **309/** - CANopen access from other networks.\n   - **CO_gateway_ascii.h/.c** - Ascii mapping: NMT master, LSS master, SDO client.\n - **storage/**\n   - **CO_storage.h/.c** - CANopen data storage base object.\n   - **CO_storageEeprom.h/.c** - CANopen data storage object for storing data into block device (eeprom).\n   - **CO_eeprom.h** - Eeprom interface for use with CO_storageEeprom, functions are target system specific.\n - **extra/**\n   - **CO_trace.h/.c** - CANopen trace object for recording variables over time.\n - **example/** - Directory with basic example, should compile on any system.\n   - **CO_driver_target.h** - Example hardware definitions for CANopenNode.\n   - **CO_driver_blank.c** - Example blank interface for CANopenNode.\n   - **main_blank.c** - Mainline and other threads - example template.\n   - **CO_storageBlank.h/.c** - Example blank demonstration for data storage to non-volatile memory.\n   - **Makefile** - Makefile for example.\n   - **DS301_profile.xpd** - CANopen device description file for DS301. It includes also CANopenNode specific properties. This file is also available in Profiles in Object dictionary editor.\n   - **DS301_profile.eds**, **DS301_profile.md** - Standard CANopen EDS file and markdown documentation file, automatically generated from DS301_profile.xpd.\n   - **OD.h/.c** - CANopen Object dictionary source files, automatically generated from DS301_profile.xpd.\n - **doc/** - Directory with documentation\n   - **CHANGELOG.md** - Change Log file.\n   - **deviceSupport.md** - Information about supported devices.\n   - **objectDictionary.md** - Description of CANopen object dictionary interface.\n   - **CANopenNode.png** - Little icon.\n   - **html** - Directory with documentation - must be generated by Doxygen.\n - **CANopen.h/.c** - Initialization and processing of CANopen objects, suitable for common configurations.\n - **Doxyfile** - Configuration file for the documentation generator *doxygen*.\n - **LICENSE** - License.\n - **MISRA.md** - MISRA C:2012 conformance information.\n - **README.md** - This file.\n\n\nObject dictionary editor\n------------------------\nObject Dictionary is one of the most essential parts of CANopen.\n\nTo customize the Object Dictionary it is necessary to use external application: [CANopenEditor](https://github.com/CANopenNode/CANopenEditor). Binaries are also available there. In Linux it runs with mono, which is available by default on Ubuntu.\n\nIn program, in preferences, set exporter to \"CANopenNode_V4\". Then start new project or open the existing project file.\n\nMany project file types are supported, EDS, XDD v1.0, XDD v1.1, old custom XML format. Generated project file can then be saved in XDD v1.1 file format (xmlns=\"http://www.canopen.org/xml/1.1\"). Project file can also be exported to other formats, it can be used to generate documentation and CANopenNode source files for Object Dictionary.\n\nIf new project was started, then `DS301_profile.xpd` may be inserted. If existing (old) project is edited, then existing `Communication Specific Parameters` may be deleted and then new `DS301_profile.xpd` may be inserted. Alternative is editing existing communication parameters with observation to Object Dictionary Requirements By CANopenNode in [objectDictionary.md](doc/objectDictionary.md).\n\nTo clone, add or delete, select object(s) and use right click. Some knowledge of CANopen is required to correctly set-up the custom Object Dictionary. Separate objects can also be inserted from another project.\n\nCANopenNode includes some custom properties inside standard project file. See [objectDictionary.md](doc/objectDictionary.md) for more information.\n\n\nDevice support\n--------------\nCANopenNode can run on many different devices. Each device (or microcontroller) must have own interface to CANopenNode. CANopenNode can run with or without operating system.\n\nIt is not practical to have all device interfaces in a single project. Interfaces to other microcontrollers are in separate projects. See [deviceSupport.md](doc/deviceSupport.md) for list of known device interfaces.\n\n\nSome details\n------------\n### RTR\nRTR (remote transmission request) is a feature of CAN bus. Usage of RTR is not recommended for CANopen. RTR PDO is not implemented in CANopenNode.\n\n### Error control\nWhen node is started (in NMT operational state), it is allowed to send or receive Process Data Objects (PDO). If Error Register (object 0x1001) is set, then NMT operational state may not be allowed.\n\n### Power saving\nAll CANopen objects calculates next timer info for OS. Calculation is based on various timers which expire in known time. Can be used to put microcontroller into sleep and wake at the calculated time.\n\n\nChange Log\n----------\nSee [CHANGELOG.md](doc/CHANGELOG.md)\n\n\nLicense\n-------\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n",
      "stars_today": 3
    },
    {
      "id": 686384682,
      "name": "cs2-dumper",
      "full_name": "a2x/cs2-dumper",
      "description": "Counter-Strike: 2 Offset Dumper",
      "html_url": "https://github.com/a2x/cs2-dumper",
      "stars": 1691,
      "forks": 252,
      "language": "Rust",
      "topics": [],
      "created_at": "2023-09-02T16:00:53Z",
      "updated_at": "2026-01-25T01:24:42Z",
      "pushed_at": "2026-01-24T02:41:08Z",
      "open_issues": 13,
      "owner": {
        "login": "a2x",
        "avatar_url": "https://avatars.githubusercontent.com/u/45197573?v=4"
      },
      "readme": "# cs2-dumper\n\nAn external offset/interface dumper for Counter-Strike 2, with support for both Windows & Linux. Powered\nby [memflow](https://github.com/memflow/memflow).\n\nThe native Linux version is available in the [linux](https://github.com/a2x/cs2-dumper/tree/linux) branch (currently\noutdated).\n\nFor a work-in-progress offline version, check out the [cs2-analyzer](https://github.com/a2x/cs2-analyzer) repository or\nview its included web demo [here](https://a2x.github.io/cs2-analyzer).\n\n## Getting Started\n\nYou can download the latest release from [Releases](https://github.com/a2x/cs2-dumper/releases) or compile it yourself.\nNote that compiling it yourself requires your Rust compiler version to be at least 1.74.0 or newer.\n\n## Usage\n\n1. Ensure the game is running (Being in the main menu should suffice).\n2. Run the `cs2-dumper` executable.\n\n_Note:_ If you run the executable without specifying an optional memflow connector name, it will automatically use the\n[memflow-native](https://github.com/memflow/memflow-native) OS layer to read the memory of the game process. If you\nwish to use an existing memflow connector instead, such as **pcileech** or **kvm**, you can pass the `connector` and\noptional `connector-args` arguments to the program. These connectors can be installed and managed using\nthe [memflowup](https://github.com/memflow/memflowup) tool.\n\nE.g (for pcileech). `cs2-dumper -c pcileech -a :device=FPGA -vv`\n\nCertain connectors, such as the [kvm](https://github.com/memflow/memflow-kvm) connector on Linux or\nthe [pcileech](https://github.com/memflow/memflow-pcileech) / [winio](https://github.com/a2x/memflow-winio)\nconnectors on Windows, require elevated privileges to work. So either run the `cs2-dumper` executable with `sudo` on\nLinux or as an administrator on Windows.\n\n### Available Arguments\n\n- `-c, --connector <connector>`: The name of the memflow connector to use.\n- `-a, --connector-args <connector-args>`: Additional arguments to pass to the memflow connector.\n- `-f, --file-types <file-types>`: The types of files to generate. Default: `cs`, `hpp`,  `json`, `rs`.\n- `-i, --indent-size <indent-size>`: The number of spaces to use per indentation level. Default: `4`.\n- `-o, --output <output>`: The output directory to write the generated files to. Default: `output`.\n- `-p, --process-name <process-name>`: The name of the game process. Default: `cs2.exe`.\n- `-v...`: Increase logging verbosity. Can be specified multiple times.\n- `-h, --help`: Print help.\n- `-V, --version`: Print version.\n\n## Running Tests\n\nTo run the few basic provided tests, use the following command: `cargo test -- --nocapture`.\n\n## License\n\nLicensed under the MIT license ([LICENSE](./LICENSE)).\n",
      "stars_today": 3
    },
    {
      "id": 902097949,
      "name": "sqlite-data",
      "full_name": "pointfreeco/sqlite-data",
      "description": "A fast, lightweight replacement for SwiftData, powered by SQL and supporting CloudKit synchronization.",
      "html_url": "https://github.com/pointfreeco/sqlite-data",
      "stars": 1550,
      "forks": 76,
      "language": "Swift",
      "topics": [
        "cloudkit",
        "database",
        "observation",
        "persistence",
        "sql",
        "sqlite",
        "swiftdata",
        "swiftui",
        "synchronization"
      ],
      "created_at": "2024-12-11T22:44:01Z",
      "updated_at": "2026-01-24T19:16:49Z",
      "pushed_at": "2026-01-24T03:36:28Z",
      "open_issues": 18,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# SQLiteData\n\nA [fast](#Performance), lightweight replacement for SwiftData, powered by SQL and supporting\nCloudKit synchronization.\n\n[![CI](https://github.com/pointfreeco/sqlite-data/actions/workflows/ci.yml/badge.svg)](https://github.com/pointfreeco/sqlite-data/actions/workflows/ci.yml)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](https://www.pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fsqlite-data%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/sqlite-data)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fsqlite-data%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/sqlite-data)\n\n  * [Learn more](#Learn-more)\n  * [Overview](#Overview)\n  * [Quick start](#Quick-start)\n  * [Performance](#Performance)\n  * [SQLite knowledge required](#SQLite-knowledge-required)\n  * [Overview](#Overview)\n  * [Demos](#Demos)\n  * [Documentation](#Documentation)\n  * [Installation](#Installation)\n  * [Community](#Community)\n  * [License](#License)\n\n## Learn more\n\nThis library was motivated and designed over the course of many episodes on\n[Point-Free](https://www.pointfree.co), a video series exploring advanced programming topics in the\nSwift language, hosted by [Brandon Williams](https://twitter.com/mbrandonw) and\n[Stephen Celis](https://twitter.com/stephencelis). To support the continued development of this\nlibrary, [subscribe today](https://www.pointfree.co/pricing).\n\n<a href=\"https://www.pointfree.co/collections/modern-persistence\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0325.jpeg\" width=\"600\">\n</a>\n\n## Overview\n\nSQLiteData is a [fast](#performance), lightweight replacement for SwiftData, including CloudKit\nsynchronization (and even CloudKit sharing), built on top of the popular [GRDB] library.\nTo populate data from the database you can use `@Table` and `@FetchAll`, which are\nsimilar to SwiftData's `@Model` and `@Query`:\n\n<table>\n<tr>\n<th>SQLiteData</th>\n<th>SwiftData</th>\n</tr>\n<tr valign=top>\n<td width=415>\n\n```swift\n@FetchAll\nvar items: [Item]\n\n@Table\nstruct Item {\n  let id: UUID\n  var title = \"\"\n  var isInStock = true\n  var notes = \"\"\n}\n```\n\n</td>\n<td width=415>\n\n```swift\n@Query\nvar items: [Item]\n\n@Model\nclass Item {\n  var title: String\n  var isInStock: Bool\n  var notes: String\n  init(\n    title: String = \"\",\n    isInStock: Bool = true,\n    notes: String = \"\"\n  ) {\n    self.title = title\n    self.isInStock = isInStock\n    self.notes = notes\n  }\n}\n```\n\n</td>\n</tr>\n</table>\n\nBoth of the above examples fetch items from an external data store using Swift data types, and both\nare automatically observed by SwiftUI so that views are recomputed when the external data changes,\nbut SQLiteData is powered directly by SQLite and is usable from UIKit, `@Observable` models, and\nmore.\n\nFor more information on SQLiteData's querying capabilities, see\n[Fetching model data][fetching-article].\n\n## Quick start\n\nBefore SQLiteData's property wrappers can fetch data from SQLite, you need to provideâ€“at\nruntimeâ€“the default database it should use. This is typically done as early as possible in your\napp's lifetime, like the app entry point in SwiftUI, and is analogous to configuring model storage\nin SwiftData:\n\n<table>\n<tr>\n<th>SQLiteData</th>\n<th>SwiftData</th>\n</tr>\n<tr valign=top>\n<td width=415>\n\n```swift\n@main\nstruct MyApp: App {\n  init() {\n    prepareDependencies {\n      let db = try! DatabaseQueue(\n        // Create/migrate a database\n        // connection\n      )\n      $0.defaultDatabase = db\n    }\n  }\n  // ...\n}\n```\n\n</td>\n<td width=415>\n\n```swift\n@main\nstruct MyApp: App {\n  let container = {\n    // Create/configure a container\n    try! ModelContainer(/* ... */)\n  }()\n\n  var body: some Scene {\n    WindowGroup {\n      ContentView()\n        .modelContainer(container)\n    }\n  }\n}\n```\n\n</td>\n</tr>\n</table>\n\n> [!NOTE]\n> For more information on preparing a SQLite database, see\n> [Preparing a SQLite database][preparing-db-article].\n\nThis `defaultDatabase` connection is used implicitly by SQLiteData's strategies, like\n[`@FetchAll`][fetchall-docs] and [`@FetchOne`][fetchone-docs], which are similar to SwiftData's\n`@Query` macro, but more powerful:\n\n<table>\n<tr>\n<th>SQLiteData</th>\n<th>SwiftData</th>\n</tr>\n<tr valign=top>\n<td width=415>\n\n```swift\n@FetchAll\nvar items: [Item]\n\n@FetchAll(Item.order(by: \\.title))\nvar items\n\n@FetchAll(Item.where(\\.isInStock))\nvar items\n\n\n\n@FetchAll(Item.order(by: \\.isInStock))\nvar items\n\n@FetchOne(Item.count())\nvar itemsCount = 0\n\n```\n\n</td>\n<td width=415>\n\n```swift\n@Query\nvar items: [Item]\n\n@Query(sort: [SortDescriptor(\\.title)])\nvar items: [Item]\n\n@Query(filter: #Predicate<Item> {\n  $0.isInStock\n})\nvar items: [Item]\n\n// No @Query equivalent of ordering\n// by boolean column.\n\n// No @Query equivalent of counting\n// entries in database without loading\n// all entries.\n```\n\n</td>\n</tr>\n</table>\n\nAnd you can access this database throughout your application in a way similar to how one accesses\na model context, via a property wrapper:\n\n<table>\n<tr>\n<th>SQLiteData</th>\n<th>SwiftData</th>\n</tr>\n<tr valign=top>\n<td width=415>\n\n```swift\n@Dependency(\\.defaultDatabase)\nvar database\n\nlet newItem = Item(/* ... */)\ntry database.write { db in\n  try Item.insert { newItem }\n    .execute(db))\n}\n```\n\n</td>\n<td width=415>\n\n```swift\n@Environment(\\.modelContext)\nvar modelContext\n\nlet newItem = Item(/* ... */)\nmodelContext.insert(newItem)\ntry modelContext.save()\n\n```\n\n</td>\n</tr>\n</table>\n\n> [!NOTE]\n> For more information on how SQLiteData compares to SwiftData, see\n> [Comparison with SwiftData][comparison-swiftdata-article].\n\nFurther, if you want to synchronize the local database to CloudKit so that it is available on\nall your user's devices, simply configure a `SyncEngine` in the entry point of the app:\n\n```swift\n@main\nstruct MyApp: App {\n  init() {\n    prepareDependencies {\n      $0.defaultDatabase = try! appDatabase()\n      $0.defaultSyncEngine = SyncEngine(\n        for: $0.defaultDatabase,\n        tables: Item.self\n      )\n    }\n  }\n  // ...\n}\n```\n\n> [!NOTE]\n> For more information on synchronizing the database to CloudKit and sharing records with iCloud\n> users, see [CloudKit Synchronization].\n\nThis is all you need to know to get started with SQLiteData, but there's much more to learn. Read\nthe [articles][articles] below to learn how to best utilize this library:\n\n  * [Fetching model data][fetching-article]\n  * [Observing changes to model data][observing-article]\n  * [Preparing a SQLite database][preparing-db-article]\n  * [Dynamic queries][dynamic-queries-article]\n  * [CloudKit Synchronization]\n  * [Comparison with SwiftData][comparison-swiftdata-article]\n\n[observing-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/observing\n[dynamic-queries-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/dynamicqueries\n[articles]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata#Essentials\n[comparison-swiftdata-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/comparisonwithswiftdata\n[fetching-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/fetching\n[preparing-db-article]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/preparingdatabase\n[CloudKit Synchronization]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/cloudkit\n[fetchall-docs]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/fetchall\n[fetchone-docs]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/fetchone\n\n## Performance\n\nSQLiteData leverages high-performance decoding from [StructuredQueries][] to turn fetched data into\nyour Swift domain types, and has a performance profile similar to invoking SQLite's C APIs directly.\n\nSee the following benchmarks against\n[Lighter's performance test suite](https://github.com/Lighter-swift/PerformanceTestSuite) for a\ntaste of how it compares:\n\n```\nOrders.fetchAll                           setup    rampup   duration\n   SQLite (generated by Enlighter 1.4.10) 0        0.144    7.183\n   Lighter (1.4.10)                       0        0.164    8.059\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  SQLiteData (1.0.0)                     0        0.172    8.511  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n   GRDB (7.4.1, manual decoding)          0        0.376    18.819\n   SQLite.swift (0.15.3, manual decoding) 0        0.564    27.994\n   SQLite.swift (0.15.3, Codable)         0        0.863    43.261\n   GRDB (7.4.1, Codable)                  0.002    1.07     53.326\n```\n\n## SQLite knowledge required\n\nSQLite is one of the\n[most established and widely distributed](https://www.sqlite.org/mostdeployed.html) pieces of\nsoftware in the history of software. Knowledge of SQLite is a great skill for any app developer to\nhave, and this library does not want to conceal it from you. So, we feel that to best wield this\nlibrary you should be familiar with the basics of SQLite, including schema design and normalization,\nSQL queries, including joins and aggregates, and performance, including indices.\n\nWith some basic knowledge you can apply this library to your database schema in order to query\nfor data and keep your views up-to-date when data in the database changes, and you can use\n[StructuredQueries][] to build queries, either using its type-safe, discoverable\n[query building APIs][], or using its `#sql` macro for writing [safe SQL strings][].\n\nFurther, this library is built on the popular and battle-tested [GRDB] library for\ninteracting with SQLite, such as executing queries and observing the database for changes.\n\n[StructuredQueries]: https://github.com/pointfreeco/swift-structured-queries\n[GRDB]: https://github.com/groue/GRDB.swift\n[query building APIs]: https://swiftpackageindex.com/pointfreeco/swift-structured-queries/~/documentation/structuredqueriescore\n[safe SQL strings]: https://swiftpackageindex.com/pointfreeco/swift-structured-queries/~/documentation/structuredqueriescore/safesqlstrings\n\n## Demos\n\nThis repo comes with _lots_ of examples to demonstrate how to solve common and complex problems with\nSQLiteData. Check out [this](./Examples) directory to see them all, including:\n\n* [**Case Studies**](./Examples/CaseStudies)\n  <br> Demonstrates how to solve some common application problems in an isolated environment, in\n  both SwiftUI and UIKit. Things like animations, dynamic queries, database transactions, and more.\n\n* [**CloudKitDemo**](./Examples/CloudKitDemo)\n  <br> A simplified demo that shows how to synchronize a SQLite database to CloudKit and how to\n  share records with other iCloud users. See our dedicated articles on [CloudKit Synchronization]\n  and [CloudKit Sharing] for more information.\n\n  [CloudKit Synchronization]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/cloudkit\n  [CloudKit Sharing]: https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/cloudkitsharing\n\n* [**Reminders**](./Examples/Reminders)\n  <br> A rebuild of Apple's [Reminders][reminders-app-store] app that uses a SQLite database to\n  model the reminders, lists and tags. It features many advanced queries, such as searching, stats\n  aggregation, and multi-table joins. It also features CloudKit synchronization and sharing.\n\n* [**SyncUps**](./Examples/SyncUps)\n  <br> This application is a faithful reconstruction of one of Apple's more interesting sample\n  projects, called [Scrumdinger][scrumdinger], and uses SQLite to persist the data for meetings.\n  We have also added CloudKit synchronization so that all changes are automatically made available\n  on all of the user's devices.\n\n[Scrumdinger]: https://developer.apple.com/tutorials/app-dev-training/getting-started-with-scrumdinger\n[reminders-app-store]: https://apps.apple.com/us/app/reminders/id1108187841\n\n## Documentation\n\nThe documentation for releases and `main` are available here:\n\n  * [`main`](https://swiftpackageindex.com/pointfreeco/sqlite-data/main/documentation/sqlitedata/)\n  * [1.x.x](https://swiftpackageindex.com/pointfreeco/sqlite-data/~/documentation/sqlitedata/)\n\n## Installation\n\nYou can add SQLiteData to an Xcode project by adding it to your project as a packageâ€¦\n\n> https://github.com/pointfreeco/sqlite-data\n\nâ€¦and adding the `SQLiteData` product to your target.\n\nIf you want to use SQLiteData in a [SwiftPM](https://swift.org/package-manager/) project, it's as\nsimple as adding it to your `Package.swift`:\n\n``` swift\ndependencies: [\n  .package(url: \"https://github.com/pointfreeco/sqlite-data\", from: \"1.0.0\")\n]\n```\n\nAnd then adding the following product to any target that needs access to the library:\n\n```swift\n.product(name: \"SQLiteData\", package: \"sqlite-data\"),\n```\n\n## Community\n\nIf you want to discuss this library or have a question about how to use it to solve a particular\nproblem, there are a number of places you can discuss with fellow\n[Point-Free](http://www.pointfree.co) enthusiasts:\n\n  * For long-form discussions, we recommend the\n    [discussions](http://github.com/pointfreeco/sqlite-data/discussions) tab of this repo.\n\n  * For casual chat, we recommend the\n    [Point-Free Community Slack](http://www.pointfree.co/slack-invite).\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n",
      "stars_today": 3
    },
    {
      "id": 3432266,
      "name": "kotlin",
      "full_name": "JetBrains/kotlin",
      "description": "The Kotlin Programming Language. ",
      "html_url": "https://github.com/JetBrains/kotlin",
      "stars": 52212,
      "forks": 6189,
      "language": "Kotlin",
      "topics": [
        "compiler",
        "gradle-plugin",
        "intellij-plugin",
        "kotlin",
        "kotlin-library",
        "maven-plugin",
        "programming-language",
        "wasm",
        "webassembly"
      ],
      "created_at": "2012-02-13T17:29:58Z",
      "updated_at": "2026-01-25T02:13:07Z",
      "pushed_at": "2026-01-25T01:06:08Z",
      "open_issues": 211,
      "owner": {
        "login": "JetBrains",
        "avatar_url": "https://avatars.githubusercontent.com/u/878437?v=4"
      },
      "readme": "[![official project](https://jb.gg/badges/official.svg)](https://confluence.jetbrains.com/display/ALL/JetBrains+on+GitHub)\n[![TeamCity (simple build status)](https://img.shields.io/teamcity/http/teamcity.jetbrains.com/s/Kotlin_KotlinPublic_Compiler.svg)](https://teamcity.jetbrains.com/buildConfiguration/Kotlin_KotlinPublic_Compiler?branch=%3Cdefault%3E&buildTypeTab=overview&mode=builds)\n[![Maven Central](https://img.shields.io/maven-central/v/org.jetbrains.kotlin/kotlin-maven-plugin.svg)](https://search.maven.org/#search%7Cga%7C1%7Cg%3A%22org.jetbrains.kotlin%22)\n[![GitHub license](https://img.shields.io/badge/license-Apache%20License%202.0-blue.svg?style=flat)](https://www.apache.org/licenses/LICENSE-2.0)\n[![Revved up by Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A)](https://ge.jetbrains.com/scans?search.rootProjectNames=Kotlin)\n\n# Kotlin Programming Language\n\nWelcome to [Kotlin](https://kotlinlang.org/)!   \nKotlin is a concise multiplatform language developed by [JetBrains](https://www.jetbrains.com/) and [contributors](https://kotlinlang.org/docs/contribute.html).\n\nSome handy links:\n\n * [Kotlin Site](https://kotlinlang.org/)\n * [Getting Started Guide](https://kotlinlang.org/docs/tutorials/getting-started.html)\n * [Try Kotlin](https://play.kotlinlang.org/)\n * [Kotlin Standard Library](https://kotlinlang.org/api/latest/jvm/stdlib/index.html)\n * [Issue Tracker](https://youtrack.jetbrains.com/issues/KT)\n * [Kotlin YouTube Channel](https://www.youtube.com/channel/UCP7uiEZIqci43m22KDl0sNw)\n * [Forum](https://discuss.kotlinlang.org/)\n * [Kotlin Blog](https://blog.jetbrains.com/kotlin/)\n * [Subscribe to Kotlin YouTube channel](https://www.youtube.com/channel/UCP7uiEZIqci43m22KDl0sNw)\n * [Follow Kotlin on Twitter](https://twitter.com/kotlin)\n * [Public Slack channel](https://slack.kotlinlang.org/)\n * [TeamCity CI build](https://teamcity.jetbrains.com/project.html?tab=projectOverview&projectId=Kotlin)\n * [Kotlin Foundation](https://kotlinfoundation.org/)\n\n## Kotlin Multiplatform capabilities\n\nSupport for multiplatform programming is one of Kotlinâ€™s key benefits. It reduces time spent writing and maintaining the same code for [different platforms](https://kotlinlang.org/docs/reference/mpp-supported-platforms.html) while retaining the flexibility and benefits of native programming.\n\n * [Kotlin Multiplatform](https://www.jetbrains.com/kotlin-multiplatform/) and [Compose Multiplatform](https://www.jetbrains.com/compose-multiplatform/) for sharing business logic and UI between Android, iOS, desktop, and web.\n * [Get started with Kotlin Multiplatform](https://www.jetbrains.com/help/kotlin-multiplatform-dev/get-started.html)\n * [Kotlin Multiplatform Benefits](https://kotlinlang.org/docs/reference/multiplatform.html)\n * [Share code on all platforms](https://kotlinlang.org/docs/reference/mpp-share-on-platforms.html#share-code-on-all-platforms)\n * [Share code on similar platforms](https://kotlinlang.org/docs/reference/mpp-share-on-platforms.html#share-code-on-similar-platforms)\n\n## Editing Kotlin\n\n * [Kotlin IntelliJ IDEA Plugin](https://kotlinlang.org/docs/tutorials/getting-started.html) ([source code](https://github.com/JetBrains/intellij-community/tree/master/plugins/kotlin))\n * [Kotlin Eclipse Plugin](https://kotlinlang.org/docs/tutorials/getting-started-eclipse.html)\n * [Kotlin Sublime Text Package](https://github.com/vkostyukov/kotlin-sublime-package)\n\n## Build environment requirements\n\nThis repository is using [Gradle toolchains](https://docs.gradle.org/current/userguide/toolchains.html) feature\nto select and auto-provision required JDKs from [Eclipse Adoptium](https://adoptium.net) project.\n\nAlternatively, it is still possible to only provide required JDKs via environment variables \n(see [gradle.properties](./gradle.properties#L5) for supported variable names). To ensure Gradle uses only JDKs \nfrom environmental variables - disable Gradle toolchain auto-detection by passing `-Porg.gradle.java.installations.auto-detect=false` option\n(or put it into `$GRADLE_USER_HOME/gradle.properties`).\n\nOn Windows you might need to add long paths setting to the repo:\n\n    git config core.longpaths true \n\n## Building\n\nThe project is built with Gradle. Run Gradle to build the project and to run the tests \nusing the following command on Unix/macOS:\n\n    ./gradlew <tasks-and-options>\n    \nor the following command on Windows:\n\n    gradlew <tasks-and-options>\n\nOn the first project configuration gradle will download and setup the dependencies on:\n\n* `intellij-core` is a part of command line compiler and contains only necessary APIs.\n* `idea-full` is a full blown IntelliJ IDEA Community Edition to be used in the plugin module.\n\nThese dependencies are quite large, so depending on the quality of your internet connection \nyou might face timeouts getting them. In this case, you can increase timeout by specifying the following \ncommand line parameters on the first run: \n    \n    ./gradlew -Dhttp.socketTimeout=60000 -Dhttp.connectionTimeout=60000\n\n## Important gradle tasks\n\n- `clean` - clean build results\n- `dist` - assembles the compiler distribution into `dist/kotlinc/` folder\n- `install` - build and install all public artifacts into local maven repository\n- `coreLibsTest` - build and run stdlib, reflect and kotlin-test tests\n- `gradlePluginTest` - build and run gradle plugin tests\n- `compilerTest` - build and run all compiler tests\n\nTo reproduce TeamCity build use `-Pteamcity=true` flag. Local builds don't run proguard and have jar compression disabled by default.\n\n**OPTIONAL:** Some artifacts, mainly Maven plugin ones, are built separately with Maven.\nRefer to [libraries/ReadMe.md](libraries/ReadMe.md) for details.\n\nTo build Kotlin/Native, see\n[kotlin-native/README.md](kotlin-native/README.md#building-from-source).\n\n## <a name=\"working-in-idea\"></a> Working with the project in IntelliJ IDEA\n\nIt is recommended to use the latest released version of Intellij IDEA (Community or Ultimate Edition). You can download IntelliJ IDEA [here](https://www.jetbrains.com/idea/download).\n\nAfter cloning the project, import the project in IntelliJ by choosing the project directory in the Open project dialog.\n\nFor handy work with compiler tests it's recommended to use [Kotlin Compiler Test Helper](https://github.com/demiurg906/test-data-helper-plugin).\n\n### Dependency verification\n\nWe have a [dependencies verification](https://docs.gradle.org/current/userguide/dependency_verification.html) feature enabled in the\nrepository for all Gradle builds. Gradle will check hashes (md5 and sha256) of used dependencies and will fail builds with\n`Dependency verification failed` errors when local artifacts are absent or have different hashes listed in the\n[verification-metadata.xml](https://github.com/JetBrains/kotlin/blob/master/gradle/verification-metadata.xml) file.\n\nIt's expected that `verification-metadata.xml` should only be updated with the commits that modify the build. There are some tips how\nto perform such updates:\n\n- Delete `components` section of `verification-metadata.xml` to avoid stockpiling of old unused dependencies. You may use the following command:\n```bash\n#macOS\nsed -i '' -e '/<components>/,/<\\/components>/d' gradle/verification-metadata.xml\n#Linux & Git for Windows\nsed -i -e '/<components>/,/<\\/components>/d' gradle/verification-metadata.xml\n```\n- Re-generate dependencies with Gradle's `--write-verification-metadata` command (verify update relates to your changes)\n\n```bash\n./gradlew --write-verification-metadata sha256,md5 -Pkotlin.native.enabled=true resolveDependencies\n```\n\n*`resolveDependencies` task resolves dependencies for all platforms including dependencies downloaded by plugins.*\n\nYou can also use `./scripts/update-verification-metadata.sh` script which includes both of these steps\n\nKeep in mind:\n\n- If youâ€™re adding a dependency with OS mentioned in an artifact name (`darwin`, `mac`, `osx`, `linux`, `windows`), remember to add them to \n  `implicitDependencies` configuration or update `resolveDependencies` task if needed. `resolveDependencies` should resolve all dependencies\n  including dependencies for different platforms.\n- If you have a `local.properties` file in your Kotlin project folder, make sure that it doesn't contain `kotlin.native.enabled=false`.\n  Otherwise, native-only dependencies may not be added to the verification metadata. This is because `local.properties` has higher \n  precedence than the `-Pkotlin.native.enabled=true` specified in the Gradle command.\n\n## Using -dev versions\n\nWe publish `-dev` versions frequently.\n\nFor `-dev` versions you can use the [list of available versions](https://redirector.kotlinlang.org/maven/bootstrap/org/jetbrains/kotlin/kotlin-compiler/maven-metadata.xml) and include this maven repository:\n\n```kotlin\nmaven(\"https://redirector.kotlinlang.org/maven/bootstrap\")\n```\n\n# License\nKotlin is distributed under the terms of the Apache License (Version 2.0). See [license folder](license/README.md) for details.\n\n# Contributing\n\nPlease be sure to review Kotlin's [contributing guidelines](docs/contributing.md) to learn how to help the project.\n\n# Kotlin Foundation\n\nThe Kotlin Foundation is a non-profit organization whose mission is to promote and advance the Kotlin ecosystem. You can learn more about the structure and goals of the Kotlin Foundation on its [official website](https://kotlinfoundation.org/).\n",
      "stars_today": 2
    },
    {
      "id": 149121954,
      "name": "jdk",
      "full_name": "openjdk/jdk",
      "description": "JDK main-line development https://openjdk.org/projects/jdk",
      "html_url": "https://github.com/openjdk/jdk",
      "stars": 22399,
      "forks": 6232,
      "language": "Java",
      "topics": [
        "java",
        "jvm",
        "openjdk"
      ],
      "created_at": "2018-09-17T12:29:20Z",
      "updated_at": "2026-01-25T01:08:44Z",
      "pushed_at": "2026-01-25T01:24:39Z",
      "open_issues": 406,
      "owner": {
        "login": "openjdk",
        "avatar_url": "https://avatars.githubusercontent.com/u/41768318?v=4"
      },
      "readme": "# Welcome to the JDK!\n\nFor build instructions please see the\n[online documentation](https://git.openjdk.org/jdk/blob/master/doc/building.md),\nor either of these files:\n\n- [doc/building.html](doc/building.html) (html version)\n- [doc/building.md](doc/building.md) (markdown version)\n\nSee <https://openjdk.org/> for more information about the OpenJDK\nCommunity and the JDK and see <https://bugs.openjdk.org> for JDK issue\ntracking.\n",
      "stars_today": 2
    },
    {
      "id": 20773773,
      "name": "bazel",
      "full_name": "bazelbuild/bazel",
      "description": "a fast, scalable, multi-language and extensible build system",
      "html_url": "https://github.com/bazelbuild/bazel",
      "stars": 25026,
      "forks": 4394,
      "language": "Java",
      "topics": [
        "bazel",
        "build",
        "build-system",
        "correct",
        "fast",
        "multi-language",
        "scalable",
        "test"
      ],
      "created_at": "2014-06-12T16:00:38Z",
      "updated_at": "2026-01-24T18:07:02Z",
      "pushed_at": "2026-01-24T04:02:21Z",
      "open_issues": 1838,
      "owner": {
        "login": "bazelbuild",
        "avatar_url": "https://avatars.githubusercontent.com/u/11684617?v=4"
      },
      "readme": "# [Bazel](https://bazel.build)\n\n*{Fast, Correct} - Choose two*\n\nBuild and test software of any size, quickly and reliably.\n\n* **Speed up your builds and tests**:\n  Bazel rebuilds only what is necessary.\n  With advanced local and distributed caching, optimized dependency analysis and\n  parallel execution, you get fast and incremental builds.\n\n* **One tool, multiple languages**: Build and test Java, C++, Android, iOS, Go,\n  and a wide variety of other language platforms. Bazel runs on Windows, macOS,\n  and Linux.\n\n* **Scalable**: Bazel helps you scale your organization, codebase, and\n  continuous integration solution. It handles codebases of any size, in multiple\n  repositories or a huge monorepo.\n\n* **Extensible to your needs**: Easily add support for new languages and\n  platforms with Bazel's familiar extension language. Share and re-use language\n  rules written by the growing Bazel community.\n\n## Getting Started\n\n  * [Install Bazel](https://bazel.build/install)\n  * [Get started with Bazel](https://bazel.build/start)\n  * Follow our tutorials:\n\n    - [Build C++](https://bazel.build/tutorials/cpp)\n    - [Build Java](https://bazel.build/tutorials/java)\n    - [Android](https://bazel.build/tutorials/android-app)\n    - [iOS](https://github.com/bazelbuild/rules_apple/blob/master/doc/tutorials/ios-app.md)\n\n## Documentation\n\n  * [Bazel command line](https://bazel.build/docs/user-manual)\n  * [Rule reference](https://bazel.build/reference/be/overview)\n  * [Use the query command](https://bazel.build/reference/query)\n  * [Extend Bazel](https://bazel.build/rules/concepts)\n  * [Write tests](https://bazel.build/reference/test-encyclopedia)\n  * [Roadmap](https://bazel.build/community/roadmaps)\n  * [Who is using Bazel?](https://bazel.build/community/users)\n\n## Reporting a Vulnerability\n\nTo report a security issue, please email security@bazel.build with a description\nof the issue, the steps you took to create the issue, affected versions, and, if\nknown, mitigations for the issue. Our vulnerability management team will respond\nwithin 3 working days of your email. If the issue is confirmed as a\nvulnerability, we will open a Security Advisory. This project follows a 90 day\ndisclosure timeline.\n\n## Contributing to Bazel\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md)\n\n[![Build status](https://badge.buildkite.com/1fd282f8ad98c3fb10758a821e5313576356709dd7d11e9618.svg?status=master)](https://buildkite.com/bazel/bazel-bazel)\n",
      "stars_today": 2
    },
    {
      "id": 49910095,
      "name": "vapor",
      "full_name": "vapor/vapor",
      "description": "ğŸ’§ A server-side Swift HTTP web framework.",
      "html_url": "https://github.com/vapor/vapor",
      "stars": 25921,
      "forks": 1522,
      "language": "Swift",
      "topics": [
        "framework",
        "http",
        "http2",
        "server",
        "server-side-swift",
        "swift",
        "vapor",
        "web-framework"
      ],
      "created_at": "2016-01-18T22:37:52Z",
      "updated_at": "2026-01-24T22:35:21Z",
      "pushed_at": "2026-01-22T17:44:23Z",
      "open_issues": 112,
      "owner": {
        "login": "vapor",
        "avatar_url": "https://avatars.githubusercontent.com/u/17364220?v=4"
      },
      "readme": "<a href=\"https://discord.gg/vapor\">\n\n![Vapor](https://user-images.githubusercontent.com/1342803/75634175-4876d680-5bd9-11ea-90d6-12c7b6a9ee3f.png)\n\n</a>\n\n<p align=\"center\">\n    <a href=\"https://docs.vapor.codes/4.0/\">\n        <img src=\"https://design.vapor.codes/images/readthedocs.svg\" alt=\"Documentation\">\n    </a>\n    <a href=\"https://discord.gg/vapor\">\n        <img src=\"https://design.vapor.codes/images/discordchat.svg\" alt=\"Team Chat\">\n    </a>\n    <a href=\"LICENSE\">\n        <img src=\"https://design.vapor.codes/images/mitlicense.svg\" alt=\"MIT License\">\n    </a>\n    <a href=\"https://github.com/vapor/vapor/actions/workflows/test.yml\">\n        <img src=\"https://img.shields.io/github/actions/workflow/status/vapor/vapor/test.yml?event=push&style=plastic&logo=github&label=tests&logoColor=%23ccc\" alt=\"Continuous Integration\">\n    </a>\n    <a href=\"https://codecov.io/gh/vapor/vapor\">\n        <img src=\"https://img.shields.io/codecov/c/github/vapor/vapor?style=plastic&logo=codecov&label=codecov\" alt=\"Code Coverage\">\n    </a>\n    <a href=\"https://swift.org\">\n        <img src=\"https://design.vapor.codes/images/swift60up.svg\" alt=\"Swift 6.0+\">\n    </a>\n    <a href=\"https://hachyderm.io/@codevapor\">\n        <img src=\"https://img.shields.io/badge/%20-@codevapor-6364f6.svg?style=plastic&logo=mastodon&labelColor=gray&logoColor=%239394ff\" alt=\"Mastodon\">\n    </a>\n</p>\n\n<br>\n\nVapor is an HTTP web framework for Swift. It provides a beautifully expressive and easy-to-use foundation for your next website, API, or cloud project.\n\nTake a look at some of the [awesome stuff](https://github.com/vapor-community/awesome-vapor) created with Vapor.\n\n### ğŸ’§ Community\n\nJoin the welcoming community of fellow Vapor developers on [Discord](https://vapor.team).\n\n### ğŸš€ Contributing\n\nTo contribute a **feature or idea** to Vapor, [create an issue](https://github.com/vapor/vapor/issues/new) explaining your idea or bring it up on [Discord](https://vapor.team).\n\nIf you find a **bug**, please [create an issue](https://github.com/vapor/vapor/issues/new). \n\nIf you find a **security vulnerability**, please contact [security@vapor.codes](mailto:security@vapor.codes) as soon as possible.\n\n### ğŸ’› Sponsors\n\nSupport Vapor's development by [becoming a sponsor](https://github.com/sponsors/vapor).\n\n<a href=\"https://www.brokenhands.io\">\n    <img src=\"https://user-images.githubusercontent.com/9938337/137103192-21f99099-6aaa-4cc1-a1a7-21ee767a72d1.png\" height=\"100px\" alt=\"Broken Hands\">\n</a>\n<a href=\"https://www.emergetools.com\">\n    <img src=\"https://user-images.githubusercontent.com/9938337/265658253-cb37d2fa-3251-497f-8eeb-ba7c95af373b.svg\" height=\"100px\" alt=\"Emerge Tools\">\n</a>\n<a href=\"https://github.com/MrLotU\">\n    <img src=\"https://user-images.githubusercontent.com/1342803/79599312-426a8580-80b3-11ea-89b3-8b2722485e37.png\" height=\"100px\" alt=\"Jari\">\n</a>\n<a href=\"https://github.com/DonutDane\">\n    <img src=\"https://user-images.githubusercontent.com/9938337/265657642-6b6b1705-9611-4547-8e2f-a3773fda87c6.png\" height=\"100px\" alt=\"Donut Dane\">\n</a>\n<a href=\"https://macstadium.com\">\n    <img src=\"https://uploads-ssl.webflow.com/5ac3c046c82724970fc60918/5c019d917bba312af7553b49_MacStadium-developerlogo.png\" height=\"100px\" alt=\"MacStadium\">\n</a>\n\n\n\n### ğŸ’š Backers\nSupport Vapor's development by [becoming a backer](https://github.com/sponsors/vapor).\n\n<!-- backers --><a href=\"https://github.com/slashmo\"><img src=\"https://github.com/slashmo.png\" width=\"60px\" alt=\"Moritz Lang\" /></a><a href=\"https://github.com/maartene\"><img src=\"https://github.com/maartene.png\" width=\"60px\" alt=\"Maarten Engels\" /></a><a href=\"https://github.com/tkrajacic\"><img src=\"https://github.com/tkrajacic.png\" width=\"60px\" alt=\"Thomas Krajacic\" /></a><a href=\"https://github.com/jessetipton\"><img src=\"https://github.com/jessetipton.png\" width=\"60px\" alt=\"Jesse Tipton\" /></a><a href=\"https://github.com/steve-h\"><img src=\"https://github.com/steve-h.png\" width=\"60px\" alt=\"Steve Hume\" /></a><a href=\"https://github.com/mikkelu\"><img src=\"https://github.com/mikkelu.png\" width=\"60px\" alt=\"Mikkel Ulstrup\" /></a><a href=\"https://github.com/g-Off\"><img src=\"https://github.com/g-Off.png\" width=\"60px\" alt=\"Geoffrey Foster\" /></a><a href=\"https://github.com/PSchmiedmayer\"><img src=\"https://github.com/PSchmiedmayer.png\" width=\"60px\" alt=\"Paul Schmiedmayer\" /></a><a href=\"https://github.com/ScottRobbins\"><img src=\"https://github.com/ScottRobbins.png\" width=\"60px\" alt=\"Scott Robbins\" /></a><a href=\"https://github.com/finestructure\"><img src=\"https://github.com/finestructure.png\" width=\"60px\" alt=\"Sven A. Schmidt\" /></a><a href=\"https://github.com/SpencerCurtis\"><img src=\"https://github.com/SpencerCurtis.png\" width=\"60px\" alt=\"Spencer Curtis\" /></a><a href=\"https://github.com/rausnitz\"><img src=\"https://github.com/rausnitz.png\" width=\"60px\" alt=\"Zach Rausnitz\" /></a><a href=\"https://github.com/masterofinsanity\"><img src=\"https://github.com/masterofinsanity.png\" width=\"60px\" alt=\"Tim â€Timinatorâ€œ Kretzschmar\" /></a><a href=\"https://github.com/klaas\"><img src=\"https://github.com/klaas.png\" width=\"60px\" alt=\"Klaas\" /></a><a href=\"https://github.com/Andrewangeta\"><img src=\"https://github.com/Andrewangeta.png\" width=\"60px\" alt=\"Andrew Edwards\" /></a><a href=\"https://github.com/addli\"><img src=\"https://github.com/addli.png\" width=\"60px\" alt=\"+Li, Inc.\" /></a><a href=\"https://github.com/doozMen\"><img src=\"https://github.com/doozMen.png\" width=\"60px\" alt=\"Stijn Willems\" /></a><a href=\"https://github.com/bitwit\"><img src=\"https://github.com/bitwit.png\" width=\"60px\" alt=\"Kyle Newsome\" /></a><a href=\"https://github.com/viaaurelia\"><img src=\"https://github.com/viaaurelia.png\" width=\"60px\" alt=\"Via Aurelia Solutions\" /></a><a href=\"https://github.com/kkiermasz\"><img src=\"https://github.com/kkiermasz.png\" width=\"60px\" alt=\"Jakub Kiermasz\" /></a><a href=\"https://github.com/bdrelling\"><img src=\"https://github.com/bdrelling.png\" width=\"60px\" alt=\"Brian Drelling\" /></a><a href=\"https://github.com/mayondigital\"><img src=\"https://github.com/mayondigital.png\" width=\"60px\" alt=\"\" /></a><a href=\"https://github.com/mattesmohr\"><img src=\"https://github.com/mattesmohr.png\" width=\"60px\" alt=\"Mattes Mohr\" /></a><a href=\"https://github.com/scibidoo\"><img src=\"https://github.com/scibidoo.png\" width=\"60px\" alt=\"Jamie\" /></a><a href=\"https://github.com/GalenRhodes\"><img src=\"https://github.com/GalenRhodes.png\" width=\"60px\" alt=\"Galen Rhodes\" /></a><a href=\"https://github.com/litmaps\"><img src=\"https://github.com/litmaps.png\" width=\"60px\" alt=\"Litmaps\" /></a><a href=\"https://github.com/davdroman\"><img src=\"https://github.com/davdroman.png\" width=\"60px\" alt=\"David Roman\" /></a><a href=\"https://github.com/Strobocop\"><img src=\"https://github.com/Strobocop.png\" width=\"60px\" alt=\"Brian Strobach\" /></a><a href=\"https://github.com/kishikawakatsumi\"><img src=\"https://github.com/kishikawakatsumi.png\" width=\"60px\" alt=\"Kishikawa Katsumi\" /></a><a href=\"https://github.com/mkll\"><img src=\"https://github.com/mkll.png\" width=\"60px\" alt=\"Alex Sherbakov\" /></a><a href=\"https://github.com/getsidetrack\"><img src=\"https://github.com/getsidetrack.png\" width=\"60px\" alt=\"Sidetrack\" /></a><a href=\"https://github.com/GregKarpati\"><img src=\"https://github.com/GregKarpati.png\" width=\"60px\" alt=\"Greg Karpati\" /></a><a href=\"https://github.com/fananek\"><img src=\"https://github.com/fananek.png\" width=\"60px\" alt=\"FrantiÅ¡ek MikÅ¡\" /></a><a href=\"https://github.com/jagreenwood\"><img src=\"https://github.com/jagreenwood.png\" width=\"60px\" alt=\"Jeremy Greenwood\" /></a><a href=\"https://github.com/rayfix\"><img src=\"https://github.com/rayfix.png\" width=\"60px\" alt=\"Ray Fix\" /></a><a href=\"https://github.com/micomiloloza\"><img src=\"https://github.com/micomiloloza.png\" width=\"60px\" alt=\"MiÄ‡o MiloloÅ¾a\" /></a><a href=\"https://github.com/awamser\"><img src=\"https://github.com/awamser.png\" width=\"60px\" alt=\"Alan\" /></a><a href=\"https://github.com/Suboptimierer\"><img src=\"https://github.com/Suboptimierer.png\" width=\"60px\" alt=\"Jonas Sannewald\" /></a><a href=\"https://github.com/TapEnvy-us-LLC\"><img src=\"https://github.com/TapEnvy-us-LLC.png\" width=\"60px\" alt=\"TapEnvy.us, LLC\" /></a><a href=\"https://github.com/JawadHF\"><img src=\"https://github.com/JawadHF.png\" width=\"60px\" alt=\"Jawad\" /></a><a href=\"https://github.com/PARAIPAN9\"><img src=\"https://github.com/PARAIPAN9.png\" width=\"60px\" alt=\"PARAIPAN SORIN\" /></a><a href=\"https://github.com/KalynDavis\"><img src=\"https://github.com/KalynDavis.png\" width=\"60px\" alt=\"Kalyn Davis\" /></a><a href=\"https://github.com/stevapple\"><img src=\"https://github.com/stevapple.png\" width=\"60px\" alt=\"YR Chen\" /></a><a href=\"https://github.com/roncuevas\"><img src=\"https://github.com/roncuevas.png\" width=\"60px\" alt=\"AarÃ³n MartÃ­nez Cuevas\" /></a><!-- backers -->\n\n<a href=\"https://opencollective.com/vapor/backer/0/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/1/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/2/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/3/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/4/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/5/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/6/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/7/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/8/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/9/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/9/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/10/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/10/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/11/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/11/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/12/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/12/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/13/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/13/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/14/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/14/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/15/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/15/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/16/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/16/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/17/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/17/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/18/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/18/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/19/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/19/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/20/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/20/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/21/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/21/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/22/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/22/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/23/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/23/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/24/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/24/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/25/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/25/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/26/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/26/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/27/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/27/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/28/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/28/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/29/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/29/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/30/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/30/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/31/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/31/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/32/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/32/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/33/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/33/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/34/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/34/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/35/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/35/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/36/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/36/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/37/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/37/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/38/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/38/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/39/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/39/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/40/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/40/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/41/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/41/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/42/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/42/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/43/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/43/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/44/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/44/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/45/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/45/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/46/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/46/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/47/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/47/avatar.svg\"></a>\n<a href=\"https://opencollective.com/vapor/backer/48/website\" target=\"_blank\"><img src=\"https://opencollective.com/vapor/backer/48/avatar.svg\"></a>\n",
      "stars_today": 2
    },
    {
      "id": 27911088,
      "name": "nifi",
      "full_name": "apache/nifi",
      "description": "Apache NiFi",
      "html_url": "https://github.com/apache/nifi",
      "stars": 5930,
      "forks": 2926,
      "language": "Java",
      "topics": [
        "apache",
        "hacktoberfest",
        "java",
        "nifi"
      ],
      "created_at": "2014-12-12T08:00:05Z",
      "updated_at": "2026-01-24T17:04:32Z",
      "pushed_at": "2026-01-23T21:55:05Z",
      "open_issues": 26,
      "owner": {
        "login": "apache",
        "avatar_url": "https://avatars.githubusercontent.com/u/47359?v=4"
      },
      "readme": "<!--\n  Licensed to the Apache Software Foundation (ASF) under one or more\n  contributor license agreements.  See the NOTICE file distributed with\n  this work for additional information regarding copyright ownership.\n  The ASF licenses this file to You under the Apache License, Version 2.0\n  (the \"License\"); you may not use this file except in compliance with\n  the License.  You may obtain a copy of the License at\n      http://www.apache.org/licenses/LICENSE-2.0\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License.\n-->\n\n# Apache NiFi\n\n<img src=\"https://nifi.apache.org/images/apache-nifi-logo.svg\" width=\"300\" alt=\"Apache NiFi\"/>\n\n### Status\n\n[![ci-workflow](https://github.com/apache/nifi/workflows/ci-workflow/badge.svg)](https://github.com/apache/nifi/actions/workflows/ci-workflow.yml)\n[![system-tests](https://github.com/apache/nifi/workflows/system-tests/badge.svg)](https://github.com/apache/nifi/actions/workflows/system-tests.yml)\n[![integration-tests](https://github.com/apache/nifi/actions/workflows/integration-tests.yml/badge.svg)](https://github.com/apache/nifi/actions/workflows/integration-tests.yml)\n[![docker-tests](https://github.com/apache/nifi/actions/workflows/docker-tests.yml/badge.svg)](https://github.com/apache/nifi/actions/workflows/docker-tests.yml)\n[![code-compliance](https://github.com/apache/nifi/actions/workflows/code-compliance.yml/badge.svg)](https://github.com/apache/nifi/actions/workflows/code-compliance.yml)\n[![code-coverage](https://github.com/apache/nifi/actions/workflows/code-coverage.yml/badge.svg)](https://github.com/apache/nifi/actions/workflows/code-coverage.yml)\n[![codecov](https://codecov.io/gh/apache/nifi/branch/main/graph/badge.svg)](https://codecov.io/gh/apache/nifi)\n\n### Resources\n\n[![NiFi API](https://img.shields.io/maven-central/v/org.apache.nifi/nifi-api.svg?label=nifi-api&logo=apachenifi&logoColor=ffffff&color=728e9b)](https://central.sonatype.com/artifact/org.apache.nifi/nifi-api)\n[![NiFi NAR Maven Plugin](https://img.shields.io/maven-central/v/org.apache.nifi/nifi-nar-maven-plugin.svg?label=nifi-nar-maven-plugin&logo=apachenifi&logoColor=ffffff&color=728e9b)](https://central.sonatype.com/artifact/org.apache.nifi/nifi-nar-maven-plugin)\n[![NiFi Framework](https://img.shields.io/maven-central/v/org.apache.nifi/nifi.svg?label=nifi-framework&logo=apachenifi&logoColor=ffffff&color=728e9b)](https://nifi.apache.org/download/)\n[![NiFI Docker Pulls](https://img.shields.io/docker/pulls/apache/nifi.svg?logo=docker&logoColor=ffffff)](https://hub.docker.com/r/apache/nifi/)\n[![License](https://img.shields.io/github/license/apache/nifi)](https://github.com/apache/nifi/blob/main/LICENSE)\n[![NiFi API Javadoc](https://javadoc.io/badge2/org.apache.nifi/nifi-api/javadoc.svg)](https://javadoc.io/doc/org.apache.nifi/nifi-api)\n\n### Contacts\n\n[![Track Issues](https://img.shields.io/badge/track-Issues-728e9b.svg?logo=jirasoftware)](https://issues.apache.org/jira/browse/NIFI)\n[![Chat on Slack](https://img.shields.io/badge/chat-Slack-728e9b.svg?logo=slack)](https://s.apache.org/nifi-community-slack)\n[![Contact Developers](https://img.shields.io/badge/contact-Developers-728e9b.svg?logo=apache)](https://lists.apache.org/list.html?dev@nifi.apache.org)\n[![Contact Users](https://img.shields.io/badge/contact-Users-728e9b.svg?logo=apache)](https://lists.apache.org/list.html?users@nifi.apache.org)\n\n### Community\n\n[![Join Slack Community](https://img.shields.io/badge/join-Slack-728e9b.svg?logo=slack)](https://join.slack.com/t/apachenifi/shared_invite/zt-11njbtkdx-ZRU8FKYSWoEHRJetidy0zA)\n[![Follow on LinkedIn](https://img.shields.io/badge/follow-Apache%20NiFi-728e9b.svg?logo=linkedin)](https://www.linkedin.com/company/apache-nifi/)\n[![Follow on X](https://img.shields.io/badge/follow-apachenifi-728e9b.svg?logo=x)](https://x.com/apachenifi)\n\n## Features\n\n[Apache NiFi](https://nifi.apache.org/) is an easy to use, powerful, and reliable system to process and distribute data.\n\nNiFi automates cybersecurity, observability, event streams, and generative AI data pipelines and distribution\nfor thousands of companies worldwide across every industry.\n\n- Browser User Interface\n  - Seamless experience for design, control, and monitoring\n  - Runtime management and versioned pipelines\n  - Secure by default with HTTPS\n- Scalable Processing\n  - Configurable prioritization for throughput and latency\n  - Guaranteed delivery with retry and backoff strategies\n  - Horizontal scaling with clustering\n- Provenance Tracking \n  - Searchable history with configurable attributes\n  - Graph data lineage from source to destination\n  - Metadata and content for each processing decision\n- Extensible Design\n  - Plugin interface for Processors and Controller Services\n  - Support for Processors in native Python\n  - REST API for orchestration and monitoring\n- Secure Configuration\n  - Single sign-on with OpenID Connect or SAML 2\n  - Flexible authorization policies for role-based access\n  - Encrypted communication with TLS and SFTP\n\n## Requirements\n\nNiFi supports modern operating systems and requires recent language versions for developing and running the application.\n\n### Platform Requirements\n\n- Java 21\n\n### Optional Dependencies\n\n- Python 3.10 or higher\n\n## Projects\n\nThe source repository includes several component projects.\n\nPlease review individual project documentation for additional details.\n\n- [Apache NiFi](https://nifi.apache.org/documentation/)\n- [Apache NiFi Registry](https://github.com/apache/nifi/blob/main/nifi-registry/nifi-registry-assembly/README.md)\n- [Apache NiFi MiNiFi](https://github.com/apache/nifi/blob/main/minifi/minifi-assembly/README.md)\n\n## Getting Started\n\nProject guides provide extensive documentation for installing and extending the application.\n\n- [Getting Started](https://nifi.apache.org/documentation/nifi-latest/html/getting-started.html)\n- [User Guide](https://nifi.apache.org/documentation/nifi-latest/html/user-guide.html)\n- [Administrator Guide](https://nifi.apache.org/documentation/nifi-latest/html/administration-guide.html)\n- [Developer Guide](https://nifi.apache.org/documentation/nifi-latest/html/developer-guide.html)\n\n## Developing\n\nNiFi uses the [Maven Wrapper](https://maven.apache.org/wrapper/) for project development. The Maven Wrapper provides\nshell scripts that download and cache a selected version of [Apache Maven](https://maven.apache.org/) for running build\ncommands.\n\nDeveloping on Microsoft Windows requires using `mvnw.cmd` instead of `mvnw` to run Maven commands.\n\n### Building\n\nRun the following command to build project modules using parallel execution:\n\n```shell\n./mvnw install -T1C\n```\n\nRun the following command to build project modules using parallel execution with static analysis to confirm compliance\nwith code and licensing requirements:\n\n```shell\n./mvnw install -T1C -P contrib-check\n```\n\nRun the following command to build the application binaries without building other optional modules:\n\n```shell\n./mvnw install -T1C -am -pl :nifi-assembly\n```\n\n### Binaries\n\nThe `nifi-assembly` module contains the binary distribution.\n\n```shell\nls nifi-assembly/target/nifi-*-bin.zip\n```\n\nThe `nifi-assembly` module includes the binary distribution in a directory for local development and testing.\n\n```shell\ncd nifi-assembly/target/nifi-*-bin/nifi-*/\n```\n\n## Running\n\nNiFi provides shell scripts for starting and stopping the system.\n\nRunning on Microsoft Windows requires using `nifi.cmd` instead of `nifi.sh` for system commands.\n\n### Starting\n\nRun the following command to start NiFi from the distribution directory:\n\n```shell\n./bin/nifi.sh start\n```\n\n### Accessing\n\nThe default configuration generates a random username and password on startup. NiFi writes the generated credentials\nto the application log located in `logs/nifi-app.log` under the NiFi installation directory.\n\nThe following command can be used to find the generated credentials on operating systems with `grep` installed:\n\n```shell\ngrep Generated logs/nifi-app*log\n```\n\nNiFi logs the generated credentials as follows:\n\n```shell\nGenerated Username [USERNAME]\nGenerated Password [PASSWORD]\n```\n\nThe `USERNAME` will be a random UUID composed of 36 characters. The `PASSWORD` will be a random string.\n\nThe username and password can be replaced with custom credentials using the following command:\n\n```shell\n./bin/nifi.sh set-single-user-credentials <username> <password>\n```\n\nNiFi defaults to running on the `localhost` address with HTTPS on port `8443` at the following URL:\n\n```\nhttps://localhost:8443/nifi\n```\n\nBrowsers will display a warning message indicating a potential security risk due to the self-signed certificate\ngenerated during initialization. Production deployments should provision a certificate from a trusted certificate\nauthority and update the NiFi keystore and truststore configuration.\n\n## License\n\nExcept as otherwise noted this software is licensed under the\n[Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0.html)\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n  https://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n## Export Control\n\nThis distribution includes cryptographic software. The country in which you\ncurrently reside may have restrictions on the import, possession, use, and/or\nre-export to another country, of encryption software. BEFORE using any\nencryption software, please check your country's laws, regulations and\npolicies concerning the import, possession, or use, and re-export of encryption\nsoftware, to see if this is permitted. See https://www.wassenaar.org for more\ninformation.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and Security\n(BIS), has classified this software as Export Commodity Control Number (ECCN)\n5D002.C.1, which includes information security software using or performing\ncryptographic functions with asymmetric algorithms. The form and manner of this\nApache Software Foundation distribution makes it eligible for export under the\nLicense Exception ENC Technology Software Unrestricted (TSU) exception (see the\nBIS Export Administration Regulations, Section 740.13) for both object code and\nsource code.\n\nThe following provides more details on the included cryptographic software:\n\nApache NiFi uses the following libraries and frameworks for encrypted\ncommunication and storage of sensitive information:\n\n- [Apache MINA SSHD](https://mina.apache.org/sshd-project/)\n- [Bouncy Castle](https://www.bouncycastle.org)\n- [Jagged](https://github.com/exceptionfactory/jagged)\n- [Java Cryptography Architecture](https://docs.oracle.com/en/java/javase/21/security/java-cryptography-architecture-jca-reference-guide.html)\n",
      "stars_today": 2
    },
    {
      "id": 38304949,
      "name": "GRDB.swift",
      "full_name": "groue/GRDB.swift",
      "description": "A toolkit for SQLite databases, with a focus on application development",
      "html_url": "https://github.com/groue/GRDB.swift",
      "stars": 8126,
      "forks": 833,
      "language": "Swift",
      "topics": [
        "database",
        "database-observation",
        "grdb",
        "spm",
        "sql",
        "sql-builder",
        "sqlite",
        "sqlite-databases"
      ],
      "created_at": "2015-06-30T11:17:06Z",
      "updated_at": "2026-01-24T14:42:44Z",
      "pushed_at": "2026-01-16T12:18:54Z",
      "open_issues": 12,
      "owner": {
        "login": "groue",
        "avatar_url": "https://avatars.githubusercontent.com/u/54219?v=4"
      },
      "readme": "<picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB~dark.png\">\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB.png\">\n    <img alt=\"GRDB: A toolkit for SQLite databases, with a focus on application development.\" src=\"https://raw.githubusercontent.com/groue/GRDB.swift/master/GRDB.png\">\n</picture>\n\n<p align=\"center\">\n    <strong>A toolkit for SQLite databases, with a focus on application development</strong><br>\n    Proudly serving the community since 2015\n</p>\n\n<p align=\"center\">\n    <a href=\"https://developer.apple.com/swift/\"><img alt=\"Swift 6.1\" src=\"https://img.shields.io/badge/swift-6.1-orange.svg?style=flat\"></a>\n    <a href=\"https://github.com/groue/GRDB.swift/blob/master/LICENSE\"><img alt=\"License\" src=\"https://img.shields.io/github/license/groue/GRDB.swift.svg?maxAge=2592000\"></a>\n    <a href=\"https://github.com/groue/GRDB.swift/actions/workflows/CI.yml\"><img alt=\"CI Status\" src=\"https://github.com/groue/GRDB.swift/actions/workflows/CI.yml/badge.svg?branch=master\"></a>\n</p>\n\n**Latest release**: December 13, 2025 â€¢ [version 7.9.0](https://github.com/groue/GRDB.swift/tree/v7.9.0) â€¢ [CHANGELOG](CHANGELOG.md) â€¢ [Migrating From GRDB 6 to GRDB 7](Documentation/GRDB7MigrationGuide.md)\n\n**Requirements**: iOS 13.0+ / macOS 10.15+ / tvOS 13.0+ / watchOS 7.0+ &bull; SQLite 3.20.0+ &bull; Swift 6.1+ / Xcode 16.3+\n\n**Contact**:\n\n- Release announcements and usage tips: follow [@groue@hachyderm.io](https://hachyderm.io/@groue) on Mastodon.\n- Report bugs in a [Github issue](https://github.com/groue/GRDB.swift/issues/new). Make sure you check the [existing issues](https://github.com/groue/GRDB.swift/issues?q=is%3Aopen) first.\n- A question? Looking for advice? Do you wonder how to contribute? Fancy a chat? Go to the [GitHub discussions](https://github.com/groue/GRDB.swift/discussions), or the [GRDB forums](https://forums.swift.org/c/related-projects/grdb).\n\n\n## What is GRDB?\n\nUse this library to save your applicationâ€™s permanent data into SQLite databases. It comes with built-in tools that address common needs:\n\n- **SQL Generation**\n    \n    Enhance your application models with persistence and fetching methods, so that you don't have to deal with SQL and raw database rows when you don't want to.\n\n- **Database Observation**\n    \n    Get notifications when database values are modified. \n\n- **Robust Concurrency**\n    \n    Multi-threaded applications can efficiently use their databases, including WAL databases that support concurrent reads and writes. \n\n- **Migrations**\n    \n    Evolve the schema of your database as you ship new versions of your application.\n    \n- **Leverage your SQLite skills**\n\n    Not all developers need advanced SQLite features. But when you do, GRDB is as sharp as you want it to be. Come with your SQL and SQLite skills, or learn new ones as you go!\n\n---\n\n<p align=\"center\">\n    <a href=\"#usage\">Usage</a> &bull;\n    <a href=\"#documentation\">Documentation</a> &bull;\n    <a href=\"#installation\">Installation</a> &bull;\n    <a href=\"#faq\">FAQ</a>\n</p>\n\n---\n\n## Usage\n\n<details open>\n  <summary>Start using the database in four steps</summary>\n\n```swift\nimport GRDB\n\n// 1. Open a database connection\nlet dbQueue = try DatabaseQueue(path: \"/path/to/database.sqlite\")\n\n// 2. Define the database schema\ntry dbQueue.write { db in\n    try db.create(table: \"player\") { t in\n        t.primaryKey(\"id\", .text)\n        t.column(\"name\", .text).notNull()\n        t.column(\"score\", .integer).notNull()\n    }\n}\n\n// 3. Define a record type\nstruct Player: Codable, Identifiable, FetchableRecord, PersistableRecord {\n    var id: String\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// 4. Write and read in the database\ntry dbQueue.write { db in\n    try Player(id: \"1\", name: \"Arthur\", score: 100).insert(db)\n    try Player(id: \"2\", name: \"Barbara\", score: 1000).insert(db)\n}\n\ntry dbQueue.read { db in\n    let player = try Player.find(db, id: \"1\"))\n    \n    let bestPlayers = try Player\n        .order(\\.score.desc)\n        .limit(10)\n        .fetchAll(db)\n}\n```\n\n</details>\n\n<details>\n    <summary>Access to raw SQL</summary>\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player (\n          id TEXT PRIMARY KEY,\n          name TEXT NOT NULL,\n          score INT NOT NULL)\n        \"\"\")\n    \n    try db.execute(sql: \"\"\"\n        INSERT INTO player (id, name, score)\n        VALUES (?, ?, ?)\n        \"\"\", arguments: [\"1\", \"Arthur\", 100])\n    \n    // Avoid SQL injection with SQL interpolation\n    let id = \"2\"\n    let name = \"O'Brien\"\n    let score = 1000\n    try db.execute(literal: \"\"\"\n        INSERT INTO player (id, name, score)\n        VALUES (\\(id), \\(name), \\(score))\n        \"\"\")\n}\n```\n\nSee [Executing Updates](#executing-updates)\n\n</details>\n\n<details>\n    <summary>Access to raw database rows and values</summary>\n\n```swift\ntry dbQueue.read { db in\n    // Fetch database rows\n    let rows = try Row.fetchCursor(db, sql: \"SELECT * FROM player\")\n    while let row = try rows.next() {\n        let id: String = row[\"id\"]\n        let name: String = row[\"name\"]\n        let score: Int = row[\"score\"]\n    }\n    \n    // Fetch values\n    let playerCount = try Int.fetchOne(db, sql: \"SELECT COUNT(*) FROM player\")! // Int\n    let playerNames = try String.fetchAll(db, sql: \"SELECT name FROM player\") // [String]\n}\n\nlet playerCount = try dbQueue.read { db in\n    try Int.fetchOne(db, sql: \"SELECT COUNT(*) FROM player\")!\n}\n```\n\nSee [Fetch Queries](#fetch-queries)\n\n</details>\n\n<details>\n    <summary>Database model types aka \"records\"</summary>\n\n```swift\nstruct Player: Codable, Identifiable, FetchableRecord, PersistableRecord {\n    var id: String\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\ntry dbQueue.write { db in\n    // Create database table\n    try db.create(table: \"player\") { t in\n        t.primaryKey(\"id\", .text)\n        t.column(\"name\", .text).notNull()\n        t.column(\"score\", .integer).notNull()\n    }\n    \n    // Insert a record\n    var player = Player(id: \"1\", name: \"Arthur\", score: 100)\n    try player.insert(db)\n    \n    // Update a record\n    player.score += 10\n    try score.update(db)\n    \n    try player.updateChanges { $0.score += 10 }\n    \n    // Delete a record\n    try player.delete(db)\n}\n```\n\nSee [Records](#records)\n\n</details>\n\n<details>\n    <summary>Query the database with the Swift query interface</summary>\n\n```swift\ntry dbQueue.read { db in\n    // Player\n    let player = try Player.find(db, id: \"1\")\n    \n    // Player?\n    let arthur = try Player.filter { $0.name == \"Arthur\" }.fetchOne(db)\n    \n    // [Player]\n    let bestPlayers = try Player.order(\\.score.desc).limit(10).fetchAll(db)\n    \n    // Int\n    let playerCount = try Player.fetchCount(db)\n    \n    // SQL is always welcome\n    let players = try Player.fetchAll(db, sql: \"SELECT * FROM player\")\n}\n```\n\nSee the [Query Interface](#the-query-interface)\n\n</details>\n\n<details>\n    <summary>Database changes notifications</summary>\n\n```swift\n// Define the observed value\nlet observation = ValueObservation.tracking { db in\n    try Player.fetchAll(db)\n}\n\n// Start observation\nlet cancellable = observation.start(\n    in: dbQueue,\n    onError: { error in ... },\n    onChange: { (players: [Player]) in print(\"Fresh players: \\(players)\") })\n```\n\nReady-made support for Combine and RxSwift:\n\n```swift\n// Swift concurrency\nfor try await players in observation.values(in: dbQueue) {\n    print(\"Fresh players: \\(players)\")\n}\n\n// Combine\nlet cancellable = observation.publisher(in: dbQueue).sink(\n    receiveCompletion: { completion in ... },\n    receiveValue: { (players: [Player]) in print(\"Fresh players: \\(players)\") })\n\n// RxSwift\nlet disposable = observation.rx.observe(in: dbQueue).subscribe(\n    onNext: { (players: [Player]) in print(\"Fresh players: \\(players)\") },\n    onError: { error in ... })\n```\n\nSee [Database Observation], [Combine Support], [RxGRDB].\n\n</details>\n\nDocumentation\n=============\n\n**GRDB runs on top of SQLite**: you should get familiar with the [SQLite FAQ](http://www.sqlite.org/faq.html). For general and detailed information, jump to the [SQLite Documentation](http://www.sqlite.org/docs.html).\n\n\n#### Demo Applications & Frequently Asked Questions\n\n- [Demo Applications]\n- [FAQ]\n\n#### Reference\n\n- ğŸ“– [GRDB Reference](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/)\n\n#### Getting Started\n\n- [Installation](#installation)\n- [Database Connections]: Connect to SQLite databases\n\n#### SQLite and SQL\n\n- [SQLite API](#sqlite-api): The low-level SQLite API &bull; [executing updates](#executing-updates) &bull; [fetch queries](#fetch-queries) &bull; [SQL Interpolation]\n\n#### Records and the Query Interface\n\n- [Records](#records): Fetching and persistence methods for your custom structs and class hierarchies\n- [Query Interface](#the-query-interface): A swift way to generate SQL &bull; [create tables, indexes, etc](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema) &bull; [requests](#requests) â€¢ [associations between record types](Documentation/AssociationsBasics.md)\n\n#### Application Tools\n\n- [Migrations]: Transform your database as your application evolves.\n- [Full-Text Search]: Perform efficient and customizable full-text searches.\n- [Database Observation]: Observe database changes and transactions.\n- [Encryption](#encryption): Encrypt your database with SQLCipher.\n- [Backup](#backup): Dump the content of a database to another.\n- [Interrupt a Database](#interrupt-a-database): Abort any pending database operation.\n- [Sharing a Database]: How to share an SQLite database between multiple processes - recommendations for App Group containers, App Extensions, App Sandbox, and file coordination.\n\n#### Good to Know\n\n- [Concurrency]: How to access databases in a multi-threaded application.\n- [Combine](Documentation/Combine.md): Access and observe the database with Combine publishers.\n- [Avoiding SQL Injection](#avoiding-sql-injection)\n- [Error Handling](#error-handling)\n- [Unicode](#unicode)\n- [Memory Management](#memory-management)\n- [Data Protection](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections)\n- :bulb: [Migrating From GRDB 6 to GRDB 7](Documentation/GRDB7MigrationGuide.md)\n- :bulb: [Why Adopt GRDB?](Documentation/WhyAdoptGRDB.md)\n- :bulb: [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices)\n\n#### Companion Libraries\n\n- [GRDBQuery](https://github.com/groue/GRDBQuery): Access and observe the database from your SwiftUI views.\n- [GRDBSnapshotTesting](https://github.com/groue/GRDBSnapshotTesting): Test your database. \n\n**[FAQ]**\n\n**[Sample Code](#sample-code)**\n\n\nInstallation\n============\n\n**The installation procedures below have GRDB use the version of SQLite that ships with the target operating system.**\n\nSee [Encryption](#encryption) for the installation procedure of GRDB with SQLCipher.\n\nSee [Custom SQLite builds](Documentation/CustomSQLiteBuilds.md) for the installation procedure of GRDB with a customized build of SQLite.\n\n\n## Swift Package Manager\n\nThe [Swift Package Manager](https://swift.org/package-manager/) automates the distribution of Swift code. To use GRDB with SPM, add a dependency to `https://github.com/groue/GRDB.swift.git`\n\nGRDB offers two libraries, `GRDB` and `GRDB-dynamic`. Pick only one. When in doubt, prefer `GRDB`. The `GRDB-dynamic` library can reveal useful if you are going to link it with multiple targets within your app and only wish to link to a shared, dynamic framework once. See [How to link a Swift Package as dynamic](https://forums.swift.org/t/how-to-link-a-swift-package-as-dynamic/32062) for more information.\n\n> **Note**: Linux support is provided by contributors. It is not automatically tested, and not officially maintained. If you notice a build or runtime failure on Linux, please open a pull request with the necessary fix, thank you!\n\n\n## CocoaPods\n\n[CocoaPods](http://cocoapods.org/) is a dependency manager for Xcode projects. To use GRDB with CocoaPods (version 1.2 or higher), specify in your `Podfile`:\n\n```ruby\npod 'GRDB.swift'\n```\n\nGRDB can be installed as a framework, or a static library.\n\n**Important Note for CocoaPods installation**\n\nDue to an [issue](https://github.com/CocoaPods/CocoaPods/issues/11839) in CocoaPods, it is currently not possible to deploy new versions of GRDB to CocoaPods. The last version available on CocoaPods is 6.24.1. To install later versions of GRDB using CocoaPods, use one of the following workarounds:\n\n- Depend on the `GRDB7` branch. This is more or less equivalent to what `pod 'GRDB.swift', '~> 7.0'` would normally do, if CocoaPods would accept new GRDB versions to be published:\n\n    ```ruby\n    # Can't use semantic versioning due to https://github.com/CocoaPods/CocoaPods/issues/11839\n    pod 'GRDB.swift', git: 'https://github.com/groue/GRDB.swift.git', branch: 'GRDB7'\n    ```\n\n- Depend on a specific version explicitly (Replace the tag with the version you want to use):\n\n    ```ruby\n    # Can't use semantic versioning due to https://github.com/CocoaPods/CocoaPods/issues/11839\n    # Replace the tag with the tag that you want to use.\n    pod 'GRDB.swift', git: 'https://github.com/groue/GRDB.swift.git', tag: 'v6.29.0' \n    ```\n\n## Carthage\n\n[Carthage](https://github.com/Carthage/Carthage) is **unsupported**. For some context about this decision, see [#433](https://github.com/groue/GRDB.swift/issues/433).\n\n\n## Manually\n\n1. [Download](https://github.com/groue/GRDB.swift/releases) a copy of GRDB, or clone its repository and make sure you checkout the latest tagged version.\n\n2. Embed the `GRDB.xcodeproj` project in your own project.\n\n3. Add the `GRDB` target in the **Target Dependencies** section of the **Build Phases** tab of your application target (extension target for WatchOS).\n\n4. Add the `GRDB.framework` to the **Embedded Binaries** section of the **General**  tab of your application target (extension target for WatchOS).\n\n\nDatabase Connections\n====================\n\nGRDB provides two classes for accessing SQLite databases: [`DatabaseQueue`] and [`DatabasePool`]:\n\n```swift\nimport GRDB\n\n// Pick one:\nlet dbQueue = try DatabaseQueue(path: \"/path/to/database.sqlite\")\nlet dbPool = try DatabasePool(path: \"/path/to/database.sqlite\")\n```\n\nThe differences are:\n\n- Database pools allow concurrent database accesses (this can improve the performance of multithreaded applications).\n- Database pools open your SQLite database in the [WAL mode](https://www.sqlite.org/wal.html) (unless read-only).\n- Database queues support [in-memory databases](https://www.sqlite.org/inmemorydb.html).\n\n**If you are not sure, choose [`DatabaseQueue`].** You will always be able to switch to [`DatabasePool`] later.\n\nFor more information and tips when opening connections, see [Database Connections](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections).\n\n\nSQLite API\n==========\n\n**In this section of the documentation, we will talk SQL.** Jump to the [query interface](#the-query-interface) if SQL is not your cup of tea.\n\n- [Executing Updates](#executing-updates)\n- [Fetch Queries](#fetch-queries)\n    - [Fetching Methods](#fetching-methods)\n    - [Row Queries](#row-queries)\n    - [Value Queries](#value-queries)\n- [Values](#values)\n    - [Data](#data-and-memory-savings)\n    - [Date and DateComponents](#date-and-datecomponents)\n    - [NSNumber, NSDecimalNumber, and Decimal](#nsnumber-nsdecimalnumber-and-decimal)\n    - [Swift enums](#swift-enums)\n    - [`DatabaseValueConvertible`]: the protocol for custom value types\n- [Transactions and Savepoints]\n- [SQL Interpolation]\n\nAdvanced topics:\n\n- [Prepared Statements]\n- [Custom SQL Functions and Aggregates](#custom-sql-functions-and-aggregates)\n- [Database Schema Introspection](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschemaintrospection)\n- [Row Adapters](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter)\n- [Raw SQLite Pointers](#raw-sqlite-pointers)\n\n\n## Executing Updates\n\nOnce granted with a [database connection], the [`execute(sql:arguments:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/execute(sql:arguments:)) method executes the SQL statements that do not return any database row, such as `CREATE TABLE`, `INSERT`, `DELETE`, `ALTER`, etc.\n\nFor example:\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            name TEXT NOT NULL,\n            score INT)\n        \"\"\")\n    \n    try db.execute(\n        sql: \"INSERT INTO player (name, score) VALUES (?, ?)\",\n        arguments: [\"Barbara\", 1000])\n    \n    try db.execute(\n        sql: \"UPDATE player SET score = :score WHERE id = :id\",\n        arguments: [\"score\": 1000, \"id\": 1])\n    }\n}\n```\n\nThe `?` and colon-prefixed keys like `:score` in the SQL query are the **statements arguments**. You pass arguments with arrays or dictionaries, as in the example above. See [Values](#values) for more information on supported arguments types (Bool, Int, String, Date, Swift enums, etc.), and [`StatementArguments`] for a detailed documentation of SQLite arguments.\n\nYou can also embed query arguments right into your SQL queries, with [`execute(literal:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/execute(literal:)), as in the example below. See [SQL Interpolation] for more details.\n\n```swift\ntry dbQueue.write { db in\n    let name = \"O'Brien\"\n    let score = 550\n    try db.execute(literal: \"\"\"\n        INSERT INTO player (name, score) VALUES (\\(name), \\(score))\n        \"\"\")\n}\n```\n\n**Never ever embed values directly in your raw SQL strings**. See [Avoiding SQL Injection](#avoiding-sql-injection) for more information:\n\n```swift\n// WRONG: don't embed values in raw SQL strings\nlet id = 123\nlet name = textField.text\ntry db.execute(\n    sql: \"UPDATE player SET name = '\\(name)' WHERE id = \\(id)\")\n\n// CORRECT: use arguments dictionary\ntry db.execute(\n    sql: \"UPDATE player SET name = :name WHERE id = :id\",\n    arguments: [\"name\": name, \"id\": id])\n\n// CORRECT: use arguments array\ntry db.execute(\n    sql: \"UPDATE player SET name = ? WHERE id = ?\",\n    arguments: [name, id])\n\n// CORRECT: use SQL Interpolation\ntry db.execute(\n    literal: \"UPDATE player SET name = \\(name) WHERE id = \\(id)\")\n```\n\n**Join multiple statements with a semicolon**:\n\n```swift\ntry db.execute(sql: \"\"\"\n    INSERT INTO player (name, score) VALUES (?, ?);\n    INSERT INTO player (name, score) VALUES (?, ?);\n    \"\"\", arguments: [\"Arthur\", 750, \"Barbara\", 1000])\n\ntry db.execute(literal: \"\"\"\n    INSERT INTO player (name, score) VALUES (\\(\"Arthur\"), \\(750));\n    INSERT INTO player (name, score) VALUES (\\(\"Barbara\"), \\(1000));\n    \"\"\")\n```\n\nWhen you want to make sure that a single statement is executed, use a prepared [`Statement`].\n\n**After an INSERT statement**, you can get the row ID of the inserted row with [`lastInsertedRowID`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/lastinsertedrowid):\n\n```swift\ntry db.execute(\n    sql: \"INSERT INTO player (name, score) VALUES (?, ?)\",\n    arguments: [\"Arthur\", 1000])\nlet playerId = db.lastInsertedRowID\n```\n\nDon't miss [Records](#records), that provide classic **persistence methods**:\n\n```swift\nvar player = Player(name: \"Arthur\", score: 1000)\ntry player.insert(db)\nlet playerId = player.id\n```\n\n\n## Fetch Queries\n\n[Database connections] let you fetch database rows, plain values, and custom models aka \"records\".\n\n**Rows** are the raw results of SQL queries:\n\n```swift\ntry dbQueue.read { db in\n    if let row = try Row.fetchOne(db, sql: \"SELECT * FROM wine WHERE id = ?\", arguments: [1]) {\n        let name: String = row[\"name\"]\n        let color: Color = row[\"color\"]\n        print(name, color)\n    }\n}\n```\n\n\n**Values** are the Bool, Int, String, Date, Swift enums, etc. stored in row columns:\n\n```swift\ntry dbQueue.read { db in\n    let urls = try URL.fetchCursor(db, sql: \"SELECT url FROM wine\")\n    while let url = try urls.next() {\n        print(url)\n    }\n}\n```\n\n\n**Records** are your application objects that can initialize themselves from rows:\n\n```swift\nlet wines = try dbQueue.read { db in\n    try Wine.fetchAll(db, sql: \"SELECT * FROM wine\")\n}\n```\n\n- [Fetching Methods](#fetching-methods) and [Cursors](#cursors)\n- [Row Queries](#row-queries)\n- [Value Queries](#value-queries)\n- [Records](#records)\n\n\n### Fetching Methods\n\n**Throughout GRDB**, you can always fetch *cursors*, *arrays*, *sets*, or *single values* of any fetchable type (database [row](#row-queries), simple [value](#value-queries), or custom [record](#records)):\n\n```swift\ntry Row.fetchCursor(...) // A Cursor of Row\ntry Row.fetchAll(...)    // [Row]\ntry Row.fetchSet(...)    // Set<Row>\ntry Row.fetchOne(...)    // Row?\n```\n\n- `fetchCursor` returns a **[cursor](#cursors)** over fetched values:\n    \n    ```swift\n    let rows = try Row.fetchCursor(db, sql: \"SELECT ...\") // A Cursor of Row\n    ```\n    \n- `fetchAll` returns an **array**:\n    \n    ```swift\n    let players = try Player.fetchAll(db, sql: \"SELECT ...\") // [Player]\n    ```\n\n- `fetchSet` returns a **set**:\n    \n    ```swift\n    let names = try String.fetchSet(db, sql: \"SELECT ...\") // Set<String>\n    ```\n\n- `fetchOne` returns a **single optional value**, and consumes a single database row (if any).\n    \n    ```swift\n    let count = try Int.fetchOne(db, sql: \"SELECT COUNT(*) ...\") // Int?\n    ```\n\n**All those fetching methods require an SQL string that contains a single SQL statement.** When you want to fetch from multiple statements joined with a semicolon, iterate the multiple [prepared statements] found in the SQL string.\n\n### Cursors\n\nğŸ“– [`Cursor`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/cursor)\n\n**Whenever you consume several rows from the database, you can fetch an Array, a Set, or a Cursor**.\n\nThe `fetchAll()` and `fetchSet()` methods return regular Swift array and sets, that you iterate like all other arrays and sets:\n\n```swift\ntry dbQueue.read { db in\n    // [Player]\n    let players = try Player.fetchAll(db, sql: \"SELECT ...\")\n    for player in players {\n        // use player\n    }\n}\n```\n\nUnlike arrays and sets, cursors returned by `fetchCursor()` load their results step after step:\n\n```swift\ntry dbQueue.read { db in\n    // Cursor of Player\n    let players = try Player.fetchCursor(db, sql: \"SELECT ...\")\n    while let player = try players.next() {\n        // use player\n    }\n}\n```\n\n- **Cursors can not be used on any thread**: you must consume a cursor on the dispatch queue it was created in. Particularly, don't extract a cursor out of a database access method:\n    \n    ```swift\n    // Wrong\n    let cursor = try dbQueue.read { db in\n        try Player.fetchCursor(db, ...)\n    }\n    while let player = try cursor.next() { ... }\n    ```\n    \n    Conversely, arrays and sets may be consumed on any thread:\n    \n    ```swift\n    // OK\n    let array = try dbQueue.read { db in\n        try Player.fetchAll(db, ...)\n    }\n    for player in array { ... }\n    ```\n    \n- **Cursors can be iterated only one time.** Arrays and sets can be iterated many times.\n\n- **Cursors iterate database results in a lazy fashion**, and don't consume much memory. Arrays and sets contain copies of database values, and may take a lot of memory when there are many fetched results.\n\n- **Cursors are granted with direct access to SQLite,** unlike arrays and sets that have to take the time to copy database values. If you look after extra performance, you may prefer cursors.\n\n- **Cursors can feed Swift collections.**\n    \n    You will most of the time use `fetchAll` or `fetchSet` when you want an array or a set. For more specific needs, you may prefer one of the initializers below. All of them accept an extra optional `minimumCapacity` argument which helps optimizing your app when you have an idea of the number of elements in a cursor (the built-in `fetchAll` and `fetchSet` do not perform such an optimization).\n    \n    **Arrays** and all types conforming to `RangeReplaceableCollection`:\n    \n    ```swift\n    // [String]\n    let cursor = try String.fetchCursor(db, ...)\n    let array = try Array(cursor)\n    ```\n    \n    **Sets**:\n    \n    ```swift\n    // Set<Int>\n    let cursor = try Int.fetchCursor(db, ...)\n    let set = try Set(cursor)\n    ```\n    \n    **Dictionaries**:\n    \n    ```swift\n    // [Int64: [Player]]\n    let cursor = try Player.fetchCursor(db)\n    let dictionary = try Dictionary(grouping: cursor, by: { $0.teamID })\n    \n    // [Int64: Player]\n    let cursor = try Player.fetchCursor(db).map { ($0.id, $0) }\n    let dictionary = try Dictionary(uniqueKeysWithValues: cursor)\n    ```\n\n- **Cursors adopt the [Cursor](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/cursor) protocol, which looks a lot like standard [lazy sequences](https://developer.apple.com/reference/swift/lazysequenceprotocol) of Swift.** As such, cursors come with many convenience methods: `compactMap`, `contains`, `dropFirst`, `dropLast`, `drop(while:)`, `enumerated`, `filter`, `first`, `flatMap`, `forEach`, `joined`, `joined(separator:)`, `max`, `max(by:)`, `min`, `min(by:)`, `map`, `prefix`, `prefix(while:)`, `reduce`, `reduce(into:)`, `suffix`:\n    \n    ```swift\n    // Prints all Github links\n    try URL\n        .fetchCursor(db, sql: \"SELECT url FROM link\")\n        .filter { url in url.host == \"github.com\" }\n        .forEach { url in print(url) }\n    \n    // An efficient cursor of coordinates:\n    let locations = try Row.\n        .fetchCursor(db, sql: \"SELECT latitude, longitude FROM place\")\n        .map { row in\n            CLLocationCoordinate2D(latitude: row[0], longitude: row[1])\n        }\n    ```\n\n- **Cursors are not Swift sequences.** That's because Swift sequences can't handle iteration errors, when reading SQLite results may fail at any time.\n\n- **Cursors require a little care**:\n    \n    - Don't modify the results during a cursor iteration:\n        \n        ```swift\n        // Undefined behavior\n        while let player = try players.next() {\n            try db.execute(sql: \"DELETE ...\")\n        }\n        ```\n    \n    - Don't turn a cursor of `Row` into an array or a set. You would not get the distinct rows you expect. To get a array of rows, use `Row.fetchAll(...)`. To get a set of rows, use `Row.fetchSet(...)`. Generally speaking, make sure you copy a row whenever you extract it from a cursor for later use: `row.copy()`.\n\nIf you don't see, or don't care about the difference, use arrays. If you care about memory and performance, use cursors when appropriate.\n\n\n### Row Queries\n\n- [Fetching Rows](#fetching-rows)\n- [Column Values](#column-values)\n- [DatabaseValue](#databasevalue)\n- [Rows as Dictionaries](#rows-as-dictionaries)\n- ğŸ“– [`Row`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/row)\n\n\n#### Fetching Rows\n\nFetch **cursors** of rows, **arrays**, **sets**, or **single** rows (see [fetching methods](#fetching-methods)):\n\n```swift\ntry dbQueue.read { db in\n    try Row.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Row\n    try Row.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Row]\n    try Row.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Row>\n    try Row.fetchOne(db, sql: \"SELECT ...\", arguments: ...)    // Row?\n    \n    let rows = try Row.fetchCursor(db, sql: \"SELECT * FROM wine\")\n    while let row = try rows.next() {\n        let name: String = row[\"name\"]\n        let color: Color = row[\"color\"]\n        print(name, color)\n    }\n}\n\nlet rows = try dbQueue.read { db in\n    try Row.fetchAll(db, sql: \"SELECT * FROM player\")\n}\n```\n\nArguments are optional arrays or dictionaries that fill the positional `?` and colon-prefixed keys like `:name` in the query:\n\n```swift\nlet rows = try Row.fetchAll(db,\n    sql: \"SELECT * FROM player WHERE name = ?\",\n    arguments: [\"Arthur\"])\n\nlet rows = try Row.fetchAll(db,\n    sql: \"SELECT * FROM player WHERE name = :name\",\n    arguments: [\"name\": \"Arthur\"])\n```\n\nSee [Values](#values) for more information on supported arguments types (Bool, Int, String, Date, Swift enums, etc.), and [`StatementArguments`] for a detailed documentation of SQLite arguments.\n\nUnlike row arrays that contain copies of the database rows, row cursors are close to the SQLite metal, and require a little care:\n\n> **Note**: **Don't turn a cursor of `Row` into an array or a set**. You would not get the distinct rows you expect. To get a array of rows, use `Row.fetchAll(...)`. To get a set of rows, use `Row.fetchSet(...)`. Generally speaking, make sure you copy a row whenever you extract it from a cursor for later use: `row.copy()`.\n\n\n#### Column Values\n\n**Read column values** by index or column name:\n\n```swift\nlet name: String = row[0]      // 0 is the leftmost column\nlet name: String = row[\"name\"] // Leftmost matching column - lookup is case-insensitive\nlet name: String = row[Column(\"name\")] // Using query interface's Column\n```\n\nMake sure to ask for an optional when the value may be NULL:\n\n```swift\nlet name: String? = row[\"name\"]\n```\n\nThe `row[]` subscript returns the type you ask for. See [Values](#values) for more information on supported value types:\n\n```swift\nlet bookCount: Int     = row[\"bookCount\"]\nlet bookCount64: Int64 = row[\"bookCount\"]\nlet hasBooks: Bool     = row[\"bookCount\"] // false when 0\n\nlet string: String     = row[\"date\"]      // \"2015-09-11 18:14:15.123\"\nlet date: Date         = row[\"date\"]      // Date\nself.date = row[\"date\"] // Depends on the type of the property.\n```\n\nYou can also use the `as` type casting operator:\n\n```swift\nrow[...] as Int\nrow[...] as Int?\n```\n\nThrowing accessors exist as well. Their use is not encouraged, because a database decoding error is a programming error. If an application stores invalid data in the database file, that is a bug that needs to be fixed:\n\n```swift\nlet name = try row.decode(String.self, atIndex: 0)\nlet bookCount = try row.decode(Int.self, forColumn: \"bookCount\")\n```\n\n> **Warning**: avoid the `as!` and `as?` operators:\n> \n> ```swift\n> if let int = row[...] as? Int { ... } // BAD - doesn't work\n> if let int = row[...] as Int? { ... } // GOOD\n> ```\n\n> **Warning**: avoid nil-coalescing row values, and prefer the `coalesce` method instead:\n>\n> ```swift\n> let name: String? = row[\"nickname\"] ?? row[\"name\"]     // BAD - doesn't work\n> let name: String? = row.coalesce([\"nickname\", \"name\"]) // GOOD\n> ```\n\nGenerally speaking, you can extract the type you need, provided it can be converted from the underlying SQLite value:\n\n- **Successful conversions include:**\n    \n    - All numeric SQLite values to all numeric Swift types, and Bool (zero is the only false boolean).\n    - Text SQLite values to Swift String.\n    - Blob SQLite values to Foundation Data.\n    \n    See [Values](#values) for more information on supported types (Bool, Int, String, Date, Swift enums, etc.)\n    \n- **NULL returns nil.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT NULL\")!\n    row[0] as Int? // nil\n    row[0] as Int  // fatal error: could not convert NULL to Int.\n    ```\n    \n    There is one exception, though: the [DatabaseValue](#databasevalue) type:\n    \n    ```swift\n    row[0] as DatabaseValue // DatabaseValue.null\n    ```\n    \n- **Missing columns return nil.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'foo' AS foo\")!\n    row[\"missing\"] as String? // nil\n    row[\"missing\"] as String  // fatal error: no such column: missing\n    ```\n    \n    You can explicitly check for a column presence with the `hasColumn` method.\n\n- **Invalid conversions throw a fatal error.**\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'Momâ€™s birthday'\")!\n    row[0] as String // \"Momâ€™s birthday\"\n    row[0] as Date?  // fatal error: could not convert \"Momâ€™s birthday\" to Date.\n    row[0] as Date   // fatal error: could not convert \"Momâ€™s birthday\" to Date.\n    \n    let row = try Row.fetchOne(db, sql: \"SELECT 256\")!\n    row[0] as Int    // 256\n    row[0] as UInt8? // fatal error: could not convert 256 to UInt8.\n    row[0] as UInt8  // fatal error: could not convert 256 to UInt8.\n    ```\n    \n    Those conversion fatal errors can be avoided with the [DatabaseValue](#databasevalue) type:\n    \n    ```swift\n    let row = try Row.fetchOne(db, sql: \"SELECT 'Momâ€™s birthday'\")!\n    let dbValue: DatabaseValue = row[0]\n    if dbValue.isNull {\n        // Handle NULL\n    } else if let date = Date.fromDatabaseValue(dbValue) {\n        // Handle valid date\n    } else {\n        // Handle invalid date\n    }\n    ```\n    \n    This extra verbosity is the consequence of having to deal with an untrusted database: you may consider fixing the content of your database instead. See [Fatal Errors](#fatal-errors) for more information.\n    \n- **SQLite has a weak type system, and provides [convenience conversions](https://www.sqlite.org/c3ref/column_blob.html) that can turn String to Int, Double to Blob, etc.**\n    \n    GRDB will sometimes let those conversions go through:\n    \n    ```swift\n    let rows = try Row.fetchCursor(db, sql: \"SELECT '20 small cigars'\")\n    while let row = try rows.next() {\n        row[0] as Int   // 20\n    }\n    ```\n    \n    Don't freak out: those conversions did not prevent SQLite from becoming the immensely successful database engine you want to use. And GRDB adds safety checks described just above. You can also prevent those convenience conversions altogether by using the [DatabaseValue](#databasevalue) type.\n\n\n#### DatabaseValue\n\nğŸ“– [`DatabaseValue`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalue)\n\n**`DatabaseValue` is an intermediate type between SQLite and your values, which gives information about the raw value stored in the database.**\n\nYou get `DatabaseValue` just like other value types:\n\n```swift\nlet dbValue: DatabaseValue = row[0]\nlet dbValue: DatabaseValue? = row[\"name\"] // nil if and only if column does not exist\n\n// Check for NULL:\ndbValue.isNull // Bool\n\n// The stored value:\ndbValue.storage.value // Int64, Double, String, Data, or nil\n\n// All the five storage classes supported by SQLite:\nswitch dbValue.storage {\ncase .null:                 print(\"NULL\")\ncase .int64(let int64):     print(\"Int64: \\(int64)\")\ncase .double(let double):   print(\"Double: \\(double)\")\ncase .string(let string):   print(\"String: \\(string)\")\ncase .blob(let data):       print(\"Data: \\(data)\")\n}\n```\n\nYou can extract regular [values](#values) (Bool, Int, String, Date, Swift enums, etc.) from `DatabaseValue` with the [fromDatabaseValue()](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible/fromdatabasevalue(_:)-21zzv) method:\n\n```swift\nlet dbValue: DatabaseValue = row[\"bookCount\"]\nlet bookCount   = Int.fromDatabaseValue(dbValue)   // Int?\nlet bookCount64 = Int64.fromDatabaseValue(dbValue) // Int64?\nlet hasBooks    = Bool.fromDatabaseValue(dbValue)  // Bool?, false when 0\n\nlet dbValue: DatabaseValue = row[\"date\"]\nlet string = String.fromDatabaseValue(dbValue)     // \"2015-09-11 18:14:15.123\"\nlet date   = Date.fromDatabaseValue(dbValue)       // Date?\n```\n\n`fromDatabaseValue` returns nil for invalid conversions:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 'Momâ€™s birthday'\")!\nlet dbValue: DatabaseValue = row[0]\nlet string = String.fromDatabaseValue(dbValue) // \"Momâ€™s birthday\"\nlet int    = Int.fromDatabaseValue(dbValue)    // nil\nlet date   = Date.fromDatabaseValue(dbValue)   // nil\n```\n\n\n#### Rows as Dictionaries\n\nRow adopts the standard [RandomAccessCollection](https://developer.apple.com/documentation/swift/randomaccesscollection) protocol, and can be seen as a dictionary of [DatabaseValue](#databasevalue):\n\n```swift\n// All the (columnName, dbValue) tuples, from left to right:\nfor (columnName, dbValue) in row {\n    ...\n}\n```\n\n**You can build rows from dictionaries** (standard Swift dictionaries and NSDictionary). See [Values](#values) for more information on supported types:\n\n```swift\nlet row: Row = [\"name\": \"foo\", \"date\": nil]\nlet row = Row([\"name\": \"foo\", \"date\": nil])\nlet row = Row(/* [AnyHashable: Any] */) // nil if invalid dictionary\n```\n\nYet rows are not real dictionaries: they may contain duplicate columns:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 1 AS foo, 2 AS foo\")!\nrow.columnNames    // [\"foo\", \"foo\"]\nrow.databaseValues // [1, 2]\nrow[\"foo\"]         // 1 (leftmost matching column)\nfor (columnName, dbValue) in row { ... } // (\"foo\", 1), (\"foo\", 2)\n```\n\n**When you build a dictionary from a row**, you have to disambiguate identical columns, and choose how to present database values. For example:\n\n- A `[String: DatabaseValue]` dictionary that keeps leftmost value in case of duplicated column name:\n\n    ```swift\n    let dict = Dictionary(row, uniquingKeysWith: { (left, _) in left })\n    ```\n\n- A `[String: AnyObject]` dictionary which keeps rightmost value in case of duplicated column name. This dictionary is identical to FMResultSet's resultDictionary from FMDB. It contains NSNull values for null columns, and can be shared with Objective-C:\n\n    ```swift\n    let dict = Dictionary(\n        row.map { (column, dbValue) in\n            (column, dbValue.storage.value as AnyObject)\n        },\n        uniquingKeysWith: { (_, right) in right })\n    ```\n\n- A `[String: Any]` dictionary that can feed, for example, JSONSerialization:\n    \n    ```swift\n    let dict = Dictionary(\n        row.map { (column, dbValue) in\n            (column, dbValue.storage.value)\n        },\n        uniquingKeysWith: { (left, _) in left })\n    ```\n\nSee the documentation of [`Dictionary.init(_:uniquingKeysWith:)`](https://developer.apple.com/documentation/swift/dictionary/2892961-init) for more information.\n\n\n### Value Queries\n\nğŸ“– [`DatabaseValueConvertible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible)\n\n**Instead of rows, you can directly fetch values.** There are many supported [value types](#values) (Bool, Int, String, Date, Swift enums, etc.).\n\nLike rows, fetch values as **cursors**, **arrays**, **sets**, or **single** values (see [fetching methods](#fetching-methods)). Values are extracted from the leftmost column of the SQL queries:\n\n```swift\ntry dbQueue.read { db in\n    try Int.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Int\n    try Int.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Int]\n    try Int.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Int>\n    try Int.fetchOne(db, sql: \"SELECT ...\", arguments: ...)    // Int?\n    \n    let maxScore = try Int.fetchOne(db, sql: \"SELECT MAX(score) FROM player\") // Int?\n    let names = try String.fetchAll(db, sql: \"SELECT name FROM player\")       // [String]\n}\n```\n\n`Int.fetchOne` returns nil in two cases: either the SELECT statement yielded no row, or one row with a NULL value:\n\n```swift\n// No row:\ntry Int.fetchOne(db, sql: \"SELECT 42 WHERE FALSE\") // nil\n\n// One row with a NULL value:\ntry Int.fetchOne(db, sql: \"SELECT NULL\")           // nil\n\n// One row with a non-NULL value:\ntry Int.fetchOne(db, sql: \"SELECT 42\")             // 42\n```\n\nFor requests which may contain NULL, fetch optionals:\n\n```swift\ntry dbQueue.read { db in\n    try Optional<Int>.fetchCursor(db, sql: \"SELECT ...\", arguments: ...) // A Cursor of Int?\n    try Optional<Int>.fetchAll(db, sql: \"SELECT ...\", arguments: ...)    // [Int?]\n    try Optional<Int>.fetchSet(db, sql: \"SELECT ...\", arguments: ...)    // Set<Int?>\n}\n```\n\n> :bulb: **Tip**: One advanced use case, when you fetch one value, is to distinguish the cases of a statement that yields no row, or one row with a NULL value. To do so, use `Optional<Int>.fetchOne`, which returns a double optional `Int??`:\n> \n> ```swift\n> // No row:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT 42 WHERE FALSE\") // .none\n> // One row with a NULL value:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT NULL\")           // .some(.none)\n> // One row with a non-NULL value:\n> try Optional<Int>.fetchOne(db, sql: \"SELECT 42\")             // .some(.some(42))\n> ```\n\nThere are many supported value types (Bool, Int, String, Date, Swift enums, etc.). See [Values](#values) for more information.\n\n\n## Values\n\nGRDB ships with built-in support for the following value types:\n\n- **Swift Standard Library**: Bool, Double, Float, all signed and unsigned integer types, String, [Swift enums](#swift-enums).\n    \n- **Foundation**: [Data](#data-and-memory-savings), [Date](#date-and-datecomponents), [DateComponents](#date-and-datecomponents), [Decimal](#nsnumber-nsdecimalnumber-and-decimal), NSNull, [NSNumber](#nsnumber-nsdecimalnumber-and-decimal), NSString, URL, [UUID](#uuid).\n    \n- **CoreGraphics**: CGFloat.\n\n- **[DatabaseValue](#databasevalue)**, the type which gives information about the raw value stored in the database.\n\n- **Full-Text Patterns**: [FTS3Pattern](Documentation/FullTextSearch.md#fts3pattern) and [FTS5Pattern](Documentation/FullTextSearch.md#fts5pattern).\n\n- Generally speaking, all types that adopt the [`DatabaseValueConvertible`] protocol.\n\nValues can be used as [statement arguments](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments):\n\n```swift\nlet url: URL = ...\nlet verified: Bool = ...\ntry db.execute(\n    sql: \"INSERT INTO link (url, verified) VALUES (?, ?)\",\n    arguments: [url, verified])\n```\n\nValues can be [extracted from rows](#column-values):\n\n```swift\nlet rows = try Row.fetchCursor(db, sql: \"SELECT * FROM link\")\nwhile let row = try rows.next() {\n    let url: URL = row[\"url\"]\n    let verified: Bool = row[\"verified\"]\n}\n```\n\nValues can be [directly fetched](#value-queries):\n\n```swift\nlet urls = try URL.fetchAll(db, sql: \"SELECT url FROM link\")  // [URL]\n```\n\nUse values in [Records](#records):\n\n```swift\nstruct Link: FetchableRecord {\n    var url: URL\n    var isVerified: Bool\n    \n    init(row: Row) {\n        url = row[\"url\"]\n        isVerified = row[\"verified\"]\n    }\n}\n```\n\nUse values in the [query interface](#the-query-interface):\n\n```swift\nlet url: URL = ...\nlet link = try Link.filter { $0.url == url }.fetchOne(db)\n```\n\n\n### Data (and Memory Savings)\n\n**Data** suits the BLOB SQLite columns. It can be stored and fetched from the database just like other [values](#values):\n\n```swift\nlet rows = try Row.fetchCursor(db, sql: \"SELECT data, ...\")\nwhile let row = try rows.next() {\n    let data: Data = row[\"data\"]\n}\n```\n\nAt each step of the request iteration, the `row[]` subscript creates *two copies* of the database bytes: one fetched by SQLite, and another, stored in the Swift Data value.\n\n**You have the opportunity to save memory** by not copying the data fetched by SQLite:\n\n```swift\nwhile let row = try rows.next() {\n    try row.withUnsafeData(name: \"data\") { (data: Data?) in\n        ...\n    }\n}\n```\n\nThe non-copied data does not live longer than the iteration step: make sure that you do not use it past this point.\n\n\n### Date and DateComponents\n\n[**Date**](#date) and [**DateComponents**](#datecomponents) can be stored and fetched from the database.\n\nHere is how GRDB supports the various [date formats](https://www.sqlite.org/lang_datefunc.html) supported by SQLite:\n\n| SQLite format                | Date               | DateComponents |\n|:---------------------------- |:------------------:|:--------------:|\n| YYYY-MM-DD                   |       Read Â¹       | Read / Write   |\n| YYYY-MM-DD HH:MM             |       Read Â¹ Â²     | Read Â² / Write |\n| YYYY-MM-DD HH:MM:SS          |       Read Â¹ Â²     | Read Â² / Write |\n| YYYY-MM-DD HH:MM:SS.SSS      | Read Â¹ Â² / Write Â¹ | Read Â² / Write |\n| YYYY-MM-DD**T**HH:MM         |       Read Â¹ Â²     |      Read Â²    |\n| YYYY-MM-DD**T**HH:MM:SS      |       Read Â¹ Â²     |      Read Â²    |\n| YYYY-MM-DD**T**HH:MM:SS.SSS  |       Read Â¹ Â²     |      Read Â²    |\n| HH:MM                        |                    | Read Â² / Write |\n| HH:MM:SS                     |                    | Read Â² / Write |\n| HH:MM:SS.SSS                 |                    | Read Â² / Write |\n| Timestamps since unix epoch  |       Read Â³       |                |\n| `now`                        |                    |                |\n\nÂ¹ Missing components are assumed to be zero. Dates are stored and read in the UTC time zone, unless the format is followed by a timezone indicator â½Â²â¾.\n\nÂ² This format may be optionally followed by a timezone indicator of the form `[+-]HH:MM` or just `Z`.\n\nÂ³ GRDB 2+ interprets numerical values as timestamps that fuel `Date(timeIntervalSince1970:)`. Previous GRDB versions used to interpret numbers as [julian days](https://en.wikipedia.org/wiki/Julian_day). Julian days are still supported, with the `Date(julianDay:)` initializer.\n\n> **Warning**: the range of valid years in the SQLite date formats is 0000-9999. You will need to pick another date format when your application needs to process years outside of this range. See the following chapters.\n\n\n#### Date\n\n**Date** can be stored and fetched from the database just like other [values](#values):\n\n```swift\ntry db.execute(\n    sql: \"INSERT INTO player (creationDate, ...) VALUES (?, ...)\",\n    arguments: [Date(), ...])\n\nlet row = try Row.fetchOne(db, ...)!\nlet creationDate: Date = row[\"creationDate\"]\n```\n\nDates are stored using the format \"YYYY-MM-DD HH:MM:SS.SSS\" in the UTC time zone. It is precise to the millisecond.\n\n> **Note**: this format was chosen because it is the only format that is:\n> \n> - Comparable (`ORDER BY date` works)\n> - Comparable with the SQLite keyword CURRENT_TIMESTAMP (`WHERE date > CURRENT_TIMESTAMP` works)\n> - Able to feed [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html)\n> - Precise enough\n>\n> **Warning**: the range of valid years in the SQLite date format is 0000-9999. You will experience problems with years outside of this range, such as decoding errors, or invalid date computations with [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html).\n\nSome applications may prefer another date format:\n\n- Some may prefer ISO-8601, with a `T` separator.\n- Some may prefer ISO-8601, with a time zone.\n- Some may need to store years beyond the 0000-9999 range.\n- Some may need sub-millisecond precision.\n- Some may need exact `Date` roundtrip.\n- Etc.\n\n**You should think twice before choosing a different date format:**\n\n- ISO-8601 is about *exchange and communication*, when SQLite is about *storage and data manipulation*. Sharing the same representation in your database and in JSON files only provides a superficial convenience, and should be the least of your priorities. Don't store dates as ISO-8601 without understanding what you lose. For example, ISO-8601 time zones forbid database-level date comparison. \n- Sub-millisecond precision and exact `Date` roundtrip are not as obvious needs as it seems at first sight. Dates generally don't precisely roundtrip as soon as they leave your application anyway, because the other systems your app communicates with use their own date representation (the Android version of your app, the server your application is talking to, etc.) On top of that, `Date` comparison is at least as hard and nasty as [floating point comparison](https://www.google.com/search?q=floating+point+comparison+is+hard).\n\nThe customization of date format is explicit. For example:\n\n```swift\nlet date = Date()\nlet timeInterval = date.timeIntervalSinceReferenceDate\ntry db.execute(\n    sql: \"INSERT INTO player (creationDate, ...) VALUES (?, ...)\",\n    arguments: [timeInterval, ...])\n\nif let row = try Row.fetchOne(db, ...) {\n    let timeInterval: TimeInterval = row[\"creationDate\"]\n    let creationDate = Date(timeIntervalSinceReferenceDate: timeInterval)\n}\n```\n\nSee also [Codable Records] for more date customization options, and [`DatabaseValueConvertible`] if you want to define a Date-wrapping type with customized database representation.\n\n\n#### DateComponents\n\nDateComponents is indirectly supported, through the **DatabaseDateComponents** helper type.\n\nDatabaseDateComponents reads date components from all [date formats supported by SQLite](https://www.sqlite.org/lang_datefunc.html), and stores them in the format of your choice, from HH:MM to YYYY-MM-DD HH:MM:SS.SSS.\n\n> **Warning**: the range of valid years is 0000-9999. You will experience problems with years outside of this range, such as decoding errors, or invalid date computations with [SQLite date & time functions](https://www.sqlite.org/lang_datefunc.html). See [Date](#date) for more information.\n\nDatabaseDateComponents can be stored and fetched from the database just like other [values](#values):\n\n```swift\nlet components = DateComponents()\ncomponents.year = 1973\ncomponents.month = 9\ncomponents.day = 18\n\n// Store \"1973-09-18\"\nlet dbComponents = DatabaseDateComponents(components, format: .YMD)\ntry db.execute(\n    sql: \"INSERT INTO player (birthDate, ...) VALUES (?, ...)\",\n    arguments: [dbComponents, ...])\n\n// Read \"1973-09-18\"\nlet row = try Row.fetchOne(db, sql: \"SELECT birthDate ...\")!\nlet dbComponents: DatabaseDateComponents = row[\"birthDate\"]\ndbComponents.format         // .YMD (the actual format found in the database)\ndbComponents.dateComponents // DateComponents\n```\n\n\n### NSNumber, NSDecimalNumber, and Decimal\n\n**NSNumber** and **Decimal** can be stored and fetched from the database just like other [values](#values).\n\nHere is how GRDB supports the various data types supported by SQLite:\n\n|                 |    Integer   |     Double   |    String    |\n|:--------------- |:------------:|:------------:|:------------:|\n| NSNumber        | Read / Write | Read / Write |     Read     |\n| NSDecimalNumber | Read / Write | Read / Write |     Read     |\n| Decimal         |     Read     |     Read     | Read / Write |\n\n- All three types can decode database integers and doubles:\n\n    ```swift\n    let number = try NSNumber.fetchOne(db, sql: \"SELECT 10\")            // NSNumber\n    let number = try NSDecimalNumber.fetchOne(db, sql: \"SELECT 1.23\")   // NSDecimalNumber\n    let number = try Decimal.fetchOne(db, sql: \"SELECT -100\")           // Decimal\n    ```\n    \n- All three types decode database strings as decimal numbers:\n\n    ```swift\n    let number = try NSNumber.fetchOne(db, sql: \"SELECT '10'\")          // NSDecimalNumber (sic)\n    let number = try NSDecimalNumber.fetchOne(db, sql: \"SELECT '1.23'\") // NSDecimalNumber\n    let number = try Decimal.fetchOne(db, sql: \"SELECT '-100'\")         // Decimal\n    ```\n\n- `NSNumber` and `NSDecimalNumber` send 64-bit signed integers and doubles in the database:\n\n    ```swift\n    // INSERT INTO transfer VALUES (10)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSNumber(value: 10)])\n    \n    // INSERT INTO transfer VALUES (10.0)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSNumber(value: 10.0)])\n    \n    // INSERT INTO transfer VALUES (10)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSDecimalNumber(string: \"10.0\")])\n    \n    // INSERT INTO transfer VALUES (10.5)\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [NSDecimalNumber(string: \"10.5\")])\n    ```\n    \n    > **Warning**: since SQLite does not support decimal numbers, sending a non-integer `NSDecimalNumber` can result in a loss of precision during the conversion to double.\n    >\n    > Instead of sending non-integer `NSDecimalNumber` to the database, you may prefer:\n    >\n    > - Send `Decimal` instead (those store decimal strings in the database).\n    > - Send integers instead (for example, store amounts of cents instead of amounts of Euros).\n\n- `Decimal` sends decimal strings in the database:\n\n    ```swift\n    // INSERT INTO transfer VALUES ('10')\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [Decimal(10)])\n    \n    // INSERT INTO transfer VALUES ('10.5')\n    try db.execute(sql: \"INSERT INTO transfer VALUES (?)\", arguments: [Decimal(string: \"10.5\")!])\n    ```\n\n\n### UUID\n\n**UUID** can be stored and fetched from the database just like other [values](#values).\n\nGRDB stores uuids as 16-bytes data blobs, and decodes them from both 16-bytes data blobs and strings such as \"E621E1F8-C36C-495A-93FC-0C247A3E6E5F\".\n\n\n### Swift Enums\n\n**Swift enums** and generally all types that adopt the [RawRepresentable](https://developer.apple.com/library/tvos/documentation/Swift/Reference/Swift_RawRepresentable_Protocol/index.html) protocol can be stored and fetched from the database just like their raw [values](#values):\n\n```swift\nenum Color : Int {\n    case red, white, rose\n}\n\nenum Grape : String {\n    case chardonnay, merlot, riesling\n}\n\n// Declare empty DatabaseValueConvertible adoption\nextension Color : DatabaseValueConvertible { }\nextension Grape : DatabaseValueConvertible { }\n\n// Store\ntry db.execute(\n    sql: \"INSERT INTO wine (grape, color) VALUES (?, ?)\",\n    arguments: [Grape.merlot, Color.red])\n\n// Read\nlet rows = try Row.fetchCursor(db, sql: \"SELECT * FROM wine\")\nwhile let row = try rows.next() {\n    let grape: Grape = row[\"grape\"]\n    let color: Color = row[\"color\"]\n}\n```\n\n**When a database value does not match any enum case**, you get a fatal error. This fatal error can be avoided with the [DatabaseValue](#databasevalue) type:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT 'syrah'\")!\n\nrow[0] as String  // \"syrah\"\nrow[0] as Grape?  // fatal error: could not convert \"syrah\" to Grape.\nrow[0] as Grape   // fatal error: could not convert \"syrah\" to Grape.\n\nlet dbValue: DatabaseValue = row[0]\nif dbValue.isNull {\n    // Handle NULL\n} else if let grape = Grape.fromDatabaseValue(dbValue) {\n    // Handle valid grape\n} else {\n    // Handle unknown grape\n}\n```\n\n\n## Custom SQL Functions and Aggregates\n\n**SQLite lets you define SQL functions and aggregates.**\n\nA custom SQL function or aggregate extends SQLite:\n\n```sql\nSELECT reverse(name) FROM player;   -- custom function\nSELECT maxLength(name) FROM player; -- custom aggregate\n```\n\n- [Custom SQL Functions](#custom-sql-functions)\n- [Custom Aggregates](#custom-aggregates)\n\n\n### Custom SQL Functions\n\nğŸ“– [`DatabaseFunction`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasefunction)\n\nA *function* argument takes an array of [DatabaseValue](#databasevalue), and returns any valid [value](#values) (Bool, Int, String, Date, Swift enums, etc.) The number of database values is guaranteed to be *argumentCount*.\n\nSQLite has the opportunity to perform additional optimizations when functions are \"pure\", which means that their result only depends on their arguments. So make sure to set the *pure* argument to true when possible.\n\n```swift\nlet reverse = DatabaseFunction(\"reverse\", argumentCount: 1, pure: true) { (values: [DatabaseValue]) in\n    // Extract string value, if any...\n    guard let string = String.fromDatabaseValue(values[0]) else {\n        return nil\n    }\n    // ... and return reversed string:\n    return String(string.reversed())\n}\n```\n\nYou make a function available to a database connection through its configuration:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(function: reverse)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // \"oof\"\n    try String.fetchOne(db, sql: \"SELECT reverse('foo')\")!\n}\n```\n\n\n**Functions can take a variable number of arguments:**\n\nWhen you don't provide any explicit *argumentCount*, the function can take any number of arguments:\n\n```swift\nlet averageOf = DatabaseFunction(\"averageOf\", pure: true) { (values: [DatabaseValue]) in\n    let doubles = values.compactMap { Double.fromDatabaseValue($0) }\n    return doubles.reduce(0, +) / Double(doubles.count)\n}\ndb.add(function: averageOf)\n\n// 2.0\ntry Double.fetchOne(db, sql: \"SELECT averageOf(1, 2, 3)\")!\n```\n\n\n**Functions can throw:**\n\n```swift\nlet sqrt = DatabaseFunction(\"sqrt\", argumentCount: 1, pure: true) { (values: [DatabaseValue]) in\n    guard let double = Double.fromDatabaseValue(values[0]) else {\n        return nil\n    }\n    guard double >= 0 else {\n        throw DatabaseError(message: \"invalid negative number\")\n    }\n    return sqrt(double)\n}\ndb.add(function: sqrt)\n\n// SQLite error 1 with statement `SELECT sqrt(-1)`: invalid negative number\ntry Double.fetchOne(db, sql: \"SELECT sqrt(-1)\")!\n```\n\n\n**Use custom functions in the [query interface](#the-query-interface):**\n\n```swift\n// SELECT reverseString(\"name\") FROM player\nPlayer.select { reverseString($0.name) }\n```\n\n\n**GRDB ships with built-in SQL functions that perform unicode-aware string transformations.** See [Unicode](#unicode).\n\n\n### Custom Aggregates\n\nğŸ“– [`DatabaseFunction`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasefunction), [`DatabaseAggregate`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseaggregate)\n\nBefore registering a custom aggregate, you need to define a type that adopts the `DatabaseAggregate` protocol:\n\n```swift\nprotocol DatabaseAggregate {\n    // Initializes an aggregate\n    init()\n    \n    // Called at each step of the aggregation\n    mutating func step(_ dbValues: [DatabaseValue]) throws\n    \n    // Returns the final result\n    func finalize() throws -> DatabaseValueConvertible?\n}\n```\n\nFor example:\n\n```swift\nstruct MaxLength : DatabaseAggregate {\n    var maxLength: Int = 0\n    \n    mutating func step(_ dbValues: [DatabaseValue]) {\n        // At each step, extract string value, if any...\n        guard let string = String.fromDatabaseValue(dbValues[0]) else {\n            return\n        }\n        // ... and update the result\n        let length = string.count\n        if length > maxLength {\n            maxLength = length\n        }\n    }\n    \n    func finalize() -> DatabaseValueConvertible? {\n        maxLength\n    }\n}\n\nlet maxLength = DatabaseFunction(\n    \"maxLength\",\n    argumentCount: 1,\n    pure: true,\n    aggregate: MaxLength.self)\n```\n\nLike [custom SQL Functions](#custom-sql-functions), you make an aggregate function available to a database connection through its configuration:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(function: maxLength)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // Some Int\n    try Int.fetchOne(db, sql: \"SELECT maxLength(name) FROM player\")!\n}\n```\n\nThe `step` method of the aggregate takes an array of [DatabaseValue](#databasevalue). This array contains as many values as the *argumentCount* parameter (or any number of values, when *argumentCount* is omitted).\n\nThe `finalize` method of the aggregate returns the final aggregated [value](#values) (Bool, Int, String, Date, Swift enums, etc.).\n\nSQLite has the opportunity to perform additional optimizations when aggregates are \"pure\", which means that their result only depends on their inputs. So make sure to set the *pure* argument to true when possible.\n\n\n**Use custom aggregates in the [query interface](#the-query-interface):**\n\n```swift\n// SELECT maxLength(\"name\") FROM player\nlet request = Player.select { maxLength($0.name) }\ntry Int.fetchOne(db, request) // Int?\n```\n\n\n## Raw SQLite Pointers\n\n**If not all SQLite APIs are exposed in GRDB, you can still use the [SQLite C Interface](https://www.sqlite.org/c3ref/intro.html) and call [SQLite C functions](https://www.sqlite.org/c3ref/funclist.html).**\n\nTo access the C SQLite functions from SQLCipher or the system SQLite, you need to perform an extra import:\n\n```swift\nimport SQLite3   // System SQLite\nimport SQLCipher // SQLCipher\n\nlet sqliteVersion = String(cString: sqlite3_libversion())\n```\n\nRaw pointers to database connections and statements are available through the `Database.sqliteConnection` and `Statement.sqliteStatement` properties:\n\n```swift\ntry dbQueue.read { db in\n    // The raw pointer to a database connection:\n    let sqliteConnection = db.sqliteConnection\n\n    // The raw pointer to a statement:\n    let statement = try db.makeStatement(sql: \"SELECT ...\")\n    let sqliteStatement = statement.sqliteStatement\n}\n```\n\n> **Note**\n>\n> - Those pointers are owned by GRDB: don't close connections or finalize statements created by GRDB.\n> - GRDB opens SQLite connections in the \"[multi-thread mode](https://www.sqlite.org/threadsafe.html)\", which (oddly) means that **they are not thread-safe**. Make sure you touch raw databases and statements inside their dedicated dispatch queues.\n> - Use the raw SQLite C Interface at your own risk. GRDB won't prevent you from shooting yourself in the foot.\n\n\nRecords\n=======\n\n**On top of the [SQLite API](#sqlite-api), GRDB provides protocols** that help manipulating database rows as regular objects named \"records\":\n\n```swift\ntry dbQueue.write { db in\n    if var place = try Player.fetchOne(db, id: 1) {\n        player.score += 10\n        try player.update(db)\n    }\n}\n```\n\nOf course, you need to open a [database connection], and [create database tables](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema) first.\n\nTo define a record type, define a type and extend it with database protocols:\n\n- `FetchableRecord` makes it possible to fetch instances from the database.\n- `PersistableRecord` makes it possible to save instances into the database.\n- `Codable` (not mandatory) provides ready-made serialization to and from database rows.\n- `Identifiable` (not mandatory) provides extra convenience database methods.\n\nTo make it easier to customize database requests, also nest a `Columns` enum: \n\n```swift\nstruct Player: Codable, Identifiable {\n    var id: Int64\n    var name: String\n    var score: Int\n    var team: String?\n}\n\n// Add database support\nextension Player: FetchableRecord, PersistableRecord {\n    enum Columns {\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n        static let team = Column(CodingKeys.team)\n    }\n}\n```\n\nSee more [examples of record definitions](#examples-of-record-definitions) below.\n\n> Note: if you are familiar with Core Data's NSManagedObject or Realm's Object, you may experience a cultural shock: GRDB records are not uniqued, do not auto-update, and do not lazy-load. This is both a purpose, and a consequence of protocol-oriented programming.\n>\n> Tip: The [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices) guide provides general guidance..\n>\n> Tip: See the [Demo Applications] for sample apps that uses records.\n\n**Overview**\n\n- [Inserting Records](#inserting-records)\n- [Fetching Records](#fetching-records)\n- [Updating Records](#updating-records)\n- [Deleting Records](#deleting-records)\n- [Counting Records](#counting-records)\n\n**Protocols and the Record Class**\n\n- [Record Protocols Overview](#record-protocols-overview)\n- [FetchableRecord Protocol](#fetchablerecord-protocol)\n- [TableRecord Protocol](#tablerecord-protocol)\n- [PersistableRecord Protocol](#persistablerecord-protocol)\n    - [Persistence Methods]\n    - [Persistence Methods and the `RETURNING` clause]\n    - [Persistence Callbacks]\n- [Identifiable Records]\n- [Codable Records]\n- [Record Comparison]\n- [Record Customization Options]\n- [Record Timestamps and Transaction Date]\n\n\n### Inserting Records\n\nTo insert a record in the database, call the `insert` method:\n\n```swift\nlet player = Player(id: 1, name: \"Arthur\", score: 1000)\ntry player.insert(db)\n```\n\n:point_right: `insert` is available for types that adopt the [PersistableRecord] protocol.\n\n\n### Fetching Records\n\nTo fetch records from the database, call a [fetching method](#fetching-methods):\n\n```swift\nlet arthur = try Player.fetchOne(db,            // Player?\n    sql: \"SELECT * FROM players WHERE name = ?\",\n    arguments: [\"Arthur\"])\n\nlet bestPlayers = try Player                    // [Player]\n    .order(\\.score.desc)\n    .limit(10)\n    .fetchAll(db)\n    \nlet spain = try Country.fetchOne(db, id: \"ES\")  // Country?\nlet italy = try Country.find(db, id: \"IT\")      // Country\n```\n\n:point_right: Fetching from raw SQL is available for types that adopt the [FetchableRecord] protocol.\n\n:point_right: Fetching without SQL, using the [query interface](#the-query-interface), is available for types that adopt both [FetchableRecord] and [TableRecord] protocol.\n\n\n### Updating Records\n\nTo update a record in the database, call the `update` method:\n\n```swift\nvar player: Player = ...\nplayer.score = 1000\ntry player.update(db)\n```\n\nIt is possible to [avoid useless updates](#record-comparison):\n\n```swift\n// does not hit the database if score has not changed\ntry player.updateChanges(db) {\n    $0.score = 1000\n}\n```\n\nSee the [query interface](#the-query-interface) for batch updates:\n\n```swift\ntry Player\n    .filter { $0.team == \"red\" }\n    .updateAll(db) { $0.score += 1 }\n```\n\n:point_right: update methods are available for types that adopt the [PersistableRecord] protocol. Batch updates are available on the [TableRecord] protocol.\n\n\n### Deleting Records\n\nTo delete a record in the database, call the `delete` method:\n\n```swift\nlet player: Player = ...\ntry player.delete(db)\n```\n\nYou can also delete by primary key, unique key, or perform batch deletes (see [Delete Requests](#delete-requests)):\n\n```swift\ntry Player.deleteOne(db, id: 1)\ntry Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\ntry Country.deleteAll(db, ids: [\"FR\", \"US\"])\ntry Player\n    .filter { $0.email == nil }\n    .deleteAll(db)\n```\n\n:point_right: delete methods are available for types that adopt the [PersistableRecord] protocol. Batch deletes are available on the [TableRecord] protocol.\n\n\n### Counting Records\n\nTo count records, call the `fetchCount` method:\n\n```swift\nlet playerCount: Int = try Player.fetchCount(db)\n\nlet playerWithEmailCount: Int = try Player\n    .filter { $0.email == nil }\n    .fetchCount(db)\n```\n\n:point_right: `fetchCount` is available for types that adopt the [TableRecord] protocol.\n\n\nDetails follow:\n\n- [Record Protocols Overview](#record-protocols-overview)\n- [FetchableRecord Protocol](#fetchablerecord-protocol)\n- [TableRecord Protocol](#tablerecord-protocol)\n- [PersistableRecord Protocol](#persistablerecord-protocol)\n- [Identifiable Records]\n- [Codable Records]\n- [Record Comparison]\n- [Record Customization Options]\n- [Examples of Record Definitions](#examples-of-record-definitions)\n\n\n## Record Protocols Overview\n\n**GRDB ships with three record protocols**. Your own types will adopt one or several of them, according to the abilities you want to extend your types with.\n\n- [FetchableRecord] is able to **decode database rows**.\n    \n    ```swift\n    struct Place: FetchableRecord { ... }\n    \n    let places = try dbQueue.read { db in\n        try Place.fetchAll(db, sql: \"SELECT * FROM place\")\n    }\n    ```\n    \n    > :bulb: **Tip**: `FetchableRecord` can derive its implementation from the standard `Decodable` protocol. See [Codable Records] for more information.\n    \n    `FetchableRecord` can decode database rows, but it is not able to build SQL requests for you. For that, you also need `TableRecord`:\n    \n- [TableRecord] is able to **generate SQL queries**:\n    \n    ```swift\n    struct Place: TableRecord { ... }\n    \n    let placeCount = try dbQueue.read { db in\n        // Generates and runs `SELECT COUNT(*) FROM place`\n        try Place.fetchCount(db)\n    }\n    ```\n    \n    When a type adopts both `TableRecord` and `FetchableRecord`, it can load from those requests:\n    \n    ```swift\n    struct Place: TableRecord, FetchableRecord { ... }\n    \n    try dbQueue.read { db in\n        let places = try Place.order(\\.title).fetchAll(db)\n        let paris = try Place.fetchOne(id: 1)\n    }\n    ```\n\n- [PersistableRecord] is able to **write**: it can create, update, and delete rows in the database:\n    \n    ```swift\n    struct Place : PersistableRecord { ... }\n    \n    try dbQueue.write { db in\n        try Place.delete(db, id: 1)\n        try Place(...).insert(db)\n    }\n    ```\n    \n    A persistable record can also [compare](#record-comparison) itself against other records, and avoid useless database updates.\n    \n    > :bulb: **Tip**: `PersistableRecord` can derive its implementation from the standard `Encodable` protocol. See [Codable Records] for more information.\n\n\n## FetchableRecord Protocol\n\nğŸ“– [`FetchableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/fetchablerecord)\n\n**The FetchableRecord protocol grants fetching methods to any type** that can be built from a database row:\n\n```swift\nprotocol FetchableRecord {\n    /// Row initializer\n    init(row: Row) throws\n}\n```\n\nFor example:\n\n```swift\nstruct Place {\n    var id: Int64?\n    var title: String\n    var coordinate: CLLocationCoordinate2D\n}\n\nextension Place: FetchableRecord {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n    \n    init(row: Row) {\n        id = row[Columns.id]\n        title = row[Columns.title]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[Columns.latitude],\n            longitude: row[Columns.longitude])\n    }\n}\n```\n\nSee [column values](#column-values) for more information about the `row[]` subscript.\n\nWhen your record type adopts the standard Decodable protocol, you don't have to provide the implementation for `init(row:)`. See [Codable Records] for more information:\n\n```swift\n// That's all\nstruct Player: Decodable, FetchableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n```\n\nFetchableRecord allows adopting types to be fetched from SQL queries:\n\n```swift\ntry Place.fetchCursor(db, sql: \"SELECT ...\", arguments:...) // A Cursor of Place\ntry Place.fetchAll(db, sql: \"SELECT ...\", arguments:...)    // [Place]\ntry Place.fetchSet(db, sql: \"SELECT ...\", arguments:...)    // Set<Place>\ntry Place.fetchOne(db, sql: \"SELECT ...\", arguments:...)    // Place?\n```\n\nSee [fetching methods](#fetching-methods) for information about the `fetchCursor`, `fetchAll`, `fetchSet` and `fetchOne` methods. See [`StatementArguments`] for more information about the query arguments.\n\n> **Note**: for performance reasons, the same row argument to `init(row:)` is reused during the iteration of a fetch query. If you want to keep the row for later use, make sure to store a copy: `self.row = row.copy()`.\n\n> **Note**: The `FetchableRecord.init(row:)` initializer fits the needs of most applications. But some application are more demanding than others. When FetchableRecord does not exactly provide the support you need, have a look at the [Beyond FetchableRecord] chapter.\n\n\n## TableRecord Protocol\n\nğŸ“– [`TableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord)\n\n**The TableRecord protocol** generates SQL for you:\n\n```swift\nprotocol TableRecord {\n    static var databaseTableName: String { get }\n    static var databaseSelection: [any SQLSelectable] { get }\n}\n```\n\nThe `databaseSelection` type property is optional, and documented in the [Columns Selected by a Request] chapter.\n\nThe `databaseTableName` type property is the name of a database table. By default, it is derived from the type name:\n\n```swift\nstruct Place: TableRecord { }\n\nprint(Place.databaseTableName) // prints \"place\"\n```\n\nFor example:\n\n- Place: `place`\n- Country: `country`\n- PostalAddress: `postalAddress`\n- HTTPRequest: `httpRequest`\n- TOEFL: `toefl`\n\nYou can still provide a custom table name:\n\n```swift\nstruct Place: TableRecord {\n    static let databaseTableName = \"location\"\n}\n\nprint(Place.databaseTableName) // prints \"location\"\n```\n\nWhen a type adopts both TableRecord and [FetchableRecord](#fetchablerecord-protocol), it can be fetched using the [query interface](#the-query-interface):\n\n```swift\n// SELECT * FROM place WHERE name = 'Paris'\nlet paris = try Place.filter { $0.name == \"Paris\" }.fetchOne(db)\n```\n\nTableRecord can also fetch deal with primary and unique keys: see [Fetching by Key](#fetching-by-key) and [Testing for Record Existence](#testing-for-record-existence).\n\n\n## PersistableRecord Protocol\n\nğŸ“– [`EncodableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/encodablerecord), [`MutablePersistableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/mutablepersistablerecord), [`PersistableRecord`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/persistablerecord)\n\n**GRDB record types can create, update, and delete rows in the database.**\n\nThose abilities are granted by three protocols:\n\n```swift\n// Defines how a record encodes itself into the database\nprotocol EncodableRecord {\n    /// Defines the values persisted in the database\n    func encode(to container: inout PersistenceContainer) throws\n}\n\n// Adds persistence methods\nprotocol MutablePersistableRecord: TableRecord, EncodableRecord {\n    /// Optional method that lets your adopting type store its rowID upon\n    /// successful insertion. Don't call it directly: it is called for you.\n    mutating func didInsert(_ inserted: InsertionSuccess)\n}\n\n// Adds immutability\nprotocol PersistableRecord: MutablePersistableRecord {\n    /// Non-mutating version of the optional didInsert(_:)\n    func didInsert(_ inserted: InsertionSuccess)\n}\n```\n\nYes, three protocols instead of one. Here is how you pick one or the other:\n\n- **If your type is a class**, choose `PersistableRecord`. On top of that, implement `didInsert(_:)` if the database table has an auto-incremented primary key.\n\n- **If your type is a struct, and the database table has an auto-incremented primary key**, choose `MutablePersistableRecord`, and implement `didInsert(_:)`.\n\n- **Otherwise**, choose `PersistableRecord`, and ignore `didInsert(_:)`.\n\nThe `encode(to:)` method defines which [values](#values) (Bool, Int, String, Date, Swift enums, etc.) are assigned to database columns.\n\nThe optional `didInsert` method lets the adopting type store its rowID after successful insertion, and is only useful for tables that have an auto-incremented primary key. It is called from a protected dispatch queue, and serialized with all database updates.\n\nFor example:\n\n```swift\nextension Place: MutablePersistableRecord {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n    \n    /// The values persisted in the database\n    func encode(to container: inout PersistenceContainer) {\n        container[Columns.id] = id\n        container[Columns.title] = title\n        container[Columns.latitude] = coordinate.latitude\n        container[Columns.longitude] = coordinate.longitude\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n\nvar paris = Place(\n    id: nil,\n    title: \"Paris\",\n    coordinate: CLLocationCoordinate2D(latitude: 48.8534100, longitude: 2.3488000))\n\ntry paris.insert(db)\nparis.id   // some value\n```\n\nWhen your record type adopts the standard Encodable protocol, you don't have to provide the implementation for `encode(to:)`. See [Codable Records] for more information:\n\n```swift\n// That's all\nstruct Player: Encodable, MutablePersistableRecord {\n    var id: Int64?\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n\n### Persistence Methods\n\nTypes that adopt the [PersistableRecord] protocol are given methods that insert, update, and delete:\n\n```swift\n// INSERT\ntry place.insert(db)\nlet insertedPlace = try place.inserted(db) // non-mutating\n\n// UPDATE\ntry place.update(db)\ntry place.update(db, columns: [\"title\"])\n\n// Maybe UPDATE\ntry place.updateChanges(db, from: otherPlace)\ntry place.updateChanges(db) { $0.isFavorite = true }\n\n// INSERT or UPDATE\ntry place.save(db)\nlet savedPlace = place.saved(db) // non-mutating\n\n// UPSERT\ntry place.upsert(db)\nlet insertedPlace = place.upsertAndFetch(db)\n\n// DELETE\ntry place.delete(db)\n\n// EXISTENCE CHECK\nlet exists = try place.exists(db)\n```\n\nSee [Upsert](#upsert) below for more information about upserts.\n\n**The [TableRecord] protocol comes with batch operations**:\n\n```swift\n// UPDATE\ntry Place.updateAll(db, ...)\n\n// DELETE\ntry Place.deleteAll(db)\ntry Place.deleteAll(db, ids:...)\ntry Place.deleteAll(db, keys:...)\ntry Place.deleteOne(db, id:...)\ntry Place.deleteOne(db, key:...)\n```\n\nFor more information about batch updates, see [Update Requests](#update-requests).\n\n- All persistence methods can throw a [DatabaseError](#error-handling).\n\n- `update` and `updateChanges` throw [RecordError] if the database does not contain any row for the primary key of the record.\n\n- `save` makes sure your values are stored in the database. It performs an UPDATE if the record has a non-null primary key, and then, if no row was modified, an INSERT. It directly performs an INSERT if the record has no primary key, or a null primary key.\n\n- `delete` and `deleteOne` returns whether a database row was deleted or not. `deleteAll` returns the number of deleted rows. `updateAll` returns the number of updated rows. `updateChanges` returns whether a database row was updated or not.\n\n**All primary keys are supported**, including composite primary keys that span several columns, and the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html).\n\n**To customize persistence methods**, you provide [Persistence Callbacks], described below. Do not attempt at overriding the ready-made persistence methods.\n\n### Upsert\n\n[UPSERT](https://www.sqlite.org/lang_UPSERT.html) is an SQLite feature that causes an INSERT to behave as an UPDATE or a no-op if the INSERT would violate a uniqueness constraint (primary key or unique index).\n\n> **Note**: Upsert apis are available from SQLite 3.35.0+: iOS 15.0+, macOS 12.0+, tvOS 15.0+, watchOS 8.0+, or with a [custom SQLite build] or [SQLCipher](#encryption).\n>\n> **Note**: With regard to [persistence callbacks](#available-callbacks), an upsert behaves exactly like an insert. In particular: the `aroundInsert(_:)` and `didInsert(_:)` callbacks reports the rowid of the inserted or updated row; `willUpdate`, `aroundUpdate`, `didUpdate` are not called.\n\n[PersistableRecord] provides three upsert methods:\n\n- `upsert(_:)`\n    \n    Inserts or updates a record.\n    \n    The upsert behavior is triggered by a violation of any uniqueness constraint on the table (primary key or unique index). In case of conflict, all columns but the primary key are overwritten with the inserted values:\n    \n    ```swift\n    struct Player: Encodable, PersistableRecord {\n        var id: Int64\n        var name: String\n        var score: Int\n    }\n    \n    // INSERT INTO player (id, name, score)\n    // VALUES (1, 'Arthur', 1000)\n    // ON CONFLICT DO UPDATE SET\n    //   name = excluded.name,\n    //   score = excluded.score\n    let player = Player(id: 1, name: \"Arthur\", score: 1000)\n    try player.upsert(db)\n    ```\n\n- `upsertAndFetch(_:onConflict:doUpdate:)` (requires [FetchableRecord] conformance)\n\n    Inserts or updates a record, and returns the upserted record.\n    \n    The `onConflict` and `doUpdate` arguments let you further control the upsert behavior. Make sure you check the [SQLite UPSERT documentation](https://www.sqlite.org/lang_UPSERT.html) for detailed information.\n    \n    - `onConflict`: the \"conflict target\" is the array of columns in the uniqueness constraint (primary key or unique index) that triggers the upsert.\n        \n        If empty (the default), all uniqueness constraint are considered.\n    \n    - `doUpdate`: a closure that returns columns assignments to perform in case of conflict. Other columns are overwritten with the inserted values.\n        \n        By default, all inserted columns but the primary key and the conflict target are overwritten.\n    \n    In the example below, we upsert the new vocabulary word \"jovial\". It is inserted if that word is not already in the dictionary. Otherwise, `count` is incremented, `isTainted` is not overwritten, and `kind` is overwritten:\n    \n    ```swift\n    // CREATE TABLE vocabulary(\n    //   word TEXT NOT NULL PRIMARY KEY,\n    //   kind TEXT NOT NULL,\n    //   isTainted BOOLEAN DEFAULT 0,\n    //   count INT DEFAULT 1))\n    struct Vocabulary: Encodable, PersistableRecord {\n        var word: String\n        var kind: String\n        var isTainted: Bool\n    }\n    \n    // INSERT INTO vocabulary(word, kind, isTainted)\n    // VALUES('jovial', 'adjective', 0)\n    // ON CONFLICT(word) DO UPDATE SET \\\n    //   count = count + 1,   -- on conflict, count is incremented\n    //   kind = excluded.kind -- on conflict, kind is overwritten\n    // RETURNING *\n    let vocabulary = Vocabulary(word: \"jovial\", kind: \"adjective\", isTainted: false)\n    let upserted = try vocabulary.upsertAndFetch(\n        db, onConflict: [\"word\"],\n        doUpdate: { _ in\n            [Column(\"count\") += 1,            // on conflict, count is incremented\n             Column(\"isTainted\").noOverwrite] // on conflict, isTainted is NOT overwritten\n        })\n    ```\n    \n    The `doUpdate` closure accepts an `excluded` TableAlias argument that refers to the inserted values that trigger the conflict. You can use it to specify an explicit overwrite, or to perform a computation. In the next example, the upsert keeps the maximum date in case of conflict:\n    \n    ```swift\n    // INSERT INTO message(id, text, date)\n    // VALUES(...)\n    // ON CONFLICT DO UPDATE SET \\\n    //   text = excluded.text,\n    //   date = MAX(date, excluded.date)\n    // RETURNING *\n    let upserted = try message.upsertAndFetch(doUpdate: { excluded in\n        // keep the maximum date in case of conflict\n        [Column(\"date\").set(to: max(Column(\"date\"), excluded[\"date\"]))]\n    })\n    ```\n\n- `upsertAndFetch(_:as:onConflict:doUpdate:)` (does not require [FetchableRecord] conformance)\n\n    This method is identical to `upsertAndFetch(_:onConflict:doUpdate:)` described above, but you can provide a distinct [FetchableRecord] record type as a result, in order to specify the returned columns.\n\n### Persistence Methods and the `RETURNING` clause\n\nSQLite is able to return values from a inserted, updated, or deleted row, with the [`RETURNING` clause](https://www.sqlite.org/lang_returning.html).\n\n> **Note**: Support for the `RETURNING` clause is available from SQLite 3.35.0+: iOS 15.0+, macOS 12.0+, tvOS 15.0+, watchOS 8.0+, or with a [custom SQLite build] or [SQLCipher](#encryption).\n\nThe `RETURNING` clause helps dealing with database features such as auto-incremented ids, default values, and [generated columns](https://sqlite.org/gencol.html). You can, for example, insert a few columns and fetch the default or generated ones in one step.\n\nGRDB uses the `RETURNING` clause in all persistence methods that contain `AndFetch` in their name.\n\nFor example, given a database table with an auto-incremented primary key and a default score:\n\n```swift\ntry dbQueue.write { db in\n    try db.execute(sql: \"\"\"\n        CREATE TABLE player(\n          id INTEGER PRIMARY KEY AUTOINCREMENT,\n          name TEXT NOT NULL,\n          score INTEGER NOT NULL DEFAULT 1000)\n        \"\"\")\n}\n```\n\nYou can define a record type with full database information, and another partial record type that deals with a subset of columns:\n\n```swift\n// A player with full database information\nstruct Player: Codable, PersistableRecord, FetchableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// A partial player\nstruct PartialPlayer: Encodable, PersistableRecord {\n    static let databaseTableName = \"player\"\n    var name: String\n    \n    typealias Columns = Player.Columns\n}\n```\n\nAnd now you can get a full player by inserting a partial one:\n\n```swift\ntry dbQueue.write { db in\n    let partialPlayer = PartialPlayer(name: \"Alice\")\n    \n    // INSERT INTO player (name) VALUES ('Alice') RETURNING *\n    let player = try partialPlayer.insertAndFetch(db, as: Player.self)\n    print(player.id)    // The inserted id\n    print(player.name)  // The inserted name\n    print(player.score) // The default score\n}\n```\n\nFor extra precision, you can select only the columns you need, and fetch the desired value from the provided prepared [`Statement`]:\n\n```swift\ntry dbQueue.write { db in\n    let partialPlayer = PartialPlayer(name: \"Alice\")\n    \n    // INSERT INTO player (name) VALUES ('Alice') RETURNING score\n    let score = try partialPlayer.insertAndFetch(db) { statement in\n        try Int.fetchOne(statement)\n    } select: {\n        [$0.score]\n    }\n    print(score) // Prints 1000, the default score\n}\n```\n\nThere are other similar persistence methods, such as `upsertAndFetch`, `saveAndFetch`, `updateAndFetch`, `updateChangesAndFetch`, etc. They all behave like `upsert`, `save`, `update`, `updateChanges`, except that they return saved values. For example:\n\n```swift\n// Save and return the saved player\nlet savedPlayer = try player.saveAndFetch(db)\n```\n\nSee [Persistence Methods], [Upsert](#upsert), and [`updateChanges` methods](#the-updatechanges-methods) for more information.\n\n**Batch operations** can return updated or deleted values:\n\n> **Warning**: Make sure you check the [documentation of the `RETURNING` clause](https://www.sqlite.org/lang_returning.html#limitations_and_caveats), which describes important limitations and caveats for batch operations.\n\n```swift\nlet request = Player.filter(...)...\n\n// Fetch all deleted players\n// DELETE FROM player RETURNING *\nlet deletedPlayers = try request.deleteAndFetchAll(db) // [Player]\n\n// Fetch a selection of columns from the deleted rows\n// DELETE FROM player RETURNING name\nlet statement = try request.deleteAndFetchStatement(db) { [$0.name] }\nlet deletedNames = try String.fetchSet(statement)\n\n// Fetch all updated players\n// UPDATE player SET score = score + 10 RETURNING *\nlet updatedPlayers = try request.updateAndFetchAll(db) { [$0.score += 10] } // [Player]\n\n// Fetch a selection of columns from the updated rows\n// UPDATE player SET score = score + 10 RETURNING score\nlet statement = try request.updateAndFetchStatement(db) {\n    [$0.score += 10]\n} select: {\n    [$0.score]\n}\nlet updatedScores = try Int.fetchAll(statement)\n```\n\n\n### Persistence Callbacks\n\nYour custom type may want to perform extra work when the persistence methods are invoked.\n\nTo this end, your record type can implement **persistence callbacks**. Callbacks are methods that get called at certain moments of a record's life cycle. With callbacks it is possible to write code that will run whenever an record is inserted, updated, or deleted.\n\nIn order to use a callback method, you need to provide its implementation. For example, a frequently used callback is `didInsert`, in the case of auto-incremented database ids:\n\n```swift\nstruct Player: MutablePersistableRecord {\n    var id: Int64?\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n\ntry dbQueue.write { db in\n    var player = Player(id: nil, ...)\n    try player.insert(db)\n    print(player.id) // didInsert was called: prints some non-nil id\n}\n```\n\nCallbacks can also help implementing record validation:\n\n```swift\nstruct Link: PersistableRecord {\n    var url: URL\n    \n    func willSave(_ db: Database) throws {\n        if url.host == nil {\n            throw ValidationError(\"url must be absolute.\")\n        }\n    }\n}\n\ntry link.insert(db) // Calls the willSave callback\ntry link.update(db) // Calls the willSave callback\ntry link.save(db)   // Calls the willSave callback\ntry link.upsert(db) // Calls the willSave callback\n```\n\n#### Available Callbacks\n\nHere is a list with all the available [persistence callbacks], listed in the same order in which they will get called during the respective operations:\n\n- Inserting a record (all `record.insert` and `record.upsert` methods)\n    - `willSave`\n    - `aroundSave`\n    - `willInsert`\n    - `aroundInsert`\n    - `didInsert`\n    - `didSave`\n    \n- Updating a record (all `record.update` methods)\n    - `willSave`\n    - `aroundSave`\n    - `willUpdate`\n    - `aroundUpdate`\n    - `didUpdate`\n    - `didSave`\n    \n- Deleting a record (only the `record.delete(_:)` method)\n    - `willDelete`\n    - `aroundDelete`\n    - `didDelete`\n\nFor detailed information about each callback, check the [reference](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/mutablepersistablerecord/).\n\nIn the `MutablePersistableRecord` protocol, `willInsert` and `didInsert` are mutating methods. In `PersistableRecord`, they are not mutating.\n\n> **Note**: The `record.save(_:)` method performs an UPDATE if the record has a non-null primary key, and then, if no row was modified, an INSERT. It directly performs an INSERT if the record has no primary key, or a null primary key. It triggers update and/or insert callbacks accordingly.\n>\n> **Warning**: Callbacks are only invoked from persistence methods called on record instances. Callbacks are not invoked when you call a type method, perform a batch operations, or execute raw SQL.\n>\n> **Warning**: When a `did***` callback is invoked, do not assume that the change is actually persisted on disk, because the database may still be inside an uncommitted transaction. When you need to handle transaction completions, use the [afterNextTransaction(onCommit:onRollback:)](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)). For example:\n>\n> ```swift\n> struct PictureFile: PersistableRecord {\n>     var path: String\n>     \n>     func willDelete(_ db: Database) {\n>         db.afterNextTransaction { _ in\n>             try? deleteFileOnDisk()\n>         }\n>     }\n> }\n> ```\n\n\n## Identifiable Records\n\n**When a record type maps a table with a single-column primary key, it is recommended to have it adopt the standard [Identifiable] protocol.**\n\n```swift\nstruct Player: Identifiable, FetchableRecord, PersistableRecord {\n    var id: Int64 // fulfills the Identifiable requirement\n    var name: String\n    var score: Int\n}\n```\n\nWhen `id` has a [database-compatible type](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible) (Int64, Int, String, UUID, ...), the `Identifiable` conformance unlocks type-safe record and request methods:\n\n```swift\nlet player = try Player.find(db, id: 1)               // Player\nlet player = try Player.fetchOne(db, id: 1)           // Player?\nlet players = try Player.fetchAll(db, ids: [1, 2, 3]) // [Player]\nlet players = try Player.fetchSet(db, ids: [1, 2, 3]) // Set<Player>\n\nlet request = Player.filter(id: 1)\nlet request = Player.filter(ids: [1, 2, 3])\n\ntry Player.deleteOne(db, id: 1)\ntry Player.deleteAll(db, ids: [1, 2, 3])\n```\n\n> **Note**: Not all record types can be made `Identifiable`, and not all tables have a single-column primary key. GRDB provides other methods that deal with primary and unique keys, but they won't check the type of their arguments:\n> \n> ```swift\n> // Available on non-Identifiable types\n> try Player.fetchOne(db, key: 1)\n> try Player.fetchOne(db, key: [\"email\": \"arthur@example.com\"])\n> try Country.fetchAll(db, keys: [\"FR\", \"US\"])\n> try Citizenship.fetchOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n> \n> let request = Player.filter(key: 1)\n> let request = Player.filter(keys: [1, 2, 3])\n> \n> try Player.deleteOne(db, key: 1)\n> try Player.deleteAll(db, keys: [1, 2, 3])\n> ```\n\n> **Note**: It is not recommended to use `Identifiable` on record types that use an auto-incremented primary key:\n>\n> ```swift\n> // AVOID declaring Identifiable conformance when key is auto-incremented\n> struct Player {\n>     var id: Int64? // Not an id suitable for Identifiable\n>     var name: String\n>     var score: Int\n> }\n> \n> extension Player: FetchableRecord, MutablePersistableRecord {\n>     // Update auto-incremented id upon successful insertion\n>     mutating func didInsert(_ inserted: InsertionSuccess) {\n>         id = inserted.rowID\n>     }\n> }\n> ```\n>\n> For a detailed rationale, please see [issue #1435](https://github.com/groue/GRDB.swift/issues/1435#issuecomment-1740857712).\n\nSome database tables have a single-column primary key which is not called \"id\":\n\n```swift\ntry db.create(table: \"country\") { t in\n    t.primaryKey(\"isoCode\", .text)\n    t.column(\"name\", .text).notNull()\n    t.column(\"population\", .integer).notNull()\n}\n```\n\nIn this case, `Identifiable` conformance can be achieved, for example, by returning the primary key column from the `id` property:\n\n```swift\nstruct Country: Identifiable, FetchableRecord, PersistableRecord {\n    var isoCode: String\n    var name: String\n    var population: Int\n    \n    // Fulfill the Identifiable requirement\n    var id: String { isoCode }\n}\n\nlet france = try dbQueue.read { db in\n    try Country.fetchOne(db, id: \"FR\")\n}\n```\n\n\n## Codable Records\n\nRecord types that adopt an archival protocol ([Codable, Encodable or Decodable](https://developer.apple.com/documentation/foundation/archives_and_serialization/encoding_and_decoding_custom_types)) get free database support just by declaring conformance to the desired [record protocols](#record-protocols-overview):\n\n```swift\n// Declare a record...\nstruct Player: Codable, FetchableRecord, PersistableRecord {\n    var id: Int64\n    var name: String\n    var score: Int\n    \n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n\n// ...and there you go:\ntry dbQueue.write { db in\n    try Player(id: 1, name: \"Arthur\", score: 100).insert(db)\n    let players = try Player.order(\\.score.desc).fetchAll(db)\n}\n```\n\nCodable records encode and decode their properties according to their own implementation of the Encodable and Decodable protocols. Yet databases have specific requirements:\n\n- Properties are always coded according to their preferred database representation, when they have one (all [values](#values) that adopt the [`DatabaseValueConvertible`] protocol).\n- You can customize the encoding and decoding of dates and uuids.\n- Complex properties (arrays, dictionaries, nested structs, etc.) are stored as JSON.\n\nFor more information about Codable records, see:\n\n- [JSON Columns]\n- [Column Names Coding Strategies]\n- [Data, Date, and UUID Coding Strategies]\n- [The userInfo Dictionary]\n- [Tip: Derive Columns from Coding Keys](#tip-derive-columns-from-coding-keys)\n\n> :bulb: **Tip**: see the [Demo Applications] for sample code that uses Codable records.\n\n\n### JSON Columns\n\nWhen a [Codable record](#codable-records) contains a property that is not a simple [value](#values) (Bool, Int, String, Date, Swift enums, etc.), that value is encoded and decoded as a **JSON string**. For example:\n\n```swift\nenum AchievementColor: String, Codable {\n    case bronze, silver, gold\n}\n\nstruct Achievement: Codable {\n    var name: String\n    var color: AchievementColor\n}\n\nstruct Player: Codable, FetchableRecord, PersistableRecord {\n    var name: String\n    var score: Int\n    var achievements: [Achievement] // stored in a JSON column\n}\n\ntry dbQueue.write { db in\n    // INSERT INTO player (name, score, achievements)\n    // VALUES (\n    //   'Arthur',\n    //   100,\n    //   '[{\"color\":\"gold\",\"name\":\"Use Codable Records\"}]')\n    let achievement = Achievement(name: \"Use Codable Records\", color: .gold)\n    let player = Player(name: \"Arthur\", score: 100, achievements: [achievement])\n    try player.insert(db)\n}\n```\n\nGRDB uses the standard [JSONDecoder](https://developer.apple.com/documentation/foundation/jsondecoder) and [JSONEncoder](https://developer.apple.com/documentation/foundation/jsonencoder) from Foundation. By default, Data values are handled with the `.base64` strategy, Date with the `.millisecondsSince1970` strategy, and non conforming floats with the `.throw` strategy.\n\nYou can customize the JSON format by implementing those methods:\n\n```swift\nprotocol FetchableRecord {\n    static func databaseJSONDecoder(for column: String) -> JSONDecoder\n}\n\nprotocol EncodableRecord {\n    static func databaseJSONEncoder(for column: String) -> JSONEncoder\n}\n```\n\n> :bulb: **Tip**: Make sure you set the JSONEncoder `sortedKeys` option. This option makes sure that the JSON output is stable. This stability is required for [Record Comparison] to work as expected, and database observation tools such as [ValueObservation] to accurately recognize changed records.\n\n\n### Column Names Coding Strategies\n\nBy default, [Codable Records] store their values into database columns that match their coding keys: the `teamID` property is stored into the `teamID` column.\n\nThis behavior can be overridden, so that you can, for example, store the `teamID` property into the `team_id` column:\n\n```swift\nprotocol FetchableRecord {\n    static var databaseColumnDecodingStrategy: DatabaseColumnDecodingStrategy { get }\n}\n\nprotocol EncodableRecord {\n    static var databaseColumnEncodingStrategy: DatabaseColumnEncodingStrategy { get }\n}\n```\n\nSee [DatabaseColumnDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasecolumndecodingstrategy) and [DatabaseColumnEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasecolumnencodingstrategy/) to learn about all available strategies.\n\n\n### Data, Date, and UUID Coding Strategies\n\nBy default, [Codable Records] encode and decode their Data properties as blobs, and Date and UUID properties as described in the general [Date and DateComponents](#date-and-datecomponents) and [UUID](#uuid) chapters.\n\nTo sum up: dates encode themselves in the \"YYYY-MM-DD HH:MM:SS.SSS\" format, in the UTC time zone, and decode a variety of date formats and timestamps. UUIDs encode themselves as 16-bytes data blobs, and decode both 16-bytes data blobs and strings such as \"E621E1F8-C36C-495A-93FC-0C247A3E6E5F\".\n\nThose behaviors can be overridden:\n\n```swift\nprotocol FetchableRecord {\n    static func databaseDataDecodingStrategy(for column: String) -> DatabaseDataDecodingStrategy\n    static func databaseDateDecodingStrategy(for column: String) -> DatabaseDateDecodingStrategy\n}\n\nprotocol EncodableRecord {\n    static func databaseDataEncodingStrategy(for column: String) -> DatabaseDataEncodingStrategy\n    static func databaseDateEncodingStrategy(for column: String) -> DatabaseDateEncodingStrategy\n    static func databaseUUIDEncodingStrategy(for column: String) -> DatabaseUUIDEncodingStrategy\n}\n```\n\nSee [DatabaseDataDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedatadecodingstrategy/), [DatabaseDateDecodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedatedecodingstrategy/), [DatabaseDataEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedataencodingstrategy/), [DatabaseDateEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasedateencodingstrategy/), and [DatabaseUUIDEncodingStrategy](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseuuidencodingstrategy/) to learn about all available strategies.\n\nThere is no customization of uuid decoding, because UUID can already decode all its encoded variants (16-bytes blobs and uuid strings, both uppercase and lowercase).\n\nCustomized coding strategies apply:\n\n- When encoding and decoding database rows to and from records (fetching and persistence methods).\n- In requests by single-column primary key: `fetchOne(_:id:)`, `filter(id:)`, `deleteAll(_:keys:)`, etc.\n\n*They do not apply* in other requests based on data, date, or uuid values.\n\nSo make sure that those are properly encoded in your requests. For example:\n\n```swift\nstruct Player: Codable, FetchableRecord, PersistableRecord, Identifiable {\n    // UUIDs are stored as strings\n    static func databaseUUIDEncodingStrategy(for column: String) -> DatabaseUUIDEncodingStrategy {\n        .uppercaseString\n    }\n    \n    var id: UUID\n    ...\n}\n\ntry dbQueue.write { db in\n    let uuid = UUID()\n    let player = Player(id: uuid, ...)\n    \n    // OK: inserts a player in the database, with a string uuid\n    try player.insert(db)\n    \n    // OK: performs a string-based query, finds the inserted player\n    _ = try Player.filter(id: uuid).fetchOne(db)\n\n    // NOT OK: performs a blob-based query, fails to find the inserted player\n    _ = try Player.filter { $0.id == uuid }.fetchOne(db)\n    \n    // OK: performs a string-based query, finds the inserted player\n    _ = try Player.filter { $0.id == uuid.uuidString }.fetchOne(db)\n}\n```\n\n\n### The userInfo Dictionary\n\nYour [Codable Records] can be stored in the database, but they may also have other purposes. In this case, you may need to customize their implementations of `Decodable.init(from:)` and `Encodable.encode(to:)`, depending on the context.\n\nThe standard way to provide such context is the `userInfo` dictionary. Implement those properties:\n\n```swift\nprotocol FetchableRecord {\n    static var databaseDecodingUserInfo: [CodingUserInfoKey: Any] { get }\n}\n\nprotocol EncodableRecord {\n    static var databaseEncodingUserInfo: [CodingUserInfoKey: Any] { get }\n}\n```\n\nFor example, here is a Player type that customizes its decoding:\n\n```swift\n// A key that holds a decoder's name\nlet decoderName = CodingUserInfoKey(rawValue: \"decoderName\")!\n\nstruct Player: FetchableRecord, Decodable {\n    init(from decoder: Decoder) throws {\n        // Print the decoder name\n        let decoderName = decoder.userInfo[decoderName] as? String\n        print(\"Decoded from \\(decoderName ?? \"unknown decoder\")\")\n        ...\n    }\n}\n```\n\nYou can have a specific decoding from JSON...\n\n```swift\n// prints \"Decoded from JSON\"\nlet decoder = JSONDecoder()\ndecoder.userInfo = [decoderName: \"JSON\"]\nlet player = try decoder.decode(Player.self, from: jsonData)\n```\n\n... and another one from database rows:\n\n```swift\nextension Player: FetchableRecord {\n    static var databaseDecodingUserInfo: [CodingUserInfoKey: Any] {\n        [decoderName: \"database row\"]\n    }\n}\n\n// prints \"Decoded from database row\"\nlet player = try Player.fetchOne(db, ...)\n```\n\n> **Note**: make sure the `databaseDecodingUserInfo` and `databaseEncodingUserInfo` properties are explicitly declared as `[CodingUserInfoKey: Any]`. If they are not, the Swift compiler may silently miss the protocol requirement, resulting in sticky empty userInfo.\n\n\n### Tip: Derive Columns from Coding Keys\n\nCodable types are granted with a [CodingKeys](https://developer.apple.com/documentation/foundation/archives_and_serialization/encoding_and_decoding_custom_types) enum. You can use them to safely define database columns:\n\n```swift\nstruct Player: Codable {\n    var id: Int64\n    var name: String\n    var score: Int\n}\n\nextension Player: FetchableRecord, PersistableRecord {\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n        static let score = Column(CodingKeys.score)\n    }\n}\n```\n\nSee the [query interface](#the-query-interface) and [Recommended Practices for Designing Record Types](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordrecommendedpractices) for further information.\n\n\n## Record Comparison\n\n**Records that adopt the [EncodableRecord] protocol can compare against other records, or against previous versions of themselves.**\n\nThis helps avoiding costly UPDATE statements when a record has not been edited.\n\n- [The `updateChanges` Methods](#the-updatechanges-methods)\n- [The `databaseEquals` Method](#the-databaseequals-method)\n- [The `databaseChanges` and `hasDatabaseChanges` Methods](#the-databasechanges-and-hasdatabasechanges-methods)\n\n\n### The `updateChanges` Methods\n\nThe `updateChanges` methods perform a database update of the changed columns only (and does nothing if record has no change).\n\n- `updateChanges(_:from:)`\n\n    This method lets you compare two records:\n\n    ```swift\n    if let oldPlayer = try Player.fetchOne(db, id: 42) {\n        var newPlayer = oldPlayer\n        newPlayer.score = 100\n        if try newPlayer.updateChanges(db, from: oldPlayer) {\n            print(\"player was modified, and updated in the database\")\n        } else {\n            print(\"player was not modified, and database was not hit\")\n        }\n    }\n    ```\n\n- `updateChanges(_:modify:)`\n    \n    This method lets you update a record in place:\n    \n    ```swift\n    if var player = try Player.fetchOne(db, id: 42) {\n        let modified = try player.updateChanges(db) {\n            $0.score = 100\n        }\n        if modified {\n            print(\"player was modified, and updated in the database\")\n        } else {\n            print(\"player was not modified, and database was not hit\")\n        }\n    }\n    ```\n\n### The `databaseEquals` Method\n\nThis method returns whether two records have the same database representation:\n\n```swift\nlet oldPlayer: Player = ...\nvar newPlayer: Player = ...\nif newPlayer.databaseEquals(oldPlayer) == false {\n    try newPlayer.save(db)\n}\n```\n\n> **Note**: The comparison is performed on the database representation of records. As long as your record type adopts the EncodableRecord protocol, you don't need to care about Equatable.\n\n\n### The `databaseChanges` and `hasDatabaseChanges` Methods\n\n`databaseChanges(from:)` returns a dictionary of differences between two records:\n\n```swift\nlet oldPlayer = Player(id: 1, name: \"Arthur\", score: 100)\nlet newPlayer = Player(id: 1, name: \"Arthur\", score: 1000)\nfor (column, oldValue) in try newPlayer.databaseChanges(from: oldPlayer) {\n    print(\"\\(column) was \\(oldValue)\")\n}\n// prints \"score was 100\"\n```\n\nFor an efficient algorithm which synchronizes the content of a database table with a JSON payload, check [groue/SortedDifference](https://github.com/groue/SortedDifference).\n\n\n## Record Customization Options\n\nGRDB records come with many default behaviors, that are designed to fit most situations. Many of those defaults can be customized for your specific needs:\n\n- [Persistence Callbacks]: define what happens when you call a persistence method such as `player.insert(db)`\n- [Conflict Resolution]: Run `INSERT OR REPLACE` queries, and generally define what happens when a persistence method violates a unique index.\n- [Columns Selected by a Request]: define which columns are selected by requests such as `Player.fetchAll(db)`.\n- [Beyond FetchableRecord]: the FetchableRecord protocol is not the end of the story.\n\n[Codable Records] have a few extra options:\n\n- [JSON Columns]: control the format of JSON columns.\n- [Column Names Coding Strategies]: control how coding keys are turned into column names\n- [Date and UUID Coding Strategies]: control the format of Date and UUID properties in your Codable records.\n- [The userInfo Dictionary]: adapt your Codable implementation for the database.\n\n\n### Conflict Resolution\n\n**Insertions and updates can create conflicts**: for example, a query may attempt to insert a duplicate row that violates a unique index.\n\nThose conflicts normally end with an error. Yet SQLite let you alter the default behavior, and handle conflicts with specific policies. For example, the `INSERT OR REPLACE` statement handles conflicts with the \"replace\" policy which replaces the conflicting row instead of throwing an error.\n\nThe [five different policies](https://www.sqlite.org/lang_conflict.html) are: abort (the default), replace, rollback, fail, and ignore.\n\n**SQLite let you specify conflict policies at two different places:**\n\n- In the definition of the database table:\n    \n    ```swift\n    // CREATE TABLE player (\n    //     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    //     email TEXT UNIQUE ON CONFLICT REPLACE\n    // )\n    try db.create(table: \"player\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"email\", .text).unique(onConflict: .replace) // <--\n    }\n    \n    // Despite the unique index on email, both inserts succeed.\n    // The second insert replaces the first row:\n    try db.execute(sql: \"INSERT INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    try db.execute(sql: \"INSERT INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    ```\n    \n- In each modification query:\n    \n    ```swift\n    // CREATE TABLE player (\n    //     id INTEGER PRIMARY KEY AUTOINCREMENT,\n    //     email TEXT UNIQUE\n    // )\n    try db.create(table: \"player\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"email\", .text).unique()\n    }\n    \n    // Again, despite the unique index on email, both inserts succeed.\n    try db.execute(sql: \"INSERT OR REPLACE INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    try db.execute(sql: \"INSERT OR REPLACE INTO player (email) VALUES (?)\", arguments: [\"arthur@example.com\"])\n    ```\n\nWhen you want to handle conflicts at the query level, specify a custom `persistenceConflictPolicy` in your type that adopts the PersistableRecord protocol. It will alter the INSERT and UPDATE queries run by the `insert`, `update` and `save` [persistence methods]:\n\n```swift\nprotocol MutablePersistableRecord {\n    /// The policy that handles SQLite conflicts when records are\n    /// inserted or updated.\n    ///\n    /// This property is optional: its default value uses the ABORT\n    /// policy for both insertions and updates, so that GRDB generate\n    /// regular INSERT and UPDATE queries.\n    static var persistenceConflictPolicy: PersistenceConflictPolicy { get }\n}\n\nstruct Player : MutablePersistableRecord {\n    static let persistenceConflictPolicy = PersistenceConflictPolicy(\n        insert: .replace,\n        update: .replace)\n}\n\n// INSERT OR REPLACE INTO player (...) VALUES (...)\ntry player.insert(db)\n```\n\n> **Note**: If you specify the `ignore` policy for inserts, the [`didInsert` callback](#persistence-callbacks) will be called with some random id in case of failed insert. You can detect failed insertions with `insertAndFetch`:\n>     \n> ```swift\n> // How to detect failed `INSERT OR IGNORE`:\n> // INSERT OR IGNORE INTO player ... RETURNING *\n> do {\n>     let insertedPlayer = try player.insertAndFetch(db) {\n>     // Successful insertion\n> catch RecordError.recordNotFound {\n>     // Failed insertion due to IGNORE policy\n> }\n> ```\n>\n> **Note**: The `replace` policy may have to delete rows so that inserts and updates can succeed. Those deletions are not reported to [transaction observers](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactionobserver) (this might change in a future release of SQLite).\n\n### Beyond FetchableRecord\n\n**Some GRDB users eventually discover that the [FetchableRecord] protocol does not fit all situations.** Use cases that are not well handled by FetchableRecord include:\n\n- Your application needs polymorphic row decoding: it decodes some type or another, depending on the values contained in a database row.\n\n- Your application needs to decode rows with a context: each decoded value should be initialized with some extra value that does not come from the database.\n\nSince those use cases are not well handled by FetchableRecord, don't try to implement them on top of this protocol: you'll just fight the framework.\n\n\n## Examples of Record Definitions\n\nWe will show below how to declare a record type for the following database table:\n\n```swift\ntry dbQueue.write { db in\n    try db.create(table: \"place\") { t in\n        t.autoIncrementedPrimaryKey(\"id\")\n        t.column(\"title\", .text).notNull()\n        t.column(\"isFavorite\", .boolean).notNull().defaults(to: false)\n        t.column(\"longitude\", .double).notNull()\n        t.column(\"latitude\", .double).notNull()\n    }\n}\n```\n\nEach one of the three examples below is correct. You will pick one or the other depending on your personal preferences and the requirements of your application:\n\n<details>\n  <summary>Define a Codable struct, and adopt the record protocols you need</summary>\n\nThis is the shortest way to define a record type.\n\nSee the [Record Protocols Overview](#record-protocols-overview), and [Codable Records] for more information.\n\n```swift\nstruct Place: Codable {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    private var latitude: CLLocationDegrees\n    private var longitude: CLLocationDegrees\n    \n    var coordinate: CLLocationCoordinate2D {\n        get {\n            CLLocationCoordinate2D(\n                latitude: latitude,\n                longitude: longitude)\n        }\n        set {\n            latitude = newValue.latitude\n            longitude = newValue.longitude\n        }\n    }\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let title = Column(CodingKeys.title)\n        static let isFavorite = Column(CodingKeys.isFavorite)\n        static let latitude = Column(CodingKeys.latitude)\n        static let longitude = Column(CodingKeys.longitude)\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord { }\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n<details>\n  <summary>Define a plain struct, and adopt the record protocols you need</summary>\n\nSee the [Record Protocols Overview](#record-protocols-overview) for more information.\n    \n```swift\nstruct Place {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    var coordinate: CLLocationCoordinate2D\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(\"id\")\n        static let title = Column(\"title\")\n        static let isFavorite = Column(\"isFavorite\")\n        static let latitude = Column(\"latitude\")\n        static let longitude = Column(\"longitude\")\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord {\n    /// Creates a record from a database row\n    init(row: Row) {\n        id = row[Columns.id]\n        title = row[Columns.title]\n        isFavorite = row[Columns.isFavorite]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[Columns.latitude],\n            longitude: row[Columns.longitude])\n    }\n}\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    /// The values persisted in the database\n    func encode(to container: inout PersistenceContainer) {\n        container[Columns.id] = id\n        container[Columns.title] = title\n        container[Columns.isFavorite] = isFavorite\n        container[Columns.latitude] = coordinate.latitude\n        container[Columns.longitude] = coordinate.longitude\n    }\n    \n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n<details>\n  <summary>Define a plain struct optimized for fetching performance</summary>\n\nThis struct derives its persistence methods from the standard Encodable protocol (see [Codable Records]), but performs optimized row decoding by accessing database columns with numeric indexes.\n\nSee the [Record Protocols Overview](#record-protocols-overview) for more information.\n    \n```swift\nstruct Place: Encodable {\n    var id: Int64?\n    var title: String\n    var isFavorite: Bool\n    private var latitude: CLLocationDegrees\n    private var longitude: CLLocationDegrees\n    \n    var coordinate: CLLocationCoordinate2D {\n        get {\n            CLLocationCoordinate2D(\n                latitude: latitude,\n                longitude: longitude)\n        }\n        set {\n            latitude = newValue.latitude\n            longitude = newValue.longitude\n        }\n    }\n}\n\n// SQL generation\nextension Place: TableRecord {\n    /// The table columns\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let title = Column(CodingKeys.title)\n        static let isFavorite = Column(CodingKeys.isFavorite)\n        static let latitude = Column(CodingKeys.latitude)\n        static let longitude = Column(CodingKeys.longitude)\n    }\n    \n    /// Arrange the selected columns and lock their order\n    static var databaseSelection: [any SQLSelectable] {\n        [\n            Columns.id,\n            Columns.title,\n            Columns.favorite,\n            Columns.latitude,\n            Columns.longitude,\n        ]\n    }\n}\n\n// Fetching methods\nextension Place: FetchableRecord {\n    /// Creates a record from a database row\n    init(row: Row) {\n        // For high performance, use numeric indexes that match the\n        // order of Place.databaseSelection\n        id = row[0]\n        title = row[1]\n        isFavorite = row[2]\n        coordinate = CLLocationCoordinate2D(\n            latitude: row[3],\n            longitude: row[4])\n    }\n}\n\n// Persistence methods\nextension Place: MutablePersistableRecord {\n    // Update auto-incremented id upon successful insertion\n    mutating func didInsert(_ inserted: InsertionSuccess) {\n        id = inserted.rowID\n    }\n}\n```\n\n</details>\n\n\nThe Query Interface\n===================\n\n**The query interface lets you write pure Swift instead of SQL:**\n\n```swift\ntry dbQueue.write { db in\n    // Update database schema\n    try db.create(table: \"player\") { t in ... }\n    \n    // Fetch records\n    let bestPlayers = try Player\n        .order(\\.score.desc)\n        .limit(10)\n        .fetchAll(db)\n    \n    // Count\n    let count = try Player\n        .filter { $0.score >= 1000 }\n        .fetchCount(db)\n    \n    // Batch update\n    try Player\n        .filter { $0.team == \"Reds\" }\n        .updateAll(db) { $0.score += 100 }\n    \n    // Batch delete\n    try Player\n        .filter { $0.score == 0 }\n        .deleteAll(db)\n}\n```\n\nYou need to open a [database connection] before you can query the database.\n\nPlease bear in mind that the query interface can not generate all possible SQL queries. You may also *prefer* writing SQL, and this is just OK. From little snippets to full queries, your SQL skills are welcome:\n\n```swift\ntry dbQueue.write { db in\n    // Update database schema (with SQL)\n    try db.execute(sql: \"CREATE TABLE player (...)\")\n    \n    // Fetch records (with SQL)\n    let bestPlayers = try Player.fetchAll(db, sql: \"\"\"\n        SELECT * FROM player ORDER BY score DESC LIMIT 10\n        \"\"\")\n    \n    // Count (with an SQL snippet)\n    let minScore = 1000\n    let count = try Player\n        .filter(sql: \"score >= ?\", arguments: [minScore])\n        .fetchCount(db)\n    \n    // Update (with SQL)\n    try db.execute(sql: \"UPDATE player SET score = score + 100 WHERE team = 'Reds'\")\n    \n    // Delete (with SQL)\n    try db.execute(sql: \"DELETE FROM player WHERE score = 0\")\n}\n```\n\nSo don't miss the [SQL API](#sqlite-api).\n\n> **Note**: the generated SQL may change between GRDB releases, without notice: don't have your application rely on any specific SQL output.\n\n- [The Database Schema](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseschema)\n- [Requests](#requests)\n- [Expressions](#expressions)\n    - [SQL Operators](#sql-operators)\n    - [SQL Functions](#sql-functions)\n- [Embedding SQL in Query Interface Requests]\n- [Fetching from Requests]\n- [Fetching by Key](#fetching-by-key)\n- [Testing for Record Existence](#testing-for-record-existence)\n- [Fetching Aggregated Values](#fetching-aggregated-values)\n- [Delete Requests](#delete-requests)\n- [Update Requests](#update-requests)\n- [Custom Requests](#custom-requests)\n- :blue_book: [Associations and Joins](Documentation/AssociationsBasics.md)\n- :blue_book: [Common Table Expressions]\n- :blue_book: [Query Interface Organization]\n\n## Requests\n\nğŸ“– [`QueryInterfaceRequest`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest), [`Table`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/table)\n\n**The query interface requests** let you fetch values from the database:\n\n```swift\nlet request = Player.filter { $0.email != nil }.order(\\.name)\nlet players = try request.fetchAll(db)  // [Player]\nlet count = try request.fetchCount(db)  // Int\n```\n\nQuery interface requests usually start from **a type** that adopts the `TableRecord` protocol:\n\n```swift\nstruct Player: TableRecord { ... }\n\n// The request for all players:\nlet request = Player.all()\nlet players = try request.fetchAll(db) // [Player]\n```\n\nWhen you can not use a record type, use `Table`:\n\n```swift\n// The request for all rows from the player table:\nlet table = Table(\"player\")\nlet request = table.all()\nlet rows = try request.fetchAll(db)    // [Row]\n\n// The request for all players from the player table:\nlet table = Table<Player>(\"player\")\nlet request = table.all()\nlet players = try request.fetchAll(db) // [Player]\n```\n\n> **Note**: all examples in the documentation below use a record type, but you can always substitute a `Table` instead.\n\nNext, declare the table **columns** that you want to use for filtering, or sorting, in a nested type named `Columns`:\n\n```swift\nextension Player {\n    enum Columns {\n        static let id = Column(\"id\")\n        static let name = Column(\"name\")\n    }\n}\n```\n\nWhen `Player` is `Codable`, you'll prefer defining columns from coding keys:\n\n```swift\nextension Player {\n    enum Columns {\n        static let id = Column(CodingKeys.id)\n        static let name = Column(CodingKeys.name)\n    }\n}\n```\n\nYou can now build requests with the following methods: `all`, `none`, `select`, `distinct`, `filter`, `matching`, `group`, `having`, `order`, `reversed`, `limit`, `joining`, `including`, `with`. All those methods return another request, which you can further refine by applying another method: `Player.select(...).filter(...).order(...)`.\n\n- [`all()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord/all()), [`none()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerecord/none()): the requests for all rows, or no row.\n\n    ```swift\n    // SELECT * FROM player\n    Player.all()\n    ```\n    \n    By default, all columns are selected. See [Columns Selected by a Request].\n\n- [`select(...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/selectionrequest/select(_:)-ruzy) and [`select(..., as:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/select(_:as:)-58954) define the selected columns. See [Columns Selected by a Request].\n    \n    ```swift\n    // SELECT name FROM player\n    Player.select(\\.name, as: String.self)\n    ```\n\n- [`selectID()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/selectID()) is available on [Identifiable Records]. It supports all tables that have a single-column primary key:\n\n    ```swift\n    // SELECT id FROM player\n    Player.selectID()\n    \n    // SELECT id FROM player WHERE name IS NOT NULL\n    Player.filter { $0.name != nil }.selectID()\n    ```\n\n- [`annotated(with: expression...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/selectionrequest/annotated(with:)-1satx) extends the selection.\n\n    ```swift\n    // SELECT *, (score + bonus) AS total FROM player\n    Player.annotated { ($0.score + $0.bonus).forKey(\"total\") }\n    ```\n\n- [`annotated(with: aggregate)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/annotated(with:)-74xfs) extends the selection with [association aggregates](Documentation/AssociationsBasics.md#association-aggregates).\n    \n    ```swift\n    // SELECT team.*, COUNT(DISTINCT player.id) AS playerCount\n    // FROM team\n    // LEFT JOIN player ON player.teamId = team.id\n    // GROUP BY team.id\n    Team.annotated(with: Team.players.count)\n    ```\n\n- [`annotated(withRequired: association)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/annotated(withrequired:)) and [`annotated(withOptional: association)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/annotated(withoptional:)) extends the selection with [Associations].\n    \n    ```swift\n    // SELECT player.*, team.color\n    // FROM player\n    // JOIN team ON team.id = player.teamId\n    Player.annotated(withRequired: Player.team.select(\\.color))\n    ```\n\n- [`distinct()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/distinct()) performs uniquing.\n    \n    ```swift\n    // SELECT DISTINCT name FROM player\n    Player.select(\\.name, as: String.self).distinct()\n    ```\n\n- [`filter(expression)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/filteredrequest/filter(_:)-6xr3d) applies conditions.\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (1, 2, 3)\n    Player.filter { [1,2,3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE (name IS NOT NULL) AND (height > 1.75)\n    Player.filter { $0.name != nil && $0.height > 1.75 }\n    ```\n\n- [`filter(id:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(id:)) and [`filter(ids:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(ids:)) are type-safe methods available on [Identifiable Records]:\n    \n    ```swift\n    // SELECT * FROM player WHERE id = 1\n    Player.filter(id: 1)\n    \n    // SELECT * FROM country WHERE isoCode IN ('FR', 'US')\n    Country.filter(ids: [\"FR\", \"US\"])\n    ```\n    \n- [`filter(key:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(key:)-1p9sq) and [`filter(keys:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/filter(keys:)-6ggt1) apply conditions on primary and unique keys:\n    \n    ```swift\n    // SELECT * FROM player WHERE id = 1\n    Player.filter(key: 1)\n    \n    // SELECT * FROM country WHERE isoCode IN ('FR', 'US')\n    Country.filter(keys: [\"FR\", \"US\"])\n    \n    // SELECT * FROM citizenship WHERE citizenId = 1 AND countryCode = 'FR'\n    Citizenship.filter(key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n    \n    // SELECT * FROM player WHERE email = 'arthur@example.com'\n    Player.filter(key: [\"email\": \"arthur@example.com\"])\n    ```\n\n- `matching(pattern)` ([FTS3](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/matching(_:)-3s3zr), [FTS5](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/matching(_:)-7c1e8)) performs [full-text search](Documentation/FullTextSearch.md).\n    \n    ```swift\n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    let pattern = FTS3Pattern(matchingAllTokensIn: \"SQLite database\")\n    Document.matching(pattern)\n    ```\n    \n    When the pattern is nil, no row will match.\n\n- [`group(expression, ...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/aggregatingrequest/group(_:)-2g7br) groups rows.\n    \n    ```swift\n    // SELECT name, MAX(score) FROM player GROUP BY name\n    Player\n        .select { [$0.name, max($0.score)] }\n        .group(\\.name)\n    ```\n\n- [`having(expression)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/aggregatingrequest/having(_:)-2oggh) applies conditions on grouped rows.\n    \n    ```swift\n    // SELECT team, MAX(score) FROM player GROUP BY team HAVING MIN(score) >= 1000\n    Player\n        .select { [$0.team, max($0.score)] }\n        .group(\\.team)\n        .having { min($0.score) >= 1000 }\n    ```\n\n- [`having(aggregate)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/having(_:)) applies conditions on grouped rows, according to an [association aggregate](Documentation/AssociationsBasics.md#association-aggregates).\n    \n    ```swift\n    // SELECT team.*\n    // FROM team\n    // LEFT JOIN player ON player.teamId = team.id\n    // GROUP BY team.id\n    // HAVING COUNT(DISTINCT player.id) >= 5\n    Team.having(Team.players.count >= 5)\n    ```\n\n- [`order(ordering, ...)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/orderedrequest/order(_:)-9d0hr) sorts.\n    \n    ```swift\n    // SELECT * FROM player ORDER BY name\n    Player.order(\\.name)\n    \n    // SELECT * FROM player ORDER BY score DESC\n    Player.order(\\.score.desc)\n    \n    // SELECT * FROM player ORDER BY score DESC, name\n    Player.order { [$0.score.desc, $0.name] }\n    ```\n    \n    SQLite considers NULL values to be smaller than any other values for sorting purposes. Hence, NULLs naturally appear at the beginning of an ascending ordering and at the end of a descending ordering. With a [custom SQLite build], this can be changed using `.ascNullsLast` and `.descNullsFirst`:\n    \n    ```swift\n    // SELECT * FROM player ORDER BY score ASC NULLS LAST\n    Player.order(\\.name.ascNullsLast)\n    ```\n    \n    Each `order` call clears any previous ordering:\n    \n    ```swift\n    // SELECT * FROM player ORDER BY name\n    Player.order(\\.score).order(\\.name)\n    ```\n\n- [`reversed()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/orderedrequest/reversed()) reverses the eventual orderings.\n    \n    ```swift\n    // SELECT * FROM player ORDER BY score ASC, name DESC\n    Player.order { [$0.score.desc, $0.name] }.reversed()\n    ```\n    \n    If no ordering was already specified, this method has no effect:\n    \n    ```swift\n    // SELECT * FROM player\n    Player.all().reversed()\n    ```\n\n- [`limit(limit, offset: offset)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/limit(_:offset:)) limits and pages results.\n    \n    ```swift\n    // SELECT * FROM player LIMIT 5\n    Player.limit(5)\n    \n    // SELECT * FROM player LIMIT 5 OFFSET 10\n    Player.limit(5, offset: 10)\n    ```\n\n- [`joining(required:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/joining(required:)), [`joining(optional:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/joining(optional:)), [`including(required:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(required:)), [`including(optional:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(optional:)), and [`including(all:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/joinablerequest/including(all:)) fetch and join records through [Associations].\n    \n    ```swift\n    // SELECT player.*, team.*\n    // FROM player\n    // JOIN team ON team.id = player.teamId\n    Player.including(required: Player.team)\n    ```\n\n- [`with(cte)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/derivablerequest/with(_:)) embeds a [common table expression]:\n    \n    ```swift\n    // WITH ... SELECT * FROM player\n    let cte = CommonTableExpression(...)\n    Player.with(cte)\n    ```\n\n- Other requests that involve the primary key:\n    \n    - [`selectPrimaryKey(as:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/selectprimarykey(as:)) selects the primary key.\n    \n        ```swift\n        // SELECT id FROM player\n        Player.selectPrimaryKey(as: Int64.self)    // QueryInterfaceRequest<Int64>\n        \n        // SELECT code FROM country\n        Country.selectPrimaryKey(as: String.self)  // QueryInterfaceRequest<String>\n        \n        // SELECT citizenId, countryCode FROM citizenship\n        Citizenship.selectPrimaryKey(as: Row.self) // QueryInterfaceRequest<Row>\n        ```\n        \n    - [`orderByPrimaryKey()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/orderbyprimarykey()) sorts by primary key.\n        \n        ```swift\n        // SELECT * FROM player ORDER BY id\n        Player.orderByPrimaryKey()\n        \n        // SELECT * FROM country ORDER BY code\n        Country.orderByPrimaryKey()\n        \n        // SELECT * FROM citizenship ORDER BY citizenId, countryCode\n        Citizenship.orderByPrimaryKey()\n        ```\n    \n    - [`groupByPrimaryKey()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/tablerequest/groupbyprimarykey()) groups rows by primary key.\n\n\nYou can refine requests by chaining those methods:\n\n```swift\n// SELECT * FROM player WHERE (email IS NOT NULL) ORDER BY name\nPlayer.order(\\.name).filter { $0.email != nil }\n```\n\nThe `select`, `order`, `group`, and `limit` methods ignore and replace previously applied selection, orderings, grouping, and limits. On the opposite, `filter`, `matching`, and `having` methods extend the query:\n\n```swift\nPlayer                          // SELECT * FROM player\n    .filter { $0.name != nil }  // WHERE (name IS NOT NULL)\n    .filter { $0.email != nil } //        AND (email IS NOT NULL)\n    .order(\\.name)              // - ignored -\n    .reversed()                 // - ignored -\n    .order(\\.score)             // ORDER BY score\n    .limit(20, offset: 40)      // - ignored -\n    .limit(10)                  // LIMIT 10\n```\n\n\nRaw SQL snippets are also accepted, with eventual [arguments](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments):\n\n```swift\n// SELECT DATE(creationDate), COUNT(*) FROM player WHERE name = 'Arthur' GROUP BY date(creationDate)\nPlayer\n    .select(sql: \"DATE(creationDate), COUNT(*)\")\n    .filter(sql: \"name = ?\", arguments: [\"Arthur\"])\n    .group(sql: \"DATE(creationDate)\")\n```\n\n\n### Columns Selected by a Request\n\nBy default, query interface requests select all columns:\n\n```swift\n// SELECT * FROM player\nstruct Player: TableRecord { ... }\nlet request = Player.all()\n\n// SELECT * FROM player\nlet table = Table(\"player\")\nlet request = table.all()\n```\n\n**The selection can be changed for each individual requests, or in the case of record-based requests, for all requests built from this record type.**\n\nThe `select(...)` and `select(..., as:)` methods change the selection of a single request (see [Fetching from Requests] for detailed information):\n\n```swift\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\nlet request = Player.select({ max($0.score) }, as: Int.self)\nlet maxScore = try request.fetchOne(db)      // Int?\n```\n\nThe default selection for a record type is controlled by the `databaseSelection` property. For example:\n\n```swift\n// Select a limited set of columns\nstruct RestrictedPlayer: TableRecord {\n    static let databaseTableName = \"player\"\n    \n    enum Columns {\n        static let id = Column(\"id\")\n        static let name = Column(\"name\")\n    }\n    \n    static var databaseSelection: [any SQLSelectable] {\n        [Columns.id, Columns.name]\n    }\n}\n\n// SELECT id, name FROM player\nlet request = RestrictedPlayer.all()\n```\n\n```swift\n// Select all but a few columns\nstruct Player : TableRecord {\n    static var databaseSelection: [any SQLSelectable] { \n        [.allColumns(excluding: [\"generatedColumn\"])]\n    }\n}\n\n// SELECT id, name FROM player\nlet request = RestrictedPlayer.all()\n```\n\n```swift\n// Select all columns and more\nstruct ExtendedPlayer : TableRecord {\n    static let databaseTableName = \"player\"\n    static var databaseSelection: [any SQLSelectable] {\n        [.allColumns, .rowID]\n    }\n}\n\n// SELECT *, rowid FROM player\nlet request = ExtendedPlayer.all()\n```\n\n> **Note**: make sure the `databaseSelection` property is explicitly declared as `[any SQLSelectable]`. If it is not, the Swift compiler may silently miss the protocol requirement, resulting in sticky `SELECT *` requests. To verify your setup, see the [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql) FAQ.\n\n\n## Expressions\n\nFeed [requests](#requests) with SQL expressions built from your Swift code:\n\n\n### SQL Operators\n\nğŸ“– [`SQLSpecificExpressible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlspecificexpressible)\n\nGRDB comes with a Swift version of many SQLite [built-in operators](https://sqlite.org/lang_expr.html#operators), listed below. But not all: see [Embedding SQL in Query Interface Requests] for a way to add support for missing SQL operators.\n\n- `=`, `<>`, `<`, `<=`, `>`, `>=`, `IS`, `IS NOT`\n    \n    Comparison operators are based on the Swift operators `==`, `!=`, `===`, `!==`, `<`, `<=`, `>`, `>=`:\n    \n    ```swift\n    // SELECT * FROM player WHERE (name = 'Arthur')\n    Player.filter { $0.name == \"Arthur\" }\n    \n    // SELECT * FROM player WHERE (name IS NULL)\n    Player.filter { $0.name == nil }\n    \n    // SELECT * FROM player WHERE (score IS 1000)\n    Player.filter { $0.score === 1000 }\n    \n    // SELECT * FROM rectangle WHERE width < height\n    Rectangle.filter { $0.width < $0.height }\n    ```\n    \n    Subqueries are supported:\n    \n    ```swift\n    // SELECT * FROM player WHERE score = (SELECT max(score) FROM player)\n    let maximumScore = Player.select { max($0.score) }\n    Player.filter { $0.score == maximumScore }\n    \n    // SELECT * FROM player WHERE score = (SELECT max(score) FROM player)\n    let maximumScore = SQLRequest(\"SELECT max(score) FROM player\")\n    Player.filter { $0.score == maximumScore }\n    ```\n    \n    > **Note**: SQLite string comparison, by default, is case-sensitive and not Unicode-aware. See [string comparison](#string-comparison) if you need more control.\n\n- `*`, `/`, `+`, `-`\n    \n    SQLite arithmetic operators are derived from their Swift equivalent:\n    \n    ```swift\n    // SELECT ((temperature * 1.8) + 32) AS fahrenheit FROM planet\n    Planet.select { ($0.temperature * 1.8 + 32).forKey(\"fahrenheit\") }\n    ```\n    \n    > **Note**: an expression like `nameColumn + \"rrr\"` will be interpreted by SQLite as a numerical addition (with funny results), not as a string concatenation. See the `concat` operator below.\n    \n    When you want to join a sequence of expressions with the `+` or `*` operator, use `joined(operator:)`:\n    \n    ```swift\n    // SELECT score + bonus + 1000 FROM player\n    Player.select {\n        [$0.score, $0.bonus, 1000.databaseValue].joined(operator: .add)\n    }\n    ```\n    \n    Note in the example above how you concatenate raw values: `1000.databaseValue`. A plain `1000` would not compile.\n    \n    When the sequence is empty, `joined(operator: .add)` returns 0, and `joined(operator: .multiply)` returns 1.\n\n- `&`, `|`, `~`, `<<`, `>>`\n    \n    Bitwise operations (bitwise and, or, not, left shift, right shift) are derived from their Swift equivalent:\n    \n    ```swift\n    // SELECT mask & 2 AS isRocky FROM planet\n    Planet.select { ($0.mask & 2).forKey(\"isRocky\") }\n    ```\n\n- `||`\n    \n    Concatenate several strings:\n    \n    ```swift\n    // SELECT firstName || ' ' || lastName FROM player\n    Player.select {\n        [$0.firstName, \" \".databaseValue, $0.lastName].joined(operator: .concat)\n    }\n    ```\n    \n    Note in the example above how you concatenate raw strings: `\" \".databaseValue`. A plain `\" \"` would not compile.\n    \n    When the sequence is empty, `joined(operator: .concat)` returns the empty string.\n\n- `AND`, `OR`, `NOT`\n    \n    The SQL logical operators are derived from the Swift `&&`, `||` and `!`:\n    \n    ```swift\n    // SELECT * FROM player WHERE ((NOT isVerified) OR (score < 1000))\n    Player.filter { !$0.isVerified || $0.score < 1000 }\n    ```\n    \n    When you want to join a sequence of expressions with the `AND` or `OR` operator, use `joined(operator:)`:\n    \n    ```swift\n    // SELECT * FROM player WHERE (isVerified AND (score >= 1000) AND (name IS NOT NULL))\n    Player.filter {\n        [$0.isVerified, $0.score >= 1000, $0.name != nil].joined(operator: .and)\n    }\n    ```\n    \n    When the sequence is empty, `joined(operator: .and)` returns true, and `joined(operator: .or)` returns false:\n\n- `BETWEEN`, `IN`, `NOT IN`\n    \n    To check inclusion in a Swift sequence (array, set, rangeâ€¦), call the `contains` method:\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (1, 2, 3)\n    Player.filter { [1, 2, 3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE id NOT IN (1, 2, 3)\n    Player.filter { ![1, 2, 3].contains($0.id) }\n    \n    // SELECT * FROM player WHERE score BETWEEN 0 AND 1000\n    Player.filter { (0...1000).contains($0.score) }\n    \n    // SELECT * FROM player WHERE (score >= 0) AND (score < 1000)\n    Player.filter { (0..<1000).contains($0.score) }\n    \n    // SELECT * FROM player WHERE initial BETWEEN 'A' AND 'N'\n    Player.filter { (\"A\"...\"N\").contains($0.initial) }\n    \n    // SELECT * FROM player WHERE (initial >= 'A') AND (initial < 'N')\n    Player.filter { (\"A\"..<\"N\").contains($0.initial) }\n    ```\n    \n    To check inclusion inside a subquery, call the `contains` method as well:\n    \n    ```swift\n    // SELECT * FROM player WHERE id IN (SELECT playerId FROM playerSelection)\n    let selectedPlayerIds = PlayerSelection.select(\\.playerId)\n    Player.filter { selectedPlayerIds.contains($0.id) }\n    \n    // SELECT * FROM player WHERE id IN (SELECT playerId FROM playerSelection)\n    let selectedPlayerIds = SQLRequest(\"SELECT playerId FROM playerSelection\")\n    Player.filter { selectedPlayerIds.contains($0.id) }\n    ```\n    \n    To check inclusion inside a [common table expression], call the `contains` method as well:\n    \n    ```swift\n    // WITH selectedName AS (...)\n    // SELECT * FROM player WHERE name IN selectedName\n    let cte = CommonTableExpression(named: \"selectedName\", ...)\n    Player\n        .with(cte)\n        .filter { cte.contains($0.name) }\n    ```\n    \n    > **Note**: SQLite string comparison, by default, is case-sensitive and not Unicode-aware. See [string comparison](#string-comparison) if you need more control.\n\n- `EXISTS`, `NOT EXISTS`\n    \n    To check if a subquery would return rows, call the `exists` method:\n    \n    ```swift\n    // Teams that have at least one other player\n    //\n    //  SELECT * FROM team\n    //  WHERE EXISTS (SELECT * FROM player WHERE teamId = team.id)\n    let teamAlias = TableAlias<Team>()\n    let player = Player.filter { $0.teamId == teamAlias.id }\n    let teams = Team.aliased(teamAlias).filter(player.exists())\n    \n    // Teams that have no player\n    //\n    //  SELECT * FROM team\n    //  WHERE NOT EXISTS (SELECT * FROM player WHERE teamId = team.id)\n    let teams = Team.aliased(teamAlias).filter(!player.exists())\n    ```\n    \n    In the above example, you use a `TableAlias` in order to let a subquery refer to a column from another table.\n    \n    In the next example, which involves the same table twice, the table alias requires an explicit disambiguation with `TableAlias(name:)`:\n    \n    ```swift    \n    // Players who coach at least one other player\n    //\n    //  SELECT coach.* FROM player coach\n    //  WHERE EXISTS (SELECT * FROM player WHERE coachId = coach.id)\n    let coachAlias = TableAlias<Player>(name: \"coach\")\n    let coachedPlayer = Player.filter { $0.coachId == coachAlias.id }\n    let coaches = Player.aliased(coachAlias).filter(coachedPlayer.exists())\n    ```\n    \n    Finally, subqueries can also be expressed as SQL, with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT coach.* FROM player coach\n    // WHERE EXISTS (SELECT * FROM player WHERE coachId = coach.id)\n    let coachedPlayer = SQLRequest(\"SELECT * FROM player WHERE coachId = \\(coachAlias.id)\")\n    let coaches = Player.aliased(coachAlias).filter(coachedPlayer.exists())\n    ```\n    \n- `LIKE`\n    \n    The SQLite LIKE operator is available as the `like` method:\n    \n    ```swift\n    // SELECT * FROM player WHERE (email LIKE '%@example.com')\n    Player.filter { $0.email.like(\"%@example.com\") }\n    \n    // SELECT * FROM book WHERE (title LIKE '%10\\%%' ESCAPE '\\')\n    Player.filter { $0.email.like(\"%10\\\\%%\", escape: \"\\\\\") }\n    ```\n    \n    > **Note**: the SQLite LIKE operator is case-insensitive but not Unicode-aware. For example, the expression `'a' LIKE 'A'` is true but `'Ã¦' LIKE 'Ã†'` is false.\n\n- `MATCH`\n    \n    The full-text MATCH operator is available through [FTS3Pattern](Documentation/FullTextSearch.md#fts3pattern) (for FTS3 and FTS4 tables) and [FTS5Pattern](Documentation/FullTextSearch.md#fts5pattern) (for FTS5):\n    \n    FTS3 and FTS4:\n    \n    ```swift\n    let pattern = FTS3Pattern(matchingAllTokensIn: \"SQLite database\")\n    \n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    Document.matching(pattern)\n    \n    // SELECT * FROM document WHERE content MATCH 'sqlite database'\n    Document.filter { $0.content.match(pattern) }\n    ```\n    \n    FTS5:\n    \n    ```swift\n    let pattern = FTS5Pattern(matchingAllTokensIn: \"SQLite database\")\n    \n    // SELECT * FROM document WHERE document MATCH 'sqlite database'\n    Document.matching(pattern)\n    ```\n- `AS`\n    \n    To give an alias to an expression, use the `forKey` method:\n    \n    ```swift\n    // SELECT (score + bonus) AS total\n    // FROM player\n    Player.select { ($0.score + $0.bonus).forKey(\"total\") }\n    ```\n    \n    If you need to refer to this aliased column in another place of the request, use a detached column:\n    \n    ```swift\n    // SELECT (score + bonus) AS total\n    // FROM player \n    // ORDER BY total\n    Player\n        .select { ($0.score + $0.bonus).forKey(\"total\") }\n        .order(Column(\"total\").detached)\n    ```\n    \n    The detached column `Column(\"total\").detached` is not considered as a part of the \"player\" table, so it is always rendered as `total` in the generated SQL, even when the request involves other tables via an [association](Documentation/AssociationsBasics.md) or a [common table expression].\n\n\n### SQL Functions\n\nğŸ“– [`SQLSpecificExpressible`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlspecificexpressible)\n\nGRDB comes with a Swift version of many SQLite [built-in functions](https://sqlite.org/lang_corefunc.html), listed below. But not all: see [Embedding SQL in Query Interface Requests] for a way to add support for missing SQL functions.\n\n- `ABS`, `AVG`, `COALESCE`, `COUNT`, `DATETIME`, `JULIANDAY`, `LENGTH`, `MAX`, `MIN`, `SUM`, `TOTAL`:\n    \n    Those are based on the `abs`, `average`, `coalesce`, `count`, `dateTime`, `julianDay`, `length`, `max`, `min`, `sum`, and `total` Swift functions:\n    \n    ```swift\n    // SELECT MIN(score), MAX(score) FROM player\n    Player.select { [min($0.score), max($0.score)] }\n    \n    // SELECT COUNT(name) FROM player\n    Player.select { count($0.name) }\n    \n    // SELECT COUNT(DISTINCT name) FROM player\n    Player.select { count(distinct: $0.name) }\n    \n    // SELECT JULIANDAY(date, 'start of year') FROM game\n    Game.select { julianDay($0.date, .startOfYear) }\n    ```\n    \n    For more information about the functions `dateTime` and `julianDay`, see [Date And Time Functions](https://www.sqlite.org/lang_datefunc.html).\n\n- `CAST`\n\n    Use the `cast` Swift function:\n    \n    ```swift\n    // SELECT (CAST(wins AS REAL) / games) AS successRate FROM player\n    Player.select { (cast($0.wins, as: .real) / $0.games).forKey(\"successRate\") }\n    ```\n    \n    See [CAST expressions](https://www.sqlite.org/lang_expr.html#castexpr) for more information about SQLite conversions.\n\n- `IFNULL`\n    \n    Use the Swift `??` operator:\n    \n    ```swift\n    // SELECT IFNULL(name, 'Anonymous') FROM player\n    Player.select { $0.name ?? \"Anonymous\" }\n    \n    // SELECT IFNULL(name, email) FROM player\n    Player.select { $0.name ?? $0.email }\n    ```\n\n- `LOWER`, `UPPER`\n    \n    The query interface does not give access to those SQLite functions. Nothing against them, but they are not unicode aware.\n    \n    Instead, GRDB extends SQLite with SQL functions that call the Swift built-in string functions `capitalized`, `lowercased`, `uppercased`, `localizedCapitalized`, `localizedLowercased` and `localizedUppercased`:\n    \n    ```swift\n    Player.select { $0.name.uppercased() }\n    ```\n    \n    > **Note**: When *comparing* strings, you'd rather use a [collation](#string-comparison):\n    >\n    > ```swift\n    > let name: String = ...\n    >\n    > // Not recommended\n    > Player.filter { $0.name.uppercased() == name.uppercased() }\n    >\n    > // Better\n    > Player.filter { $0.name.collating(.caseInsensitiveCompare) == name }\n    > ```\n\n- Custom SQL functions and aggregates\n    \n    You can apply your own [custom SQL functions and aggregates](#custom-functions-):\n    \n    ```swift\n    let myFunction = DatabaseFunction(\"myFunction\", ...)\n    \n    // SELECT myFunction(name) FROM player\n    Player.select { myFunction($0.name) }\n    ```\n\n## Embedding SQL in Query Interface Requests\n\nYou will sometimes want to extend your query interface requests with SQL snippets. This can happen because GRDB does not provide a Swift interface for some SQL function or operator, or because you want to use an SQLite construct that GRDB does not support.\n\nSupport for extensibility is large, but not unlimited. All the SQL queries built by the query interface request have the shape below. _If you need something else, you'll have to use [raw SQL requests](#sqlite-api)._\n\n```sql\nWITH ...     -- 1\nSELECT ...   -- 2\nFROM ...     -- 3\nJOIN ...     -- 4\nWHERE ...    -- 5\nGROUP BY ... -- 6\nHAVING ...   -- 7\nORDER BY ... -- 8\nLIMIT ...    -- 9\n```\n\n1. `WITH ...`: see [Common Table Expressions].\n\n2. `SELECT ...`\n\n    The selection can be provided as raw SQL:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let request = Player.select(sql: \"IFNULL(name, 'O''Brien'), score\")\n    \n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select(sql: \"IFNULL(name, ?), score\", arguments: [suffix])\n    ```\n\n    The selection can be provided with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien'), score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select(literal: \"IFNULL(name, \\(defaultName)), score\")\n    ```\n    \n    The selection can be provided with a mix of Swift and [SQL Interpolation]:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien') AS displayName, score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select {\n        let displayName: SQL = \"IFNULL(\\($0.name), \\(defaultName)) AS displayName\"\n        return [displayName, $0.score]\n    }\n    ```\n    \n    When the custom SQL snippet should behave as a full-fledged expression, with support for the `+` Swift operator, the `forKey` aliasing method, and all other [SQL Operators](#sql-operators), build an _expression literal_ with the `SQL.sqlExpression` method:\n    \n    ```swift\n    // SELECT IFNULL(name, 'O''Brien') AS displayName, score FROM player\n    let defaultName = \"O'Brien\"\n    let request = Player.select {\n        let displayName = SQL(\"IFNULL(\\($0.name), \\(defaultName))\").sqlExpression\n        return [displayName.forKey(\"displayName\"), $0.score]\n    }\n    ```\n    \n    Such expression literals allow you to build a reusable support library of SQL functions or operators that are missing from the query interface. For example, you can define a Swift `date` function:\n    \n    ```swift\n    func date(_ value: some SQLSpecificExpressible) -> SQLExpression {\n        SQL(\"DATE(\\(value))\").sqlExpression\n    }\n    \n    // SELECT * FROM \"player\" WHERE DATE(\"createdAt\") = '2020-01-23'\n    let request = Player.filter { date($0.createdAt) == \"2020-01-23\" }\n    ```\n    \n    See the [Query Interface Organization] for more information about `SQLSpecificExpressible` and `SQLExpression`.\n    \n3. `FROM ...`: only one table is supported here. You can not customize this SQL part.\n\n4. `JOIN ...`: joins are fully controlled by [Associations]. You can not customize this SQL part.\n\n5. `WHERE ...`\n    \n    The WHERE clause can be provided as raw SQL:\n    \n    ```swift\n    // SELECT * FROM player WHERE score >= 1000\n    let request = Player.filter(sql: \"score >= 1000\")\n    \n    // SELECT * FROM player WHERE score >= 1000\n    let minScore = 1000\n    let request = Player.filter(sql: \"score >= ?\", arguments: [minScore])\n    ```\n\n    The WHERE clause can be provided with [SQL Interpolation]:\n    \n    ```swift\n    // SELECT * FROM player WHERE score >= 1000\n    let minScore = 1000\n    let request = Player.filter(literal: \"score >= \\(minScore)\")\n    ```\n    \n    The WHERE clause can be provided with a mix of Swift and [SQL Interpolation]:\n    \n    ```swift\n    // SELECT * FROM player WHERE (score >= 1000) AND (team = 'red')\n    let minScore = 1000\n    let request = Player.filter { \n        let scoreCondition: SQL = \"\\($0.score) >= \\(minScore)\"\n        return scoreCondition && $0.team == \"red\"\n    }\n    ```\n    \n    See `SELECT ...` above for more SQL Interpolation examples.\n    \n6. `GROUP BY ...`\n\n    The GROUP BY clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n7. `HAVING ...`\n\n    The HAVING clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n8. `ORDER BY ...`\n\n    The ORDER BY clause can be provided as raw SQL, SQL Interpolation, or a mix of Swift and SQL Interpolation, just as the selection and the WHERE clause (see above).\n    \n    In order to support the `desc` and `asc` query interface operators, and the `reversed()` query interface method, you must provide your orderings as _expression literals_ with the `SQL.sqlExpression` method:\n    \n    ```swift\n    // SELECT * FROM \"player\" \n    // ORDER BY (score + bonus) ASC, name DESC\n    let request = Player\n        .order {\n            let total = SQL(\"(\\($0.score) + \\($0.bonus))\").sqlExpression\n            return [total.desc, $0.name]\n        }\n        .reversed()\n    ```\n    \n9. `LIMIT ...`: use the `limit(_:offset:)` method. You can not customize this SQL part.\n\n\n## Fetching from Requests\n\nOnce you have a request, you can fetch the records at the origin of the request:\n\n```swift\n// Some request based on `Player`\nlet request = Player.filter { ... }... // QueryInterfaceRequest<Player>\n\n// Fetch players:\ntry request.fetchCursor(db) // A Cursor of Player\ntry request.fetchAll(db)    // [Player]\ntry request.fetchSet(db)    // Set<Player>\ntry request.fetchOne(db)    // Player?\n```\n\nFor example:\n\n```swift\nlet allPlayers = try Player.fetchAll(db)                            // [Player]\nlet arthur = try Player.filter { $0.name == \"Arthur\" }.fetchOne(db) // Player?\n```\n\nSee [fetching methods](#fetching-methods) for information about the `fetchCursor`, `fetchAll`, `fetchSet` and `fetchOne` methods.\n\n**You sometimes want to fetch other values**.\n\nThe simplest way is to use the request as an argument to a fetching method of the desired type:\n\n```swift\n// Fetch an Int\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\n// Fetch a Row\nlet request = Player.select { [min($0.score), max($0.score)] }\nlet row = try Row.fetchOne(db, request)!     // Row\nlet minScore = row[0] as Int?\nlet maxScore = row[1] as Int?\n```\n\nYou can also change the request so that it knows the type it has to fetch:\n\n- With `asRequest(of:)`, useful when you use [Associations]:\n    \n    ```swift\n    struct BookInfo: FetchableRecord, Decodable {\n        var book: Book\n        var author: Author\n    }\n    \n    // A request of BookInfo\n    let request = Book\n        .including(required: Book.author)\n        .asRequest(of: BookInfo.self)\n    \n    let bookInfos = try dbQueue.read { db in\n        try request.fetchAll(db) // [BookInfo]\n    }\n    ```\n    \n- With `select(..., as:)`, which is handy when you change the selection:\n    \n    ```swift\n    // A request of Int\n    let request = Player.select({ max($0.score) }, as: Int.self)\n    \n    let maxScore = try dbQueue.read { db in\n        try request.fetchOne(db) // Int?\n    }\n    ```\n\n\n## Fetching by Key\n\n**Fetching records according to their primary key** is a common task.\n\n[Identifiable Records] can use the type-safe methods `find(_:id:)`, `fetchOne(_:id:)`, `fetchAll(_:ids:)` and `fetchSet(_:ids:)`:\n\n```swift\ntry Player.find(db, id: 1)                   // Player\ntry Player.fetchOne(db, id: 1)               // Player?\ntry Country.fetchAll(db, ids: [\"FR\", \"US\"])  // [Countries]\n```\n\nAll record types can use `find(_:key:)`, `fetchOne(_:key:)`, `fetchAll(_:keys:)` and `fetchSet(_:keys:)` that apply conditions on primary and unique keys:\n\n```swift\ntry Player.find(db, key: 1)                  // Player\ntry Player.fetchOne(db, key: 1)              // Player?\ntry Country.fetchAll(db, keys: [\"FR\", \"US\"]) // [Country]\ntry Player.fetchOne(db, key: [\"email\": \"arthur@example.com\"])            // Player?\ntry Citizenship.fetchOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"]) // Citizenship?\n```\n\nWhen the table has no explicit primary key, GRDB uses the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html):\n\n```swift\n// SELECT * FROM document WHERE rowid = 1\ntry Document.fetchOne(db, key: 1)            // Document?\n```\n\n**When you want to build a request and plan to fetch from it later**, use a `filter` method:\n\n```swift\nlet request = Player.filter(id: 1)\nlet request = Country.filter(ids: [\"FR\", \"US\"])\nlet request = Player.filter(key: [\"email\": \"arthur@example.com\"])\nlet request = Citizenship.filter(key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\n\n## Testing for Record Existence\n\n**You can check if a request has matching rows in the database.**\n\n```swift\n// Some request based on `Player`\nlet request = Player.filter { ... }...\n\n// Check for player existence:\nlet noSuchPlayer = try request.isEmpty(db) // Bool\n```\n\nYou should check for emptiness instead of counting:\n\n```swift\n// Correct\nlet noSuchPlayer = try request.fetchCount(db) == 0\n// Even better\nlet noSuchPlayer = try request.isEmpty(db)\n```\n\n**You can also check if a given primary or unique key exists in the database.**\n\n[Identifiable Records] can use the type-safe method `exists(_:id:)`:\n\n```swift\ntry Player.exists(db, id: 1)\ntry Country.exists(db, id: \"FR\")\n```\n\nAll record types can use `exists(_:key:)` that can check primary and unique keys:\n\n```swift\ntry Player.exists(db, key: 1)\ntry Country.exists(db, key: \"FR\")\ntry Player.exists(db, key: [\"email\": \"arthur@example.com\"])\ntry Citizenship.exists(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\nYou should check for key existence instead of fetching a record and checking for nil:\n\n```swift\n// Correct\nlet playerExists = try Player.fetchOne(db, id: 1) != nil\n// Even better\nlet playerExists = try Player.exists(db, id: 1)\n```\n\n\n## Fetching Aggregated Values\n\n**Requests can count.** The `fetchCount()` method returns the number of rows that would be returned by a fetch request:\n\n```swift\n// SELECT COUNT(*) FROM player\nlet count = try Player.fetchCount(db) // Int\n\n// SELECT COUNT(*) FROM player WHERE email IS NOT NULL\nlet count = try Player.filter { $0.email != nil }.fetchCount(db)\n\n// SELECT COUNT(DISTINCT name) FROM player\nlet count = try Player.select(\\.name).distinct().fetchCount(db)\n\n// SELECT COUNT(*) FROM (SELECT DISTINCT name, score FROM player)\nlet count = try Player.select { [$0.name, $0.score] }.distinct().fetchCount(db)\n```\n\n\n**Other aggregated values** can also be selected and fetched (see [SQL Functions](#sql-functions)):\n\n```swift\nlet request = Player.select { max($0.score) }\nlet maxScore = try Int.fetchOne(db, request) // Int?\n\nlet request = Player.select { [min($0.score), max($0.score)] }\nlet row = try Row.fetchOne(db, request)!     // Row\nlet minScore = row[0] as Int?\nlet maxScore = row[1] as Int?\n```\n\n\n## Delete Requests\n\n**Requests can delete records**, with the `deleteAll()` method:\n\n```swift\n// DELETE FROM player\ntry Player.deleteAll(db)\n\n// DELETE FROM player WHERE team = 'Reds'\ntry Player\n    .filter { $0.team == \"Reds\" }\n    .deleteAll(db)\n\n// DELETE FROM player ORDER BY score LIMIT 10\ntry Player\n    .order(\\.score)\n    .limit(10)\n    .deleteAll(db)\n```\n\n> **Note** Deletion methods are available on types that adopt the [TableRecord] protocol, and `Table`:\n>\n> ```swift\n> struct Player: TableRecord { ... }\n> try Player.deleteAll(db)          // Fine\n> try Table(\"player\").deleteAll(db) // Just as fine\n> ```\n\n**Deleting records according to their primary key** is a common task.\n\n[Identifiable Records] can use the type-safe methods `deleteOne(_:id:)` and `deleteAll(_:ids:)`:\n\n```swift\ntry Player.deleteOne(db, id: 1)\ntry Country.deleteAll(db, ids: [\"FR\", \"US\"])\n```\n\nAll record types can use `deleteOne(_:key:)` and `deleteAll(_:keys:)` that apply conditions on primary and unique keys:\n\n```swift\ntry Player.deleteOne(db, key: 1)\ntry Country.deleteAll(db, keys: [\"FR\", \"US\"])\ntry Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\ntry Citizenship.deleteOne(db, key: [\"citizenId\": 1, \"countryCode\": \"FR\"])\n```\n\nWhen the table has no explicit primary key, GRDB uses the [hidden `rowid` column](https://www.sqlite.org/rowidtable.html):\n\n```swift\n// DELETE FROM document WHERE rowid = 1\ntry Document.deleteOne(db, id: 1)             // Document?\n```\n\n\n## Update Requests\n\n**Requests can batch update records**. The `updateAll()` method accepts *column assignments* defined with the `set(to:)` method:\n\n```swift\n// UPDATE player SET score = 0, isHealthy = 1, bonus = NULL\ntry Player.updateAll(db) { [\n    $0.score.set(to: 0), \n    $0.isHealthy.set(to: true), \n    $0.bonus.set(to: nil),\n] }\n\n// UPDATE player SET score = 0 WHERE team = 'Reds'\ntry Player\n    .filter { $0.team == \"Reds\" }\n    .updateAll(db) { $0.score.set(to: 0) }\n\n// UPDATE player SET isGreat = 1 ORDER BY score DESC LIMIT 10\ntry Player\n    .order(\\.score.desc)\n    .limit(10)\n    .updateAll(db) { $0.isGreat.set(to: true) }\n\n// UPDATE country SET population = 67848156 WHERE id = 'FR'\ntry Country\n    .filter(id: \"FR\")\n    .updateAll(db) { $0.population.set(to: 67_848_156) }\n```\n\nColumn assignments accept any expression:\n\n```swift\n// UPDATE player SET score = score + (bonus * 2)\ntry Player.updateAll(db) {\n    $0.score.set(to: $0.score + $0.bonus * 2)\n}\n```\n\nAs a convenience, you can also use the `+=`, `-=`, `*=`, or `/=` operators:\n\n```swift\n// UPDATE player SET score = score + (bonus * 2)\ntry Player.updateAll(db) { $0.score += $0.bonus * 2 }\n```\n\nDefault [Conflict Resolution] rules apply, and you may also provide a specific one:\n\n```swift\n// UPDATE OR IGNORE player SET ...\ntry Player.updateAll(db, onConflict: .ignore) { /* assignments... */ }\n```\n\n> **Note** The `updateAll` method is available on types that adopt the [TableRecord] protocol, and `Table`:\n>\n> ```swift\n> struct Player: TableRecord { ... }\n> try Player.updateAll(db, ...)          // Fine\n> try Table(\"player\").updateAll(db, ...) // Just as fine\n> ```\n\n\n## Custom Requests\n\nUntil now, we have seen [requests](#requests) created from any type that adopts the [TableRecord] protocol:\n\n```swift\nlet request = Player.all()  // QueryInterfaceRequest<Player>\n```\n\nThose requests of type `QueryInterfaceRequest` can fetch and count:\n\n```swift\ntry request.fetchCursor(db) // A Cursor of Player\ntry request.fetchAll(db)    // [Player]\ntry request.fetchSet(db)    // Set<Player>\ntry request.fetchOne(db)    // Player?\ntry request.fetchCount(db)  // Int\n```\n\n**When the query interface can not generate the SQL you need**, you can still fallback to [raw SQL](#fetch-queries):\n\n```swift\n// Custom SQL is always welcome\ntry Player.fetchAll(db, sql: \"SELECT ...\")   // [Player]\n```\n\nBut you may prefer to bring some elegance back in, and build custom requests:\n\n```swift\n// No custom SQL in sight\ntry Player.customRequest().fetchAll(db) // [Player]\n```\n\n**To build custom requests**, you can use one of the built-in requests or derive requests from other requests.\n\n- [SQLRequest] is a fetch request built from raw SQL. For example:\n    \n    ```swift\n    extension Player {\n        static func filter(color: Color) -> SQLRequest<Player> {\n            SQLRequest<Player>(\n                sql: \"SELECT * FROM player WHERE color = ?\"\n                arguments: [color])\n        }\n    }\n    \n    // [Player]\n    try Player.filter(color: .red).fetchAll(db)\n    ```\n    \n    SQLRequest supports [SQL Interpolation]:\n    \n    ```swift\n    extension Player {\n        static func filter(color: Color) -> SQLRequest<Player> {\n            \"SELECT * FROM player WHERE color = \\(color)\"\n        }\n    }\n    ```\n    \n- The [`asRequest(of:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterfacerequest/asrequest(of:)) method changes the type fetched by the request. It is useful, for example, when you use [Associations]:\n\n    ```swift\n    struct BookInfo: FetchableRecord, Decodable {\n        var book: Book\n        var author: Author\n    }\n    \n    let request = Book\n        .including(required: Book.author)\n        .asRequest(of: BookInfo.self)\n    \n    // [BookInfo]\n    try request.fetchAll(db)\n    ```\n\n- The [`adapted(_:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/fetchrequest/adapted(_:)) method eases the consumption of complex rows with row adapters. See [`RowAdapter`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter) and [`splittingRowAdapters(columnCounts:)`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/splittingrowadapters(columncounts:)) for a sample code that uses `adapted(_:)`.\n\n\nEncryption\n==========\n\n**GRDB can encrypt your database with [SQLCipher](http://sqlcipher.net) v3.4+.**\n\nUse [CocoaPods](http://cocoapods.org/), and specify in your `Podfile`:\n\n```ruby\n# GRDB with SQLCipher 4\npod 'GRDB.swift/SQLCipher'\npod 'SQLCipher', '~> 4.0'\n\n# GRDB with SQLCipher 3\npod 'GRDB.swift/SQLCipher'\npod 'SQLCipher', '~> 3.4'\n```\n\nMake sure you remove any existing `pod 'GRDB.swift'` from your Podfile. `GRDB.swift/SQLCipher` must be the only active GRDB pod in your whole project, or you will face linker or runtime errors, due to the conflicts between SQLCipher and the system SQLite.\n\n- [Creating or Opening an Encrypted Database](#creating-or-opening-an-encrypted-database)\n- [Changing the Passphrase of an Encrypted Database](#changing-the-passphrase-of-an-encrypted-database)\n- [Exporting a Database to an Encrypted Database](#exporting-a-database-to-an-encrypted-database)\n- [Security Considerations](#security-considerations)\n\n\n### Creating or Opening an Encrypted Database\n\n**You create and open an encrypted database** by providing a passphrase to your [database connection]:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nIt is also in `prepareDatabase` that you perform other [SQLCipher configuration steps](https://www.zetetic.net/sqlcipher/sqlcipher-api/) that must happen early in the lifetime of a SQLCipher connection. For example:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n    try db.execute(sql: \"PRAGMA cipher_page_size = ...\")\n    try db.execute(sql: \"PRAGMA kdf_iter = ...\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nWhen you want to open an existing SQLCipher 3 database with SQLCipher 4, you may want to run the `cipher_compatibility` pragma:\n\n```swift\n// Open an SQLCipher 3 database with SQLCipher 4\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n    try db.execute(sql: \"PRAGMA cipher_compatibility = 3\")\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nSee [SQLCipher 4.0.0 Release](https://www.zetetic.net/blog/2018/11/30/sqlcipher-400-release/) and [Upgrading to SQLCipher 4](https://discuss.zetetic.net/t/upgrading-to-sqlcipher-4/3283) for more information.\n\n\n### Changing the Passphrase of an Encrypted Database\n\n**You can change the passphrase** of an already encrypted database.\n\nWhen you use a [database queue](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue), open the database with the old passphrase, and then apply the new passphrase:\n\n```swift\ntry dbQueue.write { db in\n    try db.changePassphrase(\"newSecret\")\n}\n```\n\nWhen you use a [database pool](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool), make sure that no concurrent read can happen by changing the passphrase within the `barrierWriteWithoutTransaction` block. You must also ensure all future reads open a new database connection by calling the `invalidateReadOnlyConnections` method:\n\n```swift\ntry dbPool.barrierWriteWithoutTransaction { db in\n    try db.changePassphrase(\"newSecret\")\n    dbPool.invalidateReadOnlyConnections()\n}\n```\n\n> **Note**: When an application wants to keep on using a database queue or pool after the passphrase has changed, it is responsible for providing the correct passphrase to the `usePassphrase` method called in the database preparation function. Consider:\n>\n> ```swift\n> // WRONG: this won't work across a passphrase change\n> let passphrase = try getPassphrase()\n> var config = Configuration()\n> config.prepareDatabase { db in\n>     try db.usePassphrase(passphrase)\n> }\n>\n> // CORRECT: get the latest passphrase when it is needed\n> var config = Configuration()\n> config.prepareDatabase { db in\n>     let passphrase = try getPassphrase()\n>     try db.usePassphrase(passphrase)\n> }\n> ```\n\n> **Note**: The `DatabasePool.barrierWriteWithoutTransaction` method does not prevent [database snapshots](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasesnapshot) from accessing the database during the passphrase change, or after the new passphrase has been applied to the database. Those database accesses may throw errors. Applications should provide their own mechanism for invalidating open snapshots before the passphrase is changed.\n\n> **Note**: Instead of changing the passphrase \"in place\" as described here, you can also export the database in a new encrypted database that uses the new passphrase. See [Exporting a Database to an Encrypted Database](#exporting-a-database-to-an-encrypted-database).\n\n\n### Exporting a Database to an Encrypted Database\n\nProviding a passphrase won't encrypt a clear-text database that already exists, though. SQLCipher can't do that, and you will get an error instead: `SQLite error 26: file is encrypted or is not a database`.\n\nInstead, create a new encrypted database, at a distinct location, and export the content of the existing database. This can both encrypt a clear-text database, or change the passphrase of an encrypted database.\n\nThe technique to do that is [documented](https://discuss.zetetic.net/t/how-to-encrypt-a-plaintext-sqlite-database-to-use-sqlcipher-and-avoid-file-is-encrypted-or-is-not-a-database-errors/868/1) by SQLCipher.\n\nWith GRDB, it gives:\n\n```swift\n// The existing database\nlet existingDBQueue = try DatabaseQueue(path: \"/path/to/existing.db\")\n\n// The new encrypted database, at some distinct location:\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(\"secret\")\n}\nlet newDBQueue = try DatabaseQueue(path: \"/path/to/new.db\", configuration: config)\n\ntry existingDBQueue.inDatabase { db in\n    try db.execute(\n        sql: \"\"\"\n            ATTACH DATABASE ? AS encrypted KEY ?;\n            SELECT sqlcipher_export('encrypted');\n            DETACH DATABASE encrypted;\n            \"\"\",\n        arguments: [newDBQueue.path, \"secret\"])\n}\n\n// Now the export is completed, and the existing database can be deleted.\n```\n\n\n### Security Considerations\n\n#### Managing the lifetime of the passphrase string\n\nIt is recommended to avoid keeping the passphrase in memory longer than necessary. To do this, make sure you load the passphrase from the `prepareDatabase` method:\n\n```swift\n// NOT RECOMMENDED: this keeps the passphrase in memory longer than necessary\nlet passphrase = try getPassphrase()\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    try db.usePassphrase(passphrase)\n}\n\n// RECOMMENDED: only load the passphrase when it is needed\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    let passphrase = try getPassphrase()\n    try db.usePassphrase(passphrase)\n}\n```\n\nThis technique helps manages the lifetime of the passphrase, although keep in mind that the content of a String may remain intact in memory long after the object has been released.\n\nFor even better control over the lifetime of the passphrase in memory, use a Data object which natively provides the `resetBytes` function.\n\n```swift\n// RECOMMENDED: only load the passphrase when it is needed and reset its content immediately after use\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    var passphraseData = try getPassphraseData() // Data\n    defer {\n        passphraseData.resetBytes(in: 0..<passphraseData.count)\n    }\n    try db.usePassphrase(passphraseData)\n}\n```\n\nSome demanding users will want to go further, and manage the lifetime of the raw passphrase bytes. See below.\n\n\n#### Managing the lifetime of the passphrase bytes\n\nGRDB offers convenience methods for providing the database passphrases as Swift strings: `usePassphrase(_:)` and `changePassphrase(_:)`. Those methods don't keep the passphrase String in memory longer than necessary. But they are as secure as the standard String type: the lifetime of actual passphrase bytes in memory is not under control.\n\nWhen you want to precisely manage the passphrase bytes, talk directly to SQLCipher, using its raw C functions.\n\nFor example:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    ... // Carefully load passphrase bytes\n    let code = sqlite3_key(db.sqliteConnection, /* passphrase bytes */)\n    ... // Carefully dispose passphrase bytes\n    guard code == SQLITE_OK else {\n        throw DatabaseError(\n            resultCode: ResultCode(rawValue: code), \n            message: db.lastErrorMessage)\n    }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\n#### Passphrase availability vs. Database availability\n\nWhen the passphrase is securely stored in the system keychain, your application can protect it using the [`kSecAttrAccessible`](https://developer.apple.com/documentation/security/ksecattraccessible) attribute.\n\nSuch protection prevents GRDB from creating SQLite connections when the passphrase is not available:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    let passphrase = try loadPassphraseFromSystemKeychain()\n    try db.usePassphrase(passphrase)\n}\n\n// Success if and only if the passphrase is available\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nFor the same reason, [database pools], which open SQLite connections on demand, may fail at any time as soon as the passphrase becomes unavailable:\n\n```swift\n// Success if and only if the passphrase is available\nlet dbPool = try DatabasePool(path: dbPath, configuration: config)\n\n// May fail if passphrase has turned unavailable\ntry dbPool.read { ... }\n\n// May trigger value observation failure if passphrase has turned unavailable\ntry dbPool.write { ... }\n```\n\nBecause DatabasePool maintains a pool of long-lived SQLite connections, some database accesses will use an existing connection, and succeed. And some other database accesses will fail, as soon as the pool wants to open a new connection. It is impossible to predict which accesses will succeed or fail.\n\nFor the same reason, a database queue, which also maintains a long-lived SQLite connection, will remain available even after the passphrase has turned unavailable.\n\nApplications are thus responsible for protecting database accesses when the passphrase is unavailable. To this end, they can use [Data Protection](https://developer.apple.com/documentation/uikit/protecting_the_user_s_privacy/encrypting_your_app_s_files). They can also destroy their instances of database queue or pool when the passphrase becomes unavailable.\n\n\n## Backup\n\n**You can backup (copy) a database into another.**\n\nBackups can for example help you copying an in-memory database to and from a database file when you implement NSDocument subclasses.\n\n```swift\nlet source: DatabaseQueue = ...      // or DatabasePool\nlet destination: DatabaseQueue = ... // or DatabasePool\ntry source.backup(to: destination)\n```\n\nThe `backup` method blocks the current thread until the destination database contains the same contents as the source database.\n\nWhen the source is a [database pool](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool), concurrent writes can happen during the backup. Those writes may, or may not, be reflected in the backup, but they won't trigger any error.\n\n`Database` has an analogous `backup` method.\n\n```swift\nlet source: DatabaseQueue = ...      // or DatabasePool\nlet destination: DatabaseQueue = ... // or DatabasePool\ntry source.write { sourceDb in\n    try destination.barrierWriteWithoutTransaction { destDb in\n        try sourceDb.backup(to: destDb)\n    }\n}\n```\n\nThis method allows for the choice of source and destination `Database` handles with which to backup the database.\n\n### Backup Progress Reporting\n\nThe `backup` methods take optional `pagesPerStep` and `progress` parameters. Together these parameters can be used to track a database backup in progress and abort an incomplete backup.\n\nWhen `pagesPerStep` is provided, the database backup is performed in _steps_. At each step, no more than `pagesPerStep` database pages are copied from the source to the destination. The backup proceeds one step at a time until all pages have been copied.\n\nWhen a `progress` callback is provided, `progress` is called after every backup step, including the last. Even if a non-default `pagesPerStep` is specified or the backup is otherwise completed in a single step, the `progress` callback will be called.\n\n```swift\ntry source.backup(\n    to: destination,\n    pagesPerStep: ...)\n    { backupProgress in\n       print(\"Database backup progress:\", backupProgress)\n    }\n```\n\n### Aborting an Incomplete Backup\n\nIf a call to `progress` throws when `backupProgress.isComplete == false`, the backup will be aborted and the error rethrown. However, if a call to `progress` throws when `backupProgress.isComplete == true`, the backup is unaffected and the error is silently ignored.\n\n> **Warning**: Passing non-default values of `pagesPerStep` or `progress` to the backup methods is an advanced API intended to provide additional capabilities to expert users. GRDB's backup API provides a faithful, low-level wrapper to the underlying SQLite online backup API. GRDB's documentation is not a comprehensive substitute for the official SQLite [documentation of their backup API](https://www.sqlite.org/c3ref/backup_finish.html).\n\n## Interrupt a Database\n\n**The `interrupt()` method** causes any pending database operation to abort and return at its earliest opportunity.\n\nIt can be called from any thread.\n\n```swift\ndbQueue.interrupt()\ndbPool.interrupt()\n```\n\nA call to `interrupt()` that occurs when there are no running SQL statements is a no-op and has no effect on SQL statements that are started after `interrupt()` returns.\n\nA database operation that is interrupted will throw a DatabaseError with code `SQLITE_INTERRUPT`. If the interrupted SQL operation is an INSERT, UPDATE, or DELETE that is inside an explicit transaction, then the entire transaction will be rolled back automatically. If the rolled back transaction was started by a transaction-wrapping method such as `DatabaseWriter.write` or `Database.inTransaction`, then all database accesses will throw a DatabaseError with code `SQLITE_ABORT` until the wrapping method returns.\n\nFor example:\n\n```swift\ntry dbQueue.write { db in\n    try Player(...).insert(db)     // throws SQLITE_INTERRUPT\n    try Player(...).insert(db)     // not executed\n}                                  // throws SQLITE_INTERRUPT\n\ntry dbQueue.write { db in\n    do {\n        try Player(...).insert(db) // throws SQLITE_INTERRUPT\n    } catch { }\n}                                  // throws SQLITE_ABORT\n\ntry dbQueue.write { db in\n    do {\n        try Player(...).insert(db) // throws SQLITE_INTERRUPT\n    } catch { }\n    try Player(...).insert(db)     // throws SQLITE_ABORT\n}                                  // throws SQLITE_ABORT\n```\n\nYou can catch both `SQLITE_INTERRUPT` and `SQLITE_ABORT` errors:\n\n```swift\ndo {\n    try dbPool.write { db in ... }\n} catch DatabaseError.SQLITE_INTERRUPT, DatabaseError.SQLITE_ABORT {\n    // Oops, the database was interrupted.\n}\n```\n\nFor more information, see [Interrupt A Long-Running Query](https://www.sqlite.org/c3ref/interrupt.html).\n\n\n## Avoiding SQL Injection\n\nSQL injection is a technique that lets an attacker nuke your database.\n\n> ![XKCD: Exploits of a Mom](https://imgs.xkcd.com/comics/exploits_of_a_mom.png)\n>\n> https://xkcd.com/327/\n\nHere is an example of code that is vulnerable to SQL injection:\n\n```swift\n// BAD BAD BAD\nlet id = 1\nlet name = textField.text\ntry dbQueue.write { db in\n    try db.execute(sql: \"UPDATE students SET name = '\\(name)' WHERE id = \\(id)\")\n}\n```\n\nIf the user enters a funny string like `Robert'; DROP TABLE students; --`, SQLite will see the following SQL, and drop your database table instead of updating a name as intended:\n\n```sql\nUPDATE students SET name = 'Robert';\nDROP TABLE students;\n--' WHERE id = 1\n```\n\nTo avoid those problems, **never embed raw values in your SQL queries**. The only correct technique is to provide [arguments](#executing-updates) to your raw SQL queries:\n\n```swift\nlet name = textField.text\ntry dbQueue.write { db in\n    // Good\n    try db.execute(\n        sql: \"UPDATE students SET name = ? WHERE id = ?\",\n        arguments: [name, id])\n    \n    // Just as good\n    try db.execute(\n        sql: \"UPDATE students SET name = :name WHERE id = :id\",\n        arguments: [\"name\": name, \"id\": id])\n}\n```\n\nWhen you use [records](#records) and the [query interface](#the-query-interface), GRDB always prevents SQL injection for you:\n\n```swift\nlet id = 1\nlet name = textField.text\ntry dbQueue.write { db in\n    if var student = try Student.fetchOne(db, id: id) {\n        student.name = name\n        try student.update(db)\n    }\n}\n```\n\n\n## Error Handling\n\nGRDB can throw [DatabaseError](#databaseerror), [RecordError], [RowDecodingError], or crash your program with a [fatal error](#fatal-errors).\n\nConsidering that a local database is not some JSON loaded from a remote server, GRDB focuses on **trusted databases**. Dealing with [untrusted databases](#how-to-deal-with-untrusted-inputs) requires extra care.\n\n- [DatabaseError](#databaseerror)\n- [RecordError]\n- [RowDecodingError]\n- [Fatal Errors](#fatal-errors)\n- [How to Deal with Untrusted Inputs](#how-to-deal-with-untrusted-inputs)\n- [Error Log](#error-log)\n\n\n### DatabaseError\n\nğŸ“– [`DatabaseError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseerror)\n\n**DatabaseError** are thrown on SQLite errors:\n\n```swift\ndo {\n    try Pet(masterId: 1, name: \"Bobby\").insert(db)\n} catch let error as DatabaseError {\n    // The SQLite error code: 19 (SQLITE_CONSTRAINT)\n    error.resultCode\n    \n    // The extended error code: 787 (SQLITE_CONSTRAINT_FOREIGNKEY)\n    error.extendedResultCode\n    \n    // The eventual SQLite message: FOREIGN KEY constraint failed\n    error.message\n    \n    // The eventual erroneous SQL query\n    // \"INSERT INTO pet (masterId, name) VALUES (?, ?)\"\n    error.sql\n    \n    // The eventual SQL arguments\n    // [1, \"Bobby\"]\n    error.arguments\n    \n    // Full error description\n    // > SQLite error 19: FOREIGN KEY constraint failed -\n    // > while executing `INSERT INTO pet (masterId, name) VALUES (?, ?)`\n    error.description\n}\n```\n\nIf you want to see statement arguments in the error description, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n**SQLite uses [results codes](https://www.sqlite.org/rescode.html) to distinguish between various errors**.\n\nYou can catch a DatabaseError and match on result codes:\n\n```swift\ndo {\n    try ...\n} catch let error as DatabaseError {\n    switch error {\n    case DatabaseError.SQLITE_CONSTRAINT_FOREIGNKEY:\n        // foreign key constraint error\n    case DatabaseError.SQLITE_CONSTRAINT:\n        // any other constraint error\n    default:\n        // any other database error\n    }\n}\n```\n\nYou can also directly match errors on result codes:\n\n```swift\ndo {\n    try ...\n} catch DatabaseError.SQLITE_CONSTRAINT_FOREIGNKEY {\n    // foreign key constraint error\n} catch DatabaseError.SQLITE_CONSTRAINT {\n    // any other constraint error\n} catch {\n    // any other database error\n}\n```\n\nEach DatabaseError has two codes: an `extendedResultCode` (see [extended result code](https://www.sqlite.org/rescode.html#extended_result_code_list)), and a less precise `resultCode` (see [primary result code](https://www.sqlite.org/rescode.html#primary_result_code_list)). Extended result codes are refinements of primary result codes, as `SQLITE_CONSTRAINT_FOREIGNKEY` is to `SQLITE_CONSTRAINT`, for example.\n\n> **Warning**: SQLite has progressively introduced extended result codes across its versions. The [SQLite release notes](http://www.sqlite.org/changes.html) are unfortunately not quite clear about that: write your handling of extended result codes with care.\n\n\n### RecordError\n\nğŸ“– [`RecordError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recorderror)\n\n**RecordError** is thrown by the [PersistableRecord] protocol when the `update` method could not find any row to update:\n\n```swift\ndo {\n    try player.update(db)\n} catch let RecordError.recordNotFound(databaseTableName: table, key: key) {\n    print(\"Key \\(key) was not found in table \\(table).\")\n}\n```\n\n**RecordError** is also thrown by the [FetchableRecord] protocol when the `find` method does not find any record:\n\n```swift\ndo {\n    let player = try Player.find(db, id: 42)\n} catch let RecordError.recordNotFound(databaseTableName: table, key: key) {\n    print(\"Key \\(key) was not found in table \\(table).\")\n}\n```\n\n\n### RowDecodingError\n\nğŸ“– [`RowDecodingError`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowdecodingerror)\n\n**RowDecodingError** is thrown when the application can not decode a value from a database row. For example:\n\n```swift\nlet row = try Row.fetchOne(db, sql: \"SELECT NULL AS name\")!\n// RowDecodingError: could not decode String from database value NULL.\nlet name = try row.decode(String.self, forColumn: \"name\")\n```\n\n### Fatal Errors\n\n**Fatal errors notify that the program, or the database, has to be changed.**\n\nThey uncover programmer errors, false assumptions, and prevent misuses. Here are a few examples:\n\n- **The code asks for a non-optional value, when the database contains NULL:**\n    \n    ```swift\n    // fatal error: could not convert NULL to String.\n    let name: String = row[\"name\"]\n    ```\n    \n    Solution: fix the contents of the database, use [NOT NULL constraints](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/columndefinition/notnull(onconflict:)), or load an optional:\n    \n    ```swift\n    let name: String? = row[\"name\"]\n    ```\n\n- **Conversion from database value to Swift type fails:**\n    \n    ```swift\n    // fatal error: could not convert \"Momâ€™s birthday\" to Date.\n    let date: Date = row[\"date\"]\n    \n    // fatal error: could not convert \"\" to URL.\n    let url: URL = row[\"url\"]\n    ```\n    \n    Solution: fix the contents of the database, or use [DatabaseValue](#databasevalue) to handle all possible cases:\n    \n    ```swift\n    let dbValue: DatabaseValue = row[\"date\"]\n    if dbValue.isNull {\n        // Handle NULL\n    } else if let date = Date.fromDatabaseValue(dbValue) {\n        // Handle valid date\n    } else {\n        // Handle invalid date\n    }\n    ```\n\n- **The database can't guarantee that the code does what it says:**\n\n    ```swift\n    // fatal error: table player has no unique index on column email\n    try Player.deleteOne(db, key: [\"email\": \"arthur@example.com\"])\n    ```\n    \n    Solution: add a unique index to the player.email column, or use the `deleteAll` method to make it clear that you may delete more than one row:\n    \n    ```swift\n    try Player.filter { $0.email == \"arthur@example.com\" }.deleteAll(db)\n    ```\n\n- **Database connections are not reentrant:**\n    \n    ```swift\n    // fatal error: Database methods are not reentrant.\n    dbQueue.write { db in\n        dbQueue.write { db in\n            ...\n        }\n    }\n    ```\n    \n    Solution: avoid reentrancy, and instead pass a database connection along.\n\n\n### How to Deal with Untrusted Inputs\n\nLet's consider the code below:\n\n```swift\nlet sql = \"SELECT ...\"\n\n// Some untrusted arguments for the query\nlet arguments: [String: Any] = ...\nlet rows = try Row.fetchCursor(db, sql: sql, arguments: StatementArguments(arguments))\n\nwhile let row = try rows.next() {\n    // Some untrusted database value:\n    let date: Date? = row[0]\n}\n```\n\nIt has two opportunities to throw fatal errors:\n\n- **Untrusted arguments**: The dictionary may contain values that do not conform to the [DatabaseValueConvertible protocol](#values), or may miss keys required by the statement.\n- **Untrusted database content**: The row may contain a non-null value that can't be turned into a date.\n\nIn such a situation, you can still avoid fatal errors by exposing and handling each failure point, one level down in the GRDB API:\n\n```swift\n// Untrusted arguments\nif let arguments = StatementArguments(arguments) {\n    let statement = try db.makeStatement(sql: sql)\n    try statement.setArguments(arguments)\n    \n    var cursor = try Row.fetchCursor(statement)\n    while let row = try iterator.next() {\n        // Untrusted database content\n        let dbValue: DatabaseValue = row[0]\n        if dbValue.isNull {\n            // Handle NULL\n        if let date = Date.fromDatabaseValue(dbValue) {\n            // Handle valid date\n        } else {\n            // Handle invalid date\n        }\n    }\n}\n```\n\nSee [`Statement`] and [DatabaseValue](#databasevalue) for more information.\n\n\n### Error Log\n\n**SQLite can be configured to invoke a callback function containing an error code and a terse error message whenever anomalies occur.**\n\nThis global error callback must be configured early in the lifetime of your application:\n\n```swift\nDatabase.logError = { (resultCode, message) in\n    NSLog(\"%@\", \"SQLite error \\(resultCode): \\(message)\")\n}\n```\n\n> **Warning**: Database.logError must be set before any database connection is opened. This includes the connections that your application opens with GRDB, but also connections opened by other tools, such as third-party libraries. Setting it after a connection has been opened is an SQLite misuse, and has no effect.\n\nSee [The Error And Warning Log](https://sqlite.org/errlog.html) for more information.\n\n\n## Unicode\n\nSQLite lets you store unicode strings in the database.\n\nHowever, SQLite does not provide any unicode-aware string transformations or comparisons.\n\n\n### Unicode functions\n\nThe `UPPER` and `LOWER` built-in SQLite functions are not unicode-aware:\n\n```swift\n// \"JÃ©RÃ´ME\"\ntry String.fetchOne(db, sql: \"SELECT UPPER('JÃ©rÃ´me')\")\n```\n\nGRDB extends SQLite with [SQL functions](#custom-sql-functions-and-aggregates) that call the Swift built-in string functions `capitalized`, `lowercased`, `uppercased`, `localizedCapitalized`, `localizedLowercased` and `localizedUppercased`:\n\n```swift\n// \"JÃ‰RÃ”ME\"\nlet uppercased = DatabaseFunction.uppercase\ntry String.fetchOne(db, sql: \"SELECT \\(uppercased.name)('JÃ©rÃ´me')\")\n```\n\nThose unicode-aware string functions are also readily available in the [query interface](#sql-functions):\n\n```swift\nPlayer.select { $0.name.uppercased }\n```\n\n\n### String Comparison\n\nSQLite compares strings in many occasions: when you sort rows according to a string column, or when you use a comparison operator such as `=` and `<=`.\n\nThe comparison result comes from a *collating function*, or *collation*. SQLite comes with three built-in collations that do not support Unicode: [binary, nocase, and rtrim](https://www.sqlite.org/datatype3.html#collation).\n\nGRDB comes with five extra collations that leverage unicode-aware comparisons based on the standard Swift String comparison functions and operators:\n\n- `unicodeCompare` (uses the built-in `<=` and `==` Swift operators)\n- `caseInsensitiveCompare`\n- `localizedCaseInsensitiveCompare`\n- `localizedCompare`\n- `localizedStandardCompare`\n\nA collation can be applied to a table column. All comparisons involving this column will then automatically trigger the comparison function:\n    \n```swift\ntry db.create(table: \"player\") { t in\n    // Guarantees case-insensitive email unicity\n    t.column(\"email\", .text).unique().collate(.nocase)\n    \n    // Sort names in a localized case insensitive way\n    t.column(\"name\", .text).collate(.localizedCaseInsensitiveCompare)\n}\n\n// Players are sorted in a localized case insensitive way:\nlet players = try Player.order(\\.name).fetchAll(db)\n```\n\n> **Warning**: SQLite *requires* host applications to provide the definition of any collation other than binary, nocase and rtrim. When a database file has to be shared or migrated to another SQLite library of platform (such as the Android version of your application), make sure you provide a compatible collation.\n\nIf you can't or don't want to define the comparison behavior of a column (see warning above), you can still use an explicit collation in SQL requests and in the [query interface](#the-query-interface):\n\n```swift\nlet collation = DatabaseCollation.localizedCaseInsensitiveCompare\nlet players = try Player.fetchAll(db,\n    sql: \"SELECT * FROM player ORDER BY name COLLATE \\(collation.name))\")\nlet players = try Player.order { $0.name.collating(collation) }.fetchAll(db)\n```\n\n\n**You can also define your own collations**:\n\n```swift\nlet collation = DatabaseCollation(\"customCollation\") { (lhs, rhs) -> NSComparisonResult in\n    // return the comparison of lhs and rhs strings.\n}\n\n// Make the collation available to a database connection\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.add(collation: collation)\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\n\n\n## Memory Management\n\nBoth SQLite and GRDB use non-essential memory that help them perform better.\n\nYou can reclaim this memory with the `releaseMemory` method:\n\n```swift\n// Release as much memory as possible.\ndbQueue.releaseMemory()\ndbPool.releaseMemory()\n```\n\nThis method blocks the current thread until all current database accesses are completed, and the memory collected.\n\n> **Warning**: If `DatabasePool.releaseMemory()` is called while a long read is performed concurrently, then no other read access will be possible until this long read has completed, and the memory has been released. If this does not suit your application needs, look for the asynchronous options below:\n\nYou can release memory in an asynchronous way as well:\n\n```swift\n// On a DatabaseQueue\ndbQueue.asyncWriteWithoutTransaction { db in\n    db.releaseMemory()\n}\n\n// On a DatabasePool\ndbPool.releaseMemoryEventually()\n```\n\n`DatabasePool.releaseMemoryEventually()` does not block the current thread, and does not prevent concurrent database accesses. In exchange for this convenience, you don't know when memory has been freed.\n\n\n### Memory Management on iOS\n\n**The iOS operating system likes applications that do not consume much memory.**\n\n[Database queues] and [pools](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool) automatically free non-essential memory when the application receives a memory warning, and when the application enters background.\n\nYou can opt out of this automatic memory management:\n\n```swift\nvar config = Configuration()\nconfig.automaticMemoryManagement = false\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config) // or DatabasePool\n```\n\nFAQ\n===\n\n**[FAQ: Opening Connections](#faq-opening-connections)**\n\n- [How do I create a database in my application?](#how-do-i-create-a-database-in-my-application)\n- [How do I open a database stored as a resource of my application?](#how-do-i-open-a-database-stored-as-a-resource-of-my-application)\n- [How do I close a database connection?](#how-do-i-close-a-database-connection)\n\n**[FAQ: SQL](#faq-sql)**\n\n- [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql)\n\n**[FAQ: General](#faq-general)**\n\n- [How do I monitor the duration of database statements execution?](#how-do-i-monitor-the-duration-of-database-statements-execution)\n- [What Are Experimental Features?](#what-are-experimental-features)\n- [Does GRDB support library evolution and ABI stability?](#does-grdb-support-library-evolution-and-abi-stability)\n\n**[FAQ: Associations](#faq-associations)**\n\n- [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record)\n- [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record)\n- [How do I select only one column of an associated record?](#how-do-i-select-only-one-column-of-an-associated-record)\n\n**[FAQ: ValueObservation](#faq-valueobservation)**\n\n- [Why is ValueObservation not publishing value changes?](#why-is-valueobservation-not-publishing-value-changes)\n\n**[FAQ: Errors](#faq-errors)**\n\n- [Generic parameter 'T' could not be inferred](#generic-parameter-t-could-not-be-inferred)\n- [Mutation of captured var in concurrently-executing code](#mutation-of-captured-var-in-concurrently-executing-code)\n- [SQLite error 1 \"no such column\"](#sqlite-error-1-no-such-column)\n- [SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"](#sqlite-error-10-disk-io-error-sqlite-error-23-not-authorized)\n- [SQLite error 21 \"wrong number of statement arguments\" with LIKE queries](#sqlite-error-21-wrong-number-of-statement-arguments-with-like-queries)\n\n\n## FAQ: Opening Connections\n\n- :arrow_up: [FAQ]\n- [How do I create a database in my application?](#how-do-i-create-a-database-in-my-application)\n- [How do I open a database stored as a resource of my application?](#how-do-i-open-a-database-stored-as-a-resource-of-my-application)\n- [How do I close a database connection?](#how-do-i-close-a-database-connection)\n\n### How do I create a database in my application?\n\nFirst choose a proper location for the database file. Document-based applications will let the user pick a location. Apps that use the database as a global storage will prefer the Application Support directory.\n\nThe sample code below creates or opens a database file inside its dedicated directory (a [recommended practice](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseconnections)). On the first run, a new empty database file is created. On subsequent runs, the database file already exists, so it just opens a connection:\n\n```swift\n// HOW TO create an empty database, or open an existing database file\n\n// Create the \"Application Support/MyDatabase\" directory\nlet fileManager = FileManager.default\nlet appSupportURL = try fileManager.url(\n    for: .applicationSupportDirectory, in: .userDomainMask,\n    appropriateFor: nil, create: true) \nlet directoryURL = appSupportURL.appendingPathComponent(\"MyDatabase\", isDirectory: true)\ntry fileManager.createDirectory(at: directoryURL, withIntermediateDirectories: true)\n\n// Open or create the database\nlet databaseURL = directoryURL.appendingPathComponent(\"db.sqlite\")\nlet dbQueue = try DatabaseQueue(path: databaseURL.path)\n```\n\n### How do I open a database stored as a resource of my application?\n\nOpen a read-only connection to your resource:\n\n```swift\n// HOW TO open a read-only connection to a database resource\n\n// Get the path to the database resource.\nif let dbPath = Bundle.main.path(forResource: \"db\", ofType: \"sqlite\") {\n    // If the resource exists, open a read-only connection.\n    // Writes are disallowed because resources can not be modified. \n    var config = Configuration()\n    config.readonly = true\n    let dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n} else {\n    // The database resource can not be found.\n    // Fix your setup, or report the problem to the user. \n}\n```\n\n### How do I close a database connection?\n\nDatabase connections are automatically closed when `DatabaseQueue` or `DatabasePool` instances are deinitialized.\n\nIf the correct execution of your program depends on precise database closing, perform an explicit call to [`close()`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasereader/close()). This method may fail and create zombie connections, so please check its detailed documentation.\n\n## FAQ: SQL\n\n- :arrow_up: [FAQ]\n- [How do I print a request as SQL?](#how-do-i-print-a-request-as-sql)\n\n### How do I print a request as SQL?\n\nWhen you want to debug a request that does not deliver the expected results, you may want to print the SQL that is actually executed.\n\nYou can compile the request into a prepared [`Statement`]:\n\n```swift\ntry dbQueue.read { db in\n    let request = Player.filter { $0.email == \"arthur@example.com\" }\n    let statement = try request.makePreparedRequest(db).statement\n    print(statement) // SELECT * FROM player WHERE email = ?\n    print(statement.arguments) // [\"arthur@example.com\"]\n}\n```\n\nAnother option is to setup a tracing function that prints out the executed SQL requests. For example, provide a tracing function when you connect to the database:\n\n```swift\n// Prints all SQL statements\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace { print($0) }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    // Prints \"SELECT * FROM player WHERE email = ?\"\n    let players = try Player.filter { $0.email == \"arthur@example.com\" }.fetchAll(db)\n}\n```\n\nIf you want to see statement arguments such as `'arthur@example.com'` in the logged statements, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n> **Note**: the generated SQL may change between GRDB releases, without notice: don't have your application rely on any specific SQL output.\n\n\n## FAQ: General\n\n- :arrow_up: [FAQ]\n- [How do I monitor the duration of database statements execution?](#how-do-i-monitor-the-duration-of-database-statements-execution)\n- [What Are Experimental Features?](#what-are-experimental-features)\n- [Does GRDB support library evolution and ABI stability?](#does-grdb-support-library-evolution-and-abi-stability)\n\n### How do I monitor the duration of database statements execution?\n\nUse the `trace(options:_:)` method, with the `.profile` option:\n\n```swift\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace(options: .profile) { event in\n        // Prints all SQL statements with their duration\n        print(event)\n        \n        // Access to detailed profiling information\n        if case let .profile(statement, duration) = event, duration > 0.5 {\n            print(\"Slow query: \\(statement.sql)\")\n        }\n    }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n\ntry dbQueue.read { db in\n    let players = try Player.filter { $0.email == \"arthur@example.com\" }.fetchAll(db)\n    // Prints \"0.003s SELECT * FROM player WHERE email = ?\"\n}\n```\n\nIf you want to see statement arguments such as `'arthur@example.com'` in the logged statements, [make statement arguments public](https://swiftpackageindex.com/groue/GRDB.swift/configuration/publicstatementarguments).\n\n### What Are Experimental Features?\n\nSince GRDB 1.0, all backwards compatibility guarantees of [semantic versioning](http://semver.org) apply: no breaking change will happen until the next major version of the library.\n\nThere is an exception, though: *experimental features*, marked with the \"**:fire: EXPERIMENTAL**\" badge. Those are advanced features that are too young, or lack user feedback. They are not stabilized yet.\n\nThose experimental features are not protected by semantic versioning, and may break between two minor releases of the library. To help them becoming stable, [your feedback](https://github.com/groue/GRDB.swift/issues) is greatly appreciated.\n\n### Does GRDB support library evolution and ABI stability?\n\nNo, GRDB does not support library evolution and ABI stability. The only promise is API stability according to [semantic versioning](http://semver.org), with an exception for [experimental features](#what-are-experimental-features).\n\nYet, GRDB can be built with the \"Build Libraries for Distribution\" Xcode option (`BUILD_LIBRARY_FOR_DISTRIBUTION`), so that you can build binary frameworks at your convenience.\n\n## FAQ: Associations\n\n- :arrow_up: [FAQ]\n- [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record)\n- [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record)\n- [How do I select only one column of an associated record?](#how-do-i-select-only-one-column-of-an-associated-record)\n\n### How do I filter records and only keep those that are associated to another record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to only fetch books that have an author, and discard anonymous books.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: TableRecord {\n    ...\n}\n```\n\nAnd then we can write our request and only fetch books that have an author, discarding anonymous ones:\n\n```swift\nlet books: [Book] = try dbQueue.read { db in\n    // SELECT book.* FROM book \n    // JOIN author ON author.id = book.authorID\n    let request = Book.joining(required: Book.author)\n    return try request.fetchAll(db)\n}\n```\n\nNote how this request does not use the `filter` method. Indeed, we don't have any condition to express on any column. Instead, we just need to \"require that a book can be joined to its author\".\n\nSee [How do I filter records and only keep those that are NOT associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-not-associated-to-another-record) below for the opposite question.\n\n\n### How do I filter records and only keep those that are NOT associated to another record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to only fetch anonymous books that do not have any author.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: TableRecord {\n    ...\n}\n```\n\nAnd then we can write our request and only fetch anonymous books that don't have any author:\n\n```swift\nlet books: [Book] = try dbQueue.read { db in\n    // SELECT book.* FROM book\n    // LEFT JOIN author ON author.id = book.authorID\n    // WHERE author.id IS NULL\n    let authorAlias = TableAlias<Author>()\n    let request = Book\n        .joining(optional: Book.author.aliased(authorAlias))\n        .filter(!authorAlias.exists)\n    return try request.fetchAll(db)\n}\n```\n\nThis request uses a TableAlias in order to be able to filter on the eventual associated author. We make sure that the `Author.primaryKey` is nil, which is another way to say it does not exist: the book has no author.\n\nSee [How do I filter records and only keep those that are associated to another record?](#how-do-i-filter-records-and-only-keep-those-that-are-associated-to-another-record) above for the opposite question.\n\n\n### How do I select only one column of an associated record?\n\nLet's say you have two record types, `Book` and `Author`, and you want to fetch all books with their author name, but not the full associated author records.\n\nWe start by defining the association between books and authors:\n\n```swift\nstruct Book: Decodable, TableRecord {\n    ...\n    static let author = belongsTo(Author.self)\n}\n\nstruct Author: Decodable, TableRecord {\n    ...\n    enum Columns {\n        static let name = Column(CodingKeys.name)\n    }\n}\n```\n\nAnd then we can write our request and the ad-hoc record that decodes it:\n\n```swift\nstruct BookInfo: Decodable, FetchableRecord {\n    var book: Book\n    var authorName: String? // nil when the book is anonymous\n    \n    static func all() -> QueryInterfaceRequest<BookInfo> {\n        // SELECT book.*, author.name AS authorName\n        // FROM book\n        // LEFT JOIN author ON author.id = book.authorID\n        return Book\n            .annotated(withOptional: Book.author.select { \n                $0.name.forKey(CodingKeys.authorName)\n            })\n            .asRequest(of: BookInfo.self)\n    }\n}\n\nlet bookInfos: [BookInfo] = try dbQueue.read { db in\n    BookInfo.all().fetchAll(db)\n}\n```\n\nBy defining the request as a static method of BookInfo, you have access to the private `CodingKeys.authorName`, and a compiler-checked SQL column name.\n\nBy using the `annotated(withOptional:)` method, you append the author name to the top-level selection that can be decoded by the ad-hoc record.\n\nBy using `asRequest(of:)`, you enhance the type-safety of your request.\n\n\n## FAQ: ValueObservation\n\n- :arrow_up: [FAQ]\n- [Why is ValueObservation not publishing value changes?](#why-is-valueobservation-not-publishing-value-changes)\n\n### Why is ValueObservation not publishing value changes?\n\nSometimes it looks that a [ValueObservation] does not notify the changes you expect.\n\nThere may be four possible reasons for this:\n\n1. The expected changes were not committed into the database.\n2. The expected changes were committed into the database, but were quickly overwritten.\n3. The observation was stopped.\n4. The observation does not track the expected database region.\n\nTo answer the first two questions, look at SQL statements executed by the database. This is done when you open the database connection:\n\n```swift\n// Prints all SQL statements\nvar config = Configuration()\nconfig.prepareDatabase { db in\n    db.trace { print(\"SQL: \\($0)\") }\n}\nlet dbQueue = try DatabaseQueue(path: dbPath, configuration: config)\n```\n\nIf, after that, you are convinced that the expected changes were committed into the database, and not overwritten soon after, trace observation events:\n\n```swift\nlet observation = ValueObservation\n    .tracking { db in ... }\n    .print() // <- trace observation events\nlet cancellable = observation.start(...)\n```\n\nLook at the observation logs which start with `cancel` or `failure`: maybe the observation was cancelled by your app, or did fail with an error.\n\nLook at the observation logs which start with `value`: make sure, again, that the expected value was not actually notified, then overwritten.\n\nFinally, look at the observation logs which start with `tracked region`. Does the printed database region cover the expected changes?\n\nFor example:\n\n- `empty`: The empty region, which tracks nothing and never triggers the observation.\n- `player(*)`: The full `player` table\n- `player(id,name)`: The `id` and `name` columns of the `player` table\n- `player(id,name)[1]`: The `id` and `name` columns of the row with id 1 in the `player` table\n- `player(*),team(*)`: Both the full `player` and `team` tables\n\nIf you happen to use the `ValueObservation.trackingConstantRegion(_:)` method and see a mismatch between the tracked region and your expectation, then change the definition of your observation by using `tracking(_:)`. You should witness that the logs which start with `tracked region` now evolve in order to include the expected changes, and that you get the expected notifications.\n\nIf after all those steps (thanks you!), your observation is still failing you, please [open an issue](https://github.com/groue/GRDB.swift/issues/new) and provide a [minimal reproducible example](https://stackoverflow.com/help/minimal-reproducible-example)!\n\n\n## FAQ: Errors\n\n- :arrow_up: [FAQ]\n- [Generic parameter 'T' could not be inferred](#generic-parameter-t-could-not-be-inferred)\n- [Mutation of captured var in concurrently-executing code](#mutation-of-captured-var-in-concurrently-executing-code)\n- [SQLite error 1 \"no such column\"](#sqlite-error-1-no-such-column)\n- [SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"](#sqlite-error-10-disk-io-error-sqlite-error-23-not-authorized)\n- [SQLite error 21 \"wrong number of statement arguments\" with LIKE queries](#sqlite-error-21-wrong-number-of-statement-arguments-with-like-queries)\n\n### Generic parameter 'T' could not be inferred\n    \nYou may get this error when using the `read` and `write` methods of database queues and pools:\n\n```swift\n// Generic parameter 'T' could not be inferred\nlet string = try dbQueue.read { db in\n    let result = try String.fetchOne(db, ...)\n    return result\n}\n```\n\nThis is a limitation of the Swift compiler.\n\nThe general workaround is to explicitly declare the type of the closure result:\n\n```swift\n// General Workaround\nlet string = try dbQueue.read { db -> String? in\n    let result = try String.fetchOne(db, ...)\n    return result\n}\n```\n\nYou can also, when possible, write a single-line closure:\n\n```swift\n// Single-line closure workaround:\nlet string = try dbQueue.read { db in\n    try String.fetchOne(db, ...)\n}\n```\n\n\n### Mutation of captured var in concurrently-executing code\n\nThe `insert` and `save` [persistence methods](#persistablerecord-protocol) can trigger a compiler error in async contexts:\n\n```swift\nvar player = Player(id: nil, name: \"Arthur\")\ntry await dbWriter.write { db in\n    // Error: Mutation of captured var 'player' in concurrently-executing code\n    try player.insert(db)\n}\nprint(player.id) // A non-nil id\n```\n\nWhen this happens, prefer the `inserted` and `saved` methods instead:\n\n```swift\n// OK\nvar player = Player(id: nil, name: \"Arthur\")\nplayer = try await dbWriter.write { [player] db in\n    return try player.inserted(db)\n}\nprint(player.id) // A non-nil id\n```\n\n\n### SQLite error 1 \"no such column\"\n\nThis error message is self-explanatory: do check for misspelled or non-existing column names.\n\nHowever, sometimes this error only happens when an app runs on a recent operating system (iOS 14+, Big Sur+, etc.) The error does not happen with previous ones.\n\nWhen this is the case, there are two possible explanations:\n\n1. Maybe a column name is *really* misspelled or missing from the database schema.\n    \n    To find it, check the SQL statement that comes with the [DatabaseError](#databaseerror).\n\n2. Maybe the application is using the character `\"` instead of the single quote `'` as the delimiter for string literals in raw SQL queries. Recent versions of SQLite have learned to tell about this deviation from the SQL standard, and this is why you are seeing this error. \n    \n    For example: this is not standard SQL: `UPDATE player SET name = \"Arthur\"`.\n    \n    The standard version is: `UPDATE player SET name = 'Arthur'`.\n    \n    It just happens that old versions of SQLite used to accept the former, non-standard version. Newer versions are able to reject it with an error.\n    \n    The fix is to change the SQL statements run by the application: replace `\"` with `'` in your string literals.\n    \n    It may also be time to learn about statement arguments and [SQL injection](#avoiding-sql-injection):\n    \n    ```swift\n    let name: String = ...\n    \n    // NOT STANDARD (double quote)\n    try db.execute(sql: \"\"\"\n        UPDATE player SET name = \"\\(name)\"\n        \"\"\")\n    \n    // STANDARD, BUT STILL NOT RECOMMENDED (single quote)\n    try db.execute(sql: \"UPDATE player SET name = '\\(name)'\")\n    \n    // STANDARD, AND RECOMMENDED (statement arguments)\n    try db.execute(sql: \"UPDATE player SET name = ?\", arguments: [name])\n    \n    // STANDARD, AND RECOMMENDED (SQL interpolation)\n    try db.execute(literal: \"UPDATE player SET name = \\(name)\")\n    ```\n    \nFor more information, see [Double-quoted String Literals Are Accepted](https://sqlite.org/quirks.html#double_quoted_string_literals_are_accepted), and [Configuration.acceptsDoubleQuotedStringLiterals](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration/acceptsdoublequotedstringliterals).\n    \n\n\n### SQLite error 10 \"disk I/O error\", SQLite error 23 \"not authorized\"\n\nThose errors may be the sign that SQLite can't access the database due to [data protection](https://developer.apple.com/documentation/uikit/protecting_the_user_s_privacy/encrypting_your_app_s_files).\n\nWhen your application should be able to run in the background on a locked device, it has to catch this error, and, for example, wait for [UIApplicationDelegate.applicationProtectedDataDidBecomeAvailable(_:)](https://developer.apple.com/reference/uikit/uiapplicationdelegate/1623044-applicationprotecteddatadidbecom) or [UIApplicationProtectedDataDidBecomeAvailable](https://developer.apple.com/reference/uikit/uiapplicationprotecteddatadidbecomeavailable) notification and retry the failed database operation.\n\n```swift\ndo {\n    try ...\n} catch DatabaseError.SQLITE_IOERR, DatabaseError.SQLITE_AUTH {\n    // Handle possible data protection error\n}\n```\n\nThis error can also be prevented altogether by using a more relaxed [file protection](https://developer.apple.com/reference/foundation/filemanager/1653059-file_protection_values).\n\n\n### SQLite error 21 \"wrong number of statement arguments\" with LIKE queries\n\nYou may get the error \"wrong number of statement arguments\" when executing a LIKE query similar to:\n\n```swift\nlet name = textField.text\nlet players = try dbQueue.read { db in\n    try Player.fetchAll(db, sql: \"SELECT * FROM player WHERE name LIKE '%?%'\", arguments: [name])\n}\n```\n\nThe problem lies in the `'%?%'` pattern.\n\nSQLite only interprets `?` as a parameter when it is a placeholder for a whole value (int, double, string, blob, null). In this incorrect query, `?` is just a character in the `'%?%'` string: it is not a query parameter, and is not processed in any way. See [https://www.sqlite.org/lang_expr.html#varparam](https://www.sqlite.org/lang_expr.html#varparam) for more information about SQLite parameters.\n\nTo fix the error, you can feed the request with the pattern itself, instead of the name:\n\n```swift\nlet name = textField.text\nlet players: [Player] = try dbQueue.read { db in\n    let pattern = \"%\\(name)%\"\n    return try Player.fetchAll(db, sql: \"SELECT * FROM player WHERE name LIKE ?\", arguments: [pattern])\n}\n```\n\n\nSample Code\n===========\n\n- The [Documentation](#documentation) is full of GRDB snippets.\n- [Demo Applications]\n- Open `GRDB.xcworkspace`: it contains GRDB-enabled playgrounds to play with.\n- [groue/SortedDifference](https://github.com/groue/SortedDifference): How to synchronize a database table with a JSON payload\n\n\n---\n\n**Thanks**\n\n- [Pierlis](http://pierlis.com), where we write great software.\n- [@alextrob](https://github.com/alextrob), [@alexwlchan](https://github.com/alexwlchan), [@bellebethcooper](https://github.com/bellebethcooper), [@bfad](https://github.com/bfad), [@cfilipov](https://github.com/cfilipov), [@charlesmchen-signal](https://github.com/charlesmchen-signal), [@Chiliec](https://github.com/Chiliec), [@chrisballinger](https://github.com/chrisballinger), [@darrenclark](https://github.com/darrenclark), [@davidkraus](https://github.com/davidkraus), [@eburns-vmware](https://github.com/eburns-vmware), [@felixscheinost](https://github.com/felixscheinost), [@fpillet](https://github.com/fpillet), [@gcox](https://github.com/gcox), [@GetToSet](https://github.com/GetToSet), [@gjeck](https://github.com/gjeck), [@guidedways](https://github.com/guidedways), [@gusrota](https://github.com/gusrota), [@haikusw](https://github.com/haikusw), [@hartbit](https://github.com/hartbit), [@holsety](https://github.com/holsety), [@jroselightricks](https://github.com/jroselightricks), [@kdubb](https://github.com/kdubb), [@kluufger](https://github.com/kluufger), [@KyleLeneau](https://github.com/KyleLeneau), [@layoutSubviews](https://github.com/layoutSubviews), [@mallman](https://github.com/mallman), [@MartinP7r](https://github.com/MartinP7r), [@Marus](https://github.com/Marus), [@mattgallagher](https://github.com/mattgallagher), [@MaxDesiatov](https://github.com/MaxDesiatov), [@michaelkirk-signal](https://github.com/michaelkirk-signal), [@mtancock](https://github.com/mtancock), [@pakko972](https://github.com/pakko972), [@peter-ss](https://github.com/peter-ss), [@pierlo](https://github.com/pierlo), [@pocketpixels](https://github.com/pocketpixels), [@pp5x](https://github.com/pp5x), [@professordeng](https://github.com/professordeng), [@robcas3](https://github.com/robcas3), [@runhum](https://github.com/runhum), [@sberrevoets](https://github.com/sberrevoets), [@schveiguy](https://github.com/schveiguy), [@SD10](https://github.com/SD10), [@sobri909](https://github.com/sobri909), [@sroddy](https://github.com/sroddy), [@steipete](https://github.com/steipete), [@swiftlyfalling](https://github.com/swiftlyfalling), [@Timac](https://github.com/Timac), [@tternes](https://github.com/tternes), [@valexa](https://github.com/valexa), [@wuyuehyang](https://github.com/wuyuehyang), [@ZevEisenberg](https://github.com/ZevEisenberg), and [@zmeyc](https://github.com/zmeyc) for their contributions, help, and feedback on GRDB.\n- [@aymerick](https://github.com/aymerick) and [@kali](https://github.com/kali) because SQL.\n- [ccgus/fmdb](https://github.com/ccgus/fmdb) for its excellency.\n\n---\n\n[URIs don't change: people change them.](https://www.w3.org/Provider/Style/URI)\n\n#### Adding support for missing SQL functions or operators\n\nThis chapter was renamed to [Embedding SQL in Query Interface Requests].\n\n#### Advanced DatabasePool\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### After Commit Hook\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)).\n\n#### Asynchronous APIs\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Changes Tracking\n\nThis chapter has been renamed [Record Comparison].\n\n#### Concurrency\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Custom Value Types\n\nCustom Value Types conform to the [`DatabaseValueConvertible`] protocol.\n\n#### Customized Decoding of Database Rows\n\nThis chapter has been renamed [Beyond FetchableRecord].\n\n#### Customizing the Persistence Methods\n\nThis chapter was replaced with [Persistence Callbacks].\n\n#### Database Changes Observation\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseobservation).\n\n#### Database Configuration\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration).\n\n#### Database Queues\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue).\n\n#### Database Pools\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool).\n\n#### Database Snapshots\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### DatabaseWriter and DatabaseReader Protocols\n\nThis chapter was removed. See the references of [DatabaseReader](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasereader) and [DatabaseWriter](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasewriter).\n\n#### Date and UUID Coding Strategies\n\nThis chapter has been renamed [Data, Date, and UUID Coding Strategies].\n\n#### Dealing with External Connections\n\nThis chapter has been superseded by the [Sharing a Database] guide.\n\n#### Differences between Database Queues and Pools\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Enabling FTS5 Support\n\nFTS5 is enabled by default since GRDB 6.7.0.\n\n#### FetchedRecordsController\n\nFetchedRecordsController has been removed in GRDB 5.\n\nThe [Database Observation] chapter describes the other ways to observe the database.\n\n#### Full-Text Search\n\nThis chapter has [moved](Documentation/FullTextSearch.md).\n\n#### Guarantees and Rules\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### Joined Queries Support\n\nThis chapter was replaced with the documentation of [splittingRowAdapters(columnCounts:)](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/splittingrowadapters(columncounts:)).\n\n#### List of Record Methods\n\nSee [Records and the Query Interface](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/queryinterface).\n\n#### Migrations\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/migrations).\n\n#### NSNumber and NSDecimalNumber\n\nThis chapter has [moved](#nsnumber-nsdecimalnumber-and-decimal).\n\n#### Persistable Protocol\n\nThis protocol has been renamed [PersistableRecord] in GRDB 3.0.\n\n#### PersistenceError\n\nThis error was renamed to [RecordError].\n\n#### Prepared Statements\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement).\n\n#### Record Class\n\nThe [`Record`](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/record) class is a legacy GRDB type. Since GRDB 7, it is not recommended to define record types by subclassing the `Record` class.\n\n#### Row Adapters\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/rowadapter).\n\n#### RowConvertible Protocol\n\nThis protocol has been renamed [FetchableRecord] in GRDB 3.0.\n\n#### TableMapping Protocol\n\nThis protocol has been renamed [TableRecord] in GRDB 3.0.\n\n#### Transactions and Savepoints\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactions).\n\n#### Transaction Hook\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/database/afternexttransaction(oncommit:onrollback:)).\n\n#### TransactionObserver Protocol\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactionobserver).\n\n#### Unsafe Concurrency APIs\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency).\n\n#### ValueObservation\n\nThis chapter has [moved](https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/valueobservation).\n\n#### ValueObservation and DatabaseRegionObservation\n\nThis chapter has been superseded by [ValueObservation] and [DatabaseRegionObservation].\n\n[Associations]: Documentation/AssociationsBasics.md\n[Beyond FetchableRecord]: #beyond-fetchablerecord\n[Identifiable Records]: #identifiable-records\n[Codable Records]: #codable-records\n[Columns Selected by a Request]: #columns-selected-by-a-request\n[common table expression]: Documentation/CommonTableExpressions.md\n[Common Table Expressions]: Documentation/CommonTableExpressions.md\n[Conflict Resolution]: #conflict-resolution\n[Column Names Coding Strategies]: #column-names-coding-strategies\n[Data, Date, and UUID Coding Strategies]: #data-date-and-uuid-coding-strategies\n[Fetching from Requests]: #fetching-from-requests\n[Embedding SQL in Query Interface Requests]: #embedding-sql-in-query-interface-requests\n[Full-Text Search]: Documentation/FullTextSearch.md\n[Migrations]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/migrations\n[The userInfo Dictionary]: #the-userinfo-dictionary\n[JSON Columns]: #json-columns\n[FetchableRecord]: #fetchablerecord-protocol\n[EncodableRecord]: #persistablerecord-protocol\n[PersistableRecord]: #persistablerecord-protocol\n[Record Comparison]: #record-comparison\n[Record Customization Options]: #record-customization-options\n[Persistence Callbacks]: #persistence-callbacks\n[persistence callbacks]: #persistence-callbacks\n[Record Timestamps and Transaction Date]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/recordtimestamps\n[TableRecord]: #tablerecord-protocol\n[ValueObservation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/valueobservation\n[DatabaseRegionObservation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseregionobservation\n[RxGRDB]: https://github.com/RxSwiftCommunity/RxGRDB\n[DatabaseRegion]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseregion\n[SQL Interpolation]: Documentation/SQLInterpolation.md\n[custom SQLite build]: Documentation/CustomSQLiteBuilds.md\n[Combine]: https://developer.apple.com/documentation/combine\n[Combine Support]: Documentation/Combine.md\n[Concurrency]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/concurrency\n[Demo Applications]: Documentation/DemoApps\n[Sharing a Database]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasesharing\n[FAQ]: #faq\n[Database Observation]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databaseobservation\n[SQLRequest]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/sqlrequest\n[SQL literal]: Documentation/SQLInterpolation.md#sql-literal\n[Identifiable]: https://developer.apple.com/documentation/swift/identifiable\n[Query Interface Organization]: Documentation/QueryInterfaceOrganization.md\n[Database Configuration]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/configuration\n[Persistence Methods]: #persistence-methods\n[persistence methods]: #persistence-methods\n[Persistence Methods and the `RETURNING` clause]: #persistence-methods-and-the-returning-clause\n[RecordError]: #recorderror\n[RowDecodingError]: #rowdecodingerror\n[Transactions and Savepoints]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/transactions\n[`DatabaseQueue`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue\n[Database queues]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasequeue\n[`DatabasePool`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool\n[database pools]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasepool\n[`DatabaseValueConvertible`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/databasevalueconvertible\n[`StatementArguments`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statementarguments\n[Prepared Statements]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[prepared statements]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[`Statement`]: https://swiftpackageindex.com/groue/GRDB.swift/documentation/grdb/statement\n[Database Connections]: #database-connections\n[Database connections]: #database-connections\n[database connection]: #database-connections\n",
      "stars_today": 2
    },
    {
      "id": 207354223,
      "name": "FreeRTOS-Kernel",
      "full_name": "FreeRTOS/FreeRTOS-Kernel",
      "description": "FreeRTOS kernel files only, submoduled into https://github.com/FreeRTOS/FreeRTOS and various other repos.",
      "html_url": "https://github.com/FreeRTOS/FreeRTOS-Kernel",
      "stars": 3817,
      "forks": 1431,
      "language": "C",
      "topics": [],
      "created_at": "2019-09-09T16:28:01Z",
      "updated_at": "2026-01-25T01:31:59Z",
      "pushed_at": "2026-01-18T18:38:16Z",
      "open_issues": 35,
      "owner": {
        "login": "FreeRTOS",
        "avatar_url": "https://avatars.githubusercontent.com/u/54647343?v=4"
      },
      "readme": "[![CMock Unit Tests](https://github.com/FreeRTOS/FreeRTOS-Kernel/actions/workflows/unit-tests.yml/badge.svg?branch=main&event=push)](https://github.com/FreeRTOS/FreeRTOS-Kernel/actions/workflows/unit-tests.yml?query=branch%3Amain+event%3Apush+workflow%3A%22CMock+Unit+Tests%22++)\n[![codecov](https://app.codecov.io/gh/FreeRTOS/FreeRTOS-Kernel/badge.svg?branch=main)](https://codecov.io/gh/FreeRTOS/FreeRTOS-Kernel)\n\n## Getting started\n\nThis repository contains FreeRTOS kernel source/header files and kernel\nports only. This repository is referenced as a submodule in\n[FreeRTOS/FreeRTOS](https://github.com/FreeRTOS/FreeRTOS)\nrepository, which contains pre-configured demo application projects under\n```FreeRTOS/Demo``` directory.\n\nThe easiest way to use FreeRTOS is to start with one of the pre-configured demo\napplication projects.  That way you will have the correct FreeRTOS source files\nincluded, and the correct include paths configured. Once a demo application is\nbuilding and executing you can remove the demo application files, and start to\nadd in your own application source files.  See the\n[FreeRTOS Kernel Quick Start Guide](https://www.freertos.org/Documentation/01-FreeRTOS-quick-start/01-Beginners-guide/02-Quick-start-guide)\nfor detailed instructions and other useful links.\n\nAdditionally, for FreeRTOS kernel feature information refer to the\n[Developer Documentation](https://www.freertos.org/Documentation/02-Kernel/02-Kernel-features/00-Developer-docs),\nand [API Reference](https://www.freertos.org/Documentation/02-Kernel/04-API-references/01-Task-creation/00-TaskHandle).\n\nAlso for contributing and creating a Pull Request please refer to\n[the instructions here](.github/CONTRIBUTING.md#contributing-via-pull-request).\n\n**FreeRTOS-Kernel V11.1.0\n[source code](https://github.com/FreeRTOS/FreeRTOS-Kernel/tree/V11.1.0) is part\nof the\n[FreeRTOS 202406.00 LTS](https://github.com/FreeRTOS/FreeRTOS-LTS/tree/202406-LTS)\nrelease.**\n\n### Getting help\n\nIf you have any questions or need assistance troubleshooting your FreeRTOS project,\nwe have an active community that can help on the\n[FreeRTOS Community Support Forum](https://forums.freertos.org).\n\n## To consume FreeRTOS-Kernel\n\n### Consume with CMake\n\nIf using CMake, it is recommended to use this repository using FetchContent.\nAdd the following into your project's main or a subdirectory's `CMakeLists.txt`:\n\n- Define the source and version/tag you want to use:\n\n```cmake\nFetchContent_Declare( freertos_kernel\n  GIT_REPOSITORY https://github.com/FreeRTOS/FreeRTOS-Kernel.git\n  GIT_TAG        main #Note: Best practice to use specific git-hash or tagged version\n)\n```\n\nIn case you prefer to add it as a git submodule, do:\n\n```bash\ngit submodule add https://github.com/FreeRTOS/FreeRTOS-Kernel.git <path of the submodule>\ngit submodule update --init\n```\n\n- Add a freertos_config library (typically an INTERFACE library) The following assumes the directory structure:\n  - `include/FreeRTOSConfig.h`\n\n```cmake\nadd_library(freertos_config INTERFACE)\n\ntarget_include_directories(freertos_config SYSTEM\nINTERFACE\n    include\n)\n\ntarget_compile_definitions(freertos_config\n  INTERFACE\n    projCOVERAGE_TEST=0\n)\n```\n\nIn case you installed FreeRTOS-Kernel as a submodule, you will have to add it as a subdirectory:\n\n```cmake\nadd_subdirectory(${FREERTOS_PATH})\n```\n\n- Configure the FreeRTOS-Kernel and make it available\n  - this particular example supports a native and cross-compiled build option.\n\n```cmake\nset( FREERTOS_HEAP \"4\" CACHE STRING \"\" FORCE)\n# Select the native compile PORT\nset( FREERTOS_PORT \"GCC_POSIX\" CACHE STRING \"\" FORCE)\n# Select the cross-compile PORT\nif (CMAKE_CROSSCOMPILING)\n  set(FREERTOS_PORT \"GCC_ARM_CA9\" CACHE STRING \"\" FORCE)\nendif()\n\nFetchContent_MakeAvailable(freertos_kernel)\n```\n\n- In case of cross compilation, you should also add the following to `freertos_config`:\n\n```cmake\ntarget_compile_definitions(freertos_config INTERFACE ${definitions})\ntarget_compile_options(freertos_config INTERFACE ${options})\n```\n\n### Consuming stand-alone - Cloning this repository\n\nTo clone using HTTPS:\n\n```\ngit clone https://github.com/FreeRTOS/FreeRTOS-Kernel.git\n```\n\nUsing SSH:\n\n```\ngit clone git@github.com:FreeRTOS/FreeRTOS-Kernel.git\n```\n\n## Repository structure\n\n- The root of this repository contains the three files that are common to\nevery port - list.c, queue.c and tasks.c.  The kernel is contained within these\nthree files.  croutine.c implements the optional co-routine functionality - which\nis normally only used on very memory limited systems.\n\n- The ```./portable``` directory contains the files that are specific to a particular microcontroller and/or compiler.\nSee the readme file in the ```./portable``` directory for more information.\n\n- The ```./include``` directory contains the real time kernel header files.\n\n- The ```./template_configuration``` directory contains a sample `FreeRTOSConfig.h` to help jumpstart a new project.\nSee the [FreeRTOSConfig.h](examples/template_configuration/FreeRTOSConfig.h) file for instructions.\n\n### Code Formatting\n\nFreeRTOS files are formatted using the\n\"[uncrustify](https://github.com/uncrustify/uncrustify)\" tool.\nThe configuration file used by uncrustify can be found in the\n[FreeRTOS/CI-CD-GitHub-Actions's](https://github.com/FreeRTOS/CI-CD-Github-Actions)\n[uncrustify.cfg](https://github.com/FreeRTOS/CI-CD-Github-Actions/tree/main/formatting)\nfile.\n\n### Line Endings\n\nFile checked into the FreeRTOS-Kernel repository use unix-style LF line endings\nfor the best compatibility with git.\n\nFor optimal compatibility with Microsoft Windows tools, it is best to enable\nthe git autocrlf feature. You can enable this setting for the current\nrepository using the following command:\n\n```\ngit config core.autocrlf true\n```\n\n### Git History Optimizations\n\nSome commits in this repository perform large refactors which touch many lines\nand lead to unwanted behavior when using the `git blame` command. You can\nconfigure git to ignore the list of large refactor commits in this repository\nwith the following command:\n\n```\ngit config blame.ignoreRevsFile .git-blame-ignore-revs\n```\n\n### Spelling and Formatting\n\nWe recommend using [Visual Studio Code](https://code.visualstudio.com),\ncommonly referred to as VSCode, when working on the FreeRTOS-Kernel.\nThe FreeRTOS-Kernel also uses [cSpell](https://cspell.org/) as part of its\nspelling check. The config file for which can be found at [cspell.config.yaml](cspell.config.yaml)\nThere is additionally a\n[cSpell plugin for VSCode](https://marketplace.visualstudio.com/items?itemName=streetsidesoftware.code-spell-checker)\nthat can be used as well.\n*[.cSpellWords.txt](.github/.cSpellWords.txt)* contains words that are not\ntraditionally found in an English dictionary. It is used by the spellchecker\nto verify the various jargon, variable names, and other odd words used in the\nFreeRTOS code base are correct. If your pull request fails to pass the spelling\nand you believe this is a mistake, then add the word to\n*[.cSpellWords.txt](.github/.cSpellWords.txt)*. When adding a word please\nthen sort the list, which can be done by running the bash command:\n`sort -u .cSpellWords.txt -o .cSpellWords.txt`\nNote that only the FreeRTOS-Kernel Source Files, [include](include),\n[portable/MemMang](portable/MemMang), and [portable/Common](portable/Common)\nfiles are checked for proper spelling, and formatting at this time.\n\n## Third Party Tools\nVisit [this link](.github/third_party_tools.md) for detailed information about\nthird-party tools with FreeRTOS support.\n",
      "stars_today": 2
    },
    {
      "id": 88200328,
      "name": "LibreraReader",
      "full_name": "foobnix/LibreraReader",
      "description": "Book Reader for Android",
      "html_url": "https://github.com/foobnix/LibreraReader",
      "stars": 4162,
      "forks": 385,
      "language": "C",
      "topics": [],
      "created_at": "2017-04-13T19:43:19Z",
      "updated_at": "2026-01-24T17:49:14Z",
      "pushed_at": "2026-01-23T19:03:16Z",
      "open_issues": 479,
      "owner": {
        "login": "foobnix",
        "avatar_url": "https://avatars.githubusercontent.com/u/432440?v=4"
      },
      "readme": "![Logo](https://raw.githubusercontent.com/foobnix/LirbiReader/master/logo.jpg)\n\n**The development and support of Librera is frozen for an unpredictable time, there is a big war in my country\nUkraine.**\n[Russian invasion of Ukraine](https://en.wikipedia.org/wiki/2022_Russian_invasion_of_Ukraine)\n\nğŸ‡ºğŸ‡¦ To help Ukraine, please donate to these funds ğŸ’™ğŸ’›\n\n[OFFICIAL FUNDRAISING PLATFORM OF UKRAINE](https://u24.gov.ua/)\n\n[ĞŸĞ¾Ğ²ĞµÑ€Ğ½Ğ¸ÑÑŒ Ğ–Ğ¸Ğ²Ğ¸Ğ¼ - Come Back Alive](https://savelife.in.ua/en/)\n\n[Ğ¤Ğ¾Ğ½Ğ´ Ğ¡ĞµÑ€Ğ³Ñ–Ñ Ğ¡Ñ‚ĞµÑ€Ğ½ĞµĞ½ĞºĞ° - Foundation Sternenko Community](https://www.sternenkofund.org/en)\n\n[Ğ¤Ğ¾Ğ½Ğ´ Ğ¡ĞµÑ€Ğ³Ñ–Ñ ĞŸÑ€Ğ¸Ñ‚ÑƒĞ»Ğ¸ - Serhiy Prytula Charity Foundation](https://prytulafoundation.org/en/)\n\n# Librera Reader\n\nLibrera Reader is an e-book reader for Android devices;\nit supports the following formats: PDF, EPUB, EPUB3, MOBI, DjVu, FB2, TXT, RTF, AZW, AZW3, HTML, CBZ, CBR, DOC, DOCX,\nand OPDS Catalogs\n\n# Download application\n\n[Librera Reader on Google Play](https://play.google.com/store/apps/details?id=com.foobnix.pdf.reader)\n\n[Librera PRO on Google Play](https://play.google.com/store/apps/details?id=com.foobnix.pro.pdf.reader)\n\n[Librera F-Droid](https://f-droid.org/en/packages/com.foobnix.pro.pdf.reader/)\n\n[Beta testing .apk](http://beta.librera.mobi/)\n\n[Application Fonts.zip](https://github.com/foobnix/LirbiReader/tree/master/Builder/fonts)\n\n\n[Web browser Librera Book Reader](https://librera.mobi/online-book-reader/)\n\nhttps://librera.mobi/online-book-reader/?file=https://pdfobject.com/pdf/sample.pdf\n\n[Google Chrome Extension](https://chromewebstore.google.com/detail/epub-reader-librera/kfpiokccdkdlbjmgiajpfcdefcbdbphe)\n\n[zip Chrome Extension](https://github.com/foobnix/LibreraReader/raw/master/Builder/librara-chrome-extension.zip)\n\n### Links\n\n[web: https://librera.mobi/](https://librera.mobi/)\n\n[What is new/Changes](https://librera.mobi/what-is-new/)\n\n[FAQ](https://librera.mobi/faq/)\n\n[Telegram Info](https://t.me/LibreraReader)\n\n[Telegram Chat](https://t.me/librera_reader_chat)\n\nâ™¥ï¸â™¥ï¸â™¥ï¸ [Support & Donation on Patreon](https://www.patreon.com/librera) â™¥ï¸â™¥ï¸â™¥ï¸\n\n[Email: librera.reader@gmail.com](mailto:librera.reader@gmail.com)\n\n## Required build libs\n\n~~~~\nmesa-common-dev libxcursor-dev libxrandr-dev libxinerama-dev libglu1-mesa-dev libxi-dev pkg-config libgl-dev\n~~~~\n\nYou also need the Android NDK in version 20+\nPlease ensure to download it using android studio and add the NDK to your PATH.\n\n## Create a keystore\n\nEven if you do not plan to upload a version yourself you need a keystore with a certificate to build.\nThe keystore needs to be in PKCS12 format.\nYou can create a keystore in your actual directory using the following call\n(replace ALIAS by your alias, it is just a name):\n\n~~~~\nkeytool -genkey -v -storetype PKCS12 -keystore keystore.pkcs12 -alias ALIAS -keyalg RSA -keysize 2048 -validity 10000\n~~~~\n\nNow edit or create the file ~/.gradle/gradle.properties and set following values\n(replacing PASSWD by the password you typed while creating the keystore, ALIAS as before and using the path to your\nkeystore):\n\n~~~~\nRELEASE_STORE_FILE=/PATH/TO/YOUR/keystore.pkcs12\nRELEASE_STORE_PASSWORD=PASSWD\nRELEASE_KEY_PASSWORD=PASSWD\nRELEASE_KEY_ALIAS=ALIAS\n~~~~\n\n## Create Firebase Authentication file\n\nTo build with firebase support (all version but the ones for Fdroid) you need to get an\nauthentication file for firebase services offered by google. Therefore please follow\nhttps://firebase.google.com/docs/android/setup to create your own project. You need to\nregister for the packages com.foobnix.pdf.info and com.foobnix.pdf.reader.a1. This way\nyou will get a google-services.json file that you have to place in the app folder of\nthe repository.\n\nFor this project only Analytics is used, so a spakling plan is all you need.\n\n## Librera Build on MuPdf\n\n~~~~\ncd Builder\n./link_to_mupdf_x.x.x.sh (Change the paths to mupdf and jniLibs folders)\ncd ..\n./gradlew assembleLibrera\n~~~~\n\n## Building for F-Droid for Android\n\nIf you wish to build for F-Droid (e.g. not using google services, Internet) you can run the build with\n\n~~~~\ncd Builder\n./link_to_mupdf_x.x.x.sh\ncd ..\n./gradlew assembleFdroid\n~~~~\n\nF-Droid build does also not need a **google-services.json**\n\n## Librera depends on:\n\nMuPDF - (AGPL License) https://github.com/ArtifexSoftware/mupdf\n\n* ebookdroid\n* djvulibre\n* hpx\n* junrar\n* glide\n* libmobi\n* commons-compress\n* eventbus\n* greendao\n* jsoup\n* juniversalchardet\n* commons-compress\n* okhttp3\n* okhttp-digest\n* okio\n* rtfparserkit\n* java-mammoth\n* zip4j\n\nLibrera is distributed under the GPL\n\n## License\n\nSee the [LICENSE](LICENSE.txt) file for license rights and limitations (GPL v.3).\n",
      "stars_today": 2
    },
    {
      "id": 294501642,
      "name": "Holy-Unblocker",
      "full_name": "QuiteAFancyEmerald/Holy-Unblocker",
      "description": "Holy Unblocker LTS is a web proxy service that helps you access websites that may be blocked by your network, government or policy all within your browser with no download or setup. It does this securely and with additional privacy features. Browse Tor/Onion sites in any browser, hide browsing activity and bypass filters. (Star if you fork it!)",
      "html_url": "https://github.com/QuiteAFancyEmerald/Holy-Unblocker",
      "stars": 1188,
      "forks": 4469,
      "language": "JavaScript",
      "topics": [
        "adblocking",
        "anonymity",
        "browsersync",
        "bypass",
        "bypass-recaptchav3",
        "docker",
        "fastify",
        "https-proxy",
        "javascript",
        "nodejs",
        "onion-service",
        "privacy",
        "proxy",
        "socks5-proxy",
        "tor",
        "unblock",
        "unblocker",
        "vpn",
        "web-proxy",
        "webproxy"
      ],
      "created_at": "2020-09-10T19:18:23Z",
      "updated_at": "2026-01-24T16:14:29Z",
      "pushed_at": "2026-01-22T00:38:50Z",
      "open_issues": 8,
      "owner": {
        "login": "QuiteAFancyEmerald",
        "avatar_url": "https://avatars.githubusercontent.com/u/46467239?v=4"
      },
      "readme": "<img align=\"center\" src=\"https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/github_banner.png\"></img>\n\n<img align=\"left\" width=\"40px\" src=\"https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/logo_github.png\"></img>\n\n# Holy Unblocker LTS (v6.x.x)\n\n![GitHub Actions Status](https://github.com/QuiteAFancyEmerald/Holy-Unblocker/workflows/CI-Production/badge.svg)\n![GitHub Actions Status](https://github.com/QuiteAFancyEmerald/Holy-Unblocker/workflows/CI-Win/badge.svg)\n[![Docker Image Version](https://img.shields.io/docker/v/quiteafancyemerald/holy-unblocker.svg)](https://hub.docker.com/r/quiteafancyemerald/holy-unblocker)\n[![Docker Pulls](https://img.shields.io/docker/pulls/quiteafancyemerald/holy-unblocker.svg)](https://hub.docker.com/r/quiteafancyemerald/holy-unblocker)\n\nHoly Unblocker LTS is an experimental web proxy service that can bypass web filters or \"blockers\" regardless of whether the method of censorship is client-side or network-based. This includes the ability to bypass content blockers from governments, chrome extensions, localized client firewalls, and network-related filters. The project even allows the ability to browse Tor/Onion sites in any browser (even Chromium) all through a website!\n\n## You can support Holy Unblocker by starring the repository!\n\nThis project serves mostly as a proof of concept for the ideal clientless solution to bypassing censorship. A good use case of this project would be if you ever needed a clientless solution to use Tor or leave minimal traces of device activity. Simply host this project on any domain and have an alternative solution to a VPN without needing to download anything on said device. Being a secure web proxy service, it supports numerous sites while being updated frequently and concentrating on being easy to self-host. Holy Unblocker LTS works with a large number of sites, including YouTube, Discord, GeForce NOW and more!\nAlso has a good amount of locally hosted games featured on the site.\n\n### Over 30M+ users since 2020. Thank you so much for the support I could have never imagined how massive the web proxy community has become.\n\n#### Current Branch: Latest\n\n<details><summary>Branch Types</summary>\n\n- Latest (master; built for FOSS and SEO)\n- Beta (pending changes; changes that may break things)\n- Production (v4, v5, v6; stable version of Holy Unblocker LTS. Changes for self hosting in production settings; max filtering evasion and request handling)\n</details>\n\n#### Considering switching branches for self-hosting to a production branch!\n\nView the <a href=\"#deploy-holy-unblocker\">self-deployment options</a> if you wish to self host this project. Can't deploy using any of the free options? Check out Railway or look into cheap, paid VPS hosting solutions. If you don't wish to self-host join the discord for more official instance links that are restocked frequently.\n\n**Be sure to join Titanium Network's Discord for more official site links:** <a href=\"https://discord.gg/unblock\">https://discord.gg/unblock</a>\n\n<br>\n\n> [!CAUTION]\n> If you are going to self-host Holy Unblocker LTS please switch to the PRODUCTION branch for filter evasion features. The master branch is intended for development work and a highly readable source for developers. You can select a production branch (v6.x_production) via the branches dropdown.\n\n> [!TIP]\n> Holy Unblocker LTS is optimized for self-hosting to provide you with maximum privacy control! Fork this repository and consider starring. You can self-host using either free or paid deployment options, or set it up on a dedicated instance (VPS) for enhanced performance.\n\n| **Supported Sites**        | **Features**                                                                                                                          |\n| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- |\n| Youtube                    | Built-in variety of open source web proxies with both a focus on speed and/or security                                                |\n| Reddit                     | Features Source Randomization and DOM Masquerading to circumvent major filters effectively along with randomizations to proxy globals |\n| Discord                    | Tab title + icon customization using the Settings Menu for improved browsing history stealth                                          |\n| Instagram                  | Adblocking support across all websites while surfing and low latency DNS on official servers                                          |\n| Reddit.com                 | SOCKS5 and Onion routing support with Tor within the Settings Menu. Use Tor/Onion sites in any browser!                               |\n| GeForce NOW                | Game library with moderately decent titles and open-source emulation projects                                                         |\n| Spotify                    | Bypass regional proxy blocks by swapping regions or enabling Tor                                                                      |\n| And essentially all sites! | Built for intensive production loads and ease of setup                                                                                |\n\n<img src=\"https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/preview/hu-v6.4.3-preview.png\"></img>\n<img src=\"https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/preview/hu-v6.3.0-preview-settings.png\"></img>\n\n## Deploy Holy Unblocker\n\n### Free Deployments\n\n[![Deploy to Koyeb](https://binbashbanana.github.io/deploy-buttons/buttons/remade/koyeb.svg)](https://app.koyeb.com/deploy?name=holy-unblocker&type=git&repository=QuiteAFancyEmerald%2FHoly-Unblocker&branch=v6.9.4_production&builder=buildpack&env%5B%5D=&ports=8080%3Bhttp%3B%2F)\n[![Deploy to Oracle Cloud](https://binbashbanana.github.io/deploy-buttons/buttons/remade/oraclecloud.svg)](https://cloud.oracle.com/resourcemanager/stacks/create?zipUrl=https://github.com/BinBashBanana/deploy-buttons/archive/refs/heads/main.zip)\n\n<details><summary>Alternative Free Sources</summary>\n\n[![Deploy to Cyclic](https://binbashbanana.github.io/deploy-buttons/buttons/remade/cyclic.svg)](https://app.cyclic.sh/api/app/deploy/shuttlenetwork/shuttle)\n[![Deploy to Render](https://render.com/images/deploy-to-render-button.svg)](https://render.com/deploy?repo=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)\n[![Deploy to Fly.io](https://img.shields.io/badge/Deploy%20to-Fly.io-blue?logo=fly.io)](https://fly.io/launch?repo=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)\n\n</details>\n\n### Production Paid/Free Options (Requires Payment Info)\n\n[![Deploy to Azure](https://raw.githubusercontent.com/BinBashBanana/deploy-buttons/master/buttons/remade/azure.svg)](https://deploy.azure.com/?repository=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)\n[![Deploy to IBM Cloud](https://raw.githubusercontent.com/BinBashBanana/deploy-buttons/master/buttons/remade/ibmcloud.svg)](https://cloud.ibm.com/devops/setup/deploy?repository=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)\n[![Deploy to Amplify Console](https://raw.githubusercontent.com/BinBashBanana/deploy-buttons/master/buttons/remade/amplifyconsole.svg)](https://console.aws.amazon.com/amplify/home#/deploy?repo=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)\n[![Run on Google Cloud](https://raw.githubusercontent.com/BinBashBanana/deploy-buttons/master/buttons/remade/googlecloud.svg)](https://deploy.cloud.run/?git_repo=https://github.com/QuiteAFancyEmerald/Holy-Unblocker)\n\n#### What happened to Replit/Heroku Deployment?\n\nReplit is no longer free and Heroku has a set policy against web proxies. Try GitHub Codespaces or Gitpod instead for development on the cloud OR Koyeb for free hosting.\n\n### GitHub Codespaces\n\n<details><summary>Setup Instructions</summary>\n\n- Fork (and star!) this repository to your GitHub account\n- Head to the official <a href=\"https://github.com/codespaces\">Codespaces</a> website (ensure you have a GitHub account already made)\n- Select **New Codespaces** and look for _[USERNAME]/Holy-Unblocker_ on your account\n- Ensure the branch is set to `master` and the dev container configuration is set to **Holy Unblocker LTS**\n- Select **Create Codespace** and allow the container to setup\n- Type `npm run fresh-install` and `npm start` in the terminal\n- Click \"Make public\" on the application popup, then access the deployed website via the ports tab.\n\n</details>\n\n## Table of contents:\n\n- [Setup](#how-to-setup)\n  - [Terminal](#terminal)\n  - [Project Configuration](#configuration)\n    - [Server Configuration](#server-configuration-setup)\n    - [TOR Routing](#toronion-routing-setup)\n    - [Proxy](#proxy-configuration)\n    - [Client Navigation](#client-navigation-configuration)\n    - [Games Management](#games-management)\n  - [Structure](#structure)\n    - [Structure Information](#structure-information)\n    - [Static Files](#details-of-views)\n    - [Scripts](#scripts-located-in-viewsassetsjs)\n  - [Future Additions](#future-additions)\n  - [Beginner's Explanation](#vauge-explanation-for-beginners-with-external-proxies-and-hosting)\n    - [Hosting Providers](#list-of-some-good-hosting-options)\n    - [Domain Setup](#freenomdomain-steps)\n    - [Cloudflare Setup](#cloudflare-steps)\n    - [Workspace Configurations](#workspace-configurations)\n  - [Detailed FAQ](#detailed-faq)\n  - [More Information](#more-information)\n\n## How to Setup\n\n#### It is highly recommended you switch branches via your IDE to a production released branch. Often the master branch contains unstable or WIP changes.|\n\n#### Example: v6.x_production instead of master\n\n### Terminal\n\nEither use the button above to deploy to the deployment options above or type the commands below on a dedicated server\n\n**THIS PROJECT REQUIRES NGINX NOT CADDY.** \n\nPlease ensure you are using Node 20.x as well:\n\n```bash\ngit clone https://github.com/QuiteAFancyEmerald/Holy-Unblocker.git\n\ncd Holy-Unblocker\n\n# Edit config.js and set production to true if you want to use pm2 (Allows for easier VPS hosting)\nnpm run fresh-install\nnpm start\n\n# Or on subsequent uses...\nnpm restart\n\n# For killing any production processes made with pm2\nnpm run kill\n\n# For clearing respective Rammerhead cache\nnpm run clean\n\n# If you encounter any build errors...\nnpm run build\n\n# If you encounter any service errors...\nnpm run test\n```\n\nThis website is hosted locally with Scramjet, Ultraviolet (Wisp, Bare-Mux, EpoxyTransport, CurlTransport) and Rammerhead built-in.\n\n### For security reasons when hosting with a reverse proxy PLEASE use NGINX not Caddy. This is due to wisp-js using loopbacks.\n\n#### Detailed Setup (Ubuntu Example)\nYou will need Node.js 20.x and Git installed; below is an example for Debian/Ubuntu setup.\n<details>\n\nFor simplicity sake you can join the TN discord at discord.gg/unblock and request for mirror site links (that are restocked and unblocked).\n\n### Hosting\n\nIf you wish to self-host however you will first need a VPS or hosting provider: \n\n- https://docs.titaniumnetwork.org/guides/vps-hosting/\n- https://github.com/QuiteAFancyEmerald/Holy-Unblocker#deploy-holy-unblocker\n- https://docs.titaniumnetwork.org/guides/dns-setup/\n\n### Dependencies\n\nYou will then need to setup git, nginx (or caddy) and Node.js. Here is an example for Ubuntu LTS:\n```\nsudo apt update\nsudo apt upgrade\nsudo apt install curl git nginx\n\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\nexport NVM_DIR=\"$HOME/.nvm\"\n[ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\"\n\nnvm install 20\nnvm use 20\n```\nhttps://github.com/nvm-sh/nvm\nhttps://docs.titaniumnetwork.org/guides/nginx/\n\n### Tor Support (Optional)\nhttps://github.com/QuiteAFancyEmerald/Holy-Unblocker#toronionsocks5-routing-setup\n\n### Configurating Holy Unblocker\nMost important options are production along with the obfuscation and DOM masquerading techniques. \n\nFrom there just configure as needed: https://github.com/QuiteAFancyEmerald/Holy-Unblocker#configuration\n\n### Cloning and Running Holy Unblocker\n\nThen run the respective process; if you have production set to true in the configuration pm2 will be automatically enabled with our own workers/cache system. \n\n```\ngit clone https://github.com/QuiteAFancyEmerald/Holy-Unblocker.git\ncd Holy-Unblocker\n\nnpm run fresh-start\n```\n\nThen of course if you used NGINX or caddy please restart/reload it\n```\nsudo systemctl restart nginx\nsudo systemctl restart tor\n```\n\n</details>\n\n\nResources for self-hosting:\n\n- https://github.com/nvm-sh/nvm\n- https://docs.titaniumnetwork.org/guides/nginx/\n- https://docs.titaniumnetwork.org/guides/vps-hosting/\n- https://docs.titaniumnetwork.org/guides/dns-setup/\n\n### Configuration\n\n#### Server Configuration Setup\n\nThe default PORT for the proxy when started is `http://localhost:8080`. You can change the PORT and other production metrics if needed in `./ecosystem.config.js`. \n\nThe default PORT for Rammerhead is `3000`. You can change this <a href=\"https://github.com/QuiteAFancyEmerald/Holy-Unblocker/blob/8f6dcfedb71439a43a19cc0a015ee6ca7e29fd11/lib/rammerhead/holy-config.js#L9\">here</a>.\n\nEvery other localized changes for source randomization, auto-minify, etc. are located in `./config.json`.\n\n**config.json**\n- `minifyScripts`: Automatically minify respective static assets upon starting the server.\n- `randomizeIdentifiers`: Enable experimental proxy global randomization for Ultraviolet. This reduces the chances of UV being detected by any extension based filters.\n- `production`: Utilize a pre-configured production setup for server hosting. Automatically has cache control, session jobs for Rammerhead and source rewrites setup.\n- `disguiseFiles`: Enable DOM masquerading which obfuscates real the real content fetches for HU LTS. This is done through disguising requests, decompressing and then reconstructing the DOM tree.\n- `usingSEO`: Enable Source Randomization which randomizes the source by swapping chunks of data specified in `./src/data.json`. Highly useful for masking keywords that will automatically flag or block Holy Unblocker LTS as well as preventing source blocks.\n\n#### Tor/Onion/SOCKS5 Routing Setup\n\nYou need to setup Tor (no GUI need/GUI is alright. With GUI replace port 9050 with 9150) in order for the Onion Routing setting to work!\n\nSimply host Tor using this guide: https://tb-manual.torproject.org/installation/\n\nAlternative Guide (for CLI): https://community.torproject.org/onion-services/setup/install/\n\nIf you are hosting Holy Unblocker LTS on a VPS utilizing Ubuntu consider attaching Tor to systemctl for easier production management. Once Tor is up and running on either Linux or Windows it will work automatically with Holy Unblocker LTS when enabled by the user via the Settings menu.\n\nIf you wish to use a custom HTTP/HTTPS/SOCKS5 proxy to route all traffic through for Scramjet and Ultraviolet this is handled in `./views/assets/js/register-sw.js.` Modify `proxyUrl` with the respective protocol and address. This is done via the proxy option for Wisp. You can change the cases as needed.\n\n```js\n  proxyUrl = {\n    tor: 'socks5h://localhost:9050',\n    eu: 'socks5h://localhost:7000',\n    jp: 'socks5h://localhost:7001',\n  }\n```\n\n#### Proxy Configuration\n\nThe primary location for tweaking any web proxy related settings assigned via the Settings menu is `./views/assets/js/register-sw.js`. Here you can modify the provided transport options set locally via a cookie, swap out SOCKS5 proxies, change Onion routing ports, specify a blacklist, and more.\n\n- `stockSW`: The default service worker configuration file for Ultraviolet. For Holy Unblocker however adblocking is automatically enabled so this is not used by default.\n- `blacklistSW`: A modified version of Ultraviolet that allows for blacklisting domains and adblocking.\n- `proxyUrl`: Specifies a SOCKS5/HTTPS/HTTP protocol URL defaulting to the default Tor proxy port. This can be swapped out with any valid port or SOCK5s proxy. This is done via the proxy option for both epoxy and libcurl.\n- `transports`: Specifies any provided ports to be swapped via Bare-Mux and utilize Wisp.\n- `wispUrl`: Modify the pathname or url handling for Wisp\n- `defaultMode`: Specify the default transport used globally (can be swapped by the users still via the Settings menu)\n- `ScramjetController`: This constructor allows you to swap out the prefix used for Scramjet dynamically and specify file locations. Note you may need to edit `./views/scram/scramjet.sw` when changing file names.\n\n#### Client Navigation Configuration\n\nThe primary location for any client side navigation scripts is `./views/assets/js/common.js`. This file is primary used for Omnibox (Search Engine) functionality, swapping proxy options and linking games.\n\n- `getDomain`: This constant is used for specifying any subdomains to remove when appending a URL into the omnibox.\n- `goFrame`: This specifies the stealth frame used for Holy Unblocker LTS\n- `sx`: This constant specifies the search engine you want to be proxied whenever a user types something in that isn't a URL\n- `search/uvUrl/sjUrl`: These functions specify and parse the queries used for submitted URLs\n- `RammerheadEncode:` This constant is a dependency for Rammerhead parsing and querying\n- `urlHandler/asyncUrlHandler`: Used to set functions for the goProx object.\n- `goProx`: This constant allows for the mapping of URL handling for specific proxies, games or links that need to fall under a web proxy.\n\n```js\nconst goProx = Object.freeze({\n  ultraviolet: urlHandler(uvUrl),\n\n  scramjet: urlHandler(sjUrl),\n\n  rammerhead: asyncUrlHandler(\n    async (url) => location.origin + (await RammerheadEncode(search(url)))\n  ),\n\n  // `location.protocol + \"//\" + getDomain()` more like `location.origin`\n\n  examplepath: urlHandler(location.protocol + `//c.${getDomain()}/example/`),\n\n  examplesubdomain: urlHandler(location.protocol + '//c.' + getDomain()),\n\n  example: urlHandler(sjUrl('https://example.com')),\n});\n```\n\n- `prSet`: Attaches event listeners using goProx for any buttons or inputs needed\n\n```js\n// prSet function code here....\n\nprSet('pr-uv', 'ultraviolet');\nprSet('pr-sj', 'scramjet');\nprSet('pr-rh', 'rammerhead');\nprSet('pr-yt', 'youtube');\nprSet('pr-example', 'example');\n```\n\n- `huLinks/navLists`: Automatically takes paths stated in `./views/assets/json` and appends them depending on the page and usage. This is used for hiding links that would lead to filter blocks and create an easier system for adding games.\n\n#### Games Management\n\nAs stated above all game links that need to be appended to a page (including images and descriptions) are managed via the nav files in`./views/assets/json`. \n\nDownload the latest release <a href=\"https://github.com/QuiteAFancyEmerald/Holy-Unblocker/blob/master/views/GAMES.md\">here</a> and extract it within a folder called `/views/archive`.\n\n- `views/archive/g`: Contains any local or external HTML5/web games.\n- `views/archive/gfiles/flash`: Contains Ruffle (an Adobe Flash emulator) and a collection of flash games linked to an external CDN.\n- `views/archive/gfiles/rarch`: Contains webretro which is a project that ports RetroArch to WASM. Supports many systems like GBA, N64, etc; ROMS are NOT INCLUDED.\n\n## Structure\n\n<details><summary>Web Pages</summary>\n\n### Structure Information\n\n- `/views/`: The physical site base of Holy Unblocker goes here where static assets are served.\n- `/src/`: For future implementation of obfuscation and keyword removing features.\n\n#### Details of `/views/`\n\n- `/dist/` is used for minfied files. Created on build.\n- `/pages/` is used for the HTML for the site.\n- `/assets/` is used for storing various CSS, JS, image, and JSON files.\n- `/scram/` contains the respective local Scramjet implementation. Some files are overridden by the node module.\n- `/uv/` contains the UV implementation.\n\n#### Scripts located in `/views/assets/js/`\n\n- `card.js` adds a fancy visual effect to the box cards displayed on the welcome screen.\n- `common.js` is used on all pages and allows most site features to function such as autocomplete.\n- `csel.js` manages the settings menu, omnibox function and other additional features.\n- `loader.js` is used as an asset for DOM masquerading.\n- `register-sw.js` creates and manages service workers that allow Ultraviolet to function, and also uses bare transport.\n\n</details>\n\n## Future Additions\n\n<a href=\"https://github.com/QuiteAFancyEmerald/Holy-Unblocker/blob/master/TODO.md\">This</a> is our nonexhaustive todo list for Holy Unblocker LTS v6.x.x and above. Release for production will be v7.x.x and above.\n\n## Vague Explanation for Beginners With External Proxies and Hosting\n\nYou will first want to host your proxies locally or externally.\n\n#### List of some good hosting options:\n\n- <a href=\"https://crunchbits.com/\">Crunchbits</a> ( Current Hosting Provider)\n- <a href=\"https://greencloudvps.com\">Greencloud</a> (Paid)\n- <a href=\"https://www.oracle.com/cloud\">Oracle Cloud</a> (Free, Paid, Dedicated)\n- <a href=\"https://azure.microsoft.com\">Azure</a> (Free and Paid)\n\nOut of the list of hosting providers Dedipath and Azure rank first as a preference. You may also self-host.\n\nAfter you have selected a decent VPS, use Cloudflare for the DNS records for both the site and the subdomains for the proxies.\n\nThis is an example of DNS records. Self-hosting will require `A records` preferably.\n<img src=\"https://raw.githubusercontent.com/titaniumnetwork-dev/Holy-Unblocker/master/views/assets/img/dnssetup.png\" width=\"500\"></img>\n\n- `@` and `www.example.com` are being used for Holy Unblocker LTS.\n- `a.example.com` is being used for other instances like Libreddit, Invidious or web ported games depending on what the site maintainer needs.\n\nAs stated previously, Holy Unblocker is hosted locally with Scramjet, Ultraviolet and Rammerhead out of the box. No need for external instances.\n\n#### Domain Steps\n\n- If you prefer to obtain premium domains (TLDs) then use <a href=\"https://porkbun.com\">Porkbun</a>, which offers domains for amazing prices. Literally a `.org` domain normally costs around $5 first year.\n\n#### Cloudflare Steps\n\n- Use Cloudflare (make an account), add your site and then add your various DNS targets to Cloudflare. Make sure you add Cloudflare's Nameservers which will be given later when you are adding your site.\n\nMake sure they are CNAME although A records also work and try to follow this structure:\n\n**Type | Name | Target**\n\n`A | @ | VPS IP GOES HERE`  \n`A | www | VPS IP GOES HERE`  \n`A | a | VPS IP GOES HERE`\n\nMake sure HTTPS is forced and have SSL set to Flexible (if you don't use LetsEncrypt). Otherwise you can have SSL set to Full.\n\n#### Workspace Configurations\n\nPreferably if you have your own device use Visual Studio Code. Pretty much the best option you can get but obviously this is an opinion. Also make sure you have <a href=\"https://nodejs.org/\">Node.JS</a> installed on your machine.\n\nNot going to go too in depth with this part but first fork this repository. The clone it locally through a Terminal of some sort depending on what OS you are on. Make sure you navigate to the folder you want to set this up in.\n\n```\ngit clone https://github.com/QuiteAFancyEmerald/Holy-Unblocker.git\n\ncd Holy-Unblocker\n\nnpm run fresh-install\n\n# If you wish to start the project\n\nnpm start\n\n# For testing endpoints and errors\n\nnpm run test\n```\n\nNow simply add the folder you cloned this repo in in VSC. Then run `npm install`. I recommend that if you are releasing this publically on GitHub that you add a `.gitignore` in your root directory with the following exclusions:\n\n```\nnode_modules\n```\n\nNow you have your following workspace environment setup. To deploy the following workspace you just created you will need to look up depending on your hosting provider.\n\nFor an online IDE that you can use on your school computer and/or chromebook use GitPod. Basically the equivalent of Visual Studio Code but with in-browser support.\n\n- Make an account: `https://gitpod.io/`\n- Fork this repo and enter in this URL to setup your workspace: `https://gitpod.io#https://github.com/YourNameHere/Holy-Unblocker/`\n\nUse the same steps above by running `npm install` in your repository and adding a `.gitignore` in your root directory specifying to exclude `node_modules`.\n\n## Detailed FAQ\n\n<details>\n<summary>Quick FAQ</summary>\n\n#### Where can I find the games for this repo? (404 errors, etc.)\n\nDue to piracy concerns, size, etc. this has been moved over <a href=\"https://github.com/QuiteAFancyEmerald/HU-Archive\">here</a>. EmuLibrary is not featured in the public version.\n\n**Why is the site I am on not working correctly or having CAPTCHA errors?**\n\nCaptcha support is spotty on all of the current proxies sadly. It is primarily supported by Scramjet. Therefore some sites may not work with any of the sites.\n\n**I am getting 502 errors. What do I do?**\n\nWhen this happens you may either switch sites to fix the error or wait a bit. Sometimes clearing your cache can help.\n\nIf you still have any questions feel free to ask them in the discord linked here.\n\n</details>\n\n### Why are official domains now numbered? Is this project maintained again?\n\nYes, this project is active again for LTS support! However, the approach is now much simpler to ensure functionality: domain restocks as needed and a highly maintained source. More than ever, this project serves as a proof of concept for the brave souls willing to innovate in the web proxy service space.\n\n<details><summary>Former Closing Message (Original - 2022)</summary>\n\nThis isnâ€™t the greatest announcement sorry. After lots of thought and severe hesitation Iâ€™m shutting down Holy Unblocker and leaving TN. It's just been something that Iâ€™ve been super conflicted with for months hence the lack of updates and the massive gaps that happened last year. I just didnâ€™t want to throw away a project that I passionately enjoyed and spent time on while making amazing friends and meeting epic devs here. I could go on forever for who these people are but ima like leave it here. They know who they are :D\n\nThe main change of thought is that Iâ€™m finally just putting an end right now due to 1) the lack of motivation 2) the community is NOT the greatest at time and not the nicest at times (have to put that out here) 3) the future doesnâ€™t look so good for HU/TN as a project.\n\nSome things Iâ€™ll be keeping secret since there are more reasons to this choice unless otherwise for those who donâ€™t find this enough information. Good friends here will know that Iâ€™ve been super stressed about this choice for months now. Also regardless a good motivator for this choice is the fact that Iâ€™ll be graduating soon.\n\nItâ€™s possible that I may continue/come back for this in the future or keep it on GitHub only. I leave this here because even now I am still doubting myself about this change. But for now Iâ€™d check out other proxy sites like Incognito (Duce DOES a ton of updates frequently and he is the creator/developer of Ultraviolet so give him some love) :yayy_hopi:\n\nCheck out his Patreon also! For current HU patrons you will not be billed next month and the HU Patreon will be archived so head over to Duceâ€™s patron so he can purchase more domains for Incognito.\n\nWith love <3\nEmerald :HuTaoHype:\n\n</details>\n\n## More Information\n\nThis project is maintained by the Holy Unblocker LTS team and is an official flagship Titanium Network web proxy site.\n\n- <a href=\"https://github.com/titaniumnetwork-dev/\">https://github.com/titaniumnetwork-dev/</a>\n- <a href=\"https://titaniumnetwork.org/\">https://titaniumnetwork.org/</a>\n\nView the official website for more detail and credits.\n\n### Web Proxy Sources:\n\nThis project currently uses Scramjet and Ultraviolet as web proxies adhering to the Wisp protocol. Bare-Mux is utilized for swapping transport systems to be utilized with Wisp. The included transport systems are EpoxyTransport and libcurl-transport. Rammerhead is also provided as an additional web proxy option.\n\n- <a href=\"https://github.com/MercuryWorkshop/scramjet\">Scramjet</a>\n- <a href=\"https://github.com/titaniumnetwork-dev/Ultraviolet\">Ultraviolet</a>\n- <a href=\"https://github.com/MercuryWorkshop/wisp-server-node\">Wisp-Server-Node</a>\n- <a href=\"https://github.com/MercuryWorkshop/wisp-server-python\">Wisp-Server-Python</a>\n- <a href=\"https://github.com/MercuryWorkshop/EpoxyTransport\">EpoxyTransport</a>\n- <a href=\"https://github.com/MercuryWorkshop/CurlTransport\">libcurl-transport</a>\n- <a href=\"https://github.com/MercuryWorkshop/bare-mux\">Bare-Mux</a>\n- <a href=\"https://github.com/binary-person/rammerhead\">Rammerhead</a>\n- <a href=\"https://gist.github.com/BinBashBanana/a1fd7345e2d86e69d5a532f16cbdbdaa\">DetectorDetector</a>\n\n### Other Dependencies:\n\n- <a href=\"https://github.com/tsparticles/tsparticles\">tsparticles</a>\n- <a href=\"https://github.com/fastify/fastify\">fastify</a>\n- <a href=\"https://github.com/fastify/fastify-helmet\">@fastify/helmet</a>\n- <a href=\"https://github.com/fastify/fastify-static\">@fastify/static</a>\n- <a href=\"https://github.com/DerpmanDev/modal\">Modal</a>\n- <a href=\"https://github.com/BinBashBanana/webretro\">webretro</a>\n- <a href=\"https://ruffle.rs/\">Ruffle</a>\n- <a href=\"https://github.com/michalsnik/aos\">AOS</a>\n- <a href=\"https://github.com/nordtheme\">Nord Theme</a>\n- <a href=\"https://fontawesome.com/\">Font Awesome</a>\n\n### Notable Mentions:\n\n- <a href=\"https://crunchbits.com/\">Crunchbits</a> (Hosting Provider)\n",
      "stars_today": 2
    },
    {
      "id": 814708478,
      "name": "unitycatalog",
      "full_name": "unitycatalog/unitycatalog",
      "description": "Open, Multi-modal Catalog for Data & AI",
      "html_url": "https://github.com/unitycatalog/unitycatalog",
      "stars": 3277,
      "forks": 570,
      "language": "Java",
      "topics": [],
      "created_at": "2024-06-13T14:39:25Z",
      "updated_at": "2026-01-24T13:48:55Z",
      "pushed_at": "2026-01-23T23:34:34Z",
      "open_issues": 355,
      "owner": {
        "login": "unitycatalog",
        "avatar_url": "https://avatars.githubusercontent.com/u/171874451?v=4"
      },
      "readme": "<img src=\"./docs/assets/images/uc-logo.png\" width=\"600px\" />\n\n# Unity Catalog: Open, Multimodal Catalog for Data & AI\n\nUnity Catalog is the industryâ€™s only universal catalog for data and AI.\n\n- **Multimodal interface supports any format, engine, and asset**\n  - Multi-format support: It is extensible and supports Delta Lake, Apache Iceberg and Apache Hudi via UniForm, Apache Parquet, JSON, CSV, and many others.\n  - Multi-engine support: With its open APIs, data cataloged in Unity can be read by many leading compute engines.\n  - Multimodal: It supports all your data and AI assets, including tables, files, functions, AI models.\n- **Open source API and implementation** - OpenAPI spec and OSS implementation (Apache 2.0 license). It is also compatible with Apache Hive's metastore API and Apache Iceberg's REST catalog API. Unity Catalog is currently a sandbox project with LF AI and Data Foundation (part of the Linux Foundation).\n- **Unified governance** for data and AI - Govern and secure tabular data, unstructured assets, and AI assets with a single interface.\n\nThe current roadmap is available at [Unity Catalog Roadmap](roadmap.md).\n\n![UC Hero Image](./docs/assets/images/uc.png)\n\n### Vibrant ecosystem\n\nThis is a community effort. Unity Catalog is supported by\n\n- [Amazon Web Services](https://aws.amazon.com/)\n- [Confluent](https://www.confluent.io/)\n- [Daft (Eventual)](https://github.com/Eventual-Inc/Daft)\n- [dbt Labs](https://www.getdbt.com/)\n- [DuckDB](https://duckdblabs.com/)\n- [Fivetran](https://www.fivetran.com/)\n- [Google Cloud](https://cloud.google.com/)\n- [Granica](https://granica.ai/)\n- [Immuta](https://www.immuta.com/)\n- [Informatica](https://www.informatica.com/)\n- [Kuzu](https://www.kuzudb.com/)\n- [LanceDB](https://lancedb.com/)\n- [LangChain](https://www.langchain.com/)\n- [LlamaIndex](https://www.llamaindex.ai/)\n- [Microsoft Azure](https://azure.microsoft.com)\n- [NVIDIA](https://www.nvidia.com/)\n- [Onehouse](https://www.onehouse.ai/)\n- [PuppyGraph](https://www.puppygraph.com/)\n- [Salesforce](https://www.salesforce.com/)\n- [StarRocks (CelerData)](https://celerdata.com/)\n- [Spice AI](https://github.com/spiceai/spiceai)\n- [Tecton](https://www.tecton.ai/)\n- [Unstructured](https://unstructured.io/)\n\nUnity Catalog is proud to be hosted by the LF AI & Data Foundation.\n\n<a href=\"https://lfaidata.foundation/projects\">\n  <img src=\"./docs/assets/images/lfaidata-project-badge-sandbox-color.png\" width=\"200px\" />\n</a>\n\n## Quickstart - Hello UC!\n\nLet's take Unity Catalog for spin. In this guide, we are going to do the following:\n\n- In one terminal, run the UC server.\n- In another terminal, we will explore the contents of the UC server using a CLI.\n  An example project is provided to demonstrate how to use the UC SDK for various assets\n  as well as provide a convenient way to explore the content of any UC server implementation.\n\n> If you prefer to run Unity Catalog in Docker use `docker compose up`. See the [Docker Compose docs](./docs/docker_compose.md) for more details.\n\n### Prerequisites\n\nYou have to ensure that your local environment has the following:\n\n- Clone this repository.\n- Ensure the `JAVA_HOME` environment variable your terminal is configured to point to JDK17.\n- Compile the project using `build/sbt package`\n\n### Run the UC Server\n\nIn a terminal, in the cloned repository root directory, start the UC server.\n\n```sh\nbin/start-uc-server\n```\n\nFor the remaining steps, continue in a different terminal.\n\n### Operate on Delta tables with the CLI\n\nLet's list the tables.\n\n```sh\nbin/uc table list --catalog unity --schema default\n```\n\nYou should see a few tables. Some details are truncated because of the nested nature of the data.\nTo see all the content, you can add `--output jsonPretty` to any command.\n\nNext, let's get the metadata of one of those tables.\n\n```sh\nbin/uc table get --full_name unity.default.numbers\n```\n\nYou can see that it is a Delta table. Now, specifically for Delta tables, this CLI can\nprint a snippet of the contents of a Delta table (powered by the [Delta Kernel Java](https://delta.io/blog/delta-kernel/) project).\nLet's try that.\n\n```sh\nbin/uc table read --full_name unity.default.numbers\n```\n\n### Operate on Delta tables with DuckDB\n\nFor operating on tables with DuckDB, you will have to [install it](https://duckdb.org/docs/installation/) (version 1.0).\nLet's start DuckDB and install a couple of extensions. To start DuckDB, run the command `duckdb` in the terminal.\nThen, in the DuckDB shell, run the following commands:\n\n```sql\ninstall uc_catalog from core_nightly;\nload uc_catalog;\ninstall delta;\nload delta;\n```\n\nIf you have installed these extensions before, you may have to run `update extensions` and restart DuckDB\nfor the following steps to work.\n\nNow that we have DuckDB all set up, let's try connecting to UC by specifying a secret.\n\n```sql\nCREATE SECRET (\n      TYPE UC,\n      TOKEN 'not-used',\n      ENDPOINT 'http://127.0.0.1:8080',\n      AWS_REGION 'us-east-2'\n );\n```\n\nYou should see it print a short table saying `Success` = `true`. Then we attach the `unity` catalog to DuckDB.\n\n```sql\nATTACH 'unity' AS unity (TYPE UC_CATALOG);\n```\n\nNow we are ready to query. Try the following:\n\n```sql\nSHOW ALL TABLES;\nSELECT * from unity.default.numbers;\n```\n\nYou should see the tables listed and the contents of the `numbers` table printed.\nTo quit DuckDB, press `Ctrl`+`D` (if your platform supports it), press `Ctrl`+`C`, or use the `.exit` command in the DuckDB shell.\n\n### Interact with the Unity Catalog UI\n\n![UC UI](./docs/assets/images/uc-ui.png)\n\nTo use the Unity Catalog UI, start a new terminal and ensure you have already started the UC server (e.g., `./bin/start-uc-server`)\n\n**Prerequisites**\n\n- Node: https://nodejs.org/en/download/package-manager\n- Yarn: https://classic.yarnpkg.com/lang/en/docs/install\n\n**How to start the UI through yarn**\n\n```\ncd /ui\nyarn install\nyarn start\n```\n\n## CLI tutorial\n\nYou can interact with a Unity Catalog server to create and manage catalogs, schemas and tables,\noperate on volumes and functions from the CLI, and much more.\nSee the [cli usage](docs/usage/cli.md) for more details.\n\n## APIs and Compatibility\n\n- Open API specification: See the [Unity Catalog Rest API](https://docs.unitycatalog.io/swagger-docs/).\n- Compatibility and stability: The APIs are currently evolving and should not be assumed to be stable.\n\n## Building Unity Catalog\n\nUnity Catalog is built using [sbt](https://www.scala-sbt.org/).\n\nTo build UC (incl. [Spark Integration](./connectors/spark) module), run the following command:\n\n```sh\nbuild/sbt clean package publishLocal\n```\n\nRefer to [sbt docs](https://www.scala-sbt.org/1.x/docs/) for more commands.\n\n## Deployment\n\n- To create a tarball that can be used to deploy the UC server or run the CLI, run the following:\n  ```sh\n  build/sbt createTarball\n  ```\n  This will create a tarball in the `target` directory. See the full [deployment guide](docs/deployment.md) for more details.\n\n## Compiling and testing\n\n- Install JDK 17 by whatever mechanism is appropriate for your system, and\n  set that version to be the default Java version (e.g. via the env variable `JAVA_HOME`)\n- To compile all the code without running tests, run the following:\n  ```sh\n  build/sbt clean compile\n  ```\n- To compile and execute tests, run the following:\n  ```sh\n  build/sbt -J-Xmx2G clean test\n  ```\n- To execute tests with coverage, run the following:\n  ```sh\n  build/sbt -J-Xmx2G jacoco\n  ```\n- To update the API specification, just update the `api/all.yaml` and then run the following:\n  ```sh\n  build/sbt generate\n  ```\n  This will regenerate the OpenAPI data models in the UC server and data models + APIs in the client SDK.\n- To format the code, run the following:\n  ```sh\n  build/sbt javafmtAll\n  ```\n\n## Setting up IDE\n\nIntelliJ is the recommended IDE to use when developing Unity Catalog. The below steps outline how to add the project to IntelliJ:\n\n1. Clone Unity Catalog into a local folder, such as `~/unitycatalog`.\n2. Select `File` > `New Project` > `Project from Existing Sources...` and select `~/unitycatalog`.\n3. Under `Import project from external model` select `sbt`. Click `Next`.\n4. Click `Finish`.\n\nJava code adheres to the [Google style](https://google.github.io/styleguide/javaguide.html), which is verified via `build/sbt javafmtCheckAll` during builds.\nIn order to automatically fix Java code style issues, please use `build/sbt javafmtAll`.\n\n### Configuring Code Formatter for Eclipse/IntelliJ\n\nFollow the instructions for [Eclipse](https://github.com/google/google-java-format#eclipse) or\n[IntelliJ](https://github.com/google/google-java-format#intellij-android-studio-and-other-jetbrains-ides) to install the **google-java-format** plugin (note the required manual actions for IntelliJ).\n\n### Using more recent JDKs\n\nThe build script [checks for a lower bound on the JDK](./build.sbt#L14) but the [current SBT version](./project/build.properties)\nimposes an upper bound. Please check the [JDK compatibility](https://docs.scala-lang.org/overviews/jdk-compatibility/overview.html) documentation for more information\n\n### Serving the documentation with mkdocs\n\nFor an overview of how to contribute to the documentation, please see our introduction [here](./docs/README.md).\nFor the official documentation, please take a look at [https://docs.unitycatalog.io/](https://docs.unitycatalog.io/).\n",
      "stars_today": 2
    },
    {
      "id": 68456226,
      "name": "rdma-core",
      "full_name": "linux-rdma/rdma-core",
      "description": "RDMA core userspace libraries and daemons",
      "html_url": "https://github.com/linux-rdma/rdma-core",
      "stars": 2119,
      "forks": 819,
      "language": "C",
      "topics": [
        "infiniband",
        "iwarp",
        "kernel-rdma-drivers",
        "linux-kernel",
        "rdma",
        "roce",
        "userspace-libraries"
      ],
      "created_at": "2016-09-17T14:13:20Z",
      "updated_at": "2026-01-25T02:15:59Z",
      "pushed_at": "2026-01-15T08:45:42Z",
      "open_issues": 23,
      "owner": {
        "login": "linux-rdma",
        "avatar_url": "https://avatars.githubusercontent.com/u/22179970?v=4"
      },
      "readme": "[![Build Status](https://dev.azure.com/ucfconsort/rdma-core/_apis/build/status/linux-rdma.rdma-core?branchName=master)](https://dev.azure.com/ucfconsort/rdma-core/_build/latest?definitionId=2&branchName=master)\n\n# RDMA Core Userspace Libraries and Daemons\n\nThis is the userspace components for the Linux Kernel's drivers/infiniband\nsubsystem. Specifically this contains the userspace libraries for the\nfollowing device nodes:\n\n - /dev/infiniband/uverbsX (libibverbs)\n - /dev/infiniband/rdma_cm (librdmacm)\n - /dev/infiniband/umadX (libibumad)\n\nThe userspace component of the libibverbs RDMA kernel drivers are included\nunder the providers/ directory. Support for the following Kernel RDMA drivers\nis included:\n\n - bnxt_re.ko\n - efa.ko\n - erdma.ko\n - iw_cxgb4.ko\n - hfi1.ko\n - hns-roce-hw-v2.ko\n - ionic_rdma.ko\n - irdma.ko\n - ib_qib.ko\n - mana_ib.ko\n - mlx4_ib.ko\n - mlx5_ib.ko\n - ib_mthca.ko\n - ocrdma.ko\n - qedr.ko\n - rdma_rxe.ko\n - siw.ko\n - vmw_pvrdma.ko\n\nAdditional service daemons are provided for:\n - srp_daemon (ib_srp.ko)\n - iwpmd (for iwarp kernel providers)\n - ibacm (for InfiniBand communication management assistant)\n\n# Building\n\nThis project uses a cmake based build system. Quick start:\n\n```sh\n$ bash build.sh\n```\n\n*build/bin* will contain the sample programs and *build/lib* will contain the\nshared libraries. The build is configured to run all the programs 'in-place'\nand cannot be installed.\n\n### Debian Derived\n\n```sh\n$ apt-get install build-essential cmake gcc libudev-dev libnl-3-dev libnl-route-3-dev ninja-build pkg-config valgrind python3-dev cython3 python3-docutils pandoc\n```\n\nSupported releases:\n\n* Debian 9 (stretch) or newer\n* Ubuntu 16.04 LTS (xenial) or newer\n\n### Fedora, CentOS 8\n\n```sh\n$ dnf builddep redhat/rdma-core.spec\n```\n\nNOTE: Fedora Core uses the name 'ninja-build' for the 'ninja' command.\n\n### openSUSE\n\n```sh\n$ zypper install cmake gcc libnl3-devel libudev-devel ninja pkg-config valgrind-devel python3-devel python3-Cython python3-docutils pandoc\n```\n\n## Building on CentOS 7, Amazon Linux 2\n\nInstall required packages:\n\n```sh\n$ yum install cmake gcc libnl3-devel libudev-devel make pkgconfig valgrind-devel\n```\n\nDevelopers on CentOS 7 or Amazon Linux 2 are suggested to install more modern\ntooling for the best experience.\n\nCentOS 7:\n\n```sh\n$ yum install epel-release\n$ yum install cmake3 ninja-build pandoc\n```\n\nAmazon Linux 2:\n\n```sh\n$ amazon-linux-extras install epel\n$ yum install cmake3 ninja-build pandoc\n```\n\nNOTE: EPEL uses the name 'ninja-build' for the 'ninja' command, and 'cmake3'\nfor the 'cmake' command.\n\n# Usage\n\nTo set up software RDMA on an existing interface with either of the available\ndrivers, use the following commands, substituting `<DRIVER>` with the name of\nthe driver of your choice (`rdma_rxe` or `siw`) and `<TYPE>` with the type\ncorresponding to the driver (`rxe` or `siw`).\n\n```\n# modprobe <DRIVER>\n# rdma link add <NAME> type <TYPE> netdev <DEVICE>\n```\n\nPlease note that you need version of `iproute2` recent enough is required for the\ncommand above to work.\n\nYou can use either `ibv_devices` or `rdma link` to verify that the device was\nsuccessfully added.\n\n# Reporting bugs\n\nBugs should be reported to the <linux-rdma@vger.kernel.org> mailing list\nIn your bug report, please include:\n\n * Information about your system:\n   - Linux distribution and version\n   - Linux kernel and version\n   - InfiniBand hardware and firmware version\n   - ... any other relevant information\n\n * How to reproduce the bug.\n\n * If the bug is a crash, the exact output printed out when the crash\n   occurred, including any kernel messages produced.\n\n# Submitting patches\n\nSee [Contributing to rdma-core](Documentation/contributing.md).\n\n# Stable branches\n\nStable versions are released regularly with backported fixes (see Documentation/stable.md)\nThe current minimum version still maintained is 'v33.X'\n",
      "stars_today": 2
    },
    {
      "id": 306977038,
      "name": "OpenLineage",
      "full_name": "OpenLineage/OpenLineage",
      "description": "An Open Standard for lineage metadata collection",
      "html_url": "https://github.com/OpenLineage/OpenLineage",
      "stars": 2279,
      "forks": 418,
      "language": "Java",
      "topics": [],
      "created_at": "2020-10-24T21:45:05Z",
      "updated_at": "2026-01-24T22:34:15Z",
      "pushed_at": "2026-01-25T02:16:28Z",
      "open_issues": 294,
      "owner": {
        "login": "OpenLineage",
        "avatar_url": "https://avatars.githubusercontent.com/u/73205353?v=4"
      },
      "readme": "[![CircleCI](https://circleci.com/gh/OpenLineage/OpenLineage/tree/main.svg?style=shield)](https://circleci.com/gh/OpenLineage/OpenLineage/tree/main)\n[![status](https://img.shields.io/badge/status-active-brightgreen.svg)](#status)\n[![Slack](https://img.shields.io/badge/slack-chat-blue.svg)](https://join.slack.com/t/openlineage/shared_invite/zt-3arpql6lg-Nt~hicnDsnDY_GK_LEX06w)\n[![license](https://img.shields.io/badge/license-Apache_2.0-blue.svg)](https://github.com/OpenLineage/OpenLineage/blob/main/LICENSE)\n[![maven](https://img.shields.io/maven-central/v/io.openlineage/openlineage-java.svg)](https://search.maven.org/search?q=g:io.openlineage)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/4888/badge)](https://bestpractices.coreinfrastructure.org/projects/4888)\n\n<div align=\"center\">\n  <img src=\"./doc/openlineage-lfai-logo.png\" width=\"754px\"/>\n</div>\n\n## Overview\nOpenLineage is an Open standard for metadata and lineage collection designed to instrument jobs as they are running.\nIt defines a generic model of run, job, and dataset entities identified using consistent naming strategies.\nThe core lineage model is extensible by defining specific facets to enrich those entities.\n\nOpenLineage is an [LF AI & Data Foundation](https://lfaidata.foundation/projects/openlineage) Graduate project under active development, and we welcome contributions.\n\n## Problem\n\n### Before\n\n- Duplication of effort: each project has to instrument all jobs\n- Integrations are external and can break with new versions\n\n![Before OpenLineage](doc/before-ol.svg)\n\n### With OpenLineage\n\n- The effort of integration is shared\n- An integration can be pushed in each project: no need to play catch up\n\n![With OpenLineage](doc/with-ol.svg)\n\n## Scope\nOpenLineage defines the metadata for running jobs and the corresponding events.\nA configurable backend allows the user to choose what protocol to send the events to.\n ![Scope](doc/scope.svg)\n\n## Core model\n\n ![Model](doc/datamodel.svg)\n\n A facet is an atomic piece of metadata attached to one of the core entities.\n See the spec for more details.\n\n## Spec\nThe [specification](spec/OpenLineage.md) is defined using OpenAPI and allows extension through custom facets.\n\n## Integration matrix\n\nOpenLineage supports integrations with several systems.\n\n| Name| Table-level lineage| Column-level lineage |\n| ----| ------------------ | -------------------- |\n|[Apache Spark](https://github.com/OpenLineage/OpenLineage/tree/main/integration/spark)| :white_check_mark: | :white_check_mark:<sup>1</sup> |\n|[Apache Airflow](https://airflow.apache.org/docs/apache-airflow-providers-openlineage/stable/index.html)| :white_check_mark: | :white_check_mark:<sup>2</sup> |\n|[dbt](https://github.com/OpenLineage/OpenLineage/tree/main/integration/dbt) |:white_check_mark: | :white_check_mark: |\n|[Flink](https://github.com/OpenLineage/OpenLineage/tree/main/integration/flink)|:white_check_mark: | :x: |\n\n1. Does not support `SELECT *` queries with JDBC.\n2. Supports selected SQL-based operators (see [all supported operators](https://airflow.apache.org/docs/apache-airflow-providers-openlineage/stable/supported_classes.html)).\n\n## Related projects\n- [Marquez](https://marquezproject.ai/): Marquez is an [LF AI & DATA](https://lfaidata.foundation/) project to collect, aggregate, and visualize a data ecosystem's metadata. It is the reference implementation of the OpenLineage API.\n  - [OpenLineage collection implementation](https://github.com/MarquezProject/marquez/blob/main/api/src/main/java/marquez/api/OpenLineageResource.java)\n- [Egeria](https://egeria.odpi.org/): Egeria offers open metadata and governance for enterprises - automatically capturing, managing and exchanging metadata between tools and platforms, no matter the vendor.\n\n## Community\n- Website: [openlineage.io](http://openlineage.io)\n- Slack: [OpenLineage.slack.com](https://join.slack.com/t/openlineage/shared_invite/zt-3arpql6lg-Nt~hicnDsnDY_GK_LEX06w)\n- Twitter: [@OpenLineage](https://twitter.com/OpenLineage)\n- Mailing list: [openlineage-tsc](https://lists.lfaidata.foundation/g/openlineage-tsc)\n- Wiki: [OpenLineage+Home](https://wiki.lfaidata.foundation/display/OpenLineage/OpenLineage+Home)\n- LinkedIn: [13927795](https://www.linkedin.com/groups/13927795/)\n- YouTube: [channel](https://www.youtube.com/channel/UCRMLy4AaSw_ka-gNV9nl7VQ)\n- Mastodon: [@openlineage@fostodon.org](openlineage@fosstodon.org)\n\n## Talks\n- [Flink Forward, October 2024. Data Lineage for Apache Flink with OpenLineage](https://www.flink-forward.org/berlin-2024/agenda#data-lineage-for-apache-flink-with-openlineage)\n- [Airflow Summit, September 2024. Activating operational metadata with Airflow, Atlan and OpenLineage](https://airflowsummit.org/sessions/2024/activating-operational-metadata-with-airflow-atlan-and-openlineage/)\n- [Kafka Summit, March 2024. OpenLineage for Stream Processing](https://www.confluent.io/events/kafka-summit-london-2024/openlineage-for-stream-processing/)\n- [Data Council Austin, March 2024. Data Lineage: We've Come a Long Way](https://www.youtube.com/watch?v=OE1o4D_iWfw)\n- [Data+AI Summit June 2023. Cross-Platform Data Lineage with OpenLineage](https://www.databricks.com/dataaisummit/session/cross-platform-data-lineage-openlineage/)\n- [Berlin Buzzwords, June 2023. Column-Level Lineage is Coming to the Rescue](https://youtu.be/xFVSZCCbZlY)\n- [Berlin Buzzwords, June 2022. Cross-Platform Data Lineage with OpenLineage](https://www.youtube.com/watch?v=pLBVGIPuwEo)\n- [Berlin Buzzwords, June 2021. Observability for Data Pipelines with OpenLineage](https://2021.berlinbuzzwords.de/member/julien-le-dem)\n- [Data Driven NYC, February 2021. Data Observability and Pipelines: OpenLineage and Marquez](https://mattturck.com/datakin/)\n- [Big Data Technology Warsaw Summit, February 2021. Data lineage and Observability with Marquez and OpenLineage](https://bigdatatechwarsaw.eu/edition-2021/)\n- [Metadata Day 2020. OpenLineage Lightning Talk](https://www.youtube.com/watch?v=anlV5Er_BpM)\n- [Open Core Summit 2020. Observability for Data Pipelines: OpenLineage Project Launch](https://www.coss.community/coss/ocs-2020-breakout-julien-le-dem-3eh4)\n\n## Contributing\n\nSee [CONTRIBUTING.md](https://github.com/OpenLineage/OpenLineage/blob/main/CONTRIBUTING.md) for more details about how to contribute.\n\n## Report a Vulnerability\n\nIf you discover a vulnerability in the project, please [open an issue](https://github.com/OpenLineage/OpenLineage/issues/new/choose) and attach the \"security\" label.\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=OpenLineage/OpenLineage&type=Date)](https://www.star-history.com/#OpenLineage/OpenLineage&Date)\n\n----\nSPDX-License-Identifier: Apache-2.0\\\nCopyright 2018-2026 contributors to the OpenLineage project\n",
      "stars_today": 2
    },
    {
      "id": 191218735,
      "name": "libavif",
      "full_name": "AOMediaCodec/libavif",
      "description": "libavif - Library for encoding and decoding .avif files",
      "html_url": "https://github.com/AOMediaCodec/libavif",
      "stars": 1989,
      "forks": 268,
      "language": "C",
      "topics": [],
      "created_at": "2019-06-10T17:54:32Z",
      "updated_at": "2026-01-24T02:44:15Z",
      "pushed_at": "2026-01-20T11:56:21Z",
      "open_issues": 156,
      "owner": {
        "login": "AOMediaCodec",
        "avatar_url": "https://avatars.githubusercontent.com/u/16354493?v=4"
      },
      "readme": "# libavif\n\nThis library aims to be a friendly, portable C implementation of the AV1 Image\nFile Format, as described here:\n\n<https://aomediacodec.github.io/av1-avif/>\n\nIt can encode and decode all AV1 supported YUV formats and bit depths (with\nalpha). In addition to the library, encoder and decoder command line tools are\nalso provided (`avifenc` and `avifdec`).\n\nIt is recommended that you check out/use\n[tagged releases](https://github.com/AOMediaCodec/libavif/releases) instead of\njust using the main branch. We will regularly create new versions as bug fixes\nand features are added.\n\n## Command line tool usage\n\n```sh\navifenc -q 75 input.[jpg|png|y4m] output.avif\navifdec output.avif decoded.png\n```\n\nSee `avifenc --help` for all options.\n\n## API usage\n\nPlease see the examples in the \"examples\" directory. If you're already building\n`libavif`, enable the CMake option `AVIF_BUILD_EXAMPLES` in order to build and\nrun the examples too.\n\n## Installation\n\n`libavif` is a package in most major OSs.\n\n### Windows\n\n```sh\nvcpkg install libavif\n```\nYou can also download the official windows binaries on the\n[release](https://github.com/AOMediaCodec/libavif/releases) page.\n\n### macOS\n\nHomebrew:\n```sh\nbrew install libavif\n```\nMacPorts:\n```sh\nsudo port install libavif\n```\n\n### Linux\n\nDebian-based distributions:\n```sh\nsudo apt install libavif-dev\n```\nRed Hat-based distributions:\n```sh\nsudo yum -y install libavif\n```\n\n### MinGW\n\nFor the \"default\" MSYS2 UCRT64 environment:\n```sh\npacman -S mingw-w64-ucrt-x86_64-libavif\n```\n\n## Build Notes\n\nBuilding libavif requires [CMake](https://cmake.org/).\nSee [Build Command Lines](#build-command-lines) below for example command lines.\n\n### Controlling Dependencies\n\nCMake flags like `AVIF_CODEC_AOM`, `AVIF_LIBYUV`, etc. allow enabling or\ndisabling dependencies. They can take three possible values:\n* `OFF`: the dependency is disabled.\n* `SYSTEM`: the dependency is expected to be installed on the system.\n* `LOCAL`: the dependency is built locally. In most cases, CMake can\n  automatically download and build it. For some dependencies, you need to run the\n  associated script in the `ext/` subdirectory yourself. In cases where\n  CMake handles downloading the dependency, you can still call the script in\n  `ext/` if you want to use a different version of the dependency (e.g. by\n  modifying the script) or make custom code changes to it.\n  If a directory with the dependency exists in the `ext/` directory, CMake will\n  use it instead of downloading a new copy.\n\n### Codec Dependencies\n\nNo AV1 codecs are enabled by default. You should enable at least one of them by\nsetting any of the following CMake options to `LOCAL` or `SYSTEM`, depending on\nwhether you want to use a locally built or a system installed version\n(e.g. `-DAVIF_CODEC_AOM=LOCAL`):\n\n* `AVIF_CODEC_AOM` for [libaom](https://aomedia.googlesource.com/aom/) (encoder\n  and decoder)\n* `AVIF_CODEC_DAV1D` for [dav1d](https://code.videolan.org/videolan/dav1d)\n  (decoder)\n* `AVIF_CODEC_LIBGAV1` for\n  [libgav1](https://chromium.googlesource.com/codecs/libgav1/) (decoder)\n* `AVIF_CODEC_RAV1E` for [rav1e](https://github.com/xiph/rav1e) (encoder)\n* `AVIF_CODEC_SVT` for [SVT-AV1](https://gitlab.com/AOMediaCodec/SVT-AV1)\n  (encoder)\n\nWhen set to `SYSTEM`, these libraries (in their C API form) must be externally\navailable (discoverable via CMake's `FIND_LIBRARY`) to use them, or if libavif\nis a child CMake project, the appropriate CMake target must already exist\nby the time libavif's CMake scripts are executed.\n\n### Libyuv Dependency\n\nLibyuv is an optional but strongly recommended dependency that speeds up\ncolor space conversions. It's enabled by default with a value of `SYSTEM`,\nso it's expected to be installed on the system. It can either be built\nlocally instead by using `-DAVIF_LIBYUV=LOCAL` or disabled with\n`-DAVIF_LIBYUV=OFF`.\n\n### Tests\n\nA few tests written in C can be built by enabling the `AVIF_BUILD_TESTS` CMake\noption.\n\nThe remaining tests require [GoogleTest](https://github.com/google/googletest),\nand can be built by enabling `AVIF_BUILD_TESTS` and setting `AVIF_GTEST` to\n`SYSTEM` or `LOCAL`.\n\nAdditionally, fuzzing tests require [fuzztest](https://github.com/google/fuzztest),\nsee also fuzzing test instructions in `ext/oss-fuzz/README.md`.\n\nCode coverage is available by enabling `AVIF_ENABLE_COVERAGE` then building\nthe `avif_coverage` target, e.g. `make avif_coverage -j`. It requires\ncompiling with clang (`-DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++`)\nand LLVM must be installed on the system.\n\n### Build Command Lines\n\nThe following instructions can be used to build the libavif library and the\n`avifenc` and `avifdec` tools.\n\n#### Build using installed dependencies\n\nTo link against the already installed `aom`, `libjpeg`, `libpng` and `libyuv` dependency\nlibraries (recommended):\n\n```sh\ngit clone -b v1.2.1 https://github.com/AOMediaCodec/libavif.git\ncmake -S libavif -B libavif/build -DAVIF_CODEC_AOM=SYSTEM -DAVIF_BUILD_APPS=ON\ncmake --build libavif/build --config Release --parallel\n```\n\n#### Build everything from scratch\n\nFor development and debugging purposes:\n\n```sh\ngit clone -b v1.2.1 https://github.com/AOMediaCodec/libavif.git\ncmake -S libavif -B libavif/build -DCMAKE_BUILD_TYPE=Debug -DBUILD_SHARED_LIBS=OFF -DAVIF_CODEC_AOM=LOCAL -DAVIF_LIBYUV=LOCAL -DAVIF_LIBSHARPYUV=LOCAL -DAVIF_JPEG=LOCAL -DAVIF_ZLIBPNG=LOCAL -DAVIF_BUILD_APPS=ON\ncmake --build libavif/build --config Debug --parallel\n```\n\n## Prebuilt Binaries (Windows)\n\nStatically-linked `avifenc.exe` and `avifdec.exe` can be downloaded from the\n[Releases](https://github.com/AOMediaCodec/libavif/releases) page.\n\n## Development Notes\n\nPlease check the [wiki](https://github.com/AOMediaCodec/libavif/wiki) for extra\nresources on libavif, such as the Release Checklist.\n\nThe libavif library is written in C99. Most of the tests are written in C++14.\n\n### Formatting\n\nUse [clang-format](https://clang.llvm.org/docs/ClangFormat.html) to format the\nsources from the top-level folder (`clang-format-19` preferred):\n\n```sh\nclang-format -style=file -i \\\n  apps/*.c apps/*/*.c apps/*/*.cc apps/*/*.h examples/*.c \\\n  include/avif/*.h src/*.c src/*.cc \\\n  tests/*.c tests/*/*.cc tests/*/*.h\n```\n\nUse [cmake-format](https://github.com/cheshirekow/cmake_format) to format the\nCMakeLists.txt files from the top-level folder:\n\n```sh\ncmake-format -i \\\n  CMakeLists.txt \\\n  tests/CMakeLists.txt \\\n  cmake/Modules/*.cmake \\\n  contrib/CMakeLists.txt \\\n  contrib/gdk-pixbuf/CMakeLists.txt \\\n  android_jni/avifandroidjni/src/main/jni/CMakeLists.txt\n```\n\n---\n\n## License\n\nReleased under the BSD License.\n\n```markdown\nCopyright 2019 Joe Drago. All rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\nlist of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\nthis list of conditions and the following disclaimer in the documentation\nand/or other materials provided with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n```\n",
      "stars_today": 2
    },
    {
      "id": 848925991,
      "name": "Muzza",
      "full_name": "Maloy-Android/Muzza",
      "description": "A Material 3 YouTube Music client for Android",
      "html_url": "https://github.com/Maloy-Android/Muzza",
      "stars": 502,
      "forks": 20,
      "language": "Kotlin",
      "topics": [],
      "created_at": "2024-08-28T16:54:02Z",
      "updated_at": "2026-01-24T15:51:18Z",
      "pushed_at": "2026-01-23T16:20:22Z",
      "open_issues": 41,
      "owner": {
        "login": "Maloy-Android",
        "avatar_url": "https://avatars.githubusercontent.com/u/177887593?v=4"
      },
      "readme": "# Muzza\n\n<img src=\"https://github.com/Maloy-Android/Muzza/blob/main/assets/Muzza-icon.jpg\" height=\"72\">\n\nA Material 3 YouTube Music client for Android\n\n- Website: https://muzza.infinityfreeapp.com\n- Telegram channel: https://t.me/appmuzzaupdatesnews\n- Downloads: https://t.me/muzzaapks\n\n[![Latest release](https://img.shields.io/github/v/release/Maloy-Android/Muzza?include_prereleases)](https://github.com/Maloy-Android/Muzza/releases)\n[![License](https://img.shields.io/github/license/Maloy-Android/Muzza)](https://www.gnu.org/licenses/gpl-3.0)\n[![Downloads](https://img.shields.io/github/downloads/Maloy-Android/Muzza/total)](https://github.com/Maloy-Android/Muzza/releases)\n\n[<img src=\"https://github.com/machiav3lli/oandbackupx/blob/034b226cea5c1b30eb4f6a6f313e4dadcbb0ece4/badge_github.png\" alt=\"Get it on GitHub\" height=\"80\">](https://github.com/Maloy-Android/Muzza/releases/latest)\n\n## Features\n\n- Play songs from YT/YT Music without ads\n- YouTube-Music synchronization\n- Importing from Spotify\n- More functionals\n- Background playback\n- Search songs, videos, albums, and playlists from YouTube Music\n- Login support\n- Cache and download songs for offline playback\n- Synchronized lyrics\n- Lyrics translator\n- Skip silence\n- Audio normalization\n- Adjust tempo/pitch\n- Dynamic theme\n- Android Auto support\n- Personalized quick picks\n- Discord Rich Presence support\n\n## Screenshots\n\n<p float=\"left\">\n  <img src=\"https://github.com/Maloy-Android/Muzza/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/01.png\" width=\"200\" />\n  <img src=\"https://github.com/Maloy-Android/Muzza/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/02.png\" width=\"200\" />\n  <img src=\"https://github.com/Maloy-Android/Muzza/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/03.png\" width=\"200\" />\n</p>\n<p float=\"left\">\n  <img src=\"https://github.com/Maloy-Android/Muzza/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/04.png\" width=\"200\" />\n  <img src=\"https://github.com/Maloy-Android/Muzza/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/05.png\" width=\"200\" />\n    <img src=\"https://github.com/Maloy-Android/Muzza/blob/main/fastlane/metadata/android/en-US/images/phoneScreenshots/06.png\" width=\"200\" />\n</p>\n\n> **Warning**\n>\n>If you're in a region where YouTube Music is not supported, you won't be able to use this app\n***unless*** you have a proxy or VPN to connect to a YTM supported region.\n\n### Q: Why Muzza isn't showing in Android Auto?\n\n1. Go to Android Auto's settings and tap multiple times on the version in the bottom to enable\n   developer settings\n2. In the three dots menu at the top-right of the screen, click \"Developer settings\"\n3. Enable \"Unknown sources\"\n\n## Donate\n\nIf you like Muzza, you're welcome to send a donation. Donations will support the development,\nincluding bug fixes and new features.\n\n- Boosty: https://boosty.to/maloybegonia/donate\n- T-Bank: https://www.tbank.ru/cf/1WDQfqCFiNn\n\n## Credit\n\nI want to give credit to \n1. [https://github.com/z-huang](https://github.com/z-huang/InnerTune) for InnerTune\n2. [https://github.com/DD3Boh, https://github.com/mikooomich](https://github.com/OuterTune/OuterTune) for OuterTune\n3. [https://github.com/mostafaalagamy](https://github.com/mostafaalagamy/Metrolist) for Metrolist\n4. [https://github.com/Arturo254](https://github.com/Arturo254/OpenTune) for OpenTune\n5. Other third-party developers â¤ï¸\n",
      "stars_today": 2
    },
    {
      "id": 33486016,
      "name": "Kingfisher",
      "full_name": "onevcat/Kingfisher",
      "description": "A lightweight, pure-Swift library for downloading and caching images from the web.",
      "html_url": "https://github.com/onevcat/Kingfisher",
      "stars": 24243,
      "forks": 2747,
      "language": "Swift",
      "topics": [
        "cache",
        "filters",
        "image",
        "image-processor",
        "ios",
        "kingfisher",
        "macos",
        "swift",
        "xcode"
      ],
      "created_at": "2015-04-06T14:26:21Z",
      "updated_at": "2026-01-24T21:30:51Z",
      "pushed_at": "2026-01-05T14:19:51Z",
      "open_issues": 174,
      "owner": {
        "login": "onevcat",
        "avatar_url": "https://avatars.githubusercontent.com/u/1019875?v=4"
      },
      "readme": "<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/onevcat/Kingfisher/master/images/logo.png\" alt=\"Kingfisher\" title=\"Kingfisher\" width=\"557\"/>\n</p>\n\n<p align=\"center\">\n<a href=\"https://github.com/onevcat/Kingfisher/actions?query=workflow%3Abuild\"><img src=\"https://github.com/onevcat/kingfisher/workflows/build/badge.svg?branch=master\"></a>\n<a href=\"https://swiftpackageindex.com/onevcat/Kingfisher/master/documentation/kingfisher\"><img src=\"https://img.shields.io/badge/Swift-Doc-DE5C43.svg?style=flat\"></a>\n<a href=\"https://cocoapods.org/pods/Kingfisher\"><img src=\"https://img.shields.io/github/v/tag/onevcat/Kingfisher.svg?color=blue&include_prereleases=&sort=semver\"></a>\n<a href=\"https://swift.org/package-manager/\"><img src=\"https://img.shields.io/badge/SPM-supported-DE5C43.svg?style=flat\"></a>\n<a href=\"https://raw.githubusercontent.com/onevcat/Kingfisher/master/LICENSE\"><img src=\"https://img.shields.io/badge/license-MIT-black\"></a>\n</p>\n\nKingfisher is a powerful, pure-Swift library for downloading and caching images from the web. It provides you a chance to use a pure-Swift way to work with remote images in your next app.\n\n## Features\n\n- [x] Asynchronous image downloading and caching.\n- [x] Loading image from either `URLSession`-based networking or local provided data.\n- [x] Useful image processors and filters provided.\n- [x] Multiple-layer hybrid cache for both memory and disk.\n- [x] Fine control on cache behavior. Customizable expiration date and size limit.\n- [x] Cancelable downloading and auto-reusing previous downloaded content to improve performance.\n- [x] Independent components. Use the downloader, caching system, and image processors separately as you need.\n- [x] Prefetching images and showing them from the cache to boost your app.\n- [x] Extensions for `UIImageView`, `NSImageView`, `NSButton`, `UIButton`, `NSTextAttachment`, `WKInterfaceImage`, `TVMonogramView` and `CPListItem` to directly set an image from a URL.\n- [x] Built-in transition animation when setting images.\n- [x] Customizable placeholder and indicator while loading images.\n- [x] Extensible image processing and image format easily.\n- [x] Low Data Mode support.\n- [x] SwiftUI support.\n- [x] Swift 6 & Swift Concurrency (strict mode) prepared.\n- [x] Load & cache for Live Photo.\n\n### Kingfisher 101\n\nThe simplest use-case is setting an image to an image view with the `UIImageView` extension:\n\n```swift\nimport Kingfisher\n\nlet url = URL(string: \"https://example.com/image.png\")\nimageView.kf.setImage(with: url)\n```\n\nKingfisher will download the image from `url`, send it to both memory cache and disk cache, and display it in `imageView`. \nWhen you set it with the same URL later, the image will be retrieved from the cache and shown immediately.\n\nIt also works if you use SwiftUI:\n\n```swift\nvar body: some View {\n    KFImage(URL(string: \"https://example.com/image.png\")!)\n}\n```\n\n### A More Advanced Example\n\nWith the powerful options, you can do hard tasks with Kingfisher in a simple way. For example, the code below: \n\n1. Downloads a high-resolution image.\n2. Downsamples it to match the image view size.\n3. Makes it round cornered with a given radius.\n4. Shows a system indicator and a placeholder image while downloading.\n5. When prepared, it animates the small thumbnail image with a \"fade in\" effect. \n6. The original large image is also cached to disk for later use, to get rid of downloading it again in a detail view.\n7. A console log is printed when the task finishes, either for success or failure.\n\n```swift\nlet url = URL(string: \"https://example.com/high_resolution_image.png\")\nlet processor = DownsamplingImageProcessor(size: imageView.bounds.size)\n             |> RoundCornerImageProcessor(cornerRadius: 20)\nimageView.kf.indicatorType = .activity\nimageView.kf.setImage(\n    with: url,\n    placeholder: UIImage(named: \"placeholderImage\"),\n    options: [\n        .processor(processor),\n        .scaleFactor(UIScreen.main.scale),\n        .transition(.fade(1)),\n        .cacheOriginalImage\n    ])\n{\n    result in\n    switch result {\n    case .success(let value):\n        print(\"Task done for: \\(value.source.url?.absoluteString ?? \"\")\")\n    case .failure(let error):\n        print(\"Job failed: \\(error.localizedDescription)\")\n    }\n}\n```\n\nIt is a common situation I can meet in my daily work. Think about how many lines you need to write without\nKingfisher!\n\n### Method Chaining\n\nIf you are not a fan of the `kf` extension, you can also prefer to use the `KF` builder and chained the method \ninvocations. The code below is doing the same thing:\n\n```swift\n// Use `kf` extension\nimageView.kf.setImage(\n    with: url,\n    placeholder: placeholderImage,\n    options: [\n        .processor(processor),\n        .loadDiskFileSynchronously,\n        .cacheOriginalImage,\n        .transition(.fade(0.25)),\n        .lowDataMode(.network(lowResolutionURL))\n    ],\n    progressBlock: { receivedSize, totalSize in\n        // Progress updated\n    },\n    completionHandler: { result in\n        // Done\n    }\n)\n\n// Use `KF` builder\nKF.url(url)\n  .placeholder(placeholderImage)\n  .setProcessor(processor)\n  .loadDiskFileSynchronously()\n  .cacheMemoryOnly()\n  .fade(duration: 0.25)\n  .lowDataModeSource(.network(lowResolutionURL))\n  .onProgress { receivedSize, totalSize in  }\n  .onSuccess { result in  }\n  .onFailure { error in }\n  .set(to: imageView)\n```\n\nAnd even better, if later you want to switch to SwiftUI, just change the `KF` above to `KFImage`, and you've done:\n\n```swift\nstruct ContentView: View {\n    var body: some View {\n        KFImage.url(url)\n          .placeholder(placeholderImage)\n          .setProcessor(processor)\n          .loadDiskFileSynchronously()\n          .cacheMemoryOnly()\n          .fade(duration: 0.25)\n          .lowDataModeSource(.network(lowResolutionURL))\n          .onProgress { receivedSize, totalSize in  }\n          .onSuccess { result in  }\n          .onFailure { error in }\n    }\n}\n```\n\n## Requirements\n\n### Kingfisher 8.0\n\n- (UIKit/AppKit) iOS 13.0+ / macOS 10.15+ / tvOS 13.0+ / watchOS 6.0+ / visionOS 1.0+\n- (SwiftUI) iOS 14.0+ / macOS 11.0+ / tvOS 14.0+ / watchOS 7.0+ / visionOS 1.0+\n- Swift 5.9+\n\n### Kingfisher 7.0\n\n- (UIKit/AppKit) iOS 12.0+ / macOS 10.14+ / tvOS 12.0+ / watchOS 5.0+ / visionOS 1.0+\n- (SwiftUI) iOS 14.0+ / macOS 11.0+ / tvOS 14.0+ / watchOS 7.0+ / visionOS 1.0+\n- Swift 5.0+\n\n### Installation\n\nRefer to one of the following tutorials to install and use the framework:\n\n- [UIKit Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstarteduikit)\n- [SwiftUI Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstartedswiftui)\n\nAlternatively, you can follow either of the methods below.\n\n#### Swift Package Manager\n\n- File > Swift Packages > Add Package Dependency\n- Add `https://github.com/onevcat/Kingfisher.git`\n- Select \"Up to Next Major\" with \"8.0.0\"\n\n#### CocoaPods\n\n```ruby\nsource 'https://github.com/CocoaPods/Specs.git'\nplatform :ios, '13.0'\nuse_frameworks!\n\ntarget 'MyApp' do\n  pod 'Kingfisher', '~> 8.0'\nend\n```\n\n#### Pre-built Framework\n\n1. Open the release page, download the latest version of Kingfisher from the assets section. \n2. Drag the `Kingfisher.xcframework` into your project and add it to the target (usually the app target).\n3. Select your target, in the \"General\" Tab, find the \"Frameworks, Libraries, and Embedded Content\" section, set the `Embed Without Signing` to Kingfisher.\n\n## Documentation\n\nCheck the documentation and tutorials:\n\n- [Documentation Home](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher)\n- [Getting Started](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/gettingstarted)\n    - [UIKit Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstarteduikit)\n    - [SwiftUI Tutorial](https://swiftpackageindex.com/onevcat/kingfisher/master/tutorials/kingfisher/gettingstartedswiftui)\n- [Common Tasks - General](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks)\n    - [Common Tasks - Cache](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks_cache)\n    - [Common Tasks - Downloader](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks_downloader)\n    - [Common tasks - Processor](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/commontasks_processor)\n\n### Migrating\n\n- [Kingfisher 8.0 Migration](https://swiftpackageindex.com/onevcat/kingfisher/master/documentation/kingfisher/migration-to-8)\n- [Kingfisher 7.0 Migration](https://github.com/onevcat/Kingfisher/wiki/Kingfisher-7.0-Migration-Guide)\n\nIf you are using an even earlier version, see the guides below to know the steps for migrating.\n\n## Other\n\n### Future of Kingfisher\n\nI want to keep Kingfisher lightweight. This framework focuses on providing a simple solution for downloading and caching images. This doesnâ€™t mean the framework canâ€™t be improved. Kingfisher is far from perfect, so necessary and useful updates will be made to make it better.\n\n### Developments and Tests\n\nAny contributing and pull requests are warmly welcome. However, before you plan to implement some features or try to fix an uncertain issue, it is recommended to open a discussion first. It would be appreciated if your pull requests could build with all tests green. :)\n\n### About the logo\n\nThe logo of Kingfisher is inspired by [Tangram (ä¸ƒå·§æ¿)](http://en.wikipedia.org/wiki/Tangram), a dissection puzzle consisting of seven flat shapes from China. I believe she's a kingfisher bird instead of a swift, but someone insists that she is a pigeon. I guess I should give her a name. Hi, guys, do you have any suggestions?\n\n### Contact\n\nFollow and contact me on [Twitter](http://twitter.com/onevcat) or [Sina Weibo](http://weibo.com/onevcat). If you find an issue, [open a ticket](https://github.com/onevcat/Kingfisher/issues/new). Pull requests are warmly welcome as well.\n\n## Backers & Sponsors\n\nOpen-source projects cannot live long without your help. If you find Kingfisher to be useful, please consider supporting this \nproject by becoming a sponsor. Your user icon or company logo shows up [on my blog](https://onevcat.com/tabs/about/) with a link to your home page. \n\nBecome a sponsor through [GitHub Sponsors](https://github.com/sponsors/onevcat). :heart:\n\nSpecial thanks to:\n\n[![imgly](https://user-images.githubusercontent.com/1812216/106253726-271ed000-6218-11eb-98e0-c9c681925770.png)](https://img.ly/)\n\n[![emergetools](https://github-production-user-asset-6210df.s3.amazonaws.com/1019875/254794187-d44f6f50-993f-42e3-b79c-960f69c4adc1.png)](https://www.emergetools.com)\n\n\n\n### License\n\nKingfisher is released under the MIT license. See LICENSE for details.\n",
      "stars_today": 1
    },
    {
      "id": 261039251,
      "name": "swift-composable-architecture",
      "full_name": "pointfreeco/swift-composable-architecture",
      "description": "A library for building applications in a consistent and understandable way, with composition, testing, and ergonomics in mind.",
      "html_url": "https://github.com/pointfreeco/swift-composable-architecture",
      "stars": 14273,
      "forks": 1628,
      "language": "Swift",
      "topics": [
        "architecture",
        "composition",
        "modularity",
        "swiftui",
        "testability",
        "uikit"
      ],
      "created_at": "2020-05-03T23:18:40Z",
      "updated_at": "2026-01-24T23:42:20Z",
      "pushed_at": "2025-12-30T21:38:44Z",
      "open_issues": 24,
      "owner": {
        "login": "pointfreeco",
        "avatar_url": "https://avatars.githubusercontent.com/u/29466629?v=4"
      },
      "readme": "# The Composable Architecture\n\n[![CI](https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml/badge.svg)](https://github.com/pointfreeco/swift-composable-architecture/actions/workflows/ci.yml)\n[![Slack](https://img.shields.io/badge/slack-chat-informational.svg?label=Slack&logo=slack)](https://www.pointfree.co/slack-invite)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fpointfreeco%2Fswift-composable-architecture%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture)\n\nThe Composable Architecture (TCA, for short) is a library for building applications in a consistent \nand understandable way, with composition, testing, and ergonomics in mind. It can be used in \nSwiftUI, UIKit, and more, and on any Apple platform (iOS, macOS, iPadOS, visionOS, tvOS, and watchOS).\n\n* [What is the Composable Architecture?](#what-is-the-composable-architecture)\n* [Learn more](#learn-more)\n* [Examples](#examples)\n* [Basic usage](#basic-usage)\n* [Documentation](#documentation)\n* [FAQ](#faq)\n* [Community](#community)\n* [Installation](#installation)\n* [Translations](#translations)\n\n## What is the Composable Architecture?\n\nThis library provides a few core tools that can be used to build applications of varying purpose and \ncomplexity. It provides compelling stories that you can follow to solve many problems you encounter \nday-to-day when building applications, such as:\n\n* **State management**\n  <br> How to manage the state of your application using simple value types, and share state across \n  many screens so that mutations in one screen can be immediately observed in another screen.\n\n* **Composition**\n  <br> How to break down large features into smaller components that can be extracted to their own, \n  isolated modules and be easily glued back together to form the feature.\n\n* **Side effects**\n  <br> How to let certain parts of the application talk to the outside world in the most testable \n  and understandable way possible.\n\n* **Testing**\n  <br> How to not only test a feature built in the architecture, but also write integration tests \n  for features that have been composed of many parts, and write end-to-end tests to understand how \n  side effects influence your application. This allows you to make strong guarantees that your \n  business logic is running in the way you expect.\n\n* **Ergonomics**\n  <br> How to accomplish all of the above in a simple API with as few concepts and moving parts as \n  possible.\n\n## Learn More\n\nThe Composable Architecture was designed over the course of many episodes on \n[Point-Free][pointfreeco], a video series exploring advanced programming topics in the Swift language, \nhosted by [Brandon Williams][mbrandonw] and [Stephen Celis][stephencelis].\n\nYou can watch all of the episodes [here][tca-episode-collection], as well as a dedicated, [multipart\ntour][tca-tour] of the architecture from scratch.\n\n<a href=\"https://www.pointfree.co/collections/tours/composable-architecture-1-0\">\n  <img alt=\"video poster image\" src=\"https://d3rccdn33rt8ze.cloudfront.net/episodes/0243.jpeg\" width=\"600\">\n</a>\n\n## Examples\n\n[![Screen shots of example applications](https://d3rccdn33rt8ze.cloudfront.net/composable-architecture/demos.png)](./Examples)\n\nThis repo comes with _lots_ of examples to demonstrate how to solve common and complex problems with \nthe Composable Architecture. Check out [this](./Examples) directory to see them all, including:\n\n* [Case Studies](./Examples/CaseStudies)\n  * Getting started\n  * Effects\n  * Navigation\n  * Higher-order reducers\n  * Reusable components\n* [Location manager](https://github.com/pointfreeco/composable-core-location/tree/main/Examples/LocationManager)\n* [Motion manager](https://github.com/pointfreeco/composable-core-motion/tree/main/Examples/MotionManager)\n* [Search](./Examples/Search)\n* [Speech Recognition](./Examples/SpeechRecognition)\n* [SyncUps app](./Examples/SyncUps)\n* [Tic-Tac-Toe](./Examples/TicTacToe)\n* [Todos](./Examples/Todos)\n* [Voice memos](./Examples/VoiceMemos)\n\nLooking for something more substantial? Check out the source code for [isowords][gh-isowords], an \niOS word search game built in SwiftUI and the Composable Architecture.\n\n## Basic Usage\n\n> [!Note] \n> For a step-by-step interactive tutorial, be sure to check out [Meet the Composable\n> Architecture][meet-tca].\n\nTo build a feature using the Composable Architecture you define some types and values that model \nyour domain:\n\n* **State**: A type that describes the data your feature needs to perform its logic and render its \nUI.\n* **Action**: A type that represents all of the actions that can happen in your feature, such as \nuser actions, notifications, event sources and more.\n* **Reducer**: A function that describes how to evolve the current state of the app to the next \nstate given an action. The reducer is also responsible for returning any effects that should be \nrun, such as API requests, which can be done by returning an `Effect` value.\n* **Store**: The runtime that actually drives your feature. You send all user actions to the store \nso that the store can run the reducer and effects, and you can observe state changes in the store \nso that you can update UI.\n\nThe benefits of doing this are that you will instantly unlock testability of your feature, and you \nwill be able to break large, complex features into smaller domains that can be glued together.\n\nAs a basic example, consider a UI that shows a number along with \"+\" and \"âˆ’\" buttons that increment \nand decrement the number. To make things interesting, suppose there is also a button that when \ntapped makes an API request to fetch a random fact about that number and displays it in the view.\n\nTo implement this feature we create a new type that will house the domain and behavior of the \nfeature, and it will be annotated with the `@Reducer` macro:\n\n```swift\nimport ComposableArchitecture\n\n@Reducer\nstruct Feature {\n}\n```\n\nIn here we need to define a type for the feature's state, which consists of an integer for the \ncurrent count, as well as an optional string that represents the fact being presented:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable {\n    var count = 0\n    var numberFact: String?\n  }\n}\n```\n\n> [!Note] \n> We've applied the `@ObservableState` macro to `State` in order to take advantage of the\n> observation tools in the library.\n\nWe also need to define a type for the feature's actions. There are the obvious actions, such as \ntapping the decrement button, increment button, or fact button. But there are also some slightly \nnon-obvious ones, such as the action that occurs when we receive a response from the fact API \nrequest:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action {\n    case decrementButtonTapped\n    case incrementButtonTapped\n    case numberFactButtonTapped\n    case numberFactResponse(String)\n  }\n}\n```\n\nAnd then we implement the `body` property, which is responsible for composing the actual logic and \nbehavior for the feature. In it we can use the `Reduce` reducer to describe how to change the\ncurrent state to the next state, and what effects need to be executed. Some actions don't need to\nexecute effects, and they can return `.none` to represent that:\n\n```swift\n@Reducer\nstruct Feature {\n  @ObservableState\n  struct State: Equatable { /* ... */ }\n  enum Action { /* ... */ }\n\n  var body: some Reducer<State, Action> {\n    Reduce { state, action in\n      switch action {\n      case .decrementButtonTapped:\n        state.count -= 1\n        return .none\n\n      case .incrementButtonTapped:\n        state.count += 1\n        return .none\n\n      case .numberFactButtonTapped:\n        return .run { [count = state.count] send in\n          let (data, _) = try await URLSession.shared.data(\n            from: URL(string: \"http://numbersapi.com/\\(count)/trivia\")!\n          )\n          await send(\n            .numberFactResponse(String(decoding: data, as: UTF8.self))\n          )\n        }\n\n      case let .numberFactResponse(fact):\n        state.numberFact = fact\n        return .none\n      }\n    }\n  }\n}\n```\n\nAnd then finally we define the view that displays the feature. It holds onto a `StoreOf<Feature>` \nso that it can observe all changes to the state and re-render, and we can send all user actions to \nthe store so that state changes:\n\n```swift\nstruct FeatureView: View {\n  let store: StoreOf<Feature>\n\n  var body: some View {\n    Form {\n      Section {\n        Text(\"\\(store.count)\")\n        Button(\"Decrement\") { store.send(.decrementButtonTapped) }\n        Button(\"Increment\") { store.send(.incrementButtonTapped) }\n      }\n\n      Section {\n        Button(\"Number fact\") { store.send(.numberFactButtonTapped) }\n      }\n      \n      if let fact = store.numberFact {\n        Text(fact)\n      }\n    }\n  }\n}\n```\n\nIt is also straightforward to have a UIKit controller driven off of this store. You can observe\nstate changes in the store in `viewDidLoad`, and then populate the UI components with data from\nthe store. The code is a bit longer than the SwiftUI version, so we have collapsed it here:\n\n<details>\n  <summary>Click to expand!</summary>\n\n  ```swift\n  class FeatureViewController: UIViewController {\n    let store: StoreOf<Feature>\n\n    init(store: StoreOf<Feature>) {\n      self.store = store\n      super.init(nibName: nil, bundle: nil)\n    }\n\n    required init?(coder: NSCoder) {\n      fatalError(\"init(coder:) has not been implemented\")\n    }\n\n    override func viewDidLoad() {\n      super.viewDidLoad()\n\n      let countLabel = UILabel()\n      let decrementButton = UIButton()\n      let incrementButton = UIButton()\n      let factLabel = UILabel()\n      \n      // Omitted: Add subviews and set up constraints...\n      \n      observe { [weak self] in\n        guard let self \n        else { return }\n        \n        countLabel.text = \"\\(self.store.count)\"\n        factLabel.text = self.store.numberFact\n      }\n    }\n\n    @objc private func incrementButtonTapped() {\n      self.store.send(.incrementButtonTapped)\n    }\n    @objc private func decrementButtonTapped() {\n      self.store.send(.decrementButtonTapped)\n    }\n    @objc private func factButtonTapped() {\n      self.store.send(.numberFactButtonTapped)\n    }\n  }\n  ```\n</details>\n\nOnce we are ready to display this view, for example in the app's entry point, we can construct a \nstore. This can be done by specifying the initial state to start the application in, as well as \nthe reducer that will power the application:\n\n```swift\nimport ComposableArchitecture\n\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n```\n\nAnd that is enough to get something on the screen to play around with. It's definitely a few more \nsteps than if you were to do this in a vanilla SwiftUI way, but there are a few benefits. It gives \nus a consistent manner to apply state mutations, instead of scattering logic in some observable \nobjects and in various action closures of UI components. It also gives us a concise way of \nexpressing side effects. And we can immediately test this logic, including the effects, without \ndoing much additional work.\n\n### Testing\n\n> [!Note] \n> For more in-depth information on testing, see the dedicated [testing][testing-article] article. \n\nTo test use a `TestStore`, which can be created with the same information as the `Store`, but it \ndoes extra work to allow you to assert how your feature evolves as actions are sent:\n\n```swift\n@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature()\n  }\n}\n```\n\nOnce the test store is created we can use it to make an assertion of an entire user flow of steps. \nEach step of the way we need to prove that state changed how we expect. For example, we can \nsimulate the user flow of tapping on the increment and decrement buttons:\n\n```swift\n// Test that tapping on the increment/decrement buttons changes the count\nawait store.send(.incrementButtonTapped) {\n  $0.count = 1\n}\nawait store.send(.decrementButtonTapped) {\n  $0.count = 0\n}\n```\n\nFurther, if a step causes an effect to be executed, which feeds data back into the store, we must \nassert on that. For example, if we simulate the user tapping on the fact button we expect to \nreceive a fact response back with the fact, which then causes the `numberFact` state to be \npopulated:\n\n```swift\nawait store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = ???\n}\n```\n\nHowever, how do we know what fact is going to be sent back to us?\n\nCurrently our reducer is using an effect that reaches out into the real world to hit an API server, \nand that means we have no way to control its behavior. We are at the whims of our internet \nconnectivity and the availability of the API server in order to write this test.\n\nIt would be better for this dependency to be passed to the reducer so that we can use a live \ndependency when running the application on a device, but use a mocked dependency for tests. We can \ndo this by adding a property to the `Feature` reducer:\n\n```swift\n@Reducer\nstruct Feature {\n  let numberFact: (Int) async throws -> String\n  // ...\n}\n```\n\nThen we can use it in the `reduce` implementation:\n\n```swift\ncase .numberFactButtonTapped:\n  return .run { [count = state.count] send in \n    let fact = try await self.numberFact(count)\n    await send(.numberFactResponse(fact))\n  }\n```\n\nAnd in the entry point of the application we can provide a version of the dependency that actually \ninteracts with the real world API server:\n\n```swift\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature(\n            numberFact: { number in\n              let (data, _) = try await URLSession.shared.data(\n                from: URL(string: \"http://numbersapi.com/\\(number)\")!\n              )\n              return String(decoding: data, as: UTF8.self)\n            }\n          )\n        }\n      )\n    }\n  }\n}\n```\n\nBut in tests we can use a mock dependency that immediately returns a deterministic, predictable \nfact: \n\n```swift\n@Test\nfunc basics() async {\n  let store = TestStore(initialState: Feature.State()) {\n    Feature(numberFact: { \"\\($0) is a good number Brent\" })\n  }\n}\n```\n\nWith that little bit of upfront work we can finish the test by simulating the user tapping on the \nfact button, and then receiving the response from the dependency to present the fact:\n\n```swift\nawait store.send(.numberFactButtonTapped)\n\nawait store.receive(\\.numberFactResponse) {\n  $0.numberFact = \"0 is a good number Brent\"\n}\n```\n\nWe can also improve the ergonomics of using the `numberFact` dependency in our application. Over \ntime the application may evolve into many features, and some of those features may also want access \nto `numberFact`, and explicitly passing it through all layers can get annoying. There is a process \nyou can follow to â€œregisterâ€ dependencies with the library, making them instantly available to any \nlayer in the application.\n\n> [!Note] \n> For more in-depth information on dependency management, see the dedicated\n> [dependencies][dependencies-article] article. \n\nWe can start by wrapping the number fact functionality in a new type:\n\n```swift\nstruct NumberFactClient {\n  var fetch: (Int) async throws -> String\n}\n```\n\nAnd then registering that type with the dependency management system by conforming the client to\nthe `DependencyKey` protocol, which requires you to specify the live value to use when running the\napplication in simulators or devices:\n\n```swift\nextension NumberFactClient: DependencyKey {\n  static let liveValue = Self(\n    fetch: { number in\n      let (data, _) = try await URLSession.shared\n        .data(from: URL(string: \"http://numbersapi.com/\\(number)\")!\n      )\n      return String(decoding: data, as: UTF8.self)\n    }\n  )\n}\n\nextension DependencyValues {\n  var numberFact: NumberFactClient {\n    get { self[NumberFactClient.self] }\n    set { self[NumberFactClient.self] = newValue }\n  }\n}\n```\n\nWith that little bit of upfront work done you can instantly start making use of the dependency in \nany feature by using the `@Dependency` property wrapper:\n\n```diff\n @Reducer\n struct Feature {\n-  let numberFact: (Int) async throws -> String\n+  @Dependency(\\.numberFact) var numberFact\n   \n   â€¦\n\n-  try await self.numberFact(count)\n+  try await self.numberFact.fetch(count)\n }\n```\n\nThis code works exactly as it did before, but you no longer have to explicitly pass the dependency \nwhen constructing the feature's reducer. When running the app in previews, the simulator or on a \ndevice, the live dependency will be provided to the reducer, and in tests the test dependency will \nbe provided.\n\nThis means the entry point to the application no longer needs to construct dependencies:\n\n```swift\n@main\nstruct MyApp: App {\n  var body: some Scene {\n    WindowGroup {\n      FeatureView(\n        store: Store(initialState: Feature.State()) {\n          Feature()\n        }\n      )\n    }\n  }\n}\n```\n\nAnd the test store can be constructed without specifying any dependencies, but you can still \noverride any dependency you need to for the purpose of the test:\n\n```swift\nlet store = TestStore(initialState: Feature.State()) {\n  Feature()\n} withDependencies: {\n  $0.numberFact.fetch = { \"\\($0) is a good number Brent\" }\n}\n\n// ...\n```\n\nThat is the basics of building and testing a feature in the Composable Architecture. There are \n_a lot_ more things to be explored, such as composition, modularity, adaptability, and complex \neffects. The [Examples](./Examples) directory has a bunch of projects to explore to see more \nadvanced usages.\n\n## Documentation\n\nThe documentation for releases and `main` are available here:\n\n* [`main`](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture)\n* [1.x.x](https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/~/documentation/composablearchitecture)\n\nThere are a number of articles in the documentation that you may find helpful as you become more \ncomfortable with the library:\n\n* [Getting started][getting-started-article]\n* [Dependencies][dependencies-article]\n* [Testing][testing-article]\n* [Navigation][navigation-article]\n* [Sharing state][sharing-state-article]\n* [Performance][performance-article]\n* [Concurrency][concurrency-article]\n* [Bindings][bindings-article]\n\n## FAQ\n\nWe have a [dedicated article][faq-article] for all of the most frequently asked questions and\ncomments people have concerning the library.\n\n## Community\n\nIf you want to discuss the Composable Architecture or have a question about how to use it to solve \na particular problem, there are a number of places you can discuss with fellow \n[Point-Free](http://www.pointfree.co) enthusiasts:\n\n* For long-form discussions, we recommend the [discussions][gh-discussions] tab of this repo.\n* For casual chat, we recommend the [Point-Free Community slack](http://pointfree.co/slack-invite).\n\n## Installation\n\nYou can add ComposableArchitecture to an Xcode project by adding it as a package dependency.\n\n  1. From the **File** menu, select **Add Package Dependencies...**\n  2. Enter \"https://github.com/pointfreeco/swift-composable-architecture\" into the package \n     repository URL text field\n  3. Depending on how your project is structured:\n      - If you have a single application target that needs access to the library, then add \n        **ComposableArchitecture** directly to your application.\n      - If you want to use this library from multiple Xcode targets, or mix Xcode targets and SPM \n        targets, you must create a shared framework that depends on **ComposableArchitecture** and \n        then depend on that framework in all of your targets. For an example of this, check out the \n        [Tic-Tac-Toe](./Examples/TicTacToe) demo application, which splits lots of features into \n        modules and consumes the static library in this fashion using the **tic-tac-toe** Swift \n        package.\n\n## Companion libraries\n\nThe Composable Architecture is built with extensibility in mind, and there are a number of\ncommunity-supported libraries available to enhance your applications:\n\n* [Composable Architecture Extras](https://github.com/Ryu0118/swift-composable-architecture-extras):\n  A companion library to the Composable Architecture.\n* [TCAComposer](https://github.com/mentalflux/tca-composer): A macro framework for generating\n  boiler-plate code in the Composable Architecture.\n* [TCACoordinators](https://github.com/johnpatrickmorgan/TCACoordinators): The coordinator pattern\n  in the Composable Architecture.\n\nIf you'd like to contribute a library, please [open a\nPR](https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md) with a link\nto it!\n\n## Translations\n\nThe following translations of this README have been contributed by members of the community:\n\n* [Arabic](https://gist.github.com/NorhanBoghdadi/1b98d55c02b683ddef7e05c2ebcccd47)\n* [French](https://gist.github.com/nikitamounier/0e93eb832cf389db12f9a69da030a2dc)\n* [Hindi](https://gist.github.com/akashsoni01/b358ee0b3b747167964ef6946123c88d)\n* [Indonesian](https://gist.github.com/wendyliga/792ea9ac5cc887f59de70a9e39cc7343)\n* [Italian](https://gist.github.com/Bellaposa/5114e6d4d55fdb1388e8186886d48958)\n* [Japanese](https://gist.github.com/Achoo-kr/2d0712deb77f78b3379551ac7baea3e4)\n* [Korean](https://gist.github.com/Achoo-kr/5d8936d12e71028fcc4a7c5e078ca038)\n* [Polish](https://gist.github.com/MarcelStarczyk/6b6153051f46912a665c32199f0d1d54)\n* [Portuguese](https://gist.github.com/SevioCorrea/2bbf337cd084a58c89f2f7f370626dc8)\n* [Russian](https://gist.github.com/SubvertDev/3317d0c3b35ed601be330d6fc0df5aba)\n* [Simplified Chinese](https://gist.github.com/sh3l6orrr/10c8f7c634a892a9c37214f3211242ad)\n* [Spanish](https://gist.github.com/pitt500/f5e32fccb575ce112ffea2827c7bf942)\n* [Turkish](https://gist.github.com/gokhanamal/93001244ef0c1cec58abeb1afc0de37c)\n* [Ukrainian](https://gist.github.com/barabashd/33b64676195ce41f4bb73c327ea512a8)\n\nIf you'd like to contribute a translation, please [open a\nPR](https://github.com/pointfreeco/swift-composable-architecture/edit/main/README.md) with a link \nto a [Gist](https://gist.github.com)!\n\n## Credits and thanks\n\nThe following people gave feedback on the library at its early stages and helped make the library \nwhat it is today:\n\nPaul Colton, Kaan Dedeoglu, Matt Diephouse, Josef DoleÅ¾al, Eimantas, Matthew Johnson, George \nKaimakas, Nikita Leonov, Christopher Liscio, Jeffrey Macko, Alejandro Martinez, Shai Mishali, Willis \nPlummer, Simon-Pierre Roy, Justin Price, Sven A. Schmidt, Kyle Sherman, Petr Å Ã­ma, Jasdev Singh, \nMaxim Smirnov, Ryan Stone, Daniel Hollis Tavares, and all of the [Point-Free][pointfreeco] \nsubscribers ğŸ˜.\n\nSpecial thanks to [Chris Liscio](https://twitter.com/liscio) who helped us work through many strange \nSwiftUI quirks and helped refine the final API.\n\nAnd thanks to [Shai Mishali](https://github.com/freak4pc) and the\n[CombineCommunity](https://github.com/CombineCommunity/CombineExt/) project, from which we took \ntheir implementation of `Publishers.Create`, which we use in `Effect` to help bridge delegate and \ncallback-based APIs, making it much easier to interface with 3rd party frameworks.\n\n## Other libraries\n\nThe Composable Architecture was built on a foundation of ideas started by other libraries, in \nparticular [Elm](https://elm-lang.org) and [Redux](https://redux.js.org/).\n\nThere are also many architecture libraries in the Swift and iOS community. Each one of these has \ntheir own set of priorities and trade-offs that differ from the Composable Architecture.\n\n* [RIBs](https://github.com/uber/RIBs)\n* [Loop](https://github.com/ReactiveCocoa/Loop)\n* [ReSwift](https://github.com/ReSwift/ReSwift)\n* [Workflow](https://github.com/square/workflow)\n* [ReactorKit](https://github.com/ReactorKit/ReactorKit)\n* [RxFeedback](https://github.com/NoTests/RxFeedback.swift)\n* [Mobius.swift](https://github.com/spotify/mobius.swift)\n* <details>\n  <summary>And more</summary>\n\n  * [Fluxor](https://github.com/FluxorOrg/Fluxor)\n  * [PromisedArchitectureKit](https://github.com/RPallas92/PromisedArchitectureKit)\n  </details>\n\n## License\n\nThis library is released under the MIT license. See [LICENSE](LICENSE) for details.\n\n[pointfreeco]: https://www.pointfree.co\n[mbrandonw]: https://twitter.com/mbrandonw\n[stephencelis]: https://twitter.com/stephencelis\n[tca-episode-collection]: https://www.pointfree.co/collections/composable-architecture\n[tca-tour]: https://www.pointfree.co/collections/tours/composable-architecture-1-0\n[gh-isowords]: https://github.com/pointfreeco/isowords\n[gh-discussions]: https://github.com/pointfreeco/swift-composable-architecture/discussions\n[swift-forum]: https://forums.swift.org/c/related-projects/swift-composable-architecture\n[testing-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/testingtca\n[faq-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/faq\n[dependencies-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/dependencymanagement\n[getting-started-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/gettingstarted\n[navigation-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/navigation\n[performance-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/performance\n[concurrency-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/swiftconcurrency\n[bindings-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/bindings\n[sharing-state-article]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/documentation/composablearchitecture/sharingstate\n[meet-tca]: https://swiftpackageindex.com/pointfreeco/swift-composable-architecture/main/tutorials/meetcomposablearchitecture\n",
      "stars_today": 1
    },
    {
      "id": 40136600,
      "name": "ktor",
      "full_name": "ktorio/ktor",
      "description": "Framework for quickly creating connected applications in Kotlin with minimal effort",
      "html_url": "https://github.com/ktorio/ktor",
      "stars": 14242,
      "forks": 1218,
      "language": "Kotlin",
      "topics": [
        "async",
        "asynchronous",
        "kotlin",
        "web",
        "web-framework"
      ],
      "created_at": "2015-08-03T16:49:36Z",
      "updated_at": "2026-01-24T23:18:49Z",
      "pushed_at": "2026-01-24T10:37:44Z",
      "open_issues": 193,
      "owner": {
        "login": "ktorio",
        "avatar_url": "https://avatars.githubusercontent.com/u/28214161?v=4"
      },
      "readme": "<div align=\"center\">\n\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/ktorio/ktor/main/.github/images/ktor-logo-for-dark.svg\">\n    <img alt=\"Ktor logo\" src=\"https://raw.githubusercontent.com/ktorio/ktor/main/.github/images/ktor-logo-for-light.svg\">\n  </picture>\n\n</div>\n\n[![Official JetBrains project](https://jb.gg/badges/official.svg)](https://confluence.jetbrains.com/display/ALL/JetBrains+on+GitHub)\n[![Maven Central](https://img.shields.io/maven-central/v/io.ktor/ktor-server)](https://central.sonatype.com/search?namespace=io.ktor)\n[![Kotlin](https://img.shields.io/badge/kotlin-2.3.0-blue.svg?logo=kotlin)](https://kotlinlang.org)\n[![Slack channel](https://img.shields.io/badge/chat-slack-green.svg?logo=slack)](https://kotlinlang.slack.com/messages/ktor/)\n[![GitHub License](https://img.shields.io/badge/license-Apache%20License%202.0-blue.svg?style=flat)](https://www.apache.org/licenses/LICENSE-2.0)\n[![Contribute with Gitpod](https://img.shields.io/badge/Contribute%20with-Gitpod-908a85?logo=gitpod)](https://gitpod.io/#https://github.com/ktorio/ktor)\n\nKtor is an asynchronous framework for creating microservices, web applications and more. Written in Kotlin from the\nground up.\n\nFirst add the dependency to your project:\n\n```kotlin\nrepositories {\n    mavenCentral()\n}\n\ndependencies {\n    implementation(\"io.ktor:ktor-server-netty:$ktor_version\")\n}\n```\n\nThen create an `Application` and install some features:\n\n```kotlin\nimport io.ktor.server.netty.*\nimport io.ktor.server.routing.*\nimport io.ktor.server.application.*\nimport io.ktor.http.*\nimport io.ktor.server.response.*\nimport io.ktor.server.engine.*\n\nfun main(args: Array<String>) {\n    embeddedServer(Netty, 8080) {\n        routing {\n            get(\"/\") {\n                call.respondText(\"Hello, world!\", ContentType.Text.Html)\n            }\n        }\n    }.start(wait = true)\n}\n```\n\nYou also can use [Ktor Gradle Plugin](https://github.com/ktorio/ktor-build-plugins) to configure bom, run tasks and deployment:\n```kotlin\nplugins {\n    id(\"io.ktor.plugin\") version \"3.1.1\"\n}\n\ndependencies {\n    implementation(\"io.ktor:ktor-server-netty\")\n}\n```\n\nTo run the created application, execute:\n```shell\n./gradlew run\n```\n\n* Runs embedded web server on `localhost:8080`\n* Installs routing and responds with `Hello, world!` when receiving a GET http request for the root path\n\n## Start using Ktor\n\nBuild your first Kotlin HTTP or RESTful application using Ktor: [start.ktor.io](https://start.ktor.io)\n\n## Principles\n\n#### Unopinionated\n\nKtor Framework doesn't impose a lot of constraints on what technology a project is going to use â€“ logging,\ntemplating, messaging, persistence, serialization, dependency injection, etc.\nSometimes it may be required to implement a simple interface, but usually it is a matter of writing a\ntransforming or intercepting function. Features are installed into the application using a unified *interception*\nmechanism\nwhich allows building arbitrary pipelines.\n\nKtor Applications can be hosted in any servlet container with Servlet 3.0+ API support such as Tomcat, or\nstandalone using Netty or Jetty. Support for other hosts can be added through the unified hosting API.\n\nKtor APIs are mostly functions calls with lambdas. Thanks to Kotlin DSL capabilities, the code looks declarative.\nApplication composition is entirely up to the developer's choice â€“ with functions or classes, using dependency injection\nframework or doing it all manually in the main function.\n\n#### Asynchronous\n\nThe Ktor pipeline machinery and API are utilising Kotlin coroutines to provide easy-to-use asynchronous\nprogramming model without making it too cumbersome. All host implementations are using asynchronous I/O facilities\nto avoid thread blocking.\n\n#### Testable\n\nKtor applications can be hosted in a special test environment, which emulates a web server to some\nextent without actually doing any networking. It provides easy way to test an application without mocking\ntoo much stuff, and still achieve good performance while validating application calls. Running integration tests with a\nreal\nembedded web server are of course possible, too.\n\n## JetBrains Product\n\nKtor is an official [JetBrains](https://jetbrains.com) product and is primarily developed by the team at JetBrains, with\ncontributions\nfrom the community.\n\n## Documentation\n\nPlease visit [ktor.io](https://ktor.io) for Quick Start and detailed explanations of features, usage and machinery.\n\n* Getting started with [Gradle](https://ktor.io/docs/gradle.html)\n* Getting started with [Maven](https://ktor.io/docs/maven.html)\n* Getting started with [IDEA](https://ktor.io/docs/intellij-idea.html)\n\n## Reporting Issues / Support\n\nPlease use [our issue tracker](https://youtrack.jetbrains.com/issues/KTOR) for filing feature requests and bugs. If\nyou'd like to ask a question, we recommend [StackOverflow](https://stackoverflow.com/questions/tagged/ktor) where\nmembers of the team monitor frequently.\n\nThere is also community support on the [Kotlin Slack Ktor channel](https://app.slack.com/client/T09229ZC6/C0A974TJ9)\n\n## Reporting Security Vulnerabilities\n\nIf you find a security vulnerability in Ktor, we kindly request that you reach out to the JetBrains security team via\nour [responsible disclosure process](https://www.jetbrains.com/legal/terms/responsible-disclosure.html).\n\n## Inspirations\n\nKotlin web frameworks such as Wasabi and Kara, which are currently deprecated.\n\n## Contributing\n\nPlease see [the contribution guide](CONTRIBUTING.md) and the [Code of conduct](CODE_OF_CONDUCT.md) before contributing.\n",
      "stars_today": 1
    },
    {
      "id": 33816473,
      "name": "testcontainers-java",
      "full_name": "testcontainers/testcontainers-java",
      "description": "Testcontainers is a Java library that supports JUnit tests, providing lightweight, throwaway instances of common databases, Selenium web browsers, or anything else that can run in a Docker container.",
      "html_url": "https://github.com/testcontainers/testcontainers-java",
      "stars": 8568,
      "forks": 1792,
      "language": "Java",
      "topics": [
        "docker",
        "docker-compose",
        "hacktoberfest",
        "integration-testing",
        "java",
        "junit",
        "jvm",
        "test-automation",
        "testing"
      ],
      "created_at": "2015-04-12T12:44:59Z",
      "updated_at": "2026-01-24T23:07:21Z",
      "pushed_at": "2026-01-19T23:09:58Z",
      "open_issues": 592,
      "owner": {
        "login": "testcontainers",
        "avatar_url": "https://avatars.githubusercontent.com/u/13393021?v=4"
      },
      "readme": "# Testcontainers\n\n[![Maven Central](https://maven-badges.herokuapp.com/maven-central/org.testcontainers/testcontainers/badge.svg)](https://maven-badges.herokuapp.com/maven-central/org.testcontainers/testcontainers)\n\n[![Netlify Status](https://api.netlify.com/api/v1/badges/189f28a2-7faa-42ff-b03c-738142079cc9/deploy-status)](https://app.netlify.com/sites/testcontainers/deploys)\n\n[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://github.com/codespaces/new?hide_repo_select=true&ref=main&repo=33816473&machine=standardLinux32gb&devcontainer_path=.devcontainer%2Fdevcontainer.json&location=EastUs)\n\n[![Revved up by Develocity](https://img.shields.io/badge/Revved%20up%20by-Develocity-06A0CE?logo=Gradle&labelColor=02303A)](https://ge.testcontainers.org/scans)\n\n> Testcontainers is a Java library that supports JUnit tests, providing lightweight, throwaway instances of common databases, Selenium web browsers, or anything else that can run in a Docker container.\n\n![Testcontainers logo](docs/logo.png)\n\n# [Read the documentation here](https://java.testcontainers.org)\n\n## License\n\nSee [LICENSE](LICENSE).\n\n## Copyright\n\nCopyright (c) 2015 - 2021 Richard North and other authors.\n\nMS SQL Server module is (c) 2017 - 2021 G DATA Software AG and other authors.\n\nHashicorp Vault module is (c) 2017 - 2021 Capital One Services, LLC and other authors.\n\nSee [contributors](https://github.com/testcontainers/testcontainers-java/graphs/contributors) for all contributors.\n",
      "stars_today": 1
    },
    {
      "id": 33100064,
      "name": "yaml-cpp",
      "full_name": "jbeder/yaml-cpp",
      "description": "A YAML parser and emitter in C++",
      "html_url": "https://github.com/jbeder/yaml-cpp",
      "stars": 5800,
      "forks": 2070,
      "language": "C++",
      "topics": [],
      "created_at": "2015-03-30T02:52:32Z",
      "updated_at": "2026-01-24T23:03:46Z",
      "pushed_at": "2026-01-01T16:15:24Z",
      "open_issues": 367,
      "owner": {
        "login": "jbeder",
        "avatar_url": "https://avatars.githubusercontent.com/u/1059334?v=4"
      },
      "readme": "# yaml-cpp ![Build Status](https://github.com/jbeder/yaml-cpp/actions/workflows/build.yml/badge.svg) [![Documentation](https://codedocs.xyz/jbeder/yaml-cpp.svg)](https://codedocs.xyz/jbeder/yaml-cpp/)\n\n`yaml-cpp` is a [YAML](http://www.yaml.org/) parser and emitter in C++ matching the [YAML 1.2 spec](http://www.yaml.org/spec/1.2/spec.html).\n\n## Usage\n\nSee [Tutorial](https://github.com/jbeder/yaml-cpp/wiki/Tutorial) and [How to Emit YAML](https://github.com/jbeder/yaml-cpp/wiki/How-To-Emit-YAML) for reference. For the old API (until 0.5.0), see [How To Parse A Document](https://github.com/jbeder/yaml-cpp/wiki/How-To-Parse-A-Document-(Old-API)).\n\n## Any Problems?\n\nIf you find a bug, post an [issue](https://github.com/jbeder/yaml-cpp/issues)! If you have questions about how to use yaml-cpp, please post it on http://stackoverflow.com and tag it [`yaml-cpp`](http://stackoverflow.com/questions/tagged/yaml-cpp).\n\n## How to Build\n\n`yaml-cpp` uses [CMake](http://www.cmake.org) to support cross-platform building. Install [CMake](http://www.cmake.org) _(Resources -> Download)_ before proceeding. The basic steps to build are:\n\n**Note:** If you don't use the provided installer for your platform, make sure that you add `CMake`'s bin folder to your path.\n\n#### 1. Navigate into the source directory, create build folder and run `CMake`:\n\n```sh\nmkdir build\ncd build\ncmake [-G generator] [-DYAML_BUILD_SHARED_LIBS=on|OFF] ..\n```\n\n  * The `generator` option is the build system you'd like to use. Run `cmake` without arguments to see a full list of available generators.\n    * On Windows, you might use \"Visual Studio 12 2013\" (VS 2013 32-bits), or \"Visual Studio 14 2015 Win64\" (VS 2015 64-bits).\n    * On OS X, you might use \"Xcode\".\n    * On a UNIX-like system, omit the option (for a Makefile).\n\n  * `yaml-cpp` builds a static library by default, you may want to build a shared library by specifying `-DYAML_BUILD_SHARED_LIBS=ON`.\n\n  * [Debug mode of the GNU standard C++\n    library](https://gcc.gnu.org/onlinedocs/libstdc++/manual/debug_mode.html)\n    can be used when both `yaml-cpp` and client code is compiled with the\n    `_GLIBCXX_DEBUG` flag (e.g. by calling CMake with `-D\n    CMAKE_CXX_FLAGS_DEBUG='-g -D_GLIBCXX_DEBUG'` option).\n\n    Note that for `yaml-cpp` unit tests to run successfully, the _GoogleTest_\n    library also must be built with this flag, i.e. the system one cannot be\n    used (the _YAML_USE_SYSTEM_GTEST_ CMake option must be _OFF_, which is the\n    default).\n\n  * For more options on customizing the build, see the [CMakeLists.txt](https://github.com/jbeder/yaml-cpp/blob/master/CMakeLists.txt) file.\n\n#### 2. Build it!\n  * The command you'll need to run depends on the generator you chose earlier.\n\n**Note:** To clean up, just remove the `build` directory.\n\n## How to Integrate it within your project using CMake\n\nYou can use for example FetchContent :\n\n```cmake\ninclude(FetchContent)\n\nFetchContent_Declare(\n  yaml-cpp\n  GIT_REPOSITORY https://github.com/jbeder/yaml-cpp.git\n  GIT_TAG <tag_name> # Can be a tag (yaml-cpp-x.x.x), a commit hash, or a branch name (master)\n)\nFetchContent_MakeAvailable(yaml-cpp)\n\ntarget_link_libraries(YOUR_LIBRARY PUBLIC yaml-cpp::yaml-cpp) # The library or executable that require yaml-cpp library\n```\n\n## Recent Releases\n\n[yaml-cpp 0.8.0](https://github.com/jbeder/yaml-cpp/releases/tag/0.8.0) released!\n\n[yaml-cpp 0.3.0](https://github.com/jbeder/yaml-cpp/releases/tag/release-0.3.0) is still available if you want the old API.\n\n**The old API will stop receiving bugfixes in 2026.** The 0.3.x versions provide the old API, and 0.5.x and above all provide the new API.\n\n# API Documentation \n\nThe autogenerated API reference is hosted on [CodeDocs](https://codedocs.xyz/jbeder/yaml-cpp/index.html)\n\n# Third Party Integrations\n\nThe following projects are not officially supported:\n\n- [Qt wrapper](https://gist.github.com/brcha/d392b2fe5f1e427cc8a6)\n- [UnrealEngine Wrapper](https://github.com/jwindgassen/UnrealYAML)\n",
      "stars_today": 1
    },
    {
      "id": 6427813,
      "name": "dplyr",
      "full_name": "tidyverse/dplyr",
      "description": "dplyr: A grammar of data manipulation",
      "html_url": "https://github.com/tidyverse/dplyr",
      "stars": 4989,
      "forks": 2130,
      "language": "R",
      "topics": [
        "data-manipulation",
        "grammar",
        "r"
      ],
      "created_at": "2012-10-28T13:39:17Z",
      "updated_at": "2026-01-25T02:16:03Z",
      "pushed_at": "2026-01-25T02:20:28Z",
      "open_issues": 76,
      "owner": {
        "login": "tidyverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/22032646?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# dplyr <a href=\"https://dplyr.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" /></a>\n\n<!-- badges: start -->\n\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/dplyr)](https://cran.r-project.org/package=dplyr)\n[![R-CMD-check](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/dplyr/actions/workflows/R-CMD-check.yaml)\n[![Codecov test\ncoverage](https://codecov.io/gh/tidyverse/dplyr/graph/badge.svg)](https://app.codecov.io/gh/tidyverse/dplyr)\n<!-- badges: end -->\n\n## Overview\n\ndplyr is a grammar of data manipulation, providing a consistent set of\nverbs that help you solve the most common data manipulation challenges:\n\n- `mutate()` adds new variables that are functions of existing variables\n- `select()` picks variables based on their names.\n- `filter()` picks cases based on their values.\n- `summarise()` reduces multiple values down to a single summary.\n- `arrange()` changes the ordering of the rows.\n\nThese all combine naturally with `group_by()` which allows you to\nperform any operation â€œby groupâ€. You can learn more about them in\n`vignette(\"dplyr\")`. As well as these single-table verbs, dplyr also\nprovides a variety of two-table verbs, which you can learn about in\n`vignette(\"two-table\")`.\n\nIf you are new to dplyr, the best place to start is the [data\ntransformation chapter](https://r4ds.hadley.nz/data-transform) in R for\nData Science.\n\n## Backends\n\nIn addition to data frames/tibbles, dplyr makes working with other\ncomputational backends accessible and efficient. Below is a list of\nalternative backends:\n\n- [arrow](https://arrow.apache.org/docs/r/) for larger-than-memory\n  datasets, including on remote cloud storage like AWS S3, using the\n  Apache Arrow C++ engine,\n  [Acero](https://arrow.apache.org/docs/cpp/acero/overview.html).\n\n- [dbplyr](https://dbplyr.tidyverse.org/) for data stored in a\n  relational database. Translates your dplyr code to SQL.\n\n- [dtplyr](https://dtplyr.tidyverse.org/) for large, in-memory datasets.\n  Translates your dplyr code to high performance\n  [data.table](https://rdatatable.gitlab.io/data.table/) code.\n\n- [duckplyr](https://duckplyr.tidyverse.org/) for large, in-memory\n  datasets. Translates your dplyr code to high performance\n  [duckdb](https://duckdb.org) queries with zero extra copies and an\n  automatic R fallback when translation isnâ€™t possible.\n\n- [sparklyr](https://spark.posit.co/) for very large datasets stored in\n  [Apache Spark](https://spark.apache.org).\n\n## Installation\n\n``` r\n# The easiest way to get dplyr is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just dplyr:\ninstall.packages(\"dplyr\")\n```\n\n### Development version\n\nTo get a bug fix or to use a feature from the development version, you\ncan install the development version of dplyr from GitHub.\n\n``` r\n# install.packages(\"pak\")\npak::pak(\"tidyverse/dplyr\")\n```\n\n## Cheat Sheet\n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/data-transformation.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-transformation-cheatsheet-thumbs.png\" width=\"630\" height=\"252\"/></a>\n\n## Usage\n\n``` r\nlibrary(dplyr)\n\nstarwars |>\n  filter(species == \"Droid\")\n#> # A tibble: 6 Ã— 14\n#>   name   height  mass hair_color skin_color  eye_color birth_year sex   gender  \n#>   <chr>   <int> <dbl> <chr>      <chr>       <chr>          <dbl> <chr> <chr>   \n#> 1 C-3PO     167    75 <NA>       gold        yellow           112 none  masculiâ€¦\n#> 2 R2-D2      96    32 <NA>       white, blue red               33 none  masculiâ€¦\n#> 3 R5-D4      97    32 <NA>       white, red  red               NA none  masculiâ€¦\n#> 4 IG-88     200   140 none       metal       red               15 none  masculiâ€¦\n#> 5 R4-P17     96    NA none       silver, red red, blue         NA none  feminine\n#> # â„¹ 1 more row\n#> # â„¹ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  select(name, ends_with(\"color\"))\n#> # A tibble: 87 Ã— 4\n#>   name           hair_color skin_color  eye_color\n#>   <chr>          <chr>      <chr>       <chr>    \n#> 1 Luke Skywalker blond      fair        blue     \n#> 2 C-3PO          <NA>       gold        yellow   \n#> 3 R2-D2          <NA>       white, blue red      \n#> 4 Darth Vader    none       white       yellow   \n#> 5 Leia Organa    brown      light       brown    \n#> # â„¹ 82 more rows\n\nstarwars |>\n  mutate(name, bmi = mass / ((height / 100)^2)) |>\n  select(name:mass, bmi)\n#> # A tibble: 87 Ã— 4\n#>   name           height  mass   bmi\n#>   <chr>           <int> <dbl> <dbl>\n#> 1 Luke Skywalker    172    77  26.0\n#> 2 C-3PO             167    75  26.9\n#> 3 R2-D2              96    32  34.7\n#> 4 Darth Vader       202   136  33.3\n#> 5 Leia Organa       150    49  21.8\n#> # â„¹ 82 more rows\n\nstarwars |>\n  arrange(desc(mass))\n#> # A tibble: 87 Ã— 14\n#>   name      height  mass hair_color skin_color eye_color birth_year sex   gender\n#>   <chr>      <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr> \n#> 1 Jabba Deâ€¦    175  1358 <NA>       green-tanâ€¦ orange         600   hermâ€¦ mascuâ€¦\n#> 2 Grievous     216   159 none       brown, whâ€¦ green, yâ€¦       NA   male  mascuâ€¦\n#> 3 IG-88        200   140 none       metal      red             15   none  mascuâ€¦\n#> 4 Darth Vaâ€¦    202   136 none       white      yellow          41.9 male  mascuâ€¦\n#> 5 Tarfful      234   136 brown      brown      blue            NA   male  mascuâ€¦\n#> # â„¹ 82 more rows\n#> # â„¹ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#> #   vehicles <list>, starships <list>\n\nstarwars |>\n  group_by(species) |>\n  summarise(\n    n = n(),\n    mass = mean(mass, na.rm = TRUE)\n  ) |>\n  filter(\n    n > 1,\n    mass > 50\n  )\n#> # A tibble: 9 Ã— 3\n#>   species      n  mass\n#>   <chr>    <int> <dbl>\n#> 1 Droid        6  69.8\n#> 2 Gungan       3  74  \n#> 3 Human       35  81.3\n#> 4 Kaminoan     2  88  \n#> 5 Mirialan     2  53.1\n#> # â„¹ 4 more rows\n```\n\n## Getting help\n\nIf you encounter a clear bug, please file an issue with a minimal\nreproducible example on\n[GitHub](https://github.com/tidyverse/dplyr/issues). For questions and\nother discussion, please use [forum.posit.co](https://forum.posit.co/).\n\n## Code of conduct\n\nPlease note that this project is released with a [Contributor Code of\nConduct](https://dplyr.tidyverse.org/CODE_OF_CONDUCT). By participating\nin this project you agree to abide by its terms.\n",
      "stars_today": 1
    },
    {
      "id": 963665823,
      "name": "embabel-agent",
      "full_name": "embabel/embabel-agent",
      "description": "Agent framework for the JVM. Pronounced Em-BAY-bel /É›mËˆbeÉªbÉ™l/",
      "html_url": "https://github.com/embabel/embabel-agent",
      "stars": 3061,
      "forks": 276,
      "language": "Kotlin",
      "topics": [
        "agent",
        "agentic-ai",
        "agents",
        "ai",
        "ai-agents",
        "aiagentframework",
        "genai",
        "generative-ai",
        "java",
        "kotlin",
        "llms",
        "multi-agents",
        "multi-agents-orchestration",
        "multi-agents-system",
        "spring"
      ],
      "created_at": "2025-04-10T03:06:07Z",
      "updated_at": "2026-01-24T23:25:11Z",
      "pushed_at": "2026-01-24T23:25:09Z",
      "open_issues": 85,
      "owner": {
        "login": "embabel",
        "avatar_url": "https://avatars.githubusercontent.com/u/152664703?v=4"
      },
      "readme": "# Embabel Agent Framework\n\n<img align=\"left\" src=\"https://github.com/embabel/embabel-agent/blob/main/embabel-agent-api/images/315px-Meister_der_Weltenchronik_001.jpg?raw=true\" width=\"180\">\n\n[![Docs](https://img.shields.io/badge/docs-live-brightgreen)](https://docs.embabel.com/embabel-agent/guide/0.1.2-SNAPSHOT/)\n![Build](https://github.com/embabel/embabel-agent/actions/workflows/maven.yml/badge.svg)\n[![YourKit](https://img.shields.io/badge/Profiling-YourKit-blue)](https://www.yourkit.com/)\n[![JProfiler](https://img.shields.io/badge/Profiled%20with-JProfiler-blue)](https://www.ej-technologies.com/products/jprofiler/overview.html)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=embabel_embabel-agent&metric=alert_status)](https://sonarcloud.io/summary/new_code?id=embabel_embabel-agent)\n[![Discord](https://img.shields.io/discord/1277751399261798401?logo=discord)](https://discord.gg/t6bjkyj93q)\n\n[//]: # ([![Quality Gate Status]&#40;https://sonarcloud.io/api/project_badges/measure?project=embabel_embabel-agent&metric=alert_status&token=d275d89d09961c114b8317a4796f84faf509691c&#41;]&#40;https://sonarcloud.io/summary/new_code?id=embabel_embabel-agent&#41;)\n\n[//]: # ([![Bugs]&#40;https://sonarcloud.io/api/project_badges/measure?project=embabel_embabel-agent&metric=bugs&#41;]&#40;https://sonarcloud.io/summary/new_code?id=embabel_embabel-agent&#41;)\n![Kotlin](https://img.shields.io/badge/kotlin-%237F52FF.svg?style=for-the-badge&logo=kotlin&logoColor=white)\n![Java](https://img.shields.io/badge/java-%23ED8B00.svg?style=for-the-badge&logo=openjdk&logoColor=white)\n![Spring](https://img.shields.io/badge/spring-%236DB33F.svg?style=for-the-badge&logo=spring&logoColor=white)\n![Spring Boot](https://img.shields.io/badge/Spring%20Boot-6DB33F.svg?style=for-the-badge&logo=Spring-Boot&logoColor=white)\n![Apache Tomcat](https://img.shields.io/badge/apache%20tomcat-%23F8DC75.svg?style=for-the-badge&logo=apache-tomcat&logoColor=black)\n![Apache Maven](https://img.shields.io/badge/Apache%20Maven-C71A36?style=for-the-badge&logo=Apache%20Maven&logoColor=white)\n![JUnit](https://img.shields.io/badge/JUnit5-25A162.svg?style=for-the-badge&logo=JUnit5&logoColor=white)\n![ChatGPT](https://img.shields.io/badge/chatGPT-74aa9c?style=for-the-badge&logo=openai&logoColor=white)\n![Jinja](https://img.shields.io/badge/jinja-white.svg?style=for-the-badge&logo=jinja&logoColor=black)\n![JSON](https://img.shields.io/badge/JSON-000?logo=json&logoColor=fff)\n![GitHub Actions](https://img.shields.io/badge/github%20actions-%232671E5.svg?style=for-the-badge&logo=githubactions&logoColor=white)\n![SonarQube](https://img.shields.io/badge/SonarQube-black?style=for-the-badge&logo=sonarqube&logoColor=4E9BCD)\n![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)\n![IntelliJ IDEA](https://img.shields.io/badge/IntelliJIDEA-000000.svg?style=for-the-badge&logo=intellij-idea&logoColor=white)\n[![License](https://img.shields.io/github/license/embabel/embabel-agent?style=for-the-badge&logo=apache&color=brightgreen)](https://www.apache.org/licenses/LICENSE-2.0)\n[![Commits](https://img.shields.io/github/commit-activity/m/embabel/embabel-agent.svg?label=commits&style=for-the-badge&logo=git&logoColor=white)](https://github.com/embabel/embabel-agent/pulse)\n\n&nbsp;&nbsp;&nbsp;&nbsp;\n\nEmbabel (Em-BAY-bel) is a framework for authoring agentic flows on the JVM that seamlessly mix LLM-prompted interactions\nwith code and domain models. Supports\nintelligent path finding towards goals. Written in Kotlin\nbut offers a natural usage\nmodel from Java.\nFrom the creator of Spring.\n\n&nbsp;\n\n## Key Concepts\n\nModels agentic flows in terms of:\n\n- **Actions**: Steps an agent takes\n- **Goals**: What an agent is trying to achieve\n- **Conditions**: Conditions to assess before executing an action or determining that a goal has been achieved.\n  Conditions are reassessed after each action is executed.\n- **Domain model**: Objects underpinning the flow and informing Actions, Goals and Conditions.\n- **Plan**: A sequence of actions to achieve a goal. Plans are dynamically formulated by the system, not the programmer.\n  The\n  system replans after the completion of each action, allowing it to adapt to new information as well as observe the\n  effects of the previous action.\n  This is effectively an [OODA loop](https://en.wikipedia.org/wiki/OODA_loop).\n\n> Application developers don't usually have to deal with these concepts directly,\n> as most conditions result from data flow defined in code, allowing the system to infer\n> pre and post conditions.\n\nThese concepts underpin these differentiators versus other agent frameworks:\n\n- **Sophisticated planning.** Goes beyond a finite state machine or sequential execution\n  with nesting by introducing a true planning step, using a\n  non-LLM AI algorithm. This enables the system to perform tasks it wasnâ€™t programmed to do by combining known\n  steps in\n  a novel order, as well as make decisions about parallelization and other runtime behavior.\n- **Superior extensibility and reuse**: Because of dynamic planning, adding more domain objects, actions, goals and\n  conditions\n  can extend the capability of the system, _without editing FSM definitions_ or existing code.\n- **Strong typing and the benefits of object orientation**: Actions, goals and conditions are informed by a domain\n  model, which can\n  include behavior. Everything is strongly typed and prompts and\n  manually authored code interact cleanly. No more magic maps. Enjoy full refactoring support.\n\nOther benefits:\n\n- **Platform abstraction**: Clean separation between programming model and platform internals allows running locally\n  while\n  potentially offering higher QoS in production without changing application code.\n- **Designed for LLM mixing**: It is easy to build applications that mix LLMs, ensuring the most cost-effective yet\n  capable solution.\n  This enables the system to leverage the strengths of different models for different tasks. In particular, it\n  facilitates\n  the use of local models for point tasks. This can be important for cost and privacy.\n- **Built on Spring and the JVM,** making it easy to access existing enterprise functionality and capabilities.\n  For example:\n    - Spring can inject and manage agents, including using Spring AOP to decorate functions.\n    - Robust persistence and transaction management solutions are available.\n- **Designed for testability** from the ground up. Both unit testing and agent end to end testing are easy.\n\nFlows can be authored in one of two ways:\n\n- An annotation-based model similar to Spring MVC, with types annotated with the Spring stereotype `@Agent`, using\n  `@Goal`, `@Condition` and\n  `@Action` methods.\n- Idiomatic Kotlin DSL with `agent {` and `action {` blocks.\n\nEither way, flows are backed by a domain model of objects that can have rich behavior.\n\n> We are working toward allowing natural language actions and goals to be deployed.\n\nThe planning step is pluggable.\n\nThe default planning approach is\n[Goal Oriented Action Planning](https://medium.com/@vedantchaudhari/goal-oriented-action-planning-34035ed40d0b).\nGOAP is a popular AI planning algorithm used in gaming. It allows for dynamic decision-making and action selection based\non the current state of the world and the goals of the agent.\n\nGoals, actions and plans are independent of GOAP. Embabel also\nsupports [Utility AI](https://en.wikipedia.org/wiki/Utility_system) out of the box, which can run the same actions but\nchooses actions\nbased on (potentially dynamic) utility scores rather than strict preconditions and postconditions. This is valuable for\nexploration and\nopen-ended tasks, when we do not need to achieve a specific goal but want to maximize overall utility.\n\nThe framework executes via an `AgentPlatform` implementation.\n\nAn agent platform supports the following modes of execution:\n\n- **Focused**, where user code requests particular functionality: User code calls a method to run a particular agent,\n  passing in input. This is ideal for code-driven flows such as a flow invoked in response to an incoming event.\n- **Closed**, where user intent (or another incoming event) is classified to choose an agent. The platform tries to\n  find a\n  suitable agent among all the agents it knows about.\n  Agent choice is dynamic, but only actions defined within the particular agent\n  will run.\n- **Open**, where the user's intent is assessed and the platform uses _all_ its resources to try to achieve it. The\n  platform tries to find a\n  suitable goal among all the goals it knows about and builds a custom agent to achieve it from the start state,\n  including relevant actions and conditions. The platform will not proceed if it is unconvinced as to the applicability\n  of any goal. The `GoalChoiceApprover` interface provides developers a way to limit goal choice further.\n\nOpen mode is the most powerful, but least deterministic.\n> In open mode, the platform is capable of finding novel paths that were not envisioned by developers, and even\n> combining functionality from multiple providers.\n\nEven in open mode, the platform will only perform individual steps\nthat have been specified. (Of course, steps may themselves be LLM\ntransforms, in which case the prompts are controlled by user code but the\nresults are still non-deterministic.)\n\nPossible future modes:\n\n- **Evolving** mode: Where the platform can work with multiple goals in the same process and modify a running process to\n  add further goals and agents.\n  For example, an action can realize that it has become important to achieve additional goals.\n\nEmbabel agent systems will also support federation, both with other Embabel systems (allowing planning to incorporate\nremote actions and goals) and third party agent frameworks.\n\n## Quick Start\n\nGet an agent running in under 5 minutes.\n\nCreate your own agent repo from our [Java](https://github.com/embabel/java-agent-template)\nor [Kotlin](https://github.com/embabel/kotlin-agent-template) GitHub template by clicking the \"Use this template\"\nbutton.\n\nYou'll have an agent running in under a minute\nif you already have an `OPENAI_API_KEY` and have Maven installed.\n\n**ğŸ“š For examples and tutorials**, see\nthe [Embabel Agent Examples Repository](https://github.com/embabel/embabel-agent-examples)\n\n**ğŸš— For a sophisticated, realistic example application**, see\nthe [Tripper travel planner agent](https://github.com/embabel/tripper)\n\n<img src=\"images/tripper_output1.jpg\" alt=\"Travel Planner Output\" width=\"600\"/>\n\n*AI-generated travel itinerary with detailed recommendations*\n\n<img src=\"images/tripper_map.jpg\" alt=\"Interactive map\" width=\"600\"/>\n\n*Map link included in output*\n\n## Why Is Embabel Needed?\n\nTL;DR Because the evolution of agent frameworks is early and there's a lot of room for improvement; because an agent\nframework on the JVM will deliver great business value.\n\n- _Why do we need an agent framework at all_? We can write code without higher level abstractions, directly invoking\n  LLMs and controlling flow directly in code. However, a higher level agent framework offers compelling benefits. For\n  example:\n    - Breaking up LLM interactions, making them simpler and more focused. This maximizes reuse and minimizes cost and\n      errors. It often allows us to use cheaper models for point interactions.\n    - Facilitating both unit and integration testing, which remain as important with agentic systems as with any other\n      software systems.\n    - Increasing composability where subflows and individual actions can be reused\n    - Making applications more manageable and robust, enabling a workflow manager to control their execution and retry\n      operations while maintaining previous state\n    - Enhancing safety through the ability to apply guardrails in many places\n- _Why do we need an agent framework for the JVM when solutions exist in Python?_: While agent frameworks initially\n  appeared predominantly Python, it's early and there's plenty of room for novel and\n  superior\n  approaches. The key adjacency is not the LLM--which is a simple HTTP call away--but existing code and\n  infrastructure\n  assets that are more valuable on the JVM than in Python.\n- _Why not use just Spring AI?_ Spring AI is great. We build on it, and embrace the Spring component model. However, we\n  believe that most applications should work with higher\n  level APIs. An analogy: Spring AI exists at the level of the Servlet API, while Embabel is more like Spring MVC.\n  Complex requirements are much easier to express and test in Embabel than with direct use of Spring AI.\n- _Why not attempt to contribute this project to Spring?_ This project requires different governance\n  from Spring, where most projects exist in stable environments and dependability and stability outweighs rapid\n  innovation. Second, the\n  concepts are not JVM-specific. We hope that Embabel will become the leading agent framework across platforms. While\n  the Spring brand is valuable in Java, it is not in TypeScript or Python.\n\n## Show Me The Code\n\nIn Java or Kotlin, agent implementation code is intuitive and easy to test.\n\n<details open>\n<summary>Java</summary>\n\n```java\n\n@Agent(description = \"Find news based on a person's star sign\")\npublic class StarNewsFinder {\n\n    private final HoroscopeService horoscopeService;\n    private final int storyCount;\n\n    // Services are injected by Spring\n    public StarNewsFinder(\n            HoroscopeService horoscopeService,\n            @Value(\"${star-news-finder.story.count:5}\") int storyCount) {\n        this.horoscopeService = horoscopeService;\n        this.storyCount = storyCount;\n    }\n\n    @Action\n    public StarPerson extractStarPerson(UserInput userInput, Ai ai) {\n        return ai\n                .withLlm(OpenAiModels.GPT_41)\n                .createObjectIfPossible(\n                        \"\"\"\n                                Create a person from this user input, extracting their name and star sign:\n                                %s\"\"\".formatted(userInput.getContent()),\n                        StarPerson.class\n                );\n    }\n\n    @Action\n    public Horoscope retrieveHoroscope(StarPerson starPerson) {\n        return new Horoscope(horoscopeService.dailyHoroscope(starPerson.sign()));\n    }\n\n    // toolGroups specifies tools that are required for this action to run\n    @Action(toolGroups = {CoreToolGroups.WEB})\n    public RelevantNewsStories findNewsStories(\n            StarPerson person,\n            Horoscope horoscope,\n            Ai ai) {\n        var prompt = \"\"\"\n                %s is an astrology believer with the sign %s.\n                Their horoscope for today is:\n                    <horoscope>%s</horoscope>\n                Given this, use web tools and generate search queries\n                to find %d relevant news stories summarize them in a few sentences.\n                Include the URL for each story.\n                Do not look for another horoscope reading or return results directly about astrology;\n                find stories relevant to the reading above.\n                \n                For example:\n                - If the horoscope says that they may\n                want to work on relationships, you could find news stories about\n                novel gifts\n                - If the horoscope says that they may want to work on their career,\n                find news stories about training courses.\"\"\".formatted(\n                person.name(), person.sign(), horoscope.summary(), storyCount);\n        return ai\n                .withDefaultLlm()\n                .createObject(prompt, RelevantNewsStories.class);\n    }\n\n    // The @AchievesGoal annotation indicates that completing this action\n    // achieves the given goal, so the agent can be complete\n    @AchievesGoal(\n            description = \"Write an amusing writeup for the target person based on their horoscope and current news stories\",\n            export = @Export(\n                    remote = true,\n                    name = \"starNewsWriteupJava\",\n                    startingInputTypes = {StarPerson.class, UserInput.class})\n    )\n    @Action\n    public Writeup writeup(\n            StarPerson person,\n            RelevantNewsStories relevantNewsStories,\n            Horoscope horoscope,\n            Ai ai) {\n        var llm = LlmOptions\n                .withModel(OpenAiModels.GPT_41_MINI)\n                // High temperature for creativity\n                .withTemperature(0.9);\n\n        var newsItems = relevantNewsStories.getItems().stream()\n                .map(item -> \"- \" + item.getUrl() + \": \" + item.getSummary())\n                .collect(Collectors.joining(\"\\n\"));\n\n        var prompt = \"\"\"\n                Take the following news stories and write up something\n                amusing for the target person.\n                \n                Begin by summarizing their horoscope in a concise, amusing way, then\n                talk about the news. End with a surprising signoff.\n                \n                %s is an astrology believer with the sign %s.\n                Their horoscope for today is:\n                    <horoscope>%s</horoscope>\n                Relevant news stories are:\n                %s\n                \n                Format it as Markdown with links.\"\"\".formatted(\n                person.name(), person.sign(), horoscope.summary(), newsItems);\n        return ai\n                .withLlm(llm)\n                .createObject(prompt, Writeup.class);\n    }\n}\n```\n\n</details>\n\n<details>\n<summary>Kotlin</summary>\n\n```kotlin\n@Agent(description = \"Find news based on a person's star sign\")\nclass StarNewsFinder(\n    // Services such as Horoscope are injected by Spring\n    private val horoscopeService: HoroscopeService,\n    // Potentially externalized by Spring\n    @param:Value(\"\\${star-news-finder.story.count:5}\")\n    private val storyCount: Int = 5,\n) {\n\n    @Action\n    fun extractPerson(\n        userInput: UserInput,\n        ai: Ai\n    ): StarPerson =\n        // All prompts are typesafe\n        ai.withDefaultLlm()\n            .createObject(\"Create a person from this user input, extracting their name and star sign: $userInput\")\n\n    // This action doesn't use an LLM\n    // Embabel makes it easy to mix LLM use with regular code\n    @Action\n    fun retrieveHoroscope(starPerson: StarPerson) =\n        Horoscope(horoscopeService.dailyHoroscope(starPerson.sign))\n\n    // This action uses tools\n    // \"toolGroups\" specifies tools that are required for this action to run\n    @Action(toolGroups = [ToolGroup.WEB])\n    fun findNewsStories(\n        person: StarPerson,\n        horoscope: Horoscope,\n        ai: Ai,\n    ): RelevantNewsStories =\n        ai.withDefaultLlm().createObject(\n            \"\"\"\n            ${person.name} is an astrology believer with the sign ${person.sign}.\n            Their horoscope for today is:\n                <horoscope>${horoscope.summary}</horoscope>\n            Given this, use web tools and generate search queries\n            to find $storyCount relevant news stories summarize them in a few sentences.\n            Include the URL for each story.\n            Do not look for another horoscope reading or return results directly about astrology;\n            find stories relevant to the reading above.\n\n            For example:\n            - If the horoscope says that they may\n            want to work on relationships, you could find news stories about\n            novel gifts\n            - If the horoscope says that they may want to work on their career,\n            find news stories about training courses.\n        \"\"\".trimIndent()\n        )\n\n    // The @AchievesGoal annotation indicates that completing this action\n    // achieves the given goal, so the agent run will be complete\n    @AchievesGoal(\n        description = \"Write an amusing writeup for the target person based on their horoscope and current news stories\",\n    )\n    @Action\n    fun writeup(\n        person: StarPerson,\n        relevantNewsStories: RelevantNewsStories,\n        horoscope: Horoscope,\n        ai: Ai,\n    ): Writeup =\n        ai\n            .withLlm(\n                LlmOptions\n                    .withModel(model)\n                    .withTemperature(0.9)\n            )\n            .createObject(\n                \"\"\"\n            Take the following news stories and write up something\n            amusing for the target person.\n\n            Begin by summarizing their horoscope in a concise, amusing way, then\n            talk about the news. End with a surprising signoff.\n\n            ${person.name} is an astrology believer with the sign ${person.sign}.\n            Their horoscope for today is:\n                <horoscope>${horoscope.summary}</horoscope>\n            Relevant news stories are:\n            ${relevantNewsStories.items.joinToString(\"\\n\") { \"- ${it.url}: ${it.summary}\" }}\n\n            Format it as Markdown with links.\n        \"\"\".trimIndent()\n            )\n\n}\n```\n\n</details>\n\n\nThe following domain classes ensure type safety:\n\n<details open>\n<summary>Java</summary>\n\n```java\n\n@JsonClassDescription(\"Person with astrology details\")\n@JsonDeserialize(as = StarPerson.class)\npublic record StarPerson(\n        String name,\n        @JsonPropertyDescription(\"Star sign\") String sign\n) implements Person {\n\n    @JsonCreator\n    public StarPerson(\n            @JsonProperty(\"name\") String name,\n            @JsonProperty(\"sign\") String sign\n    ) {\n        this.name = name;\n        this.sign = sign;\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n}\n\npublic record Horoscope(String summary) {\n}\n\n@JsonClassDescription(\"Writeup relating to a person's horoscope and relevant news\")\npublic record Writeup(String text) implements HasContent {\n\n    @JsonCreator\n    public Writeup(@JsonProperty(\"text\") String text) {\n        this.text = text;\n    }\n\n    @Override\n    public String getContent() {\n        return text;\n    }\n}\n\n```\n\n</details>\n\n<details>\n<summary>Kotlin</summary>\n\n```kotlin\ndata class RelevantNewsStories(\n    val items: List<NewsStory>\n)\n\ndata class NewsStory(\n    val url: String,\n\n    val summary: String,\n)\n\ndata class Subject(\n    val name: String,\n    val sign: String,\n)\n\ndata class Horoscope(\n    val summary: String,\n)\n\ndata class FunnyWriteup(\n    override val text: String,\n) : HasContent\n```\n\n</details>\n\nIt's easy to unit test your agents to ensure that they correctly execute logic\nand pass the correct prompts and hyperparameters to LLMs. For example:\n\n```java\npublic class StarNewsFinderTest {\n\n    @Test\n    void writeupPromptMustContainKeyData() {\n        HoroscopeService horoscopeService = mock(HoroscopeService.class);\n        StarNewsFinder starNewsFinder = new StarNewsFinder(horoscopeService, 5);\n        var context = new FakeOperationContext();\n        context.expectResponse(new com.embabel.example.horoscope.Writeup(\"Gonna be a good day\"));\n\n        NewsStory cockatoos = new NewsStory(\n                \"https://fake.com.au\",\n                \"Cockatoo behavior\",\n                \"Cockatoos are eating cabbages\"\n        );\n\n        NewsStory emus = new NewsStory(\n                \"https://morefake.com.au\",\n                \"Emu movements\",\n                \"Emus are massing\"\n        );\n\n        StarPerson starPerson = new StarPerson(\"Lynda\", \"Scorpio\");\n        RelevantNewsStories relevantNewsStories = new RelevantNewsStories(Arrays.asList(cockatoos, emus));\n        Horoscope horoscope = new Horoscope(\"This is a good day for you\");\n\n        starNewsFinder.writeup(starPerson, relevantNewsStories, horoscope, context);\n\n        var prompt = context.getLlmInvocations().getFirst().getPrompt();\n        var toolGroups = context.getLlmInvocations().getFirst().getInteraction().getToolGroups();\n\n\n        assertTrue(prompt.contains(starPerson.getName()));\n        assertTrue(prompt.contains(starPerson.sign()));\n        assertTrue(prompt.contains(cockatoos.getSummary()));\n        assertTrue(prompt.contains(emus.getSummary()));\n\n        assertTrue(toolGroups.isEmpty(), \"The LLM should not have been given any tool groups\");\n    }\n}\n```\n\n## Dog Food Policy\n\nWe believe that all aspects of software development and business can and should\nbe greatly accelerated through the use of AI agents. The ultimate decision\nmakers remain human, but they can and should be greatly augmented.\n\n> This project practices extreme dogfooding.\n\n<!-- TODO photo of Duke with kibble -->\n\nOur key principles:\n\n1. **We will use AI agents to help every aspect of the project:** coding, documentation, community management, producing\n   marketing copy etc.\n   Any\n   human performing a task should ask why it cannot be automated, and strive toward maximum automation.\n2. **Developers retain ultimate control.** Developers are responsible for guiding agents toward the solution and\n   iterating\n   as necessary. A developer who commits or merges an agent contribution\n   is responsible for ensuring that it meets the project coding standards, which are\n   independent of the use of agents. For example, code must be human-readable.\n3. **We will favour open source agents built on the Embabel platform,** and contribute improvements. While\n   commercial agents\n   may be more advanced in some areas, we believe that our\n   platform is the best general solution for automation and by dogfooding we will improve it fastest.\n   By open sourcing agents used on our open source projects, we will maximize benefit to the community.\n4. **We will prioritize agents that help accelerate our progress.** Per the flight safety advice to fit your own mask\n   before helping others, we will prioritize\n   agents that help us accelerate our own progress. This will not only produce useful examples, but increase overall\n   project velocity.\n\nDevelopers must carefully read all code they commit and improve generated code if possible.\n\n> Coding agents are a special case. While the `embabel-agent-code` submodule offers support for project modification\n> that is useful for project bootstrapping, coding agents are the most mature of commercial agents, and their vendors\n> are\n> heavily subsidising their users, making it economically irrational to insist on our own platform.\n\n## Getting Started\n\n- Get the bits\n- Set up your environment\n- Run the application\n\n### Getting the bits\n\nChoose one of the following:\n\n- Clone the repository via `git clone https://github.com/embabel/embabel-agent`\n- Create a new Spring Boot project and add the necessary dependencies (see \"Using Embabel Agent Framework in Your\n  Project\" below)\n\n### Environment variables\n\n> Environment variables are consistent with common usage, rather than Spring AI.\n> For example, we prefer `OPENAI_API_KEY` to `SPRING_AI_OPENAI_API_KEY`.\n\nRequired:\n\n- `OPENAI_API_KEY`: For the OpenAI API\n\nOptional:\n\n- `ANTHROPIC_API_KEY`: For the Anthropic API. Necessary for the coding agent.\n\n> We strongly recommend providing both an OpenAI and Anthropic key, as some examples require both. And it's important to\n> try to find the best LLM for a given task, rather than automatically choose a familiar provider.\n\n### Services\n\nYou will need a Docker Desktop version [`>4.43.2`](https://docs.docker.com/desktop/release-notes/).\nBe sure to activate the following MCP tools from the catalog:\n\n- Brave Search\n- Fetch\n- Puppeteer\n- Wikipedia\n\n> You can also set up your own MCP tools using Spring AI conventions. See the `application-docker-desktop.yml` file for\n> an example.\n\nIf you're running Ollama locally, include the `embabel ollama starter` and Embabel will automatically connect to your\nOllama\nendpoint and make all models available.\n\n```xml\n\n<dependency>\n    <groupId>com.embabel.agent</groupId>\n    <artifactId>embabel-agent-starter-ollama</artifactId>\n</dependency>\n```\n\n### Running\n\nCreate your own agent project with\n\n```\nuvx --from git+https://github.com/embabel/project-creator.git project-creator\n```\n\n### Example Agents\n\n> **ğŸ“š For examples and tutorials**, see\n> the [Embabel Agent Examples Repository](https://github.com/embabel/embabel-agent-examples)\n\n```bash\n# Clone and run examples\ngit clone https://github.com/embabel/embabel-agent-examples\ncd embabel-agent-examples/scripts/kotlin\n./shell.sh\n```\n\n#### Shell Commands\n\nSpring Shell is an easy way to interact with the Embabel agent framework, especially during development.\n\nType `help` to see available commands. Use `execute` or `x` to run an agent:\n\n```\nexecute \"Lynda is a Scorpio, find news for her\" -p -r\n```\n\nThis will look for an agent, choose the star finder agent and\nrun the flow. `-p` will log prompts `-r` will log LLM responses.\nOmit these for less verbose logging.\n\nOptions:\n\n- `-p` logs prompts\n- `-r` logs LLM responses\n\nUse the `chat` command to enter an interactive chat with the agent.\nIt will attempt to run the most appropriate\nagent for each command.\n\n> Spring Shell supports history. Type `!!` to repeat the last command.\n> This will survive restarts, so is handy when iterating on an agent.\n\n#### Further examples\n\nExample commands within the shell:\n\n```\n# Perplexity style deep research\n# Requires both OpenAI and Anthropic keys and Docker Desktop with the MCP extension (or your own web tools)\nexecute \"research the recent australian federal election. what is the position of the greens party?\"\n\n# x is a shortcut for execute\nx \"fact check the following: holden cars are still made in australia; the koel is a bird native only to australia; fidel castro is justin trudeau's father\"\n\n```\n\n### Bringing in additional LLMs\n\n#### Local models with well-known providers\n\nThe Embabel Agent Framework supports local models from:\n\n- Ollama: Simply add `embabel-agent-starter-ollama` starter to your pom.xml and your local Ollama endpoint will be\n  queries. All local models will be\n  available.\n- Docker: Add the `embabel-agent-starter-dockermodels` starter to your pom.xml and your local Docker endpoint will be\n  queried. All local models will be available.\n- LMStudio: This uses the openAI compatible client. Just include LMStudio as a dependency and make sure your LMStudio\n  server is running.\n\n#### Custom LLMs\n\nYou can define an LLM for any provider for which a Spring AI `ChatModel` is available.\n\nSimply define Spring beans of type `Llm`.\nSee the `OpenAiConfiguration` class as an example.\n\nRemember:\n\n- Provide the knowledge cutoff date if you know it\n- Make the configuration class conditional on any required API key.\n\n## Roadmap\n\nThis project is in its early stages, but we have big plans.\nThe milestones and issues in this repository are a good reference.\nOur key goals:\n\n- **Become the natural way to Gen AI-enable Java applications**, and especially those built on Spring.\n- **Prove the power of the approach**. Demonstrate that this approach is the best way to build safe, dependable, Gen AI\n  applications.\n  In particular:\n    - Demonstrate the power of extensibility without modification, by adding goals and actions\n    - Demonstrate the potential to become the PaaS for natural language\n    - Demonstrate the potential of agent federation within the GOAP model\n    - Demonstrate budget-aware agents, such as \"Research the following topic, spending up to 20c if you are still\n      learning\"\n    - Integrate with data stores and demonstrate the power of surfacing existing functionality inside an organization\n- **Take the model to other platforms**: The conceptual framework is not JVM specific. Once established, we intend to\n  create TypeScript\n  and Python projects.\n\nThere is a lot to do, and you are awesome. We look forward to your contribution!\n\n## Application Design\n\n### Domain objects\n\nApplications center around domain objects. These can be instantiated by LLMs or user\ncode, and manipulated by user code.\n\nUse Jackson annotations to help LLMs with descriptions as well as mark fields to ignore.\nFor example:\n\n```kotlin\n@JsonClassDescription(\"Person with astrology details\")\ndata class StarPerson(\n    override val name: String,\n    @get:JsonPropertyDescription(\"Star sign\")\n    val sign: String,\n) : Person\n```\n\nSee [Java Json Schema Generation - Module Jackson](https://github.com/victools/jsonschema-generator/tree/main/jsonschema-module-jackson)\nfor documentation of the library used.\n\nDomain objects can have behaviors that are automatically exposed to LLMs when they are in scope. Simply annotate methods\nwith the Spring AI `@Tool` annotation.\n\n> When exposing `@Tool` methods on domain objects, be sure that the tool is safe to invoke. Even the best LLMs can get\n> trigger-happy. For example, be careful about methods that can mutate or delete data. This is likely better modeled via\n> an explicit call to a non-tool method on the same domain class, in a code action.\n\n## Using Embabel as an MCP server\n\nYou can use the Embabel agent platform as an MCP server from a\nUI like Claude Desktop. The Embabel MCP server is available over SSE.\n\nConfigure Claude Desktop as follows in your `claude_desktop_config.yml`:\n\n```json\n{\n  \"mcpServers\": {\n    \"embabel\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"mcp-remote\",\n        \"http://localhost:8080/sse\"\n      ]\n    }\n  }\n}\n\n```\n\nSee [MCP Quickstart for Claude Desktop Users](https://modelcontextprotocol.io/quickstart/user) for how to configure\nClaude Desktop.\n\nThe [MCP Inspector](https://github.com/modelcontextprotocol/inspector) is a helpful tool for interacting with your\nEmbabel\nSSE server, manually invoking tools and checking the exposed prompts and resources.\n\nStart the MCP Inspector with:\n\n```bash\nnpx @modelcontextprotocol/inspector\n```\n\n## Consuming MCP Servers\n\nThe Embabel Agent Framework provides built-in support for consuming Model Context Protocol (MCP) servers, allowing you\nto extend your applications with powerful AI capabilities through standardized interfaces.\n\n### What is MCP?\n\nModel Context Protocol (MCP) is an open protocol that standardizes how applications provide context and extra\nfunctionality to large language models. Introduced by Anthropic, MCP has emerged as the de facto standard for connecting\nAI agents to tools, functioning as a client-server protocol where:\n\n- **Clients** (like Embabel Agent) send requests to servers\n- **Servers** process those requests to deliver necessary context to the AI model\n\nMCP simplifies integration between AI applications and external tools, transforming an \"MÃ—N problem\" into an \"M+N\nproblem\" through standardization - similar to what USB did for hardware peripherals.\n\n### Configuring MCP in Embabel Agent\n\nTo configure MCP servers in your Embabel Agent application, add the following to your `application.yml`:\n\n```yaml\nspring:\n  ai:\n    mcp:\n      client:\n        enabled: true\n        name: embabel\n        version: 1.0.0\n        request-timeout: 30s\n        type: SYNC\n        stdio:\n          connections:\n            docker-mcp:\n              command: docker\n              args:\n                - run\n                - -i\n                - --rm\n                - alpine/socat\n                - STDIO\n                - TCP:host.docker.internal:8811\n```\n\nThis configuration sets up an MCP client that connects to a Docker-based MCP server. The connection uses STDIO transport\nthrough Docker's socat utility to connect to a TCP endpoint.\n\n### Docker Desktop MCP Integration\n\nDocker has embraced MCP with their Docker MCP Catalog and Toolkit, which provides:\n\n1. **Centralized Discovery** - A trusted hub for discovering MCP tools integrated into Docker Hub\n2. **Containerized Deployment** - Run MCP servers as containers without complex setup\n3. **Secure Credential Management** - Centralized, encrypted credential handling\n4. **Built-in Security** - Sandbox isolation and permissions management\n\nThe Docker MCP ecosystem includes over 100 verified tools from partners like Stripe, Elastic, Neo4j, and more, all\naccessible through Docker's infrastructure.\n\n### Learn More\n\n- [Docker MCP Documentation](https://docs.docker.com/desktop/features/gordon/mcp/)\n- [Docker MCP Servers Repository](https://github.com/docker/mcp-servers)\n- [Introducing Docker MCP Catalog and Toolkit](https://www.docker.com/blog/introducing-docker-mcp-catalog-and-toolkit/)\n- [MCP Introduction and Overview](https://www.philschmid.de/mcp-introduction)\n\n## A2A\n\nEmbabel integrates with the [A2A](https://github.com/google-a2a/A2A) protocol, allowing you to connect to other\nA2A-enabled agents and\nservices.\n\nEnable the `a2a` Spring profile to start the A2A server.\n\nYou'll need the following environment variable:\n\n- `GOOGLE_STUDIO_API_KEY`: Your Google Studio API key, which is used for Gemini.\n\nStart the Google A2A web interface using the `a2a` Docker profile:\n\n```bash\ndocker compose --profile a2a up\n```\n\nGo to the web interface running within the container at `http://localhost:12000/`.\n\nConnect to your agent at `host.docker.internal:8080/a2a`. Note that `localhost:8080/a2a` won't work as the server\ncannot access it when running in a Docker container.\n\n## Running Tests\n\nRun the tests via Maven.\n\n```bash\nmvn test\n```\n\nThis will run both unit and integration tests\nbut will not require an internet connection or any external services.\n\n## Spring profiles\n\nSpring profiles are used to configure the application for different environments and behaviors.\n\nModel profiles:\n\n- `docker-desktop`: Talking to Docker Desktop with the MCP extension. **This is recommended for the best experience,\n  with Docker-provided web tools.**\n\nLogging profiles:\n\n- `severance`: [Severance](https://www.youtube.com/watch?v=xEQP4VVuyrY&ab_channel=AppleTV) specific logging. Praise\n  Kier!\n- `starwars`: Star Wars specific logging. Feel the force\n- `colossus`: Colossus specific logging. The Forbin Project.\n\n## Testing\n\nA key goal of this framework is ease of testing.\nJust as Spring eased testing of early enterprise Java applications,\nthis framework facilitates testing of AI applications.\n\nTypes of testing:\n\n- Unit tests: All agents are unit testable, like any Spring-managed beans. Construct them with mock objects; call\n  individual action methods. The testing library facilitates testing prompts.\n- Integration tests: tbd\n\n## Logging\n\nAll logging in this project is either debug logging in the relevant\nclass itself, or results from the stream of events of type `AgentEvent`.\n\nEdit `application.yml` if you want to see debug logging from the relevant classes and packages.\n\nAvailable logging experiences:\n\n- `severance`: Severance logging. Praise Kier\n- `starwars`: Star Wars logging. Feel the force. The default as it's understood throughout the galaxy.\n- `colossus`: Colossus logging. The Forbin Project.\n- `montypython`: Monty Python logging. No one expects it.\n- `hh`: Hitchhiker's Guide to the Galaxy logging. The answer is 42.\n\nIf none of these profiles is chosen, Embabel will use vanilla logging.\nThis makes me sad.\n\n## Adding Embabel Agent Framework to Your Project\n\n### Maven Central Availability\n\n**Since version 0.2.0**, Embabel Agent Framework is available directly on Maven Central, simplifying dependency\nmanagement. You no longer need to configure custom repositories for stable releases.\n\n---\n\n### Maven\n\n#### For version 0.2.0 and above (Recommended)\n\nSimply add the Embabel Spring Boot starter dependency to your `pom.xml`:\n\n```xml\n\n<dependency>\n    <groupId>com.embabel.agent</groupId>\n    <artifactId>embabel-agent-starter</artifactId>\n    <version>${embabel-agent.version}</version>\n</dependency>\n```\n\nNo additional repository configuration is needed! Maven Central is configured by default.\n\n#### For versions prior to 0.2.0 or for SNAPSHOT versions\n\nYou need to add the Embabel repositories to your `pom.xml`:\n\n```xml\n\n<repositories>\n    <repository>\n        <id>embabel-releases</id>\n        <url>https://repo.embabel.com/artifactory/libs-release</url>\n        <releases>\n            <enabled>true</enabled>\n        </releases>\n        <snapshots>\n            <enabled>false</enabled>\n        </snapshots>\n    </repository>\n    <repository>\n        <id>embabel-snapshots</id>\n        <url>https://repo.embabel.com/artifactory/libs-snapshot</url>\n        <releases>\n            <enabled>false</enabled>\n        </releases>\n        <snapshots>\n            <enabled>true</enabled>\n        </snapshots>\n    </repository>\n</repositories>\n```\n\nThen add the dependency:\n\n```xml\n\n<dependency>\n    <groupId>com.embabel.agent</groupId>\n    <artifactId>embabel-agent-starter</artifactId>\n    <version>${embabel-agent.version}</version>\n</dependency>\n```\n\n---\n\n### Gradle (Kotlin DSL)\n\n#### For version 0.2.0 and above (Recommended)\n\nAdd the required repositories to your `build.gradle.kts`:\n\n```kotlin\nrepositories {\n    mavenCentral()\n    maven {\n        name = \"Spring Milestones\"\n        url = uri(\"https://repo.spring.io/milestone\")\n    }\n}\n```\n\nAdd the Embabel Agent starter:\n\n```kotlin\ndependencies {\n    implementation(\"com.embabel.agent:embabel-agent-starter:${embabelAgentVersion}\")\n}\n```\n\n#### For versions prior to 0.2.0 or for SNAPSHOT versions\n\nAdd all required repositories to your `build.gradle.kts`:\n\n```kotlin\nrepositories {\n    mavenCentral()\n    maven {\n        name = \"embabel-releases\"\n        url = uri(\"https://repo.embabel.com/artifactory/libs-release\")\n        mavenContent {\n            releasesOnly()\n        }\n    }\n    maven {\n        name = \"embabel-snapshots\"\n        url = uri(\"https://repo.embabel.com/artifactory/libs-snapshot\")\n        mavenContent {\n            snapshotsOnly()\n        }\n    }\n    maven {\n        name = \"Spring Milestones\"\n        url = uri(\"https://repo.spring.io/milestone\")\n    }\n}\n```\n\nAdd the Embabel Agent starter:\n\n```kotlin\ndependencies {\n    implementation(\"com.embabel.agent:embabel-agent-starter:${embabelAgentVersion}\")\n}\n```\n\n---\n\n### Gradle (Groovy DSL)\n\n#### For version 0.2.0 and above (Recommended)\n\nAdd the required repositories to your `build.gradle`:\n\n```groovy\nrepositories {\n    mavenCentral()\n    maven {\n        name = 'Spring Milestones'\n        url = 'https://repo.spring.io/milestone'\n    }\n}\n```\n\nAdd the Embabel Agent starter:\n\n```groovy\ndependencies {\n    implementation \"com.embabel.agent:embabel-agent-starter:${embabelAgentVersion}\"\n}\n```\n\n#### For versions prior to 0.2.0 or for SNAPSHOT versions\n\nAdd all required repositories to your `build.gradle`:\n\n```groovy\nrepositories {\n    mavenCentral()\n    maven {\n        name = 'embabel-releases'\n        url = 'https://repo.embabel.com/artifactory/libs-release'\n        mavenContent {\n            releasesOnly()\n        }\n    }\n    maven {\n        name = 'embabel-snapshots'\n        url = 'https://repo.embabel.com/artifactory/libs-snapshot'\n        mavenContent {\n            snapshotsOnly()\n        }\n    }\n    maven {\n        name = 'Spring Milestones'\n        url = 'https://repo.spring.io/milestone'\n    }\n}\n```\n\nAdd the Embabel Agent starter:\n\n```groovy\ndependencies {\n    implementation 'com.embabel.agent:embabel-agent-starter:${embabelAgentVersion}'\n}\n```\n\n---\n\n### Important Notes\n\n#### Spring Milestones Repository\n\nThe Spring Milestones repository is required because the Embabel BOM (`embabel-agent-dependencies`) has transitive\ndependencies on experimental Spring components, specifically the `mcp-bom`. This BOM is not available on Maven Central\nand is only published to the Spring milestone repository.\n\n**Note for Gradle users:** Unlike Maven, Gradle does not inherit repository configurations declared in parent POMs or\nBOMs. Therefore, it is necessary to explicitly declare the Spring milestone repository in your repositories block to\nensure proper resolution of all transitive dependencies.\n\n#### Repository Types\n\n- **Maven Central** (since v0.2.0): For stable releases 0.2.0 and above\n- **Embabel Releases Repository**: For stable releases prior to 0.2.0\n- **Embabel Snapshots Repository**: For development/snapshot versions (e.g., `0.3.0-SNAPSHOT`)\n\n---\n\n### Quick Start Examples\n\n#### Maven with latest stable version\n\n```xml\n\n<dependency>\n    <groupId>com.embabel.agent</groupId>\n    <artifactId>embabel-agent-starter</artifactId>\n    <version>0.3.0</version>\n</dependency>\n```\n\n#### Gradle Kotlin DSL with latest stable version\n\n```kotlin\nimplementation(\"com.embabel.agent:embabel-agent-starter:0.3.0\")\n```\n\n#### Gradle Groovy DSL with latest stable version\n\n```groovy\nimplementation 'com.embabel.agent:embabel-agent-starter:0.3.0'\n```\n\n## Contributing\n\nWe welcome contributions to the Embabel Agent Framework.\n\nLook at the [coding style guide](embabel-agent-api/.embabel/coding-style.md) for style guidelines.\nThis file also informs coding agent behavior.\n\n## Miscellaneous\n\n- _Why the name Embabel?_\n  The \"babel\" part is ultimately inspired by the story of the Tower of Babel, perhaps via Douglas\n  Adams' [babelfish](https://www.youtube.com/watch?v=iuumnjJWFO4&ab_channel=BBCStudios).\n  Per @lasuac:\n  _While Adams' fish in the ear enabled universal translation between species, Embabel aims at translating human intent\n  to JVM code, AI models, and enterprise systems._\n  \"embabel\" also sounds like \"enable.\"\n- Milestone names are Australian animals. Mythical animals such as \"bunyip\" and \"yowie\" are used for futures that may or\n  not be implemented.\n- README badges come from [here](https://github.com/Ileriayo/markdown-badges)\n  and [here](https://home.aveek.io/GitHub-Profile-Badges/).\n- Don't forget to join [Discord](https://discord.gg/t6bjkyj93q) to collaborate with the Embabel community. It is a good\n  place to receive support, showcase your work, discuss ideas and connect with like-minded people.\n\n## Star history\n\n[![Star History Chart](https://api.star-history.com/svg?repos=embabel/embabel-agent&type=Date)](https://star-history.com/#embabel/embabel-agent&Date)\n\n## Contributors\n\n[![Embabel contributors](https://contrib.rocks/image?repo=embabel/embabel-agent)](https://github.com/embabel/embabel-agent/graphs/contributors)\n\n\n\n--------------------\n(c) Embabel Software Inc 2024-2025.\n",
      "stars_today": 1
    },
    {
      "id": 369991603,
      "name": "supabase-swift",
      "full_name": "supabase/supabase-swift",
      "description": "A Swift SDK for Supabase. Query your Supabase database, subscribe to realtime events, upload and download files, browse Swift examples, invoke postgres functions via rpc, invoke supabase edge functions, query pgvector. ",
      "html_url": "https://github.com/supabase/supabase-swift",
      "stars": 1158,
      "forks": 223,
      "language": "Swift",
      "topics": [
        "database",
        "ios",
        "supabase",
        "swift"
      ],
      "created_at": "2021-05-23T07:46:26Z",
      "updated_at": "2026-01-24T02:32:18Z",
      "pushed_at": "2026-01-23T17:10:44Z",
      "open_issues": 27,
      "owner": {
        "login": "supabase",
        "avatar_url": "https://avatars.githubusercontent.com/u/54469796?v=4"
      },
      "readme": "# supabase-swift\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fsupabase%2Fsupabase-swift%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/supabase/supabase-swift)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fsupabase%2Fsupabase-swift%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/supabase/supabase-swift)\n[![Coverage Status](https://coveralls.io/repos/github/supabase/supabase-swift/badge.svg?branch=main)](https://coveralls.io/github/supabase/supabase-swift?branch=main)\n\nSupabase SDK for Swift. Mirrors the design of [supabase-js](https://github.com/supabase/supabase-js/blob/master/README.md).\n\n* Documentation: [https://supabase.com/docs/reference/swift/introduction](https://supabase.com/docs/reference/swift/introduction)\n\n## Usage\n\n### Requirements\n- iOS 13.0+ / macOS 10.15+ / tvOS 13+ / watchOS 6+ / visionOS 1+\n- Xcode 15.3+\n- Swift 5.10+\n\n> [!IMPORTANT]\n> Check the [Support Policy](#support-policy) to learn when dropping Xcode, Swift, and platform versions will not be considered a **breaking change**.\n\n### Installation\nInstall the library using the Swift Package Manager.\n\n```swift\nlet package = Package(\n    ...\n    dependencies: [\n        ...\n        .package(\n            url: \"https://github.com/supabase/supabase-swift.git\",\n            from: \"2.0.0\"\n        ),\n    ],\n    targets: [\n        .target(\n            name: \"YourTargetName\",\n            dependencies: [\n                .product(name: \"Supabase\", package: \"supabase-swift\") // Add as a dependency\n            ]\n        )\n    ]\n)\n```\n\nIf you're using Xcode, [use this guide](https://developer.apple.com/documentation/swift_packages/adding_package_dependencies_to_your_app) to add `supabase-swift` to your project. Use `https://github.com/supabase-community/supabase-swift.git` for the url when Xcode asks.\n\nIf you don't want the full Supabase environment, you can also add individual packages, such as `Functions`, `Auth`, `Realtime`, `Storage`, or `PostgREST`.\n\nThen you're able to import the package and establish the connection with the database.\n\n```swift\n/// Create a single supabase client for interacting with your database\nlet client = SupabaseClient(\n    supabaseURL: URL(string: \"https://xyzcompany.supabase.co\")!,\n    supabaseKey: \"public-anon-key\"\n)\n```\n\n### Initialize with custom options\n\n```swift\nlet client = SupabaseClient(\n    supabaseURL: URL(string: \"https://xyzcompany.supabase.co\")!, \n    supabaseKey: \"public-anon-key\",\n    options: SupabaseClientOptions(\n        db: .init(\n            schema: \"public\"\n        ),\n        auth: .init(\n            storage: MyCustomLocalStorage(),\n            flowType: .pkce\n        ),\n        global: .init(\n            headers: [\"x-my-custom-header\": \"my-app-name\"],\n            session: URLSession.myCustomSession\n        )\n    )\n)\n```\n\nAdditional examples are available [here](https://github.com/supabase/supabase-swift/tree/main/Examples).\n\n## Support Policy\n\nThis document outlines the scope of support for Xcode, Swift, and the various platforms (iOS, macOS, tvOS, watchOS, and visionOS) in Supabase.\n\n### Xcode\nWe only support Xcode versions that are currently eligible for submitting apps to the App Store. Once a specific version of Xcode is no longer supported, its removal from Supabase **won't be treated as a breaking change** and will occur in a minor release.\n\n### Swift\nThe minimum supported Swift version corresponds to the minor version released with the oldest-supported Xcode version. When a Swift version reaches its end of support, it will be dropped from Supabase in a **minor release**, and **this won't be considered a breaking change**.\n\n### Platforms\nWe maintain support for the four latest major versions of each platform, including the current version.\n\nWhen a platform version is no longer supported, Supabase will drop it in a **minor release**, and **this won't count as a breaking change**. For instance, iOS 14 will no longer be supported after the release of iOS 18, allowing its removal in a minor update.\n\nFor macOS, the named yearly releases are treated as major versions for this policy, regardless of their version numbers.\n\n> [!IMPORTANT]\n> Android, Linux and Windows works but aren't supported, and may stop working on future versions of the library.\n\n## Contributing\n\n- Fork the repo on GitHub\n- Clone the project to your own machine\n- Commit changes to your own branch\n- Push your work back up to your fork\n- Submit a Pull request so that we can review your changes and merge\n\n## Sponsors\n\nWe are building the features of Firebase using enterprise-grade, open source products. We support existing communities wherever possible, and if the products donâ€™t exist we build them and open source them ourselves. Thanks to these sponsors who are making the OSS ecosystem better for everyone.\n\n[![New Sponsor](https://user-images.githubusercontent.com/10214025/90518111-e74bbb00-e198-11ea-8f88-c9e3c1aa4b5b.png)](https://github.com/sponsors/supabase)\n",
      "stars_today": 1
    },
    {
      "id": 159560389,
      "name": "renv",
      "full_name": "rstudio/renv",
      "description": "renv: Project environments for R.",
      "html_url": "https://github.com/rstudio/renv",
      "stars": 1127,
      "forks": 162,
      "language": "R",
      "topics": [],
      "created_at": "2018-11-28T20:25:39Z",
      "updated_at": "2026-01-24T11:27:02Z",
      "pushed_at": "2026-01-22T07:14:26Z",
      "open_issues": 213,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# renv <img src=\"man/figures/logo.svg\" align=\"right\" height=\"115\"/>\n\n<!-- badges: start -->\n\n[![Lifecycle:\nstable](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html)\n[![CRAN\nstatus](https://www.r-pkg.org/badges/version/renv)](https://CRAN.R-project.org/package=renv)\n[![R-CMD-check](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/renv/actions/workflows/R-CMD-check.yaml)\n\n<!-- badges: end -->\n\n## Overview\n\nThe renv package[^1] helps you create **r**eproducible **env**ironments\nfor your R projects. Use renv to make your R projects more isolated,\nportable and reproducible.\n\n- **Isolated**: Installing a new or updated package for one project\n  wonâ€™t break your other projects, and vice versa. Thatâ€™s because renv\n  gives each project its own private library.\n- **Portable**: Easily transport your projects from one computer to\n  another, even across different platforms. renv makes it easy to\n  install the packages your project depends on.\n- **Reproducible**: renv records the exact package versions you depend\n  on, and ensures those exact versions are the ones that get installed\n  wherever you go.\n\n## Installation\n\nInstall the latest version of renv from CRAN with:\n\n``` r\ninstall.packages(\"renv\")\n```\n\nAlternatively, install the development version from\n[r-universe](https://rstudio.r-universe.dev/renv) with:\n\n``` r\ninstall.packages(\"renv\", repos = \"https://rstudio.r-universe.dev\")\n```\n\n## Workflow\n\n<img src=\"vignettes/renv.png\" alt=\"A diagram showing the most important verbs and nouns of renv. Projects start with init(), which creates a project library using packages from the system library. snapshot() updates the lockfile using the packages installed in the project library, where restore() installs packages into the project library using the metadata from the lockfile, and status() compares the lockfile to the project library. You install and update packages from CRAN and GitHub using install() and update(), but because you'll need to do this for multiple projects, renv uses cache to make this fast.\" width=\"408\" style=\"display: block; margin: auto;\" />\n\nUse `renv::init()` to initialize renv in a new or existing project. This\nwill set up a **project library**, containing all the packages youâ€™re\ncurrently using. The packages (and all the metadata needed to reinstall\nthem) are recorded into a **lockfile**, `renv.lock`, and a `.Rprofile`\nensures that the library is used every time you open that project.\n\nAs you continue to work on your project, you will install and upgrade\npackages, either using `install.packages()` and `update.packages()` or\n`renv::install()` and `renv::update()`. After youâ€™ve confirmed your code\nworks as expected, use `renv::snapshot()` to record the packages and\ntheir sources in the lockfile.\n\nLater, if you need to share your code with someone else or run your code\non new machine, your collaborator (or you) can call `renv::restore()` to\nreinstall the specific package versions recorded in the lockfile.\n\n## Learning more\n\nIf this is your first time using renv, we strongly recommend starting\nwith the [Introduction to\nrenv](https://rstudio.github.io/renv/articles/renv.html) vignette: this\nwill help you understand the most important verbs and nouns of renv.\n\nIf you have a question about renv, please first check the\n[FAQ](https://rstudio.github.io/renv/articles/faq.html) to see whether\nyour question has already been addressed. If it hasnâ€™t, please feel free\nto ask on the [Posit Forum](https://forum.posit.co).\n\nIf you believe youâ€™ve found a bug in renv, please file a bug (and, if\npossible, a [reproducible example](https://reprex.tidyverse.org)) at\n<https://github.com/rstudio/renv/issues>.\n\n[^1]: Pronounced â€œRâ€ â€œenvâ€\n",
      "stars_today": 1
    },
    {
      "id": 167440342,
      "name": "monocle3",
      "full_name": "cole-trapnell-lab/monocle3",
      "description": null,
      "html_url": "https://github.com/cole-trapnell-lab/monocle3",
      "stars": 434,
      "forks": 116,
      "language": "R",
      "topics": [
        "single-cell-rna-seq"
      ],
      "created_at": "2019-01-24T21:26:18Z",
      "updated_at": "2026-01-24T03:39:16Z",
      "pushed_at": "2026-01-08T18:32:17Z",
      "open_issues": 260,
      "owner": {
        "login": "cole-trapnell-lab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8060918?v=4"
      },
      "readme": "MONOCLE 3\n=======================\n\nMonocle 3 is an analysis toolkit for single-cell RNA-Seq experiments.  To use this package, you will need the R statistical computing environment (version 3.0 or later) and several packages available through Bioconductor and CRAN.\n\nDetails on how to install and use Monocle 3 are available on our website:\n\nhttp://cole-trapnell-lab.github.io/monocle3/\n\n## Monocle3 with BPCells counts matrix support\n\nThis development branch version of Monocle3 adds the ability to store the counts matrix on-disk using the BPCells package. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as in previous versions. In order to store the matrix on-disk, you must set the matrix_control list value `matrix_class=\"BPCells\"` in the affected commands. For example, to load a MatrixMarket file as an on-disk matrix, use the command\n\n```\ncds <- load_mm_data(mat_path=<path_to_mtx_file>,\n                    feature_anno_path=<path_to_feature_anno_file>,\n                    cell_anno_path=<path_to_cell_anno_file>,\n                    matrix_control=list(matrix_class='BPCells'))\n```\n\n### Install Monocle3 with BPCells\n\nYou must install BPCells from Github before you can install this Monocle3 version, and BPCells requires an HDF5 object library for installation. After installing the HDF5 library, you install BPCells using the command\n\n```\nremotes::install_github(\"bnprks/BPCells/r\")\n```\n\nThe [BPCells Github site](https://github.com/bnprks/BPCells)  has additional information.\n\nSome Linux distributions provide the HDF5 library as an option. The\nBPCells site has information about installing the HDF5 library on various operating systems.\n\nI used Homebrew to install an HDF5 library on MacOS. I seemed to need to install the pkg-config package as well, and add a pkg-config configuration file for HDF5. Homebrew installed pkg-config in '/opt/homebrew' so I added the hdf5.pc file in\n\n> /opt/homebrew/lib/pkgconfig/hdf5.pc\n\nwith the contents\n\n```\nprefix=/opt/homebrew/Cellar/hdf5/1.12.2_2\nexec_prefix=${prefix}\nincludedir=${prefix}/include\nlibdir=/opt/homebrew/Cellar/hdf5/1.12.2_2/lib\n  \nName: hdf5\nDescription: HDF5\nURL: xx\nVersion: 1.12.2_2\nCflags: -I${includedir}\nLibs: -L${libdir} -lhdf5\n```\n\nYou may need to update the version strings in your hdf5.pc file.\n\nMonocle3 no longer uses the terra package, so it does not need to be installed.\n\n### Notes\n\n- Monocle3 can use the BPCells package to store the feature-cell counts matrix on-disk rather than in-memory, which enables analysis of considerably larger data sets than before. By default, Monocle3 stores the counts matrix in-memory as a sparse matrix, as it has in the past. To store the counts matrix on-disk, use the parameter `matrix_control=list(matrix_class=\"BPCells\")` when you make the CDS or convert the counts matrix using one of the functions\n  - `load_mm_data()`\n  - `load_mtx_data()`\n  - `load_cellranger_data()`\n  - `load_a549()`\n  - `load_worm_embryo()`\n  - `load_worm_l2()`\n  - `convert_counts_matrix()`\n\n  For example, to convert a dgCMatrix counts matrix to a BPCells on-disk matrix in an existing CDS, use the command `cds <- convert_counts_matrix(cds, matrix_control=list(matrix_class=\"BPCells\"))`.\n- BPCells stores the count matrix information in directories with names similar to `monocle.bpcells.20230830.4c4b1bebe4b4.tmp`. Monocle3 tries to remove those directories when you quit R. Please do not remove them while Monocle3 is running because doing so eliminates the count matrix data. You *can* remove them after quitting R if Monocle3 fails to remove them.\n- The method `new_cell_data_set()` accepts a BPCells on-disk counts matrix.\n- The functions `save_monocle_objects()` and `load_monocle_objects()` store and load BPCells on-disk matrices when the CDS counts matrix is an on-disk BPCells matrix.\n- The Monocle3 `saveRDS()` function warns the user to use `save_monocle_objects()` when saving a CDS with a BPCells on-disk counts matrix. If you insist on using the `saveRDS()` function, the BPCells on-disk matrix directory will not be stored and you will be unable to load it with the `readRDS()` function.\n- The function `combine_cds()` combines CDSes with mixes of dgCMatrix and BPCells on-disk counts matrices into a BPCells on-disk counts matrix. When called with the `matrix_control=list(matrix_class=\"BPCells\")` parameter, `combine_cds()` combines CDSes with all dgCMatrix counts matrices into a BPCells on-disk counts matrix.\n- Note that when the counts matrix is stored as a BPCells on-disk matrix, the `new_cell_data_set()` method stores a second BPCells on-disk copy of the matrix in the CDS assays slot with the name `counts_row_order`. The `counts_row_order` matrix is used by Monocle3 when the counts matrix is accessed intensively by row. The reason is that, by default, BPCells stores the matrix as a one-dimensional vector in column-major order, as does R. As a result, column access is fast and row access is slow. We use BPCell's ability to also store and access matrices in row-major order, which gives fast row access. However, this means that the two copies of the counts matrix must have the same count values. If you replace or change the CDS's counts matrix, you must also update the `counts_row_order` matrix, which you can do using the function `set_cds_row_order_matrix()`.\n  - The CDS assays slot is a named list where the standard, column-major order, matrix is called `counts` and the BPCells row-major order matrix is called `counts_row_order`.\n  - The `counts` matrix getter and setter methods are `counts(cds)` and `counts(cds)<-`.\n  - The Monocle3 setter warns about re-setting the BPCells `counts_row_order` matrix, unless called with the parameter `bpcells_warn=FALSE`.\n  - The `counts_row_order` getter method is called `counts_row_order`.\n  - There is no corresponding `counts_row_order` setter method\n- By default, the BPCells on-disk matrix is stored in a directory that is created where R is started. You can change the directory location using the `matrix_path` value in the `matrix_control` parameter.\n- For more information about the `matrix_control` values, see the help document for the function `set_matrix_control()`.\n- I tested this version using BPCells counts matrices on the examples in the Monocle3 documentation although I did not try all of the plotting functions.\n\n",
      "stars_today": 1
    },
    {
      "id": 962090208,
      "name": "rocm-systems",
      "full_name": "ROCm/rocm-systems",
      "description": "super repo for rocm systems projects",
      "html_url": "https://github.com/ROCm/rocm-systems",
      "stars": 221,
      "forks": 111,
      "language": "C++",
      "topics": [],
      "created_at": "2025-04-07T16:23:38Z",
      "updated_at": "2026-01-24T23:03:41Z",
      "pushed_at": "2026-01-24T20:48:21Z",
      "open_issues": 915,
      "owner": {
        "login": "ROCm",
        "avatar_url": "https://avatars.githubusercontent.com/u/21157610?v=4"
      },
      "readme": "# ROCm Systems\n\nWelcome to the ROCm Systems super-repo. This repository consolidates multiple ROCm systems projects into a single repository to streamline development, CI, and integration. The first set of projects focuses on requirements for building PyTorch.\n\n# Super-repo Status and CI Health\n\nThis table provides the current status of the migration of specific ROCm systems projects as well as a pointer to their current CI health.\n\n**Key:**\n- **Completed**: Fully migrated and integrated. This super-repo should be considered the source of truth for this project. The old repo may still be used for release activities.\n- **In Progress**: Ongoing migration, tests, or integration. Please refrain from submitting new pull requests on the individual repo of the project, and develop on the super-repo.\n- **Pending**: Not yet started or in the early planning stages. The individual repo should be considered the source of truth for this project.\n\n| Component              | Source of Truth | Migration Status | Azure CI Status                       | Component CI Status                   |\n|------------------------|-----------------|------------------|---------------------------------------|---------------------------------------|\n| `amdsmi`               | EMU             | Pending          |                                       |                                       |\n| `aqlprofile`           | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Faqlprofile?repoName=ROCm%2Frocm-systems&branchName=refs%2Fpull%2F368%2Fmerge)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=365&repoName=ROCm%2Frocm-systems&branchName=refs%2Fpull%2F368%2Fmerge) | [![CodeQL](https://github.com/ROCm/rocm-systems/actions/workflows/aqlprofile-codeql.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/aqlprofile-codeql.yml) <br> [![Continuous Integration](https://github.com/ROCm/rocm-systems/actions/workflows/aqlprofile-continuous_integration.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/aqlprofile-continuous_integration.yml) |\n| `clr`                  | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Fhip-clr?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=335&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `hip`                  | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Fhip-clr?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=335&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `hipother`             | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Fhip-clr?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=335&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `hip-tests`            | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Fhip-tests?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=362&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `rdc`                  | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frdc?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=360&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `rocm-core`            | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocm-core?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=349&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `rocminfo`             | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocminfo?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=356&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `rocm-smi-lib`         | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocm-smi-lib?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=358&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `rocprofiler`          | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocprofiler?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=329&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `rocprofiler-compute`  | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocprofiler-compute?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=344&repoName=ROCm%2Frocm-systems&branchName=develop) | [![Formatting](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-formatting.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-formatting.yml) <br> [![ rhel-8](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-rhel-8.yml/badge.svg)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-rhel-8.yml) <br> [![tarball](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-tarball.yml/badge.svg)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-tarball.yml) <br> [![ubuntu jammy](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-ubuntu-jammy.yml/badge.svg)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-compute-ubuntu-jammy.yml) |\n| `rocprofiler-register` | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocprofiler-register?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=327&repoName=ROCm%2Frocm-systems&branchName=develop) | [![Continuous Integration](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-register-continuous-integration.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-register-continuous-integration.yml) |\n| `rocprofiler-sdk`      | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocprofiler-sdk?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=347&repoName=ROCm%2Frocm-systems&branchName=develop) | [![Code Coverage Integration](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-code_coverage.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-code_coverage.yml) <br> [![CodeQL](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-codeql.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-codeql.yml) <br> [![Continuous Integration](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-continuous_integration.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-continuous_integration.yml) <br> [![Documentation](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-docs.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-docs.yml) <br> [![Formatting](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-formatting.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-formatting.yml) <br> [![Python Linting](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-python.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-python.yml) <br> [![Restrictions](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-restrictions.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-restrictions.yml) <br> [![Release Compatibility](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-rocm_release_compatibility.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-sdk-rocm_release_compatibility.yml) |\n| `rocprofiler-systems`  | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocprofiler-systems?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=345&repoName=ROCm%2Frocm-systems&branchName=develop) | [![Containers](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-containers.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-containers.yml) <br> [![rocprofiler-systems GHCR Packages for CI Images](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-ghcr.yml/badge.svg)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-ghcr.yml) <br> [![CPack](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-cpack.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-cpack.yml) <br> [![Formatting](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-formatting.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-formatting.yml) <br> [![OpenSUSE](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-opensuse.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-opensuse.yml) <br> [![Python Linting](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-python.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-python.yml) <br> [![RedHat Linux](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-redhat.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-redhat.yml) <br> [![Ubuntu Jammy](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-ubuntu-jammy.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-ubuntu-jammy.yml) <br> [![Ubuntu Noble](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-ubuntu-noble.yml/badge.svg?branch=develop)](https://github.com/ROCm/rocm-systems/actions/workflows/rocprofiler-systems-ubuntu-noble.yml) |\n| `rocr-runtime`         | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Frocr-runtime?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=354&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n| `roctracer`            | Public          | Completed        | [![Azure Pipelines](https://dev.azure.com/ROCm-CI/ROCm-CI/_apis/build/status%2Fmonorepo%2Froctracer?repoName=ROCm%2Frocm-systems&branchName=develop)](https://dev.azure.com/ROCm-CI/ROCm-CI/_build/latest?definitionId=331&repoName=ROCm%2Frocm-systems&branchName=develop) |                                       |\n\n\n## Tentative migration schedule\n\n| Component              | Tentative Date |\n|------------------------|----------------|\n\n\n*Remaining schedule to be determined.\n\n# TheRock CI Status\n\nNote TheRock CI performs multi-component testing on top of builds leveraging [TheRock](https://github.com/ROCm/TheRock) build system.\n\n[![The Rock CI](https://github.com/ROCm/rocm-systems/actions/workflows/therock-ci.yml/badge.svg?branch%3Adevelop+event%3Apush)](https://github.com/ROCm/rocm-systems/actions/workflows/therock-ci.yml?query=branch%3Adevelop+event%3Apush)\n\n---\n\n## Nomenclature\n\nProject names have been standardized to match the casing and punctuation of released packages. This removes inconsistent camel-casing and underscores used in legacy repositories.\n\n## Structure\n\nThe repository is organized as follows:\n\n```\nprojects/\n  amdsmi/\n  aqlprofile/\n  clr/\n  hip/\n  hipother/\n  hip-tests/\n  rccl/\n  rdc/\n  rocm-core\n  rocminfo/\n  rocmsmilib/\n  rocprofiler/\n  rocprofiler-compute/\n  rocprofiler-register/\n  rocprofiler-sdk/\n  rocprofiler-systems/\n  rocrruntime/\n  rocshmem/\n  roctracer/\n```\n\n- Each folder under `projects/` corresponds to a ROCm systems project that was previously maintained in a standalone GitHub repository and released as distinct packages.\n- Each folder under `shared/` contains code that existed in its own repository and is used as a dependency by multiple projects, but does not produce its own distinct packages in previous ROCm releases.\n\n## Goals\n\n- Enable unified build and test workflows across ROCm libraries.\n- Facilitate shared tooling, CI, and contributor experience.\n- Improve integration, visibility, and collaboration across ROCm library teams.\n\n## Getting Started\n\nTo begin contributing or building, see the [CONTRIBUTING.md](./CONTRIBUTING.md) guide. It includes setup instructions, sparse-checkout configuration, development workflow, and pull request guidelines.\n\n## License\n\nThis super-repo contains multiple subprojects, each of which retains the license under which it was originally published.\n\nğŸ“ Refer to the `LICENSE`, `LICENSE.md`, or `LICENSE.txt` file within each `projects/` or `shared/` directory for specific license terms.\nğŸ“„ Refer to the header notice in individual files outside `projects/` or `shared/` folders for their specific license terms.\n\n> **Note**: The root of this repository does not define a unified license across all components.\n\n## Questions or Feedback?\n\n- ğŸ’¬ [Start a discussion](https://github.com/ROCm/rocm-systems/discussions)\n- ğŸ [Open an issue](https://github.com/ROCm/rocm-systems/issues)\n\nWe're happy to help!\n",
      "stars_today": 1
    },
    {
      "id": 33569135,
      "name": "RxSwift",
      "full_name": "ReactiveX/RxSwift",
      "description": "Reactive Programming in Swift",
      "html_url": "https://github.com/ReactiveX/RxSwift",
      "stars": 24684,
      "forks": 4174,
      "language": "Swift",
      "topics": [
        "functional",
        "ios",
        "observer",
        "reactive",
        "reactivex",
        "rxswift",
        "swift",
        "unidirectional"
      ],
      "created_at": "2015-04-07T21:25:17Z",
      "updated_at": "2026-01-24T15:02:18Z",
      "pushed_at": "2026-01-22T08:14:18Z",
      "open_issues": 6,
      "owner": {
        "login": "ReactiveX",
        "avatar_url": "https://avatars.githubusercontent.com/u/6407041?v=4"
      },
      "readme": "<p align=\"center\">\n<img src=\"https://github.com/ReactiveX/RxSwift/blob/main/assets/RxSwift_Logo.png?raw=true\" width=\"35%\" alt=\"RxSwift Logo\" />\n<br />\n<a href=\"https://github.com/ReactiveX/RxSwift/actions/workflows/tests.yml\" target=\"_blank\"><img src=\"https://github.com/ReactiveX/RxSwift/actions/workflows/tests.yml/badge.svg\" alt=\"Build Status\" /></a>\n<img src=\"https://img.shields.io/badge/platforms-iOS%20%7C%20macOS%20%7C%20tvOS%20%7C%20watchOS%20%7C%20Linux-333333.svg\" alt=\"Supported Platforms: iOS, macOS, tvOS, watchOS & Linux\" />\n<br />\n<a href=\"https://github.com/Carthage/Carthage\" alt=\"RxSwift on Carthage\" title=\"RxSwift on Carthage\"><img src=\"https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat\" /></a>\n<a href=\"https://github.com/swiftlang/swift-package-manager\" alt=\"RxSwift on Swift Package Manager\" title=\"RxSwift on Swift Package Manager\"><img src=\"https://img.shields.io/badge/Swift%20Package%20Manager-compatible-brightgreen.svg\" /></a>\n</p>\n\nRx is a [generic abstraction of computation](https://youtu.be/looJcaeboBY) expressed through `Observable<Element>` interface, which lets you broadcast and subscribe to values and other events from an `Observable` stream.\n\nRxSwift is the Swift-specific implementation of the [Reactive Extensions](http://reactivex.io) standard.\n\n<p align=\"center\"><img src=\"https://github.com/ReactiveX/RxSwift/blob/main/assets/example.png?raw=true\" width=\"55%\" alt=\"RxSwift Observable Example of a price constantly changing and updating the app's UI\" /></p>\n\nWhile this version aims to stay true to the original spirit and naming conventions of Rx, this project also aims to provide a true Swift-first API for Rx APIs.\n\nCross platform documentation can be found on [ReactiveX.io](http://reactivex.io/).\n\nLike other Rx implementations, RxSwift's intention is to enable easy composition of asynchronous operations and streams of data in the form of `Observable` objects and a suite of methods to transform and compose these pieces of asynchronous work.\n\nKVO observation, async operations, UI Events and other streams of data are all unified under [abstraction of sequence](Documentation/GettingStarted.md#observables-aka-sequences). This is the reason why Rx is so simple, elegant and powerful.\n\n## I came here because I want to ...\n\n###### ... understand\n\n* [why use rx?](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Why.md)\n* [the basics, getting started with RxSwift](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/GettingStarted.md)\n* [traits](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Traits.md) - what are `Single`, `Completable`, `Maybe`, `Driver`, and `ControlProperty` ... and why do they exist?\n* [testing](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/UnitTests.md)\n* [tips and common errors](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Tips.md)\n* [debugging](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/GettingStarted.md#debugging)\n* [the math behind Rx](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/MathBehindRx.md)\n* [what are hot and cold observable sequences?](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/HotAndColdObservables.md)\n\n###### ... install\n\n* Integrate RxSwift/RxCocoa with my app. [Installation Guide](#installation)\n\n###### ... hack around\n\n* with the example app. [Running Example App](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/ExampleApp.md)\n* with operators in playgrounds. [Playgrounds](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Playgrounds.md)\n\n###### ... interact\n\n* All of this is great, but it would be nice to talk with other people using RxSwift and exchange experiences. <br />[Join Slack Channel](http://slack.rxswift.org)\n* Report a problem using the library. [Open an Issue With Bug Template](https://github.com/ReactiveX/RxSwift/blob/main/.github/ISSUE_TEMPLATE.md)\n* Request a new feature. [Open an Issue With Feature Request Template](Documentation/NewFeatureRequestTemplate.md)\n* Help out [Check out contribution guide](https://github.com/ReactiveX/RxSwift/blob/main/CONTRIBUTING.md)\n\n###### ... compare\n\n* [with Combine and ReactiveSwift](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/ComparisonWithOtherLibraries.md).\n\n###### ... understand the structure\n\nRxSwift is as compositional as the asynchronous work it drives. The core unit is RxSwift itself, while other dependencies can be added for UI Work, testing, and more.\n\nIt comprises five separate components depending on each other in the following way:\n\n```none\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   RxCocoa    â”œâ”€â”€â”€â”€â–¶   RxRelay    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n        â”‚                  â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚             RxSwift              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”˜\n        â”‚                  â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚    RxTest    â”‚    â”‚  RxBlocking  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n* **RxSwift**: The core of RxSwift, providing the Rx standard as (mostly) defined by [ReactiveX](https://reactivex.io). It has no other dependencies.\n* **RxCocoa**: Provides Cocoa-specific capabilities for general iOS/macOS/watchOS & tvOS app development, such as Shared Sequences, Traits, and much more. It depends on both `RxSwift` and `RxRelay`.\n* **RxRelay**: Provides `PublishRelay`, `BehaviorRelay` and `ReplayRelay`, three [simple wrappers around Subjects](https://github.com/ReactiveX/RxSwift/blob/main/Documentation/Subjects.md#relays). It depends on `RxSwift`.\n* **RxTest** and **RxBlocking**: Provides testing capabilities for Rx-based systems. It depends on `RxSwift`.\n\n## Usage\n\n<table>\n  <tr>\n    <th width=\"30%\">Here's an example</th>\n    <th width=\"30%\">In Action</th>\n  </tr>\n  <tr>\n    <td>Define search for GitHub repositories ...</td>\n    <th rowspan=\"9\"><img src=\"https://raw.githubusercontent.com/kzaher/rxswiftcontent/master/GithubSearch.gif\"></th>\n  </tr>\n  <tr>\n    <td><div class=\"highlight highlight-source-swift\"><pre>\nlet searchResults = searchBar.rx.text.orEmpty\n    .throttle(.milliseconds(300), scheduler: MainScheduler.instance)\n    .distinctUntilChanged()\n    .flatMapLatest { query -> Observable&lt;[Repository]&gt; in\n        if query.isEmpty {\n            return .just([])\n        }\n        return searchGitHub(query)\n            .catchAndReturn([])\n    }\n    .observe(on: MainScheduler.instance)</pre></div></td>\n  </tr>\n  <tr>\n    <td>... then bind the results to your tableview</td>\n  </tr>\n  <tr>\n    <td width=\"30%\"><div class=\"highlight highlight-source-swift\"><pre>\nsearchResults\n    .bind(to: tableView.rx.items(cellIdentifier: \"Cell\")) {\n        (index, repository: Repository, cell) in\n        cell.textLabel?.text = repository.name\n        cell.detailTextLabel?.text = repository.url\n    }\n    .disposed(by: disposeBag)</pre></div></td>\n  </tr>\n</table>\n\n## Installation\n\nRxSwift doesn't contain any external dependencies.\n\nThese are currently the supported installation options:\n\n### Manual\n\nOpen Rx.xcworkspace, choose `RxExample` and hit run. This method will build everything and run the sample app\n\n### XCFrameworks\n\nEach release starting with RxSwift 6 includes `*.xcframework` framework binaries.\n\nSimply drag the needed framework binaries to your **Frameworks, Libraries, and Embedded Content** section under your target's **General** tab.\n\n<img src=\"https://raw.githubusercontent.com/ReactiveX/RxSwift/main/assets/xcframeworks.png\" alt=\"XCFrameworks instructions\" width=\"65%\">\n\n> [!TIP]\n> RxSwift's xcframework(s) are signed with an Apple Developer account, and you can always verify the Team Name: Shai Mishali\n>\n> <img src=\"https://raw.githubusercontent.com/ReactiveX/RxSwift/main/assets/xcframeworks_signing.png\" alt=\"XCFrameworks Signing Team Name Validation\" width=\"65%\">\n\n### [Carthage](https://github.com/Carthage/Carthage)\n\nAdd this to `Cartfile`\n\n```\ngithub \"ReactiveX/RxSwift\" \"6.10.0\"\n```\n\n```bash\n$ carthage update\n```\n\n#### Carthage as a Static Library\n\nCarthage defaults to building RxSwift as a Dynamic Library.\n\nIf you wish to build RxSwift as a Static Library using Carthage you may use the script below to manually modify the framework type before building with Carthage:\n\n```bash\ncarthage update RxSwift --platform iOS --no-build\nsed -i -e 's/MACH_O_TYPE = mh_dylib/MACH_O_TYPE = staticlib/g' Carthage/Checkouts/RxSwift/Rx.xcodeproj/project.pbxproj\ncarthage build RxSwift --platform iOS\n```\n\n### [Swift Package Manager](https://github.com/swiftlang/swift-package-manager)\n\n> **Note**: There is a critical cross-dependency bug affecting many projects including RxSwift in Swift Package Manager. We've [filed a bug (SR-12303)](https://bugs.swift.org/browse/SR-12303) in early 2020 but have no answer yet. Your mileage may vary. A partial workaround can be found [here](https://github.com/ReactiveX/RxSwift/issues/2127#issuecomment-717830502).\n\nCreate a `Package.swift` file.\n\n```swift\n// swift-tools-version:5.0\n\nimport PackageDescription\n\nlet package = Package(\n  name: \"RxProject\",\n  dependencies: [\n    .package(url: \"https://github.com/ReactiveX/RxSwift.git\", .upToNextMajor(from: \"6.0.0\"))\n  ],\n  targets: [\n    .target(name: \"RxProject\", dependencies: [\"RxSwift\", .product(name: \"RxCocoa\", package: \"RxSwift\")]),\n  ]\n)\n```\n\n```bash\n$ swift build\n```\n\nTo build or test a module with RxTest dependency, set `TEST=1`.\n\n```bash\n$ TEST=1 swift test\n```\n\n### Manually using git submodules\n\n* Add RxSwift as a submodule\n\n```bash\n$ git submodule add git@github.com:ReactiveX/RxSwift.git\n```\n\n* Drag `Rx.xcodeproj` into Project Navigator\n* Go to `Project > Targets > Build Phases > Link Binary With Libraries`, click `+` and select `RxSwift`, `RxCocoa` and `RxRelay` targets\n\n## References\n\n* [http://reactivex.io/](http://reactivex.io/)\n* [Reactive Extensions GitHub (GitHub)](https://github.com/Reactive-Extensions)\n* [RxSwift RayWenderlich.com Book](https://store.raywenderlich.com/products/rxswift-reactive-programming-with-swift)\n* [RxSwift: Debunking the myth of hard (YouTube)](https://www.youtube.com/watch?v=GdvLP0ZAhhc)\n* [Boxue.io RxSwift Online Course](https://boxueio.com/series/rxswift-101) (Chinese ğŸ‡¨ğŸ‡³)\n* [Expert to Expert: Brian Beckman and Erik Meijer - Inside the .NET Reactive Framework (Rx) (video)](https://youtu.be/looJcaeboBY)\n* [Reactive Programming Overview (Jafar Husain from Netflix)](https://youtu.be/-8Y1-lE6NSA)\n* [Subject/Observer is Dual to Iterator (paper)](http://csl.stanford.edu/~christos/pldi2010.fit/meijer.duality.pdf)\n* [Rx standard sequence operators visualized (visualization tool)](http://rxmarbles.com/)\n* [Haskell](https://www.haskell.org/)\n",
      "stars_today": 0
    },
    {
      "id": 12499251,
      "name": "checkstyle",
      "full_name": "checkstyle/checkstyle",
      "description": "Checkstyle is a development tool to help programmers write Java code that adheres to a coding standard. By default it supports the Google Java Style Guide and Sun Code Conventions, but is highly configurable. It can be invoked with an ANT task and a command line program.",
      "html_url": "https://github.com/checkstyle/checkstyle",
      "stars": 8826,
      "forks": 3964,
      "language": "Java",
      "topics": [
        "code-quality",
        "command-line-tool",
        "hacktoberfest",
        "java",
        "static-analysis",
        "static-code-analysis"
      ],
      "created_at": "2013-08-31T02:05:05Z",
      "updated_at": "2026-01-25T01:19:51Z",
      "pushed_at": "2026-01-25T01:19:46Z",
      "open_issues": 940,
      "owner": {
        "login": "checkstyle",
        "avatar_url": "https://avatars.githubusercontent.com/u/5179750?v=4"
      },
      "readme": "# Checkstyle - Java Code Quality Tool\n\n![](https://raw.githubusercontent.com/checkstyle/resources/master/img/checkstyle-logos/checkstyle-logo-260x99.png)\n\n--------------------------\n\n*Checkstyle is a tool that ensures adherence to a code standard or a set of best practices.*\n\n[![][appveyor img]][appveyor]\n[![][circleci img]][circleci]\n[![][cirrusci img]][cirrusci]\n[![][coverage img]][coverage]\n[![][snyk img]][snyk]\n[![][semaphoreci img]][semaphoreci]\n[![][azure img]][azure]\n[![][error prone img]][error prone]\n[![][pitest img]][pitest]\n[![][checker framework img]][checker framework]\n[![][dependabot img]][dependabot]\n[![][release notes/version img]][release notes/version]\n[![][closed issues img]][closed issues]\n[![][link check img]][link check]\n[![][milestone img]][milestone]\n\n[![][mavenbadge img]][mavenbadge]\n\nThe latest release version can be found at\n[GitHub releases](https://github.com/checkstyle/checkstyle/releases/)\nor at [Maven repo](https://repo1.maven.org/maven2/com/puppycrawl/tools/checkstyle/).\n\nDocumentation is available in HTML format, see https://checkstyle.org/checks.html .\n\n## Table of Contents\n\n- [Quick Start](#quick-start)\n- [Contributing](#contributing)\n- [Feedback and Support](#feedback-and-support)\n- [Javadoc](#javadoc)\n- [Sponsor Checkstyle](#sponsor-checkstyle)\n- [Licensing](#licensing)\n\n## Quick Start\n\n- Download our [Latest Release](https://github.com/checkstyle/checkstyle/releases/) from GitHub\n  or Add Checkstyle to your build from [Maven Central](https://mvnrepository.com/artifact/com.puppycrawl.tools/checkstyle).\n- Read our Documentation for [usage](https://checkstyle.org/cmdline.html)\n  and [configuration](https://checkstyle.org/config.html).\n\n```bash\n$ cat config.xml\n<?xml version=\"1.0\"?>\n<!DOCTYPE module PUBLIC\n          \"-//Puppy Crawl//DTD Check Configuration 1.3//EN\"\n          \"https://checkstyle.org/dtds/configuration_1_3.dtd\">\n<module name=\"Checker\">\n  <module name=\"TreeWalker\">\n    <module name=\"FallThrough\"/>\n  </module>\n</module>\n\n$ cat Test.java\nclass Test {\n  public void foo() {\n    int i = 0;\n    while (i >= 0) {\n      switch (i) {\n        case 1:\n        case 2:\n          i++;\n        case 3: // violation 'fall from previous branch of the switch'\n          i++;\n      }\n    }\n  }\n}\n\n$ java -jar checkstyle-10.18.1-all.jar -c config.xml Test.java\nStarting audit...\n[ERROR] Test.java:9:9: Fall through from previous branch of switch statement [FallThrough]\nAudit done.\nCheckstyle ends with 1 errors.\n```\n\n## Contributing\n\nThanks for your interest in contributing to CheckStyle! Please see the\n[Contribution Guidelines](https://github.com/checkstyle/checkstyle/blob/master/.github/CONTRIBUTING.md)\nfor information on how to contribute to the project. This includes creating issues, submitting pull\nrequests, and setting up your development environment.\n\n## Build Instructions\n\nPlease see the [CheckStyle Documentation](https://checkstyle.org/contributing.html#Build) for\ninformation on how to build the project.\n\n## Feedback and Support\n\n- Visit our [Discussions Page](https://github.com/checkstyle/checkstyle/discussions), where you\n  can ask questions and discuss the project with other users and contributors. This is our\n  preferred method of communication for topics\n  like usage and configuration questions, debugging, and other feedback.\n- [Stack Overflow](https://stackoverflow.com/questions/tagged/checkstyle) is another place to\n  ask questions about Checkstyle usage.\n- If you are interested in contributing to the project, you can join our\n  [Discord Contributors Chat](https://discord.com/channels/845645228467159061/1216455699488313554)\n  [with invite link](https://discord.gg/FsUsYC2ura).\n- Our [Google Groups Forum](https://groups.google.com/forum/?hl=en#!forum/checkstyle) is a\n  mailing list for discussion and support; however, we may be slow to respond there.\n\n## Javadoc\n\nTake a look at our [javadoc](https://checkstyle.org/apidocs/index.html) to see\nour API documentation.\n\n## Sponsor Checkstyle\n\nCheckstyle is an open-source project that is developed and maintained by volunteers. If you\nfind Checkstyle useful, please consider sponsoring the project. Your support helps us to\nmaintain and improve Checkstyle.\n\n- [Liberapay](https://liberapay.com/checkstyle/)\n- [OpenCollective](https://opencollective.com/checkstyle/)\n\n[![][backers.opencollective img]][backers.opencollective]\n\n[![][sponsors.opencollective img]][sponsors.opencollective]\n\n## Licensing\n\nCheckstyle is licensed under the [GNU LGPL v2.1 License](LICENSE).\nCheckstyle uses libraries:\n\n- [ANTLR](https://www.antlr.org/)\n- [Apache Commons](https://commons.apache.org/)\n- [Google Guava](https://github.com/google/guava/)\n- [Picocli](https://github.com/remkop/picocli/)\n\n## Development Tools Powered by\n\n[![JetBrains logo.][jetbrains img]][jetbrains]\n\n[![JProfiler logo.][jprofiler img]][jprofiler]\n\n[jetbrains]:https://jb.gg/OpenSource\n[jetbrains img]:https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg\n\n[jprofiler]:https://www.ej-technologies.com/jprofiler\n[jprofiler img]:https://www.ej-technologies.com/images/product_banners/jprofiler_medium.png\n\n[appveyor]:https://ci.appveyor.com/project/checkstyle/checkstyle/history\n[appveyor img]:https://ci.appveyor.com/api/projects/status/rw6bw3dl9kph6ucc?svg=true\n\n[coverage]:https://codecov.io/github/checkstyle/checkstyle?branch=master\n[coverage img]:https://codecov.io/github/checkstyle/checkstyle/coverage.svg?branch=master\n\n[mavenbadge]:https://search.maven.org/search?q=g:%22com.puppycrawl.tools%22%20AND%20a:%22checkstyle%22\n[mavenbadge img]:https://img.shields.io/maven-central/v/com.puppycrawl.tools/checkstyle.svg?label=Maven%20Central\n\n[stackoverflow]:https://stackoverflow.com/questions/tagged/checkstyle\n[stackoverflow img]:https://img.shields.io/badge/stackoverflow-CHECKSTYLE-blue.svg\n\n[teamcity]:https://teamcity.jetbrains.com/viewType.html?buildTypeId=Checkstyle_IdeaInspectionsMaster\n[teamcity img]:https://teamcity.jetbrains.com/app/rest/builds/buildType:(id:Checkstyle_IdeaInspectionsMaster)/statusIcon\n\n[circleci]: https://circleci.com/gh/checkstyle/checkstyle/tree/master\n[circleci img]: https://circleci.com/gh/checkstyle/checkstyle/tree/master.svg?style=svg\n\n[cirrusci]: https://cirrus-ci.com/github/checkstyle/checkstyle\n[cirrusci img]: https://api.cirrus-ci.com/github/checkstyle/checkstyle.svg?branch=master\n\n[snyk]: https://snyk.io/test/github/checkstyle/checkstyle?targetFile=pom.xml\n[snyk img]: https://snyk.io/test/github/checkstyle/checkstyle/badge.svg\n\n[semaphoreci]: https://checkstyle.semaphoreci.com/projects/checkstyle\n[semaphoreci img]: https://checkstyle.semaphoreci.com/badges/checkstyle/branches/master.svg?style=shields\n\n[azure]:https://dev.azure.com/romanivanovjr/romanivanovjr/_build/latest?definitionId=1&branchName=master\n[azure img]:https://dev.azure.com/romanivanovjr/romanivanovjr/_apis/build/status/checkstyle.checkstyle?branchName=master\n\n[backers.opencollective]:https://opencollective.com/checkstyle/\n[backers.opencollective img]:https://opencollective.com/checkstyle/backers/badge.svg\n\n[sponsors.opencollective]:https://opencollective.com/checkstyle/\n[sponsors.opencollective img]:https://opencollective.com/checkstyle/sponsors/badge.svg\n\n[dependabot]:https://github.com/dependabot\n[dependabot img]:https://img.shields.io/badge/dependabot-025E8C?style=for-the-badge&logo=dependabot\n\n[closed issues]:https://github.com/checkstyle/checkstyle/actions/workflows/no-old-refs.yml\n[closed issues img]:https://github.com/checkstyle/checkstyle/actions/workflows/no-old-refs.yml/badge.svg\n\n[release notes/version]:https://github.com/checkstyle/checkstyle/actions/workflows/releasenotes-gen.yml\n[release notes/version img]:https://github.com/checkstyle/checkstyle/actions/workflows/releasenotes-gen.yml/badge.svg\n\n[link check]:https://github.com/checkstyle/checkstyle/actions/workflows/run-link-check.yml\n[link check img]:https://github.com/checkstyle/checkstyle/actions/workflows/run-link-check.yml/badge.svg\n\n[error prone]:https://github.com/checkstyle/checkstyle/actions/workflows/error-prone.yml\n[error prone img]:https://github.com/checkstyle/checkstyle/actions/workflows/error-prone.yml/badge.svg\n\n[pitest]:https://github.com/checkstyle/checkstyle/actions/workflows/pitest.yml\n[pitest img]:https://github.com/checkstyle/checkstyle/actions/workflows/pitest.yml/badge.svg\n\n[checker framework]:https://github.com/checkstyle/checkstyle/actions/workflows/checker-framework.yml\n[checker framework img]:https://github.com/checkstyle/checkstyle/actions/workflows/checker-framework.yml/badge.svg\n\n[milestone]:https://github.com/checkstyle/checkstyle/actions/workflows/set-milestone-on-referenced-issue.yml\n[milestone img]:https://github.com/checkstyle/checkstyle/actions/workflows/set-milestone-on-referenced-issue.yml/badge.svg\n",
      "stars_today": 0
    },
    {
      "id": 16734696,
      "name": "janus-gateway",
      "full_name": "meetecho/janus-gateway",
      "description": "Janus WebRTC Server",
      "html_url": "https://github.com/meetecho/janus-gateway",
      "stars": 9010,
      "forks": 2606,
      "language": "C",
      "topics": [],
      "created_at": "2014-02-11T15:14:39Z",
      "updated_at": "2026-01-25T02:02:35Z",
      "pushed_at": "2026-01-23T17:41:27Z",
      "open_issues": 35,
      "owner": {
        "login": "meetecho",
        "avatar_url": "https://avatars.githubusercontent.com/u/4520545?v=4"
      },
      "readme": "Janus WebRTC Server\n===================\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-brightgreen.svg)](COPYING)\n![janus-ci](https://github.com/meetecho/janus-gateway/workflows/janus-ci/badge.svg)\n[![Coverity Scan Build Status](https://scan.coverity.com/projects/13265/badge.svg)](https://scan.coverity.com/projects/meetecho-janus-gateway)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/janus-gateway.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:janus-gateway)\n\nJanus is an open source, general purpose, WebRTC server designed and developed by [Meetecho](https://www.meetecho.com). This version of the server is tailored for Linux systems, although it can be compiled for, and installed on, MacOS machines as well. Windows is not supported, but if that's a requirement, Janus is known to work in the \"Windows Subsystem for Linux\" on Windows 10: do **NOT** trust repos that provide .exe builds of Janus, they are not official and will not be supported.\n\nFor some online demos and documentations, make sure you pay the [project website](https://janus.conf.meetecho.com/) a visit!\n\n> **Note well:** this is the main branch for the `multistream` version of Janus, which is the new version. If you want to check the legacy version of Janus instead (i.e., `0.x`, a.k.a. \"legacy\") click [here](https://github.com/meetecho/janus-gateway/tree/0.x) instead.\n\nIf you have questions on Janus, or wish to discuss Janus with us and other users, please join our [Community](https://janus.discourse.group/). If you encounter bugs, please submit an issue on [GitHub](https://github.com/meetecho/janus-gateway/issues): make sure you read the [guidelines](.github/CONTRIBUTING.md) before opening an issue or a pull request, though.\n\n\n## Dependencies\nTo install it, you'll need to satisfy the following dependencies:\n\n* [GLib](https://docs.gtk.org/glib/)\n* [zlib](https://zlib.net/)\n* [pkg-config](https://www.freedesktop.org/wiki/Software/pkg-config/)\n* [Jansson](https://github.com/akheron/jansson)\n* [libconfig](https://hyperrealm.github.io/libconfig/)\n* [libnice](https://libnice.freedesktop.org/) (at least v0.1.16 suggested, v0.1.18 recommended)\n* [OpenSSL](https://www.openssl.org/) (at least v1.0.1e)\n* [libsrtp](https://github.com/cisco/libsrtp) (at least v2.x suggested)\n\nThese are optional dependencies, depending on which features you're interested in:\n\n* [usrsctp](https://github.com/sctplab/usrsctp) (only needed if you are interested in Data Channels)\n* [libmicrohttpd](https://www.gnu.org/software/libmicrohttpd/) (at least v0.9.59; only needed if you are interested in REST support for the Janus API)\n* [libwebsockets](https://libwebsockets.org/) (at least v4.x suggested; only needed if you are interested in WebSockets support for the Janus API)\n* [cmake](https://www.cmake.org/) (only needed if you are interested in WebSockets and/or BoringSSL support, as they make use of it)\n* [rabbitmq-c](https://github.com/alanxz/rabbitmq-c) (only needed if you are interested in RabbitMQ support for the Janus API or events)\n* [paho.mqtt.c](https://eclipse.org/paho/clients/c) (only needed if you are interested in MQTT support for the Janus API or events)\n* [nanomsg](https://nanomsg.org/) (only needed if you are interested in Nanomsg support for the Janus API)\n* [libcurl](https://curl.haxx.se/libcurl/) (only needed if you are interested in the TURN REST API support)\n\nA couple of plugins depend on a few more libraries (you only need to install the ones for the plugins you need):\n\n* [Sofia-SIP](https://github.com/freeswitch/sofia-sip) (only needed for the SIP plugin)\n* [libopus](https://opus-codec.org/) (only needed for the AudioBridge plugin)\n* [libogg](https://xiph.org/ogg/) (needed for the recordings post-processor, and optionally AudioBridge and Streaming plugins)\n* [libcurl](https://curl.haxx.se/libcurl/) (only needed if you are interested in RTSP support in the Streaming plugin or in the sample Event Handler plugin)\n* [Lua](https://www.lua.org/download.html) (only needed for the Lua plugin)\n* [Duktape](https://duktape.org/) (only needed for the Duktape plugin)\n\n\nAll of those libraries are usually available on most of the most common distributions. Installing these libraries on a recent Fedora, for instance, is very simple:\n\n    yum install libmicrohttpd-devel jansson-devel \\\n       openssl-devel libsrtp-devel sofia-sip-devel glib2-devel \\\n       opus-devel libogg-devel libcurl-devel pkgconfig \\\n       libconfig-devel libtool autoconf automake\n\nNotice that you may have to `yum install epel-release` as well if you're attempting an installation on a CentOS machine instead.\n\nOn Ubuntu or Debian, it would require something like this:\n\n\tapt install libmicrohttpd-dev libjansson-dev \\\n\t\tlibssl-dev libsofia-sip-ua-dev libglib2.0-dev \\\n\t\tlibopus-dev libogg-dev libcurl4-openssl-dev liblua5.3-dev \\\n\t\tlibconfig-dev pkg-config libtool automake\n\n* *Note:* please notice that libopus may not be available out of the box on your distro. In that case, you'll have to [install it manually](https://www.opus-codec.org).\n\nWhile `libnice` is typically available in most distros as a package, the version available out of the box in Ubuntu is known to cause problems. As such, we always recommend manually compiling and installing the master version of libnice.\nTo build libnice, you need Python 3, Meson and Ninja:\n\n\tgit clone https://gitlab.freedesktop.org/libnice/libnice\n\tcd libnice\n\tmeson --prefix=/usr build && ninja -C build && sudo ninja -C build install\n\n* *Note:* Make sure you remove the distro version first, or you'll cause conflicts between the installations. In case you want to keep both for some reason, for custom installations of libnice you can also run `pkg-config --cflags --libs nice` to make sure Janus can find the right installation. If that fails, you may need to set the `PKG_CONFIG_PATH` environment variable prior to compiling Janus, e.g., `export PKG_CONFIG_PATH=/path/to/libnice/lib/pkgconfig`\n\nIn case you're interested in compiling the sample Event Handler plugin, you'll need to install the development version of libcurl as well (usually `libcurl-devel` on Fedora/CentOS, `libcurl4-openssl-dev` on Ubuntu/Debian).\n\nIf your distro ships a pre-1.5 version of libsrtp, you'll have to uninstall that version and [install 1.5.x, 1.6.x or 2.x manually](https://github.com/cisco/libsrtp/releases). In fact, 1.4.x is known to cause several issues with WebRTC. While 1.5.x is supported, we recommend installing 2.x instead. Notice that the following steps are for version 2.2.0, but there may be more recent versions available:\n\n\twget https://github.com/cisco/libsrtp/archive/v2.2.0.tar.gz\n\ttar xfv v2.2.0.tar.gz\n\tcd libsrtp-2.2.0\n\t./configure --prefix=/usr --enable-openssl\n\tmake shared_library && sudo make install\n\nNotice that the `--enable-openssl` part is _important_, as it's needed for AES-GCM support. As an alternative, you can also pass `--enable-nss` to have libsrtp use NSS instead of OpenSSL. A failure to configure libsrtp with either might cause undefined references when starting Janus, as we'd be trying to use methods that aren't there.\n\nThe Janus configure script autodetects which one you have installed and links to the correct library automatically, choosing 2.x if both are installed. If you want 1.5 or 1.6 to be picked (which is NOT recommended), pass `--disable-libsrtp2` when configuring Janus to force it to use the older version instead.\n\n* *Note:* when installing libsrtp, no matter which version, you may need to pass `--libdir=/usr/lib64` to the configure script if you're installing on a x86_64 distribution.\n\nIf you want to make use of BoringSSL instead of OpenSSL (e.g., because you want to take advantage of `--enable-dtls-settimeout`), you'll have to manually install it to a specific location. Use the following steps:\n\n\tgit clone https://boringssl.googlesource.com/boringssl\n\tcd boringssl\n\t# Don't barf on errors\n\tsed -i s/\" -Werror\"//g CMakeLists.txt\n\t# Build\n\tmkdir -p build\n\tcd build\n\tcmake -DCMAKE_INSTALL_PREFIX=/opt/boringssl -DCMAKE_CXX_FLAGS=\"-lrt\" ..\n\tmake\n\tsudo make install\n\nOnce the library is installed, you'll have to pass an additional `--enable-boringssl` flag to the configure script, as by default Janus will be built assuming OpenSSL will be used. By default, Janus expects BoringSSL to be installed in `/opt/boringssl` -- if it's installed in another location, pass the path to the configure script as such: `--enable-boringssl=/path/to/boringssl` If you were using OpenSSL and want to switch to BoringSSL, make sure you also do a `make clean` in the Janus folder before compiling with the new BoringSSL support. If you enabled BoringSSL support and also want Janus to detect and react to DTLS timeouts with faster retransmissions, then pass `--enable-dtls-settimeout` to the configure script too.\n\n* *Note:* as explained in [this issue](https://github.com/meetecho/janus-gateway/issues/3456), building Janus with more recent versions of BoringSSL may require you to pass a `CCLD=c++` for any `make` command to build Janus itself.\n\nFor what concerns usrsctp, which is needed for Data Channels support, it is usually not available in repositories, so if you're interested in them (support is optional) you'll have to install it manually. It is a pretty easy and standard process:\n\n\tgit clone https://github.com/sctplab/usrsctp\n\tcd usrsctp\n\t./bootstrap\n\t./configure --prefix=/usr --disable-programs --disable-inet --disable-inet6\n\tmake && sudo make install\n\n* *Note:* you may need to pass `--libdir=/usr/lib64` to the configure script if you're installing on a x86_64 distribution.\n\nThe same applies for libwebsockets, which is needed for the optional WebSockets support. If you're interested in supporting WebSockets to control Janus, as an alternative (or replacement) to the default plain HTTP REST API, you'll have to install it manually:\n\n\tgit clone https://libwebsockets.org/repo/libwebsockets\n\tcd libwebsockets\n\t# If you want the stable version of libwebsockets, uncomment the next line\n\t# git checkout v4.3-stable\n\tmkdir build\n\tcd build\n\t# See https://github.com/meetecho/janus-gateway/issues/732 re: LWS_MAX_SMP\n\t# See https://github.com/meetecho/janus-gateway/issues/2476 re: LWS_WITHOUT_EXTENSIONS\n\tcmake -DLWS_MAX_SMP=1 -DLWS_WITHOUT_EXTENSIONS=0 -DCMAKE_INSTALL_PREFIX:PATH=/usr -DCMAKE_C_FLAGS=\"-fpic\" ..\n\tmake && sudo make install\n\n* *Note:* if libwebsockets.org is unreachable for any reason, replace the first line with this:\n\n\tgit clone https://github.com/warmcat/libwebsockets.git\n\nThe same applies for Eclipse Paho MQTT C client library, which is needed for the optional MQTT support. If you're interested in integrating MQTT channels as an alternative (or replacement) to HTTP and/or WebSockets to control Janus, or as a carrier of Janus Events, you can install the latest version with the following steps:\n\n\tgit clone https://github.com/eclipse/paho.mqtt.c.git\n\tcd paho.mqtt.c\n\tmake && sudo make install\n\n* *Note:* you may want to set up a different install path for the library, to achieve that, replace the last command by 'sudo prefix=/usr make install'.\n\nIn case you're interested in Nanomsg support, you'll need to install the related C library. It is usually available as an easily installable package in pretty much all repositories. The following is an example on how to install it on Ubuntu:\n\n\taptitude install libnanomsg-dev\n\nFinally, the same can be said for rabbitmq-c as well, which is needed for the optional RabbitMQ support. In fact, several different versions of the library can be found, and the versions usually available in most distribution repositories are not up-do-date with respect to the current state of the development. As such, if you're interested in integrating RabbitMQ queues as an alternative (or replacement) to HTTP and/or WebSockets to control Janus, you can install the latest version with the following steps:\n\n\tgit clone https://github.com/alanxz/rabbitmq-c\n\tcd rabbitmq-c\n\tgit submodule init\n\tgit submodule update\n\tmkdir build && cd build\n\tcmake -DCMAKE_INSTALL_PREFIX=/usr ..\n\tmake && sudo make install\n\n* *Note:* you may need to pass `--libdir=/usr/lib64` to the configure script if you're installing on a x86_64 distribution.\n\nTo conclude, should you be interested in building the Janus documentation as well, you'll need some additional tools too:\n\n* [Doxygen](https://www.doxygen.org)\n* [Graphviz](https://www.graphviz.org/)\n\nOn Fedora:\n\n\tyum install doxygen graphviz\n\nOn Ubuntu/Debian:\n\n\taptitude install doxygen graphviz\n\n\n## Compile\nOnce you have installed all the dependencies, get the code:\n\n\tgit clone https://github.com/meetecho/janus-gateway.git\n\tcd janus-gateway\n\nThen just use:\n\n\tsh autogen.sh\n\nto generate the configure file. After that, configure and compile as usual to start the whole compilation process:\n\n\t./configure --prefix=/opt/janus\n\tmake\n\tmake install\n\nSince Janus requires configuration files for both the core and its modules in order to work, you'll probably also want to install the default configuration files to use, which you can do this way:\n\n\tmake configs\n\nRemember to only do this once, or otherwise a subsequent `make configs` will overwrite any configuration file you may have modified in the meanwhile.\n\nIf you've installed the above libraries but are not interested, for instance, in Data Channels, WebSockets, MQTT and/or RabbitMQ, you can disable them when configuring:\n\n\t./configure --disable-websockets --disable-data-channels --disable-rabbitmq --disable-mqtt\n\nThere are configuration flags for pretty much all external modules and many of the features, so you may want to issue a `./configure --help` to dig through the available options. A summary of what's going to be built will always appear after you do a configure, allowing you to double check if what you need and don't need is there.\n\nIf Doxygen and graphviz are available, the process can also build the documentation for you. By default the compilation process will not try to build the documentation, so if you instead prefer to build it, use the `--enable-docs` configuration option:\n\n\t./configure --enable-docs\n\nYou can also selectively enable/disable other features (e.g., specific plugins you don't care about, or whether or not you want to build the recordings post-processor). Use the --help option when configuring for more info.\n\n### Building on FreeBSD\n* *Note*: rtp_forward of streams only works streaming to IPv6,\nbecause of #2051 and thus the feature is not supported on FreeBSD at the moment.\n\nWhen building on FreeBSD you can install the depencencies from ports or packages, here only pkg method is used. You also need to use `gmake` instead of `make`,\nsince it is a GNU makefile. `./configure` can be run without arguments since the default prefix is `/usr/local` which is your default `LOCALBASE`.\nNote that the `configure.ac` is coded to use openssl in base. If you wish to use openssl from ports or any other ssl you must change `configure.ac` accordingly.\n\n\tpkg install libsrtp2 libusrsctp jansson libnice libmicrohttpd libwebsockets curl opus sofia-sip libogg jansson libnice libconfig \\\n        libtool gmake autoconf autoconf-wrapper glib\n\n\n### Building on MacOS\nWhile most of the above instructions will work when compiling Janus on MacOS as well, there are a few aspects to highlight when doing that.\n\nFirst of all, you can use `brew` to install most of the dependencies:\n\n\tbrew install jansson libnice openssl srtp libusrsctp libmicrohttpd \\\n\t\tlibwebsockets cmake rabbitmq-c sofia-sip opus libogg curl glib \\\n\t\tlibconfig pkg-config autoconf automake libtool\n\nFor what concerns libwebsockets, though, make sure that the installed version is higher than `2.4.1`, or you might encounter the problems described in [this post](https://groups.google.com/forum/#!topic/meetecho-janus/HsFaEXBz4Cg). If `brew` doesn't provide a more recent version, you'll have to install the library manually.\n\nNotice that you may need to provide a custom `prefix` and `PKG_CONFIG_PATH` when configuring Janus as well, e.g.:\n\n\t./configure --prefix=/usr/local/janus PKG_CONFIG_PATH=/usr/local/opt/openssl/lib/pkgconfig\n\nEverything else works exactly the same way as on Linux.\n\n## Configure and start\nTo start the server, you can use the `janus` executable. There are several things you can configure, either in a configuration file:\n\n\t<installdir>/etc/janus/janus.jcfg\n\nor on the command line:\n\n\t<installdir>/bin/janus --help\n\n\tUsage: janus [OPTIONS]...\n\n\t-h, --help                    Print help and exit\n\t-V, --version                 Print version and exit\n\t-b, --daemon                  Launch Janus in background as a daemon\n                                  (default=off)\n\t-p, --pid-file=path           Open the specified PID file when starting Janus\n                                  (default=none)\n\t-N, --disable-stdout          Disable stdout based logging  (default=off)\n\t-L, --log-file=path           Log to the specified file (default=stdout only)\n\t-H  --cwd-path                Working directory for Janus daemon process\n\t                              (default=/)\n\t-i, --interface=ipaddress     Interface to use (will be the public IP)\n\t-P, --plugins-folder=path     Plugins folder (default=./plugins)\n\t-C, --config=filename         Configuration file to use\n\t-F, --configs-folder=path     Configuration files folder (default=./conf)\n\t-c, --cert-pem=filename       DTLS certificate\n\t-k, --cert-key=filename       DTLS certificate key\n\t-K, --cert-pwd=text           DTLS certificate key passphrase (if needed)\n\t-S, --stun-server=address:port\n                                  STUN server(:port) to use, if needed (e.g.,\n                                  Janus behind NAT, default=none)\n\t-1, --nat-1-1=ip              Public IP to put in all host candidates,\n                                  assuming a 1:1 NAT is in place (e.g., Amazon\n                                  EC2 instances, default=none)\n\t-2, --keep-private-host       When nat-1-1 is used (e.g., Amazon EC2\n                                  instances), don't remove the private host,\n                                  but keep both to simulate STUN  (default=off)\n\t-E, --ice-enforce-list=list   Comma-separated list of the only interfaces to\n                                  use for ICE gathering; partial strings are\n                                  supported (e.g., eth0 or eno1,wlan0,\n                                  default=none)\n\t-X, --ice-ignore-list=list    Comma-separated list of interfaces or IP\n                                  addresses to ignore for ICE gathering;\n                                  partial strings are supported (e.g.,\n                                  vmnet8,192.168.0.1,10.0.0.1 or\n                                  vmnet,192.168., default=vmnet)\n\t-6, --ipv6-candidates         Whether to enable IPv6 candidates or not\n                                  (experimental)  (default=off)\n\t-O, --ipv6-link-local         Whether IPv6 link-local candidates should be\n                                  gathered as well  (default=off)\n\t-f, --full-trickle            Do full-trickle instead of half-trickle\n                                  (default=off)\n\t-I, --ice-lite                Whether to enable the ICE Lite mode or not\n                                  (default=off)\n\t-T, --ice-tcp                 Whether to enable ICE-TCP or not (warning: only\n                                  works with ICE Lite)\n                                  (default=off)\n\t-Q, --min-nack-queue=number   Minimum size of the NACK queue (in ms) per user\n                                  for retransmissions, no matter the RTT\n\t-t, --no-media-timer=number   Time (in s) that should pass with no media\n                                  (audio or video) being received before Janus\n                                  notifies you about this\n\t-W, --slowlink-threshold=number\n                                  Number of lost packets (per s) that should\n                                  trigger a 'slowlink' Janus API event to users\n                                  (default=0, feature disabled)\n\t-r, --rtp-port-range=min-max  Port range to use for RTP/RTCP (only available\n\t\t\t\t\t\t\t\t  if the installed libnice supports it)\n\t-B, --twcc-period=number      How often (in ms) to send TWCC feedback back to\n                                  senders, if negotiated (default=200ms)\n\t-n, --server-name=name        Public name of this Janus instance\n                                  (default=MyJanusInstance)\n\t-s, --session-timeout=number  Session timeout value, in seconds (default=60)\n\t-m, --reclaim-session-timeout=number\n                                  Reclaim session timeout value, in seconds\n                                  (default=0)\n\t-d, --debug-level=1-7         Debug/logging level (0=disable debugging,\n                                  7=maximum debug level; default=4)\n\t-D, --debug-timestamps        Enable debug/logging timestamps  (default=off)\n\t-o, --disable-colors          Disable color in the logging  (default=off)\n\t-M, --debug-locks             Enable debugging of locks/mutexes (very\n                                  verbose!)  (default=off)\n\t-a, --apisecret=randomstring  API secret all requests need to pass in order\n                                  to be accepted by Janus (useful when wrapping\n                                  Janus API requests in a server, none by\n                                  default)\n\t-A, --token-auth              Enable token-based authentication for all\n                                  requests  (default=off)\n\t-e, --event-handlers          Enable event handlers  (default=off)\n\t-w, --no-webrtc-encryption    Disable WebRTC encryption, so no DTLS or SRTP\n                                  (only for debugging!)  (default=off)\n\n\nOptions passed through the command line have the precedence on those specified in the configuration file. To start the server, simply run:\n\n\t<installdir>/bin/janus\n\nThis will start the server, and have it look at the configuration file.\n\nMake sure you have a look at all of the configuration files, to tailor Janus to your specific needs: each configuration file is documented, so it shouldn't be hard to make changes according to your requirements. The repo comes with some defaults (assuming you issues `make configs` after installing the server) that tend to make sense for generic deployments, and also includes some sample configurations for all the plugins (e.g., web servers to listen on, conference rooms to create, streaming mountpoints to make available at startup, etc.).\n\nTo test whether it's working correctly, you can use the demos provided with this package in the `html` folder: these are exactly the same demos available online on the [project website](https://janus.conf.meetecho.com/). Just copy the file it contains in a webserver, or use a userspace webserver to serve the files in the `html` folder (e.g., with php or python), and open the `index.html` page in either Chrome or Firefox. A list of demo pages exploiting the different plugins will be available. Remember to edit the transport/port details in the demo JavaScript files if you changed any transport-related configuration from its defaults. Besides, the demos refer to the pre-configured plugin resources, so if you add some new resources (e.g., a new videoconference) you may have to tweak the demo pages to actually use them.\n\n## Documentation\nJanus is thoroughly documented. You can find the current documentation, automatically generated with Doxygen, on the [project website](https://janus.conf.meetecho.com/docs/).\n\n## Help us!\nAny thought, feedback or (hopefully not!) insult is welcome!\n\nDeveloped by [@meetecho](https://github.com/meetecho)\n",
      "stars_today": 0
    },
    {
      "id": 24797553,
      "name": "SQLite.swift",
      "full_name": "stephencelis/SQLite.swift",
      "description": "A type-safe, Swift-language layer over SQLite3.",
      "html_url": "https://github.com/stephencelis/SQLite.swift",
      "stars": 10086,
      "forks": 1625,
      "language": "Swift",
      "topics": [
        "sqlite",
        "swift"
      ],
      "created_at": "2014-10-04T18:23:46Z",
      "updated_at": "2026-01-23T12:55:44Z",
      "pushed_at": "2026-01-22T13:52:32Z",
      "open_issues": 142,
      "owner": {
        "login": "stephencelis",
        "avatar_url": "https://avatars.githubusercontent.com/u/658?v=4"
      },
      "readme": "# SQLite.swift\n\n![Build Status][GitHubActionBadge] [![CocoaPods Version][CocoaPodsVersionBadge]][CocoaPodsVersionLink] [![Swift5 compatible][Swift5Badge]][Swift5Link] [![Platform][PlatformBadge]][PlatformLink] [![Carthage compatible][CartagheBadge]][CarthageLink] [![Join the chat at https://gitter.im/stephencelis/SQLite.swift][GitterBadge]][GitterLink]\n\nA type-safe, [Swift][]-language layer over [SQLite3][].\n\n[SQLite.swift][] provides compile-time confidence in SQL statement\nsyntax _and_ intent.\n\n## Features\n\n - A pure-Swift interface\n - A type-safe, optional-aware SQL expression builder\n - A flexible, chainable, lazy-executing query layer\n - Automatically-typed data access\n - A lightweight, uncomplicated query and parameter binding interface\n - Developer-friendly error handling and debugging\n - [Full-text search][] support\n - [Well-documented][See Documentation]\n - Extensively tested\n - [SQLCipher][] support via Swift Package Manager\n - [Schema query/migration][]\n - Works on [Linux](Documentation/Linux.md) (with some limitations)\n - Active support at\n   [StackOverflow](https://stackoverflow.com/questions/tagged/sqlite.swift),\n   and [Gitter Chat Room](https://gitter.im/stephencelis/SQLite.swift)\n   (_experimental_)\n\n[SQLCipher]: https://www.zetetic.net/sqlcipher/\n[Full-text search]: Documentation/Index.md#full-text-search\n[Schema query/migration]: Documentation/Index.md#querying-the-schema\n[See Documentation]: Documentation/Index.md#sqliteswift-documentation\n\n\n## Usage\n\n```swift\nimport SQLite\n\n// Wrap everything in a do...catch to handle errors\ndo {\n    let db = try Connection(\"path/to/db.sqlite3\")\n\n    let users = Table(\"users\")\n    let id = SQLite.Expression<Int64>(\"id\")\n    let name = SQLite.Expression<String?>(\"name\")\n    let email = SQLite.Expression<String>(\"email\")\n\n    try db.run(users.create { t in\n        t.column(id, primaryKey: true)\n        t.column(name)\n        t.column(email, unique: true)\n    })\n    // CREATE TABLE \"users\" (\n    //     \"id\" INTEGER PRIMARY KEY NOT NULL,\n    //     \"name\" TEXT,\n    //     \"email\" TEXT NOT NULL UNIQUE\n    // )\n\n    let insert = users.insert(name <- \"Alice\", email <- \"alice@mac.com\")\n    let rowid = try db.run(insert)\n    // INSERT INTO \"users\" (\"name\", \"email\") VALUES ('Alice', 'alice@mac.com')\n\n    for user in try db.prepare(users) {\n        print(\"id: \\(user[id]), name: \\(user[name]), email: \\(user[email])\")\n        // id: 1, name: Optional(\"Alice\"), email: alice@mac.com\n    }\n    // SELECT * FROM \"users\"\n\n    let alice = users.filter(id == rowid)\n\n    try db.run(alice.update(email <- email.replace(\"mac.com\", with: \"me.com\")))\n    // UPDATE \"users\" SET \"email\" = replace(\"email\", 'mac.com', 'me.com')\n    // WHERE (\"id\" = 1)\n\n    try db.run(alice.delete())\n    // DELETE FROM \"users\" WHERE (\"id\" = 1)\n\n    try db.scalar(users.count) // 0\n    // SELECT count(*) FROM \"users\"\n} catch {\n    print (error)\n}\n```\n\nNote that `Expression` should be written as `SQLite.Expression` to avoid\nconflicts with the `SwiftUI.Expression` if you are using SwiftUI too.\n\nSQLite.swift also works as a lightweight, Swift-friendly wrapper over the C\nAPI.\n\n```swift\n// Wrap everything in a do...catch to handle errors\ndo {\n    // ...\n\n    let stmt = try db.prepare(\"INSERT INTO users (email) VALUES (?)\")\n    for email in [\"betty@icloud.com\", \"cathy@icloud.com\"] {\n        try stmt.run(email)\n    }\n\n    db.totalChanges    // 3\n    db.changes         // 1\n    db.lastInsertRowid // 3\n\n    for row in try db.prepare(\"SELECT id, email FROM users\") {\n        print(\"id: \\(row[0]), email: \\(row[1])\")\n        // id: Optional(2), email: Optional(\"betty@icloud.com\")\n        // id: Optional(3), email: Optional(\"cathy@icloud.com\")\n    }\n\n    try db.scalar(\"SELECT count(*) FROM users\") // 2\n} catch {\n    print (error)\n}\n```\n\n[Read the documentation][See Documentation] or explore more,\ninteractively, from the Xcode projectâ€™s playground.\n\n![SQLite.playground Screen Shot](Documentation/Resources/playground@2x.png)\n\n## Installation\n\n### Swift Package Manager\n\nThe [Swift Package Manager][] is a tool for managing the distribution of\nSwift code.\n\n1. Add the following to your `Package.swift` file:\n\n  ```swift\n  dependencies: [\n      .package(url: \"https://github.com/stephencelis/SQLite.swift.git\", from: \"0.15.5\")\n  ]\n  ```\n\n2. Build your project:\n\n  ```sh\n  $ swift build\n  ```\n\nSee the [Tests/SPM](https://github.com/stephencelis/SQLite.swift/tree/master/Tests/SPM) folder for a small demo project which uses SPM.\n\n[Swift Package Manager]: https://swift.org/package-manager\n\n### Carthage\n\n[Carthage][] is a simple, decentralized dependency manager for Cocoa. To\ninstall SQLite.swift with Carthage:\n\n 1. Make sure Carthage is [installed][Carthage Installation].\n\n 2. Update your Cartfile to include the following:\n\n    ```ruby\n    github \"stephencelis/SQLite.swift\" ~> 0.15.5\n    ```\n\n 3. Run `carthage update` and\n    [add the appropriate framework][Carthage Usage].\n\n\n[Carthage]: https://github.com/Carthage/Carthage\n[Carthage Installation]: https://github.com/Carthage/Carthage#installing-carthage\n[Carthage Usage]: https://github.com/Carthage/Carthage#adding-frameworks-to-an-application\n\n\n### CocoaPods\n\n[CocoaPods][] is a dependency manager for Cocoa projects. To install\nSQLite.swift with CocoaPods:\n\n 1. Make sure CocoaPods is [installed][CocoaPods Installation].\n\n    ```sh\n    # Using the default Ruby install will require you to use sudo when\n    # installing and updating gems.\n    [sudo] gem install cocoapods\n    ```\n\n 2. Update your Podfile to include the following:\n\n    ```ruby\n    use_frameworks!\n\n    target 'YourAppTargetName' do\n        pod 'SQLite.swift', '~> 0.15.0'\n    end\n    ```\n\n 3. Run `pod install --repo-update`.\n\n[CocoaPods]: https://cocoapods.org\n[CocoaPods Installation]: https://guides.cocoapods.org/using/getting-started.html#getting-started\n\n### Manual\n\nTo install SQLite.swift as an Xcode sub-project:\n\n 1. Drag the **SQLite.xcodeproj** file into your own project.\n    ([Submodule][], clone, or [download][] the project first.)\n\n    ![Installation Screen Shot](Documentation/Resources/installation@2x.png)\n\n 2. In your targetâ€™s **General** tab, click the **+** button under **Linked\n    Frameworks and Libraries**.\n\n 3. Select the appropriate **SQLite.framework** for your platform.\n\n 4. **Add**.\n\nSome additional steps are required to install the application on an actual\ndevice:\n\n 5. In the **General** tab, click the **+** button under **Embedded\n    Binaries**.\n\n 6. Select the appropriate **SQLite.framework** for your platform.\n\n 7. **Add**.\n\n\n[Xcode]: https://developer.apple.com/xcode/downloads/\n[Submodule]: https://git-scm.com/book/en/Git-Tools-Submodules\n[download]: https://github.com/stephencelis/SQLite.swift/archive/master.zip\n\n\n## Communication\n\n[Read the contributing guidelines][]. The _TL;DR_ (but please; _R_):\n\n - Need **help** or have a **general question**? [Ask on Stack\n   Overflow][] (tag `sqlite.swift`).\n - Found a **bug** or have a **feature request**? [Open an issue][].\n - Want to **contribute**? [Submit a pull request][].\n\n[Read the contributing guidelines]: ./CONTRIBUTING.md#contributing\n[Ask on Stack Overflow]: https://stackoverflow.com/questions/tagged/sqlite.swift\n[Open an issue]: https://github.com/stephencelis/SQLite.swift/issues/new\n[Submit a pull request]: https://github.com/stephencelis/SQLite.swift/fork\n\n\n## Original author\n\n - [Stephen Celis](mailto:stephen@stephencelis.com)\n   ([@stephencelis](https://twitter.com/stephencelis))\n\n\n## License\n\nSQLite.swift is available under the MIT license. See [the LICENSE\nfile](./LICENSE.txt) for more information.\n\n## Related\n\nThese projects enhance or use SQLite.swift:\n\n - [SQLiteMigrationManager.swift][] (inspired by\n   [FMDBMigrationManager][])\n\n## Alternatives\n\nLooking for something else? Try another Swift wrapper (or [FMDB][]):\n\n - [GRDB](https://github.com/groue/GRDB.swift)\n - [SQLiteDB](https://github.com/FahimF/SQLiteDB)\n\n[Swift]: https://swift.org/\n[SQLite3]: https://www.sqlite.org\n[SQLite.swift]: https://github.com/stephencelis/SQLite.swift\n\n[GitHubActionBadge]: https://img.shields.io/github/actions/workflow/status/stephencelis/SQLite.swift/build.yml?branch=master\n\n[CocoaPodsVersionBadge]: https://img.shields.io/cocoapods/v/SQLite.swift.svg?style=flat\n[CocoaPodsVersionLink]: https://cocoapods.org/pods/SQLite.swift\n\n[PlatformBadge]: https://img.shields.io/cocoapods/p/SQLite.swift.svg?style=flat\n[PlatformLink]: https://cocoapods.org/pods/SQLite.swift\n\n[CartagheBadge]: https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat\n[CarthageLink]: https://github.com/Carthage/Carthage\n\n[GitterBadge]: https://badges.gitter.im/stephencelis/SQLite.swift.svg\n[GitterLink]: https://gitter.im/stephencelis/SQLite.swift\n\n[Swift5Badge]: https://img.shields.io/badge/swift-5-orange.svg?style=flat\n[Swift5Link]: https://developer.apple.com/swift/\n\n[SQLiteMigrationManager.swift]: https://github.com/garriguv/SQLiteMigrationManager.swift\n[FMDB]: https://github.com/ccgus/fmdb\n[FMDBMigrationManager]: https://github.com/layerhq/FMDBMigrationManager\n",
      "stars_today": 0
    },
    {
      "id": 17101828,
      "name": "swirl_courses",
      "full_name": "swirldev/swirl_courses",
      "description": ":mortar_board: A collection of interactive courses for the swirl R package.",
      "html_url": "https://github.com/swirldev/swirl_courses",
      "stars": 4523,
      "forks": 7241,
      "language": "R",
      "topics": [],
      "created_at": "2014-02-23T04:48:04Z",
      "updated_at": "2026-01-23T10:12:20Z",
      "pushed_at": "2024-01-10T17:38:19Z",
      "open_issues": 206,
      "owner": {
        "login": "swirldev",
        "avatar_url": "https://avatars.githubusercontent.com/u/5671732?v=4"
      },
      "readme": "# swirl courses\n\nThis is a collection of interactive courses for use with the [swirl R package](http://swirlstats.com). You'll find instructions for installing courses further down on this page. Some courses are still in development and we'd love to hear any [suggestions](https://github.com/swirldev/swirl_courses/issues/new) you have as you work through them.\n\nFor more information regarding swirl, visit [swirlstats.com](http://swirlstats.com) or the [swirl GitHub repository](https://github.com/swirldev/swirl). If you'd like to write your own interactive content, please visit the [Instructors page](http://swirlstats.com/instructors.html) of our website.\n\nHere are our current offerings, organized by level of difficulty:\n\n#### Beginner\n\n- **R Programming**: The basics of programming in R\n- [**R Programming E**](https://github.com/swirldev/R_Programming_E): Same as the original, but modified slightly for in-class use (see below ***)\n- [**The R Programming Environment**](https://swirlstats.com/scn/rpe.html)\n<!-- - **Data Analysis**: Basic ideas in statistics and data visualization -->\n<!-- - **Mathematical Biostatistics Boot Camp**: One- and two-sample t-tests, power, and sample size -->\n<!-- - **Open Intro**: A very basic introduction to statistics, data analysis, and data visualization -->\n\n\\*\\*\\* *R Programming E is identical to R Programming, except we've eliminated the prompts for Coursera credentials at the end of each lesson and instead give students the option to send an email to their instructor notifying them of completion. Admittedly, it's sort of a hack until we come up with a more robust solution for in-class use (i.e. an instructor \"dashboard\").*\n\n#### Intermediate\n\n- **Regression Models**: The basics of regression modeling in R\n- **Getting and Cleaning Data**: dplyr, tidyr, lubridate, oh my!\n\n#### Advanced\n\n- **Statistical Inference**: This intermediate to advanced level course closely follows the\n[Statistical Inference course](https://www.coursera.org/course/statinference) of the Johns Hopkins \n[Data Science Specialization](https://www.coursera.org/specialization/jhudatascience/1) on Coursera. It\nintroduces the student to basic concepts of statistical inference\nincluding probability, hypothesis testing, confidence intervals and\np-values. It concludes with an initiation to topics of particular\nrelevance to big data, issues of multiple testing and resampling.\n- [**Advanced R Programming**](https://swirlstats.com/scn/arp.html)\n\nSince our users come from a variety backgrounds, it's very hard to label material as **Beginner**, **Intermediate**, or **Advanced**. If you find something that is labelled **Beginner** to be challenging, please don't be discouraged. The first step of learning anything is to acknowledge that you are capable of understanding it. True understanding will come with time and practice.\n\n#### Course Authors\n\n- **Writing swirl Courses**: An interactive guides and example \n  for swirl course authors. The first group of lessons cover basics. The rest cover \n  special topics useful primarily as samples--points of departure for one's own material.\n  For more comprehensive documentation about writing your own swirl courses see http://swirlstats.com/swirlify/.\n\n## Install and run a course automatically from swirl\n\n**This is the preferred method of installing courses.** It automates the process by allowing you to do everything right from the R console.\n\n1) Make sure you have a recent version version of swirl:\n\n```\ninstall.packages(\"swirl\")\n```\n\n2) Enter the following from the R console, **substituting the name of the course** that you wish to install:\n\n```\nlibrary(swirl)\ninstall_course(\"Course Name Here\")\nswirl()\n```\n\nFor example, `install_course(\"R Programming\")` will install the R Programming course. **Please note that course names are case sensitive!**\n\nIf that doesn't work for you...\n\n## Install and run a course manually\n\nIf the automatic course installation method outlined above does not work for you, then there's a simple alternative.\n\n1. Find the course you want to install on the [Swirl Course network website](https://swirlstats.com/scn/title.html).\n2. Follow the manual installation instructions on the course page.\n\nIf that does not work for you, consider taking a look at the \n[legacy manual install instructions](https://github.com/swirldev/swirl_courses/wiki/Legacy-Manual-Install-Instructions-for-Swirl-Courses).\n\n## Uninstall a course\n\nIf you'd like to remove a course at any time, you can use `uninstall_course(\"Course Name Here\")`.\n\n## Using swirl in the classroom\n\nInstructors around the world are using swirl in their classrooms. We think this is awesome. If you're an instructor, please feel free to do the same -- free of charge. While your students may be paying to take your course or attend your institution, we simply ask that you don't charge people *directly* for the use of our software or instructional content.\n\nIf you are not sure about a particular use case, don't hesitate to post a\nquestion to our [Google Group](https://groups.google.com/forum/#!forum/swirl-discuss).\n",
      "stars_today": 0
    },
    {
      "id": 15917132,
      "name": "ProgrammingAssignment2",
      "full_name": "rdpeng/ProgrammingAssignment2",
      "description": "Repository for Programming Assignment 2 for R Programming on Coursera",
      "html_url": "https://github.com/rdpeng/ProgrammingAssignment2",
      "stars": 875,
      "forks": 143958,
      "language": "R",
      "topics": [],
      "created_at": "2014-01-14T22:07:41Z",
      "updated_at": "2026-01-24T15:20:31Z",
      "pushed_at": "2024-08-14T21:14:33Z",
      "open_issues": 4319,
      "owner": {
        "login": "rdpeng",
        "avatar_url": "https://avatars.githubusercontent.com/u/9612?v=4"
      },
      "readme": "### Introduction\n\nThis second programming assignment will require you to write an R\nfunction that is able to cache potentially time-consuming computations.\nFor example, taking the mean of a numeric vector is typically a fast\noperation. However, for a very long vector, it may take too long to\ncompute the mean, especially if it has to be computed repeatedly (e.g.\nin a loop). If the contents of a vector are not changing, it may make\nsense to cache the value of the mean so that when we need it again, it\ncan be looked up in the cache rather than recomputed. In this\nProgramming Assignment you will take advantage of the scoping rules of\nthe R language and how they can be manipulated to preserve state inside\nof an R object.\n\n### Example: Caching the Mean of a Vector\n\nIn this example we introduce the `<<-` operator which can be used to\nassign a value to an object in an environment that is different from the\ncurrent environment. Below are two functions that are used to create a\nspecial object that stores a numeric vector and caches its mean.\n\nThe first function, `makeVector` creates a special \"vector\", which is\nreally a list containing a function to\n\n1.  set the value of the vector\n2.  get the value of the vector\n3.  set the value of the mean\n4.  get the value of the mean\n\n<!-- -->\n\n    makeVector <- function(x = numeric()) {\n            m <- NULL\n            set <- function(y) {\n                    x <<- y\n                    m <<- NULL\n            }\n            get <- function() x\n            setmean <- function(mean) m <<- mean\n            getmean <- function() m\n            list(set = set, get = get,\n                 setmean = setmean,\n                 getmean = getmean)\n    }\n\nThe following function calculates the mean of the special \"vector\"\ncreated with the above function. However, it first checks to see if the\nmean has already been calculated. If so, it `get`s the mean from the\ncache and skips the computation. Otherwise, it calculates the mean of\nthe data and sets the value of the mean in the cache via the `setmean`\nfunction.\n\n    cachemean <- function(x, ...) {\n            m <- x$getmean()\n            if(!is.null(m)) {\n                    message(\"getting cached data\")\n                    return(m)\n            }\n            data <- x$get()\n            m <- mean(data, ...)\n            x$setmean(m)\n            m\n    }\n\n### Assignment: Caching the Inverse of a Matrix\n\nMatrix inversion is usually a costly computation and there may be some\nbenefit to caching the inverse of a matrix rather than computing it\nrepeatedly (there are also alternatives to matrix inversion that we will\nnot discuss here). Your assignment is to write a pair of functions that\ncache the inverse of a matrix.\n\nWrite the following functions:\n\n1.  `makeCacheMatrix`: This function creates a special \"matrix\" object\n    that can cache its inverse.\n2.  `cacheSolve`: This function computes the inverse of the special\n    \"matrix\" returned by `makeCacheMatrix` above. If the inverse has\n    already been calculated (and the matrix has not changed), then\n    `cacheSolve` should retrieve the inverse from the cache.\n\nComputing the inverse of a square matrix can be done with the `solve`\nfunction in R. For example, if `X` is a square invertible matrix, then\n`solve(X)` returns its inverse.\n\nFor this assignment, assume that the matrix supplied is always\ninvertible.\n\nIn order to complete this assignment, you must do the following:\n\n1.  Fork the GitHub repository containing the stub R files at\n    [https://github.com/rdpeng/ProgrammingAssignment2](https://github.com/rdpeng/ProgrammingAssignment2)\n    to create a copy under your own account.\n2.  Clone your forked GitHub repository to your computer so that you can\n    edit the files locally on your own machine.\n3.  Edit the R file contained in the git repository and place your\n    solution in that file (please do not rename the file).\n4.  Commit your completed R file into YOUR git repository and push your\n    git branch to the GitHub repository under your account.\n5.  Submit to Coursera the URL to your GitHub repository that contains\n    the completed R code for the assignment.\n\n### Grading\n\nThis assignment will be graded via peer assessment.\n",
      "stars_today": 0
    },
    {
      "id": 39799721,
      "name": "r4ds",
      "full_name": "hadley/r4ds",
      "description": "R for data science: a book",
      "html_url": "https://github.com/hadley/r4ds",
      "stars": 4978,
      "forks": 4408,
      "language": "R",
      "topics": [
        "book",
        "bookdown",
        "data-science",
        "r"
      ],
      "created_at": "2015-07-27T21:52:44Z",
      "updated_at": "2026-01-24T15:20:31Z",
      "pushed_at": "2026-01-16T04:04:49Z",
      "open_issues": 21,
      "owner": {
        "login": "hadley",
        "avatar_url": "https://avatars.githubusercontent.com/u/4196?v=4"
      },
      "readme": "# R for Data Science\n\n<!-- badges: start -->\n\n[![Render and deploy Book to Netlify](https://github.com/hadley/r4ds/actions/workflows/build_book.yaml/badge.svg)](https://github.com/hadley/r4ds/actions/workflows/build_book.yaml)\n\n<!-- badges: end -->\n\nThis repository contains the source of [R for Data Science](http://r4ds.hadley.nz) book.\nThe book is built using [Quarto](https://quarto.org/).\n\n## Images\n\n### Omnigraffle drawings\n\n-   Font: 12pt Guardian Sans Condensed / Ubuntu mono\n\n-   Export as 300 dpi png.\n\n-   Website font is 18 px = 13.5 pt, so scale dpi to match font sizes: 270 = 300 \\* 12 / 13.5.\n    (I also verified this empirically by screenshotting.)\n\n    ``` r\n    #| echo: FALSE\n    #| out.width: NULL\n    knitr::include_graphics(\"diagrams/transform.png\", dpi = 270)\n    ```\n\n### Screenshots\n\n-   Make sure you're using a light theme.\n    For small interface elements (eg. toolbars), zoom in twice.\n\n-   Screenshot with Cmd + Shift + 4.\n\n-   Don't need to set dpi:\n\n    ``` r\n    #| echo: FALSE\n    #| out.width: NULL\n    knitr::include_graphics(\"screenshots/rstudio-wg.png\")\n    ```\n\n### O'Reilly\n\nTo generate book for O'Reilly, build the book then:\n\n```{r}\n# pak::pak(\"hadley/htmlbook\")\nhtmlbook::convert_book()\n\nhtml <- list.files(\"oreilly\", pattern = \"[.]html$\", full.names = TRUE)\nfile.copy(html, \"../r-for-data-science-2e/\", overwrite = TRUE)\n\npngs <- list.files(\"oreilly\", pattern = \"[.]png$\", full.names = TRUE, recursive = TRUE)\ndest <- gsub(\"oreilly\", \"../r-for-data-science-2e/\", pngs)\nfs::dir_create(unique(dirname(dest)))\nfile.copy(pngs, dest, overwrite = TRUE)\n```\n\nThen commit and push to atlas.\n\n## Code of Conduct\n\nPlease note that r4ds uses a [Contributor Code of Conduct](https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html).\nBy contributing to this book, you agree to abide by its terms.\n",
      "stars_today": 0
    },
    {
      "id": 19438,
      "name": "ggplot2",
      "full_name": "tidyverse/ggplot2",
      "description": "An implementation of the Grammar of Graphics in R",
      "html_url": "https://github.com/tidyverse/ggplot2",
      "stars": 6868,
      "forks": 2116,
      "language": "R",
      "topics": [
        "data-visualisation",
        "r",
        "visualisation"
      ],
      "created_at": "2008-05-25T01:21:32Z",
      "updated_at": "2026-01-23T13:48:18Z",
      "pushed_at": "2025-12-18T13:22:01Z",
      "open_issues": 96,
      "owner": {
        "login": "tidyverse",
        "avatar_url": "https://avatars.githubusercontent.com/u/22032646?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# ggplot2 <a href=\"https://ggplot2.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" alt=\"ggplot2 website\" /></a>\n\n<!-- badges: start -->\n\n[![R-CMD-check](https://github.com/tidyverse/ggplot2/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/ggplot2/actions/workflows/R-CMD-check.yaml)\n[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/ggplot2)](https://cran.r-project.org/package=ggplot2)\n[![Codecov test\ncoverage](https://codecov.io/gh/tidyverse/ggplot2/graph/badge.svg)](https://app.codecov.io/gh/tidyverse/ggplot2)\n<!-- badges: end -->\n\n## Overview\n\nggplot2 is a system for declaratively creating graphics, based on [The\nGrammar of\nGraphics](https://link.springer.com/book/10.1007/0-387-28695-0). You\nprovide the data, tell ggplot2 how to map variables to aesthetics, what\ngraphical primitives to use, and it takes care of the details.\n\n## Installation\n\n``` r\n# The easiest way to get ggplot2 is to install the whole tidyverse:\ninstall.packages(\"tidyverse\")\n\n# Alternatively, install just ggplot2:\ninstall.packages(\"ggplot2\")\n\n# Or the development version from GitHub:\n# install.packages(\"pak\")\npak::pak(\"tidyverse/ggplot2\")\n```\n\n## Cheatsheet\n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/thumbnails/data-visualization-cheatsheet-thumbs.png\" width=\"630\" height=\"252\" alt=\"ggplot2 cheatsheet\" /></a>\n\n## Usage\n\nItâ€™s hard to succinctly describe how ggplot2 works because it embodies a\ndeep philosophy of visualisation. However, in most cases you start with\n`ggplot()`, supply a dataset and aesthetic mapping (with `aes()`). You\nthen add on layers (like `geom_point()` or `geom_histogram()`), scales\n(like `scale_colour_brewer()`), faceting specifications (like\n`facet_wrap()`) and coordinate systems (like `coord_flip()`).\n\n``` r\nlibrary(ggplot2)\n\nggplot(mpg, aes(displ, hwy, colour = class)) +\n  geom_point()\n```\n\n<img src=\"man/figures/README-example-1.png\" alt=\"Scatterplot of engine displacement versus highway miles per gallon, for 234 cars coloured by 7 'types' of car. The displacement and miles per gallon are inversely correlated.\"  />\n\n## Lifecycle\n\n[![lifecycle](https://img.shields.io/badge/lifecycle-stable-brightgreen.svg)](https://lifecycle.r-lib.org/articles/stages.html)\n\nggplot2 is now 18 years old and is used by hundreds of thousands of\npeople to make millions of plots. That means, by-and-large, ggplot2\nitself changes relatively little. When we do make changes, they will be\ngenerally to add new functions or arguments rather than changing the\nbehaviour of existing functions, and if we do make changes to existing\nbehaviour we will do them for compelling reasons.\n\nIf you are looking for innovation, look to ggplot2â€™s rich ecosystem of\nextensions. See a community maintained list at\n<https://exts.ggplot2.tidyverse.org/gallery/>.\n\n## Learning ggplot2\n\nIf you are new to ggplot2 you are better off starting with a systematic\nintroduction, rather than trying to learn from reading individual\ndocumentation pages. Currently, there are several good places to start:\n\n1.  The [Data Visualization](https://r4ds.hadley.nz/data-visualize) and\n    [Communication](https://r4ds.hadley.nz/communication) chapters in [R\n    for Data Science](https://r4ds.hadley.nz). R for Data Science is\n    designed to give you a comprehensive introduction to the\n    [tidyverse](https://tidyverse.org/), and these two chapters will get\n    you up to speed with the essentials of ggplot2 as quickly as\n    possible.\n\n2.  If youâ€™d like to take an online course, try [Data Visualization in R\n    With\n    ggplot2](https://learning.oreilly.com/videos/data-visualization-in/9781491963661/)\n    by Kara Woo.\n\n3.  If youâ€™d like to follow a webinar, try [Plotting Anything with\n    ggplot2](https://youtu.be/h29g21z0a68) by Thomas Lin Pedersen.\n\n4.  If you want to dive into making common graphics as quickly as\n    possible, I recommend [The R Graphics\n    Cookbook](https://r-graphics.org) by Winston Chang. It provides a\n    set of recipes to solve common graphics problems.\n\n5.  If youâ€™ve mastered the basics and want to learn more, read [ggplot2:\n    Elegant Graphics for Data Analysis](https://ggplot2-book.org). It\n    describes the theoretical underpinnings of ggplot2 and shows you how\n    all the pieces fit together. This book helps you understand the\n    theory that underpins ggplot2, and will help you create new types of\n    graphics specifically tailored to your needs.\n\n6.  For articles about announcements and deep-dives you can visit the\n    [tidyverse blog](https://tidyverse.org/tags/ggplot2/).\n\n## Getting help\n\nThere are two main places to get help with ggplot2:\n\n1.  The [Posit Community](https://forum.posit.co/) (formerly RStudio\n    Community) is a friendly place to ask any questions about ggplot2.\n\n2.  [Stack\n    Overflow](https://stackoverflow.com/questions/tagged/ggplot2?sort=frequent&pageSize=50)\n    is a great source of answers to common ggplot2 questions. It is also\n    a great place to get help, once you have created a reproducible\n    example that illustrates your problem.\n",
      "stars_today": 0
    },
    {
      "id": 73963835,
      "name": "spring-cloud-gateway",
      "full_name": "spring-cloud/spring-cloud-gateway",
      "description": "An API Gateway built on Spring Framework and Spring Boot providing routing and more.",
      "html_url": "https://github.com/spring-cloud/spring-cloud-gateway",
      "stars": 4811,
      "forks": 3427,
      "language": "Java",
      "topics": [
        "api-gateway",
        "java",
        "microservices",
        "proxy",
        "reactor",
        "spring",
        "spring-boot",
        "spring-cloud",
        "spring-cloud-core"
      ],
      "created_at": "2016-11-16T21:42:51Z",
      "updated_at": "2026-01-24T07:10:24Z",
      "pushed_at": "2026-01-24T07:10:16Z",
      "open_issues": 501,
      "owner": {
        "login": "spring-cloud",
        "avatar_url": "https://avatars.githubusercontent.com/u/7815877?v=4"
      },
      "readme": "////\nDO NOT EDIT THIS FILE. IT WAS GENERATED.\nManual changes to this file will be lost when it is generated again.\nEdit the files in the src/main/asciidoc/ directory instead.\n////\n\n\nimage::https://github.com/spring-cloud/spring-cloud-gateway/workflows/Build/badge.svg?style=svg[\"Actions Status\", link=\"https://github.com/spring-cloud/spring-cloud-gateway/actions\"]\nimage::https://codecov.io/gh/spring-cloud/spring-cloud-gateway/branch/main/graph/badge.svg[\"Codecov\", link=\"https://codecov.io/gh/spring-cloud/spring-cloud-gateway/branch/main\"]\n\n\n\n[[features]]\n= Features\n\n* Java 17\n* Spring Framework 6\n* Spring Boot 3\n* Dynamic routing\n* Route matching built into Spring Handler Mapping\n* Route matching on HTTP Request (Path, Method, Header, Host, etc...)\n* Filters scoped to Matching Route\n* Filters can modify downstream HTTP Request and HTTP Response (Add/Remove Headers, Add/Remove Parameters, Rewrite Path, Set Path, Circuit Breaker, etc...)\n* API or configuration driven\n* Supports Spring Cloud `DiscoveryClient` for configuring Routes\n\n[[building]]\n= Building\n\n:jdkversion: 17\n\n[[basic-compile-and-test]]\n== Basic Compile and Test\n\nTo build the source you will need to install JDK {jdkversion}.\n\nSpring Cloud uses Maven for most build-related activities, and you\nshould be able to get off the ground quite quickly by cloning the\nproject you are interested in and typing\n\n----\n$ ./mvnw install\n----\n\nNOTE: You can also install Maven (>=3.3.3) yourself and run the `mvn` command\nin place of `./mvnw` in the examples below. If you do that you also\nmight need to add `-P spring` if your local Maven settings do not\ncontain repository declarations for spring pre-release artifacts.\n\nNOTE: Be aware that you might need to increase the amount of memory\navailable to Maven by setting a `MAVEN_OPTS` environment variable with\na value like `-Xmx512m -XX:MaxPermSize=128m`. We try to cover this in\nthe `.mvn` configuration, so if you find you have to do it to make a\nbuild succeed, please raise a ticket to get the settings added to\nsource control.\n\nThe projects that require middleware (i.e. Redis) for testing generally\nrequire that a local instance of https://www.docker.com/get-started[Docker] is installed and running.\n\n[[documentation]]\n== Documentation\n\nThe spring-cloud-build module has a \"docs\" profile, and if you switch\nthat on it will try to build asciidoc sources using https://docs.antora.org/antora/latest/[Antora] from\n`modules/ROOT/`.\n\nAs part of that process it will look for a\n`docs/src/main/asciidoc/README.adoc` and process it by loading all the includes, but not\nparsing or rendering it, just copying it to `${main.basedir}`\n(defaults to `$\\{basedir}`, i.e. the root of the project). If there are\nany changes in the README it will then show up after a Maven build as\na modified file in the correct place. Just commit it and push the change.\n\n[[working-with-the-code]]\n== Working with the code\nIf you don't have an IDE preference we would recommend that you use\nhttps://spring.io/tools[Spring Tools Suite] or\nhttps://eclipse.org[Eclipse] when working with the code. We use the\nhttps://eclipse.org/m2e/[m2eclipse] eclipse plugin for maven support. Other IDEs and tools\nshould also work without issue as long as they use Maven 3.3.3 or better.\n\n[[activate-the-spring-maven-profile]]\n=== Activate the Spring Maven profile\nSpring Cloud projects require the 'spring' Maven profile to be activated to resolve\nthe spring milestone and snapshot repositories. Use your preferred IDE to set this\nprofile to be active, or you may experience build errors.\n\n[[importing-into-eclipse-with-m2eclipse]]\n=== Importing into eclipse with m2eclipse\nWe recommend the https://eclipse.org/m2e/[m2eclipse] eclipse plugin when working with\neclipse. If you don't already have m2eclipse installed it is available from the \"eclipse\nmarketplace\".\n\nNOTE: Older versions of m2e do not support Maven 3.3, so once the\nprojects are imported into Eclipse you will also need to tell\nm2eclipse to use the right profile for the projects.  If you\nsee many different errors related to the POMs in the projects, check\nthat you have an up to date installation.  If you can't upgrade m2e,\nadd the \"spring\" profile to your `settings.xml`. Alternatively you can\ncopy the repository settings from the \"spring\" profile of the parent\npom into your `settings.xml`.\n\n[[importing-into-eclipse-without-m2eclipse]]\n=== Importing into eclipse without m2eclipse\nIf you prefer not to use m2eclipse you can generate eclipse project metadata using the\nfollowing command:\n\n[indent=0]\n----\n\t$ ./mvnw eclipse:eclipse\n----\n\nThe generated eclipse projects can be imported by selecting `import existing projects`\nfrom the `file` menu.\n\n\n[[contributing]]\n= Contributing\n\n:spring-cloud-build-branch: main\n\nSpring Cloud is released under the non-restrictive Apache 2.0 license,\nand follows a very standard Github development process, using Github\ntracker for issues and merging pull requests into main. If you want\nto contribute even something trivial please do not hesitate, but\nfollow the guidelines below.\n\n[[developer-certificate-of-origin]]\n== Developer Certificate of Origin (DCO)\n\nAll commits must include a __Signed-off-by__ trailer at the end of each commit message to indicate that the contributor agrees to the Developer Certificate of Origin.\nFor additional details, please refer to the blog post https://spring.io/blog/2025/01/06/hello-dco-goodbye-cla-simplifying-contributions-to-spring[Hello DCO, Goodbye CLA: Simplifying Contributions to Spring].\n\n[[code-of-conduct]]\n== Code of Conduct\nThis project adheres to the Contributor Covenant https://github.com/spring-cloud/spring-cloud-build/blob/main/docs/modules/ROOT/partials/code-of-conduct.adoc[code of\nconduct]. By participating, you  are expected to uphold this code. Please report\nunacceptable behavior to code-of-conduct@spring.io.\n\n[[code-conventions-and-housekeeping]]\n== Code Conventions and Housekeeping\nNone of these is essential for a pull request, but they will all help.  They can also be\nadded after the original pull request but before a merge.\n\n* Use the Spring Framework code format conventions. If you use Eclipse\n  you can import formatter settings using the\n  `eclipse-code-formatter.xml` file from the\n  https://raw.githubusercontent.com/spring-cloud/spring-cloud-build/main/spring-cloud-dependencies-parent/eclipse-code-formatter.xml[Spring\n  Cloud Build] project. If using IntelliJ, you can use the\n  https://plugins.jetbrains.com/plugin/6546[Eclipse Code Formatter\n  Plugin] to import the same file.\n* Make sure all new `.java` files to have a simple Javadoc class comment with at least an\n  `@author` tag identifying you, and preferably at least a paragraph on what the class is\n  for.\n* Add the ASF license header comment to all new `.java` files (copy from existing files\n  in the project)\n* Add yourself as an `@author` to the .java files that you modify substantially (more\n  than cosmetic changes).\n* Add some Javadocs and, if you change the namespace, some XSD doc elements.\n* A few unit tests would help a lot as well -- someone has to do it.\n* If no-one else is using your branch, please rebase it against the current main (or\n  other target branch in the main project).\n* When writing a commit message please follow https://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html[these conventions],\n  if you are fixing an existing issue please add `Fixes gh-XXXX` at the end of the commit\n  message (where XXXX is the issue number).\n\n[[checkstyle]]\n== Checkstyle\n\nSpring Cloud Build comes with a set of checkstyle rules. You can find them in the `spring-cloud-build-tools` module. The most notable files under the module are:\n\n.spring-cloud-build-tools/\n----\nâ””â”€â”€ src\n Â Â  â”œâ”€â”€ checkstyle\n Â Â  â”‚Â Â  â””â”€â”€ checkstyle-suppressions.xml <3>\n Â Â  â””â”€â”€ main\n Â Â      â””â”€â”€ resources\n Â Â          â”œâ”€â”€ checkstyle-header.txt <2>\n Â Â          â””â”€â”€ checkstyle.xml <1>\n----\n<1> Default Checkstyle rules\n<2> File header setup\n<3> Default suppression rules\n\n[[checkstyle-configuration]]\n=== Checkstyle configuration\n\nCheckstyle rules are *disabled by default*. To add checkstyle to your project just define the following properties and plugins.\n\n.pom.xml\n----\n<properties>\n<maven-checkstyle-plugin.failsOnError>true</maven-checkstyle-plugin.failsOnError> <1>\n        <maven-checkstyle-plugin.failsOnViolation>true\n        </maven-checkstyle-plugin.failsOnViolation> <2>\n        <maven-checkstyle-plugin.includeTestSourceDirectory>true\n        </maven-checkstyle-plugin.includeTestSourceDirectory> <3>\n</properties>\n\n<build>\n        <plugins>\n            <plugin> <4>\n                <groupId>io.spring.javaformat</groupId>\n                <artifactId>spring-javaformat-maven-plugin</artifactId>\n            </plugin>\n            <plugin> <5>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-checkstyle-plugin</artifactId>\n            </plugin>\n        </plugins>\n\n    <reporting>\n        <plugins>\n            <plugin> <5>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-checkstyle-plugin</artifactId>\n            </plugin>\n        </plugins>\n    </reporting>\n</build>\n----\n<1> Fails the build upon Checkstyle errors\n<2> Fails the build upon Checkstyle violations\n<3> Checkstyle analyzes also the test sources\n<4> Add the Spring Java Format plugin that will reformat your code to pass most of the Checkstyle formatting rules\n<5> Add checkstyle plugin to your build and reporting phases\n\nIf you need to suppress some rules (e.g. line length needs to be longer), then it's enough for you to define a file under `${project.root}/src/checkstyle/checkstyle-suppressions.xml` with your suppressions. Example:\n\n.projectRoot/src/checkstyle/checkstyle-suppressions.xml\n----\n<?xml version=\"1.0\"?>\n<!DOCTYPE suppressions PUBLIC\n\t\t\"-//Puppy Crawl//DTD Suppressions 1.1//EN\"\n\t\t\"https://www.puppycrawl.com/dtds/suppressions_1_1.dtd\">\n<suppressions>\n\t<suppress files=\".*ConfigServerApplication\\.java\" checks=\"HideUtilityClassConstructor\"/>\n\t<suppress files=\".*ConfigClientWatch\\.java\" checks=\"LineLengthCheck\"/>\n</suppressions>\n----\n\nIt's advisable to copy the `${spring-cloud-build.rootFolder}/.editorconfig` and `${spring-cloud-build.rootFolder}/.springformat` to your project. That way, some default formatting rules will be applied. You can do so by running this script:\n\n[source,bash]\n----\n$ curl https://raw.githubusercontent.com/spring-cloud/spring-cloud-build/main/.editorconfig -o .editorconfig\n$ touch .springformat\n----\n\n[[ide-setup]]\n== IDE setup\n\n[[intellij-idea]]\n=== Intellij IDEA\n\nIn order to setup Intellij you should import our coding conventions, inspection profiles and set up the checkstyle plugin.\nThe following files can be found in the https://github.com/spring-cloud/spring-cloud-build/tree/main/spring-cloud-build-tools[Spring Cloud Build] project.\n\n.spring-cloud-build-tools/\n----\nâ””â”€â”€ src\n Â Â  â”œâ”€â”€ checkstyle\n Â Â  â”‚Â Â  â””â”€â”€ checkstyle-suppressions.xml <3>\n Â Â  â””â”€â”€ main\n Â Â      â””â”€â”€ resources\n Â Â          â”œâ”€â”€ checkstyle-header.txt <2>\n Â Â          â”œâ”€â”€ checkstyle.xml <1>\n Â Â          â””â”€â”€ intellij\n Â Â           Â Â  â”œâ”€â”€ Intellij_Project_Defaults.xml <4>\n Â Â           Â Â  â””â”€â”€ Intellij_Spring_Boot_Java_Conventions.xml <5>\n----\n<1> Default Checkstyle rules\n<2> File header setup\n<3> Default suppression rules\n<4> Project defaults for Intellij that apply most of Checkstyle rules\n<5> Project style conventions for Intellij that apply most of Checkstyle rules\n\n.Code style\n\nimage::https://raw.githubusercontent.com/spring-cloud/spring-cloud-build/main/docs/modules/ROOT/assets/images/intellij-code-style.png[Code style]\n\nGo to `File` -> `Settings` -> `Editor` -> `Code style`. There click on the icon next to the `Scheme` section. There, click on the `Import Scheme` value and pick the `Intellij IDEA code style XML` option. Import the `spring-cloud-build-tools/src/main/resources/intellij/Intellij_Spring_Boot_Java_Conventions.xml` file.\n\n.Inspection profiles\n\nimage::https://raw.githubusercontent.com/spring-cloud/spring-cloud-build/main/docs/modules/ROOT/assets/images/intellij-inspections.png[Code style]\n\nGo to `File` -> `Settings` -> `Editor` -> `Inspections`. There click on the icon next to the `Profile` section. There, click on the `Import Profile` and import the `spring-cloud-build-tools/src/main/resources/intellij/Intellij_Project_Defaults.xml` file.\n\n.Checkstyle\n\nTo have Intellij work with Checkstyle, you have to install the `Checkstyle` plugin. It's advisable to also install the `Assertions2Assertj` to automatically convert the JUnit assertions\n\nimage::https://raw.githubusercontent.com/spring-cloud/spring-cloud-build/main/docs/modules/ROOT/assets/images/intellij-checkstyle.png[Checkstyle]\n\nGo to `File` -> `Settings` -> `Other settings` -> `Checkstyle`. There click on the `+` icon in the `Configuration file` section. There, you'll have to define where the checkstyle rules should be picked from. In the image above, we've picked the rules from the cloned Spring Cloud Build repository. However, you can point to the Spring Cloud Build's GitHub repository (e.g. for the `checkstyle.xml` : `https://raw.githubusercontent.com/spring-cloud/spring-cloud-build/main/spring-cloud-build-tools/src/main/resources/checkstyle.xml`). We need to provide the following variables:\n\n- `checkstyle.header.file` - please point it to the Spring Cloud Build's, `spring-cloud-build-tools/src/main/resources/checkstyle-header.txt` file either in your cloned repo or via the `https://raw.githubusercontent.com/spring-cloud/spring-cloud-build/main/spring-cloud-build-tools/src/main/resources/checkstyle-header.txt` URL.\n- `checkstyle.suppressions.file` - default suppressions. Please point it to the Spring Cloud Build's, `spring-cloud-build-tools/src/checkstyle/checkstyle-suppressions.xml` file either in your cloned repo or via the `https://raw.githubusercontent.com/spring-cloud/spring-cloud-build/main/spring-cloud-build-tools/src/checkstyle/checkstyle-suppressions.xml` URL.\n- `checkstyle.additional.suppressions.file` - this variable corresponds to suppressions in your local project. E.g. you're working on `spring-cloud-contract`. Then point to the `project-root/src/checkstyle/checkstyle-suppressions.xml` folder. Example for `spring-cloud-contract` would be: `/home/username/spring-cloud-contract/src/checkstyle/checkstyle-suppressions.xml`.\n\nIMPORTANT: Remember to set the `Scan Scope` to `All sources` since we apply checkstyle rules for production and test sources.\n\n[[duplicate-finder]]\n== Duplicate Finder\n\nSpring Cloud Build brings along the  `basepom:duplicate-finder-maven-plugin`, that enables flagging duplicate and conflicting classes and resources on the java classpath.\n\n[[duplicate-finder-configuration]]\n=== Duplicate Finder configuration\n\nDuplicate finder is *enabled by default* and will run in the `verify` phase of your Maven build, but it will only take effect in your project if you add the `duplicate-finder-maven-plugin` to the `build` section of the project's `pom.xml`.\n\n.pom.xml\n[source,xml]\n----\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.basepom.maven</groupId>\n            <artifactId>duplicate-finder-maven-plugin</artifactId>\n        </plugin>\n    </plugins>\n</build>\n----\n\nFor other properties, we have set defaults as listed in the https://github.com/basepom/duplicate-finder-maven-plugin/wiki[plugin documentation].\n\nYou can easily override them but setting the value of the selected property prefixed with `duplicate-finder-maven-plugin`. For example, set `duplicate-finder-maven-plugin.skip` to `true` in order to skip duplicates check in your build.\n\nIf you need to add `ignoredClassPatterns` or `ignoredResourcePatterns` to your setup, make sure to add them in the plugin configuration section of your project:\n\n[source,xml]\n----\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.basepom.maven</groupId>\n            <artifactId>duplicate-finder-maven-plugin</artifactId>\n            <configuration>\n                <ignoredClassPatterns>\n                    <ignoredClassPattern>org.joda.time.base.BaseDateTime</ignoredClassPattern>\n                    <ignoredClassPattern>.*module-info</ignoredClassPattern>\n                </ignoredClassPatterns>\n                <ignoredResourcePatterns>\n                    <ignoredResourcePattern>changelog.txt</ignoredResourcePattern>\n                </ignoredResourcePatterns>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n\n\n----\n\n",
      "stars_today": 0
    },
    {
      "id": 89033556,
      "name": "firebase-ios-sdk",
      "full_name": "firebase/firebase-ios-sdk",
      "description": "Firebase SDK for Apple App Development",
      "html_url": "https://github.com/firebase/firebase-ios-sdk",
      "stars": 6511,
      "forks": 1715,
      "language": "C++",
      "topics": [
        "ai",
        "analytics",
        "authentication",
        "crash-reporting",
        "database",
        "database-as-a-service",
        "firebase",
        "firebase-auth",
        "firebase-authentication",
        "firebase-database",
        "firebase-messaging",
        "firebase-storage",
        "gemini",
        "ios-sdk",
        "objective-c",
        "push-notifications",
        "storage-service"
      ],
      "created_at": "2017-04-22T00:26:50Z",
      "updated_at": "2026-01-24T23:32:26Z",
      "pushed_at": "2026-01-24T17:17:11Z",
      "open_issues": 430,
      "owner": {
        "login": "firebase",
        "avatar_url": "https://avatars.githubusercontent.com/u/1335026?v=4"
      },
      "readme": "<p align=\"center\">\n  <a href=\"https://cocoapods.org/pods/Firebase\">\n    <img src=\"https://img.shields.io/github/v/release/Firebase/firebase-ios-sdk?style=flat&label=CocoaPods\"/>\n  </a>\n  <a href=\"https://swiftpackageindex.com/firebase/firebase-ios-sdk\">\n    <img src=\"https://img.shields.io/github/v/release/Firebase/firebase-ios-sdk?style=flat&label=Swift%20Package%20Index&color=red\"/>\n  </a>\n  <a href=\"https://cocoapods.org/pods/Firebase\">\n    <img src=\"https://img.shields.io/github/license/Firebase/firebase-ios-sdk?style=flat\"/>\n  </a><br/>\n  <a href=\"https://swiftpackageindex.com/firebase/firebase-ios-sdk\">\n    <img src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Ffirebase%2Ffirebase-ios-sdk%2Fbadge%3Ftype%3Dplatforms\"/>\n  </a>\n  <a href=\"https://swiftpackageindex.com/firebase/firebase-ios-sdk\">\n    <img src=\"https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Ffirebase%2Ffirebase-ios-sdk%2Fbadge%3Ftype%3Dswift-versions\"/>\n  </a>\n</p>\n\n# Firebase Apple Open Source Development\n\nThis repository contains the source code for all Apple platform Firebase SDKs except FirebaseAnalytics.\n\nFirebase is an app development platform with tools to help you build, grow, and\nmonetize your app. More information about Firebase can be found on the\n[official Firebase website](https://firebase.google.com).\n\n## Installation\n\nSee the subsections below for details about the different installation methods. Where\navailable, it's recommended to install any libraries with a `Swift` suffix to get the\nbest experience when writing your app in Swift.\n\n1. [Standard pod install](#standard-pod-install)\n2. [Swift Package Manager](#swift-package-manager)\n3. [Installing from the GitHub repo](#installing-from-github)\n4. [Experimental Carthage](#carthage-ios-only)\n\n### Standard pod install\n\nFor instructions on the standard pod install, visit:\n[https://firebase.google.com/docs/ios/setup](https://firebase.google.com/docs/ios/setup).\n\n### Swift Package Manager\n\nInstructions for [Swift Package Manager](https://swift.org/package-manager/) support can be\nfound in the [SwiftPackageManager.md](SwiftPackageManager.md) Markdown file.\n\n### Installing from GitHub\n\nThese instructions can be used to access the Firebase repo at other branches,\ntags, or commits.\n\n#### Background\n\nSee [the Podfile Syntax Reference](https://guides.cocoapods.org/syntax/podfile.html#pod)\nfor instructions and options about overriding pod source locations.\n\n#### Accessing Firebase Source Snapshots\n\nAll official releases are tagged in this repo and available via CocoaPods. To access a local\nsource snapshot or unreleased branch, use Podfile directives like the following:\n\nTo access FirebaseFirestore via a branch:\n```ruby\npod 'FirebaseCore', :git => 'https://github.com/firebase/firebase-ios-sdk.git', :branch => 'main'\npod 'FirebaseFirestore', :git => 'https://github.com/firebase/firebase-ios-sdk.git', :branch => 'main'\n```\n\nTo access FirebaseMessaging via a checked-out version of the firebase-ios-sdk repo:\n```ruby\npod 'FirebaseCore', :path => '/path/to/firebase-ios-sdk'\npod 'FirebaseMessaging', :path => '/path/to/firebase-ios-sdk'\n```\n\n### Carthage (iOS only)\n\nInstructions for the experimental Carthage distribution can be found at\n[Carthage.md](Carthage.md).\n\n### Using Firebase from a Framework or a library\n\nFor details on using Firebase from a Framework or a library, refer to [firebase_in_libraries.md](docs/firebase_in_libraries.md).\n\n## Development\n\nTo develop Firebase software in this repository, ensure that you have at least\nthe following software:\n\n* Xcode 16.2 (or later)\n\nCocoaPods is still the canonical way to develop, but much of the repo now supports\ndevelopment with Swift Package Manager.\n\n### CocoaPods\n\nInstall the following:\n* CocoaPods 1.12.0 (or later)\n* [CocoaPods generate](https://github.com/square/cocoapods-generate)\n\nFor the pod that you want to develop:\n\n```ruby\npod gen Firebase{name here}.podspec --local-sources=./ --auto-open --platforms=ios\n```\n\nNote: If the CocoaPods cache is out of date, you may need to run\n`pod repo update` before the `pod gen` command.\n\nNote: Set the `--platforms` option to `macos` or `tvos` to develop/test for\nthose platforms. Since 10.2, Xcode does not properly handle multi-platform\nCocoaPods workspaces.\n\nFirestore has a self-contained Xcode project. See\n[Firestore/README](Firestore/README.md) Markdown file.\n\n#### Development for Catalyst\n* `pod gen {name here}.podspec --local-sources=./ --auto-open --platforms=ios`\n* Check the Mac box in the App-iOS Build Settings\n* Sign the App in the Settings Signing & Capabilities tab\n* Click Pods in the Project Manager\n* Add Signing to the iOS host app and unit test targets\n* Select the Unit-unit scheme\n* Run it to build and test\n\nAlternatively, disable signing in each target:\n* Go to Build Settings tab\n* Click `+`\n* Select `Add User-Defined Setting`\n* Add `CODE_SIGNING_REQUIRED` setting with a value of `NO`\n\n### Swift Package Manager\n* To enable test schemes: `./scripts/setup_spm_tests.sh`\n* `open Package.swift` or double click `Package.swift` in Finder.\n* Xcode will open the project\n  * Choose a scheme for a library to build or test suite to run\n  * Choose a target platform by selecting the run destination along with the scheme\n\n### Adding a New Firebase Pod\n\nRefer to [AddNewPod](docs/AddNewPod.md) Markdown file for details.\n\n### Managing Headers and Imports\n\nFor information about managing headers and imports, see [HeadersImports](HeadersImports.md) Markdown file.\n\n### Code Formatting\n\nTo ensure that the code is formatted consistently, run the script\n[./scripts/check.sh](https://github.com/firebase/firebase-ios-sdk/blob/main/scripts/check.sh)\nbefore creating a pull request (PR).\n\nGitHub Actions will verify that any code changes are done in a style-compliant\nway. Install `clang-format` and `mint`:\n\n```console\nbrew install clang-format@21\nbrew install mint\n```\n\n### Running Unit Tests\n\nSelect a scheme and press Command-u to build a component and run its unit tests.\n\n### Running Sample Apps\nTo run the sample apps and integration tests, you'll need a valid\n`GoogleService-Info.plist\n` file. The Firebase Xcode project contains dummy plist\nfiles without real values, but they can be replaced with real plist files. To get your own\n`GoogleService-Info.plist` files:\n\n1. Go to the [Firebase Console](https://console.firebase.google.com/)\n2. Create a new Firebase project, if you don't already have one\n3. For each sample app you want to test, create a new Firebase app with the sample app's bundle\nidentifier (e.g., `com.google.Database-Example`)\n4. Download the resulting `GoogleService-Info.plist` and add it to the Xcode project.\n\n### Coverage Report Generation\n\nFor coverage report generation instructions, see [scripts/code_coverage_report/README](scripts/code_coverage_report/README.md) Markdown file.\n\n## Specific Component Instructions\nSee the sections below for any special instructions for those components.\n\n### Firebase AI Logic\n\nSee the [Firebase AI Logic README](FirebaseAI#development) for instructions\nabout building and testing the SDK.\n\n### Firebase Auth\n\nFor specific Firebase Auth development, refer to the [Auth Sample README](FirebaseAuth/Tests/Sample/README.md) for instructions about\nbuilding and running the FirebaseAuth pod along with various samples and tests.\n\n### Firebase Database\n\nThe Firebase Database Integration tests can be run against a locally running Database Emulator\nor against a production instance.\n\nTo run against a local emulator instance, invoke `./scripts/run_database_emulator.sh start` before\nrunning the integration test.\n\nTo run against a production instance, provide a valid `GoogleServices-Info.plist` and copy it to\n`FirebaseDatabase/Tests/Resources/GoogleService-Info.plist`. Your Security Rule must be set to\n[public](https://firebase.google.com/docs/database/security/quickstart) while your tests are\nrunning.\n\n### Firebase Dynamic Links\n\nFirebase Dynamic Links is **deprecated** and should not be used in new projects. The service will shut down on August 25, 2025.\n\nPlease see our [Dynamic Links Deprecation FAQ documentation](https://firebase.google.com/support/dynamic-links-faq) for more guidance.\n\n### Firebase Performance Monitoring\n\nFor specific Firebase Performance Monitoring development, see\n[the Performance README](FirebasePerformance/README.md) for instructions about building the SDK\nand [the Performance TestApp README](FirebasePerformance/Tests/TestApp/README.md) for instructions about\nintegrating Performance with the dev test App.\n\n### Firebase Storage\n\nTo run the Storage Integration tests, follow the instructions in\n[StorageIntegration.swift](FirebaseStorage/Tests/Integration/StorageIntegration.swift).\n\n#### Push Notifications\n\nPush notifications can only be delivered to specially provisioned App IDs in the developer portal.\nIn order to test receiving push notifications, you will need to:\n\n1. Change the bundle identifier of the sample app to something you own in your Apple Developer\naccount and enable that App ID for push notifications.\n2. You'll also need to\n[upload your APNs Provider Authentication Key or certificate to the\nFirebase Console](https://firebase.google.com/docs/cloud-messaging/ios/certs)\nat **Project Settings > Cloud Messaging > [Your Firebase App]**.\n3. Ensure your iOS device is added to your Apple Developer portal as a test device.\n\n#### iOS Simulator\n\nThe iOS Simulator cannot register for remote notifications and will not receive push notifications.\nTo receive push notifications, follow the steps above and run the app on a physical device.\n\n## Building with Firebase on Apple platforms\n\nFirebase provides official beta support for macOS, Catalyst, and tvOS. visionOS and watchOS\nare community supported. Thanks to community contributions for many of the multi-platform PRs.\n\nAt this time, most of Firebase's products are available across Apple platforms. There are still\na few gaps, especially on visionOS and watchOS. For details about the current support matrix, see\n[this chart](https://firebase.google.com/docs/ios/learn-more#firebase_library_support_by_platform)\nin Firebase's documentation.\n\n### visionOS\n\nWhere supported, visionOS works as expected with the exception of Firestore via Swift Package\nManager where it is required to use the source distribution.\n\nTo enable the Firestore source distribution, quit Xcode and open the desired\nproject from the command line with the `FIREBASE_SOURCE_FIRESTORE` environment\nvariable: `open --env FIREBASE_SOURCE_FIRESTORE /path/to/project.xcodeproj`.\nTo go back to using the binary distribution of Firestore, quit Xcode and open\nXcode like normal, without the environment variable.\n\n### watchOS\nThanks to contributions from the community, many of Firebase SDKs now compile, run unit tests, and\nwork on watchOS. See the [Independent Watch App Sample](Example/watchOSSample).\n\nKeep in mind that watchOS is not officially supported by Firebase. While we can catch basic unit\ntest issues with GitHub Actions, there may be some changes where the SDK no longer works as expected\non watchOS. If you encounter this, please\n[file an issue](https://github.com/firebase/firebase-ios-sdk/issues).\n\nDuring app setup in the console, you may get to a step that mentions something like \"Checking if the\napp has communicated with our servers\". This relies on Analytics and will not work on watchOS.\n**It's safe to ignore the message and continue**, the rest of the SDKs will work as expected.\n\n#### Additional Crashlytics Notes\n* watchOS has limited support. Due to watchOS restrictions, mach exceptions and signal crashes are\nnot recorded. (Crashes in SwiftUI are generated as mach exceptions, so will not be recorded)\n\n## Combine\nThanks to contributions from the community, _FirebaseCombineSwift_ contains support for Apple's Combine\nframework. This module is currently under development and not yet supported for use in production\nenvironments. For more details, please refer to the [docs](FirebaseCombineSwift/README.md).\n\n## Roadmap\n\nSee [Roadmap](ROADMAP.md) for more about the Firebase Apple SDK Open Source\nplans and directions.\n\n## Contributing\n\nSee [Contributing](CONTRIBUTING.md) for more information on contributing to the Firebase\nApple SDK.\n\n## License\n\nThe contents of this repository are licensed under the\n[Apache License, version 2.0](http://www.apache.org/licenses/LICENSE-2.0).\n\nYour use of Firebase is governed by the\n[Terms of Service for Firebase Services](https://firebase.google.com/terms/).\n",
      "stars_today": 0
    },
    {
      "id": 66302557,
      "name": "SwiftFormat",
      "full_name": "nicklockwood/SwiftFormat",
      "description": "A command-line tool and Xcode Extension for formatting Swift code",
      "html_url": "https://github.com/nicklockwood/SwiftFormat",
      "stars": 8667,
      "forks": 670,
      "language": "Swift",
      "topics": [],
      "created_at": "2016-08-22T19:39:05Z",
      "updated_at": "2026-01-23T08:57:28Z",
      "pushed_at": "2026-01-24T03:28:15Z",
      "open_issues": 328,
      "owner": {
        "login": "nicklockwood",
        "avatar_url": "https://avatars.githubusercontent.com/u/546885?v=4"
      },
      "readme": "![](EditorExtension/Application/Assets.xcassets/AppIcon.appiconset/icon_256x256.png)\n\n[![PayPal](https://img.shields.io/badge/paypal-donate-blue.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=9ZGWNK5FEZFF6&source=url)\n[![Build](https://github.com/nicklockwood/SwiftFormat/actions/workflows/build.yml/badge.svg)](https://github.com/nicklockwood/SwiftFormat/actions/workflows/build.yml)\n[![Codecov](https://codecov.io/gh/nicklockwood/SwiftFormat/graphs/badge.svg)](https://codecov.io/gh/nicklockwood/SwiftFormat)\n[![](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fnicklockwood%2FSwiftFormat%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/nicklockwood/swiftformat)\n[![License](https://img.shields.io/badge/license-MIT-lightgrey.svg)](https://opensource.org/licenses/MIT)\n[![Mastodon](https://img.shields.io/badge/mastodon-@nicklockwood@mastodon.social-636dff.svg)](https://mastodon.social/@nicklockwood)\n\nTable of Contents\n-----------------\n\n- [What?](#what-is-this)\n- [Why?](#why-would-i-want-to-do-that)\n- [How?](#how-do-i-install-it)\n    - [Command-line tool](#command-line-tool)\n    - [Xcode source editor extension](#xcode-source-editor-extension)\n    - [Xcode build phase](#xcode-build-phase)\n    - [Swift Package Manager plugin](#swift-package-manager-plugin)\n    - [Via Applescript](#via-applescript)\n    - [VSCode plugin](#vscode-plugin)\n    - [Sublime Text plugin](#sublime-text-plugin)\n    - [Nova plugin](nova-plugin)\n    - [Git pre-commit hook](#git-pre-commit-hook)\n    - [GitHub Actions](#github-actions)\n    - [On CI using Danger](#on-ci-using-danger)\n    - [Bazel build](#bazel-build)\n    - [Docker](#docker)\n    - [Prerelease Builds](#prerelease-builds)\n- [Configuration](#configuration)\n    - [Options](#options)\n    - [Rules](#rules)\n    - [Swift version](#swift-version)\n    - [Config file](#config-file)\n    - [Globs](#globs)\n    - [Linting](#linting)\n    - [Error codes](#error-codes)\n    - [Cache](#cache)\n    - [File headers](#file-headers)\n    - [Markdown formatting](#markdown-formatting)\n- [FAQ](#faq)\n- [Known issues](#known-issues)\n- [Tip Jar](#tip-jar)\n- [Credits](#credits)\n\n\nWhat is this?\n----------------\n\nSwiftFormat is a code library and command-line tool for reformatting Swift code on macOS, Linux or Windows.\n\nSwiftFormat goes above and beyond what you might expect from a code formatter. In addition to adjusting white space it can insert or remove implicit `self`, remove redundant parentheses, and correct many other deviations from the standard Swift idioms.\n\n\nWhy would I want to do that?\n-----------------------------\n\nMany programmers have a preferred style for formatting their code, and others seem entirely blind to the existing formatting conventions of a project (to the enragement of their colleagues).\n\nWhen collaborating on a project, it can be helpful to agree on a common coding style, but enforcing that manually is tedious and error-prone, and can lead to arguments if some participants take it more seriously than others.\n\nHaving a tool to automatically enforce a common style eliminates those issues, and lets you focus on the behavior of the code, not its presentation.\n\n\nHow do I install it?\n---------------------\n\nThat depends - There are several ways you can use SwiftFormat:\n\n1. As a command-line tool that you run manually, or as part of some other toolchain\n2. As a Source Editor Extension that you can invoke via the Editor > SwiftFormat menu within Xcode\n3. As a build phase in your Xcode project, so that it runs every time you press Cmd-R or Cmd-B, or\n4. As a Git pre-commit hook, so that it runs on any files you've changed before you check them in\n\n\nCommand-line tool\n-------------------\n\n**Installation:**\n\nYou can install the `swiftformat` command-line tool on macOS or Linux using [Homebrew](http://brew.sh/). Assuming you already have Homebrew installed, just type:\n\n```bash\n$ brew install swiftformat\n```\n\nTo update to the latest version once installed:\n\n```bash\n$ brew upgrade swiftformat\n```\n\nAlternatively, you can install the tool on macOS or Linux by using [Mint](https://github.com/yonaskolb/Mint) as follows:\n\n```bash\n$ mint install nicklockwood/SwiftFormat\n```\n\nOr if you prefer, you can check out and build SwiftFormat manually on macOS, Linux or Windows as follows:\n\n```bash\n$ git clone https://github.com/nicklockwood/SwiftFormat\n$ cd SwiftFormat\n$ swift build -c release\n```\n\nIf you are installing SwiftFormat into your project directory, you can use [CocoaPods](https://cocoapods.org/) on macOS to automatically install the swiftformat binary along with your other pods - see the Xcode build phase instructions below for details.\n\nAnother option is to include the binary artifactbundle in your `Package.swift`:\n\n```swift\n.binaryTarget(\n    name: \"swiftformat\",\n    url: \"https://github.com/nicklockwood/SwiftFormat/releases/download/0.55.0/swiftformat-macos.artifactbundle.zip\",\n    checksum: \"CHECKSUM\"\n),\n``` \n\nIf you would prefer not to use a package manager, you can build the command-line app manually:\n\n1. open `SwiftFormat.xcodeproj` and build the `SwiftFormat (Application)` scheme.\n\n2. Drag the `swiftformat` binary into `/usr/local/bin/` (this is a hidden folder, but you can use the Finder's `Go > Go to Folder...` menu to open it).\n\n3. Open `~/.bash_profile` in your favorite text editor (this is a hidden file, but you can type `open ~/.bash_profile` in the terminal to open it).\n\n4. Add the following line to the file: `alias swiftformat=\"/usr/local/bin/swiftformat --indent 4\"` (you can omit the `--indent 4`, or replace it with something else. Run `swiftformat --help` to see the available options).\n\n5. Save the `.bash_profile` file and run the command `source ~/.bash_profile` for the changes to take effect.\n\n**Usage:**\n\nIf you followed the installation instructions above, you can now just type\n\n```bash\n$ swiftformat .\n```\n\n(that's a space and then a period after the command) in the terminal to format any Swift files in the current directory. In place of the `.`, you can instead type an absolute or relative path to the file or directory that you want to format.\n\n**WARNING:** `swiftformat .` will overwrite any Swift files it finds in the current directory, and any subfolders therein. If you run it in your home directory, it will probably reformat every Swift file on your hard drive.\n\nTo use it safely, do the following:\n\n1. Choose a file or directory that you want to apply the changes to.\n\n2. Make sure that you have committed all your changes to that code safely in git (or whatever source control system you use).\n\n3. (Optional) In Terminal, type `swiftformat --infer-options \"/path/to/your/code/\"`. This will suggest a set of formatting options to use that match your existing project style (but you are free to ignore these and use the defaults, or your own settings if you prefer).\n\n    The path can point to either a single Swift file or a directory of files. It can be either be absolute, or relative to the current directory. The `\"\"` quotes around the path are optional, but if the path contains spaces then you either need to use quotes, or escape each space with `\\`. You may include multiple paths separated by spaces.\n\n4. In Terminal, type `swiftformat \"/path/to/your/code/\"`. The same rules apply as above with respect to paths, and multiple space-delimited paths are allowed.\n\n    If you used `--infer-options` to generate a suggested set of options in step 3, you should copy and paste them into the command, either before or after the path(s) to your source files.\n\n    If you have created a [config file](#config-file), you can specify its path using `--config \"/path/to/your/config-file/\"`. Alternatively, if you name the file `.swiftformat` and place it inside the project you are formatting, it will be picked up automatically.\n\n5. Press enter to begin formatting. Once the formatting is complete, use your source control system to check the changes, and verify that no undesirable changes have been introduced. If they have, revert the changes, tweak the options and try again.\n\n6. (Optional) commit the changes.\n\nFollowing these instructions *should* ensure that you avoid catastrophic data loss, but in the unlikely event that it wipes your hard drive, **please note that I accept no responsibility**.\n\n**Using Standard Input/Output:**\n\nIf you prefer, you can use unix pipes to include SwiftFormat as part of a command chain. For example, this is an alternative way to format a file:\n\n```bash\n$ cat /path/to/file.swift | swiftformat --output /path/to/file.swift\n```\n\nOmitting the `--output /path/to/file.swift` will print the formatted file to Standard Output (stdout). You can also pass \"stdout\" explicitly as the output path:\n\n```bash\n$ cat /path/to/file.swift | swiftformat --output stdout\n```\n\nOr you can use `>` to specify the output path as follows:\n\n```bash\n$ cat /path/to/file.swift | swiftformat > /path/to/file.swift\n```\n\nIf you do not supply an input file, SwiftFormat will automatically take its input from Standard Input (stdin), but will time-out if no input is received immediately and display the help screen. To make it explicit, pass \"stdin\" as the input path:\n\n```bash\n$ cat /path/to/file.swift | swiftformat stdin\n```\n\nWhen using stdin, SwiftFormat does not have access to the file path of the input, so features that rely on the file location (such as inserting the creation date into header comments, or detecting `.swiftformat` configuration files in the file path) will not work. To solve this, you can provide the file path using the `--stdin-path` argument:\n\n```bash\n$ cat /path/to/file.swift | swiftformat stdin --stdinpath /path/to/file.swift\n```\n\n\nXcode source editor extension\n-----------------------------\n\n**Installation:**\n\nLike the command-line tool, you can install the SwiftFormat for Xcode extension application via [Homebrew](http://brew.sh/). Assuming you already have Homebrew installed, type:\n\n```bash\n$ brew install --cask swiftformat-for-xcode\n```\n\nThis will install SwiftFormat for Xcode in your Applications folder. Double-click the app to launch it, and then follow the on-screen instructions.\n\n**NOTE:** The app should be correctly signed, but if you get a Gatekeeper warning when trying to open it you can bypass this by right-clicking (or control-clicking) the app and selecting `Open`.\n\nTo update to the latest version once installed use:\n\n```bash\n$ brew upgrade --cask swiftformat-for-xcode\n```\n\nAlternatively, if you prefer not to use Homebrew, you'll find the latest version of the SwiftFormat for Xcode application on the [GitHub Releases](https://github.com/nicklockwood/SwiftFormat/releases) page. Download and unpack the zip archive, then drag `SwiftFormat for Xcode.app` into your `Applications` folder.\n\n**Usage:**\n\nOnce you have launched the app and restarted Xcode, you'll find a SwiftFormat option under Xcode's Editor menu. If the SwiftFormat menu does not appear [this thread](https://github.com/nicklockwood/SwiftFormat/issues/494) may help. \n\nYou can configure the formatting [rules](#rules) and [options](#options) using the SwiftFormat for Xcode host application. There is currently no way to override these per-project, however, you can import and export different configurations using the File menu. You will need to do this again each time you switch projects.\n\nThe format of the configuration file is described in the [Config section](#config-file) below.\n\n**Note:** SwiftFormat for Xcode cannot automatically detect changes to an imported configuration file. If you update the `.swiftformat` file for your project, you will need to manually re-import that file into SwiftFormat for Xcode in order for the Xcode source editor extension to use the new configuration.\n\n\nXcode build phase\n-------------------\n\n**NOTE:** Adding this script will overwrite your source files as you work on them, which has the annoying side-effect of clearing the undo history. You may wish to add the script to your test target rather than your main target, so that it is invoked only when you run the unit tests, and not every time you build the app.\n\nAlternatively, you might want to consider running SwiftFormat in [lint](#linting) mode as part of your normal build, and then running a formatting pass manually, or as part of a less-frequent build target (such as the tests).\n\n### Using Swift Package Manager\n\nTo set up SwiftFormat as an Xcode build phase, do the following:\n\n#### 1) Create a BuildTools folder and Package.swift\n\n1. Create a folder called `BuildTools` in the same folder as your xcodeproj file\n2. In this folder, create a file called `Package.swift`, with the following contents:\n```swift\n// swift-tools-version:5.1\nimport PackageDescription\n\nlet package = Package(\n    name: \"BuildTools\",\n    platforms: [.macOS(.v10_11)],\n    dependencies: [\n        .package(url: \"https://github.com/nicklockwood/SwiftFormat\", from: \"0.58.7\"),\n    ],\n    targets: [.target(name: \"BuildTools\", path: \"\")]\n)\n```\n3. If you are running Xcode 11.4 or later, in the `BuildTools` folder create a file called `Empty.swift` with nothing in it. This is to satisfy a change in Swift Package Manager.\n\n#### 2) Add a Build phase to your app target\n\n1. Click on your project in the file list, choose your target under `TARGETS`, click the `Build Phases` tab\n2. Add a `New Run Script Phase` by clicking the little plus icon in the top left\n3. Uncheck the `Based on dependency analysis` checkbox\n4. Drag the new `Run Script` phase **above** the `Compile Sources` phase, expand it and paste the following script:\n\n    ```bash\n    cd BuildTools\n    SDKROOT=(xcrun --sdk macosx --show-sdk-path)\n    #swift package update #Uncomment this line temporarily to update the version used to the latest matching your BuildTools/Package.swift file\n    swift run -c release swiftformat \"$SRCROOT\"\n    ```\n\nYou can also use `swift run -c release --package-path BuildTools swiftformat \"$SRCROOT\"` if you need a more complex script and `cd BuildTools` breaks stuff.\n\n**NOTE:** You may wish to check BuildTools/Package.swift into your source control so that the version used by your run-script phase is kept in version control. It is recommended to add the following to your .gitignore file: `BuildTools/.build` and `BuildTools/.swiftpm`.\n\n**NOTE (2):** If you are using Xcode 15 or later, make sure that the `ENABLE_USER_SCRIPT_SANDBOXING` (aka \"User Script Sandboxing\") option is set to NO, otherwise SwiftFormat won't be able to run correctly.\n\n### Using CocoaPods\n\n#### 1) Add the SwiftFormat CLI to your Podfile\n\n1. Add the `swiftformat` binary to your project directory via [CocoaPods](https://cocoapods.org/), by adding the following line to your Podfile then running `pod install`:\n\n    ```ruby\n    pod 'SwiftFormat/CLI', '~> 0.58.7'\n    ```\n\n**NOTE:** This will only install the pre-built command-line app, not the source code for the SwiftFormat framework.\n\n**NOTE (2):** When installing this way, GateKeeper may block swiftformat from running until you open it manually the first time by right-clicking in the Finder and selecting \"Open\".\n\n#### 2) Add a Build phase to your app target\n\n1. Click on your project in the file list, choose your target under `TARGETS`, click the `Build Phases` tab\n2. Add a `New Run Script Phase` by clicking the little plus icon in the top left\n3. Uncheck the `Based on dependency analysis` checkbox\n4. Drag the new `Run Script` phase **above** the `Compile Sources` phase, expand it and paste the following script:\n\n    ```bash\n    \"${PODS_ROOT}/SwiftFormat/CommandLineTool/swiftformat\" \"$SRCROOT\"\n    ```\n\n### Alternative: Locally installed SwiftFormat\n\nAlternatively, you could use a locally installed swiftformat command-line tool instead by putting the following in your Run Script build phase:\n\n```bash\nif which swiftformat >/dev/null; then\n  swiftformat .\nelse\n  echo \"warning: SwiftFormat not installed, download from https://github.com/nicklockwood/SwiftFormat\"\nfi\n```\n\nThis is not recommended for shared projects however, as different team members using different versions of SwiftFormat may result in noise in the commit history as code gets reformatted inconsistently.\n\nIf you installed SwiftFormat via Homebrew on Apple Silicon, you might experience this warning:\n\n> warning: SwiftFormat not installed, download from https://github.com/nicklockwood/SwiftFormat\n\nThat is because Homebrew on Apple Silicon installs the binaries into the `/opt/homebrew/bin`\nfolder by default. To instruct Xcode where to find SwiftFormat, you can either add\n`/opt/homebrew/bin` to the `PATH` environment variable in your build phase\n\n```bash\nif [[ \"$(uname -m)\" == arm64 ]]; then\n    export PATH=\"/opt/homebrew/bin:$PATH\"\nfi\n\nif which swiftformat > /dev/null; then\n  swiftformat .\nelse\n  echo \"warning: SwiftFormat not installed, download from https://github.com/nicklockwood/SwiftFormat\"\nfi\n```\n\nor you can create a symbolic link in `/usr/local/bin` pointing to the actual binary:\n\n```bash\nln -s /opt/homebrew/bin/swiftformat /usr/local/bin/swiftformat\n```\n\nSwift Package Manager plugin\n-----------------------------\n\nYou can use `SwiftFormat` as a SwiftPM command plugin.\n\n**NOTE:** Swift 5.6 or higher is required. Add the package to your dependencies in your `Package.swift` file.\n\n```swift\ndependencies: [\n    // ...\n    .package(url: \"https://github.com/nicklockwood/SwiftFormat\", from: \"0.58.7\"),\n]\n```\n\nThe plugin will find an existing `.swiftformat` in your package root folder and honor it automatically.\n\n### Trigger Plugin From Command-Line\n\n```bash\nswift package plugin --allow-writing-to-package-directory swiftformat\n```\n\nYou can limit the formatting to a particular target with `--target` option.\n\nYou can also specify `SwiftFormat` arguments, e.g. `--swift-version`.\n\nExample\n\n```bash\nswift package plugin --allow-writing-to-package-directory swiftformat --target MyLibrary --swift-version 5.6 --verbose\n```\n\n### Trigger Plugin From Xcode\n\nIn Xcode 14 you can trigger the command plugin execution for a Swift package or an Xcode project.\n\nFor an Xcode project the project's main directory will be processed and the `--target` option will be ignored.\n\nYou can also specify `SwiftFormat` arguments, e.g. `--swift-version`.\n\n![Run plugin in Xcode 14](https://user-images.githubusercontent.com/4176826/179352584-db7f7f42-452c-4a42-a329-01b115a237a7.gif)\n\nVia AppleScript\n----------------\n\nTo run SwiftFormat on the frontmost Xcode document (project or workspace) you can use the following AppleScript:\n\n```applescript\ntell application \"Xcode\"\n    set frontWindow to the first window\n    set myPath to path of document of frontWindow\n    do shell script \"cd \" & myPath & \";cd ..; /usr/local/bin/swiftformat .\"\nend tell\n```\n\nSome Apps you can trigger this from are [BetterTouchTool](https://folivora.ai), [Alfred](https://www.alfredapp.com) or [Keyboard Maestro](https://www.keyboardmaestro.com/main/). Another option is to define a QuickAction for Xcode via Automator and then assign a keyboard shortcut for it in the System Preferences.\n\n\nVSCode plugin\n--------------\n\nIf you prefer to use Microsoft's [VSCode](https://code.visualstudio.com) editor for writing Swift, [Valentin Knabel](https://github.com/vknabel) has created a [VSCode plugin](https://marketplace.visualstudio.com/items?itemName=vknabel.vscode-swiftformat) for SwiftFormat.\n\n\nSublime Text plugin\n--------------------\n\nIf you prefer to use the [Sublime Text](https://www.sublimetext.com) editor, try the [Sublime-Swift-Format plugin](https://github.com/aerobounce/Sublime-Swift-Format) by [Aerobounce](https://github.com/aerobounce).\n\n\nNova plugin\n-----------\n\nIf you prefer to use the [Nova](https://panic.com/nova) editor, try the [SwiftFormat extension](https://extensions.panic.com/extensions/org.padraig/org.padraig.SwiftFormat/) by [PÃ¡draig Ã“ CinnÃ©ide](https://mastodon.social/@PadraigOCinneide).\n\n\nGit pre-commit hook\n---------------------\n\n1. Follow the instructions for installing the SwiftFormat command-line tool.\n\n2. Install [git-format-staged](https://github.com/hallettj/git-format-staged).\n\n3. Edit or create a `.git/hooks/pre-commit` file in your project folder. The .git folder is hidden but should already exist if you are using Git with your project, so open it with the terminal, or the Finder's `Go > Go to Folder...` menu.\n\n4. Add the following line in the pre-commit file. The `{}` will be replaced automatically by the path to the Swift file being formatted:\n\n    ```bash\n    #!/bin/bash\n    git-format-staged --formatter \"swiftformat stdin --stdin-path '{}'\" \"*.swift\"\n    ```\n    \n    (Note that this example uses your locally installed version of SwiftFormat, not a separate copy in your project repository. You can replace `swiftformat` with the path to a copy inside your project if you prefer.)\n    \n5. enable the hook by typing `chmod +x .git/hooks/pre-commit` in the terminal.\n \nThe pre-commit hook will now run whenever you run `git commit`. Running `git commit --no-verify` will skip the pre-commit hook.\n\n**NOTE:** If you are using Git via a GUI client such as [Tower](https://www.git-tower.com), [additional steps](https://www.git-tower.com/help/mac/faq-and-tips/faq/hook-scripts) may be needed.\n\n**NOTE (2):** Unlike the Xcode build phase approach, git pre-commit hook won't be checked in to source control, and there's no way to guarantee that all users of the project are using the same version of SwiftFormat. For a collaborative project, you might want to consider a *post*-commit hook instead, which would run on your continuous integration server.\n\nGitHub Actions\n---------------------\n\n1. SwiftFormat comes preinstalled on all macOS GitHub-hosted runners. If you are self hosting you will need to ensure SwiftFormat is installed on your runner.\n2. Create a GitHub Actions workflow using SwiftFormat, passing the `--reporter github-actions-log` command line option. The following example action lints pull requests using SwiftFormat, reporting warnings using the GitHub Actions log.\n```yaml\n# Lint.yml\nname: Lint\non: pull_request\n\njobs:\n  Lint:\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: SwiftFormat\n        run: swiftformat --lint . --reporter github-actions-log\n```\n\nOn CI using Danger\n-------------------\n\nTo setup SwiftFormat to be used by your continuous integration system using [Danger](http://danger.systems/ruby/), do the following:\n\n1. Follow the [`instructions`](http://danger.systems/guides/getting_started.html) to setup Danger.\n2. Add the [`danger-swiftformat`](https://github.com/garriguv/danger-ruby-swiftformat) plugin to your `Gemfile`.\n3. Add the following to your `Dangerfile`:\n\n    ```ruby\n    swiftformat.binary_path = \"/path/to/swiftformat\" # optional\n    swiftformat.additional_args = \"--indent tab --self insert\" # optional\n    swiftformat.check_format(fail_on_error: true)\n    ```\n\n    **NOTE:** It is recommended to add the `swiftformat` binary to your project directory to ensure the same version is used each time (see the [Xcode build phase](#xcode-build-phase) instructions above).\n\n\nBazel Build\n-----------\n\nIf you use [Bazel](https://bazel.build/) to build your Swift projects and want to ensure that only properly formatted code is merged to your main branch, try [rules_swiftformat](https://github.com/cgrindel/rules_swiftformat). The repository contains Bazel rules and macros that format Swift source files using SwiftFormat, test that the formatted files exist in the workspace directory, and copy the formatted files to the workspace directory.\n\n\nDocker\n-----------\n\nSwiftFormat publishes releases into [GitHub Packages](https://github.com/features/packages) Docker registry. To pull the image call:\n\n```bash\n$ docker pull ghcr.io/nicklockwood/swiftformat:latest\n```\n\nBy default, the container runs `swiftformat .` Therefore, you need to provide a path either via an argument:\n\n```bash\ndocker run --rm -v /local/source/path:/work ghcr.io/nicklockwood/swiftformat:latest /work\n```\n\nor by changing the working dir:\n\n```bash\ndocker run --rm -v /local/source/path:/work -w /work ghcr.io/nicklockwood/swiftformat:latest\n```\n\nTo check the installed SwiftFormat version:\n\n```bash\ndocker run --rm ghcr.io/nicklockwood/swiftformat:latest --version\n```\n\nLinting example:\n\n```bash\ndocker run --rm -v /local/source/path:/work ghcr.io/nicklockwood/swiftformat:latest /work --lint\n```\n\nPrerelease Builds\n-----------------\n\n***Prerelease builds are subject to breaking changes.***\n\nNew rules, options, and fixes are merged to the [`develop`](https://github.com/nicklockwood/SwiftFormat/commits/develop/) branch before being incorporated into an official release. You may want to use a prerelease version of SwiftFormat that includes the latest unreleased changes.\n\n**Homebrew:**\n\nThe [Homebrew](http://brew.sh/) `--HEAD` option downloads, builds, and installs the latest changes from the `develop` branch. \n\nYou can install a prerelease build via Homebrew by running:\n\n```bash\n$ brew install swiftformat --HEAD\n```\n\n**Nightly Builds:**\n\nNightly builds of the `develop` branch are available in the [calda/SwiftFormat-nightly](https://github.com/calda/SwiftFormat-nightly) repo. A new release is published every day, unless there have been no changes to `develop` since the last release. You can download executables for the latest nightly release [here](https://github.com/calda/SwiftFormat-nightly/releases/latest).\n\nCommit SHAs on `develop` are unstable since that branch is occasionally rebased, but artifact URLs and tags in [calda/SwiftFormat-nightly](https://github.com/calda/SwiftFormat-nightly) are stable references that can be used from other repos or tools.\n\nConfiguration\n-------------\n\nSwiftFormat's configuration is split between **rules** and **options**. Rules are functions in the SwiftFormat library that apply changes to the code. Options are settings that control the behavior of the rules. \n\n\nOptions\n-------\n\nThe options available in SwiftFormat can be displayed using the `--options` command-line argument. The default value for each option is indicated in the help text.\n\nRules are configured by adding `--[option_name] [value]` to your command-line arguments, or by creating a `.swiftformat` [config file](#config-file) and placing it in your project directory.\n\nA given option may affect multiple rules. Use `--rule-info [rule_name]` command for details about which options affect a given rule, or see the [Rules.md](https://github.com/nicklockwood/SwiftFormat/blob/main/Rules.md) file.\n\nYou can configure options for specific files or code ranges by using `swiftformat:options` directive in comments inside your Swift file. To temporarily set one or more options inside a source file, use:\n\n```swift\n// swiftformat:options --indent 2 --allman true\n```\n\nTo apply an options override only to a particular line, use the `:this`, `:next` or `:previous` modifiers:\n\n```swift\nlet indexUrl: URL // swiftformat:options:this --preserve-acronyms url \n\n// swiftformat:options:next --semicolons inline\ndoTheThing(); print(\"Did the thing\")\n```\n\n\nRules\n-----\n\nSwiftFormat includes over 50 rules, and new ones are added all the time. An up-to-date list can be found in [Rules.md](https://github.com/nicklockwood/SwiftFormat/blob/main/Rules.md) along with documentation for how they are used.\n\nThe list of available rules can be displayed within the command-line app using the `--rules` argument. Rules can be either enabled or disabled. Most are enabled by default. Disabled rules are marked with \"(disabled)\" when displayed using `--rules`.\n\nYou can use the `--rule-info [rule_name]` command to get information about a specific rule. Pass a comma-delimited list of rule names to get information for multiple rules at once, or use `--rule-info` with no argument for info on all rules.\n\nYou can disable rules individually using `--disable` followed by a list of one or more comma-delimited rule names, or enable opt-in rules using `--enable` followed by the rule names:\n\n```bash\n--disable redundantSelf,trailingClosures\n--enable isEmpty\n```\n\nIf you prefer, you can use multiple `--enable`/`--disable` arguments instead of using commas:\n\n```bash\n--disable indent\n--disable linebreaks\n--disable redundantSelf\n```\n\nAlternatively, you can use the line continuation character `\\` to wrap a single argument over multiple line:\n\n```bash         \n--disable          \\\n    indent,        \\\n    linebreaks,    \\\n    redundantSelf\n```\n\nTo avoid automatically opting-in to new rules when SwiftFormat is updated, you can disable all rules using:\n\n```bash\n--disable all\n```\n\nAnd then individually enable just the rules you want. Alternatively, use the`--rules` argument to *only* enable the rules you specify:\n\n```bash\n--rules indent,linebreaks\n```\n\nAs above, you may include multiple `--rules` arguments, or use the line continuation character `\\` to wrap the rules onto separate lines:\n\n```bash\n--rules redundantSelf\n--rules         \\\n    indent,     \\\n    linebreaks\n```\n\nTo see exactly which rules were applied to a given file, you can use the `--verbose` command-line option to force SwiftFormat to print a more detailed log as it applies the formatting. **NOTE:** running in verbose mode is slower than the default mode.\n\nYou can disable rules for specific files or code ranges by using `swiftformat:` directives in comments inside your Swift file. To temporarily disable one or more rules inside a source file, use:\n\n```swift\n// swiftformat:disable <rule1> [<rule2> [rule<3> ...]]\n```\n\nTo enable the rule(s) again, use:\n\n```swift\n// swiftformat:enable <rule1> [<rule2> [rule<3> ...]]\n```\n\nTo disable all rules use:\n\n```swift\n// swiftformat:disable all\n```\n\nAnd to enable them all again, use:\n\n```swift\n// swiftformat:enable all\n```\n\nTo temporarily prevent one or more rules being applied to just the next line, use:\n\n```swift\n// swiftformat:disable:next <rule1> [<rule2> [rule<3> ...]]\nlet foo = bar // rule(s) will be disabled for this line\nlet bar = baz // rule(s) will be re-enabled for this line\n```\n\nYou can also use `this` or `previous` to enable or disable rules for the current or previous line. There is no need to manually re-enable a rule after using the `next`, `this` or `previous` directives.\n\n**NOTE:** The `swiftformat:enable` directive only serves to counter a previous `swiftformat:disable` directive in the same file. It is not possible to use `swiftformat:enable` to enable a rule that was not already enabled when formatting started.\n\n\nSwift version\n-------------\n\nMost SwiftFormat rules are version-agnostic, but some are applicable only to newer Swift versions. These rules will be disabled automatically if the Swift version is not specified, so to make sure that the full functionality is available you should specify the version of Swift that is used by your project.\n\nYou can specify the Swift compiler version in one of two ways:\n\nYou can specify your project's Swift compiler version using the `--swift-version` command line argument. You can also add the `--swift-version` option to your `.swiftformat` file.\n\nAnother option is to add a `.swift-version` file to your project directory. This is a text file that should contain the minimum Swift version supported by your project, and is also supported by some other tools. Any `.swift-version` files always take precedence over the `--swift-version` argument.\n\nBoth the `.swift-version` file and the `--swift-version` option in a `.swiftformat` file are applied hierarchically; If you have submodules in your project that use a different Swift version, you can add separate swift version configurations for those directories.\n\nSwift language mode\n-------------------\n\nSwiftFormat also allows you to specify the Swift _language mode_ used by your project. This is distinct from the Swift compiler version. For example, you can use the Swift 6.0 compiler with either the Swift 5 language mode or the Swift 6 language mode. Some SwiftFormat rules will behave differently under different Swift language modes.\n\nYou can specify your project's Swift language mode using the `--language-mode` command line argument. You can also add the `--language-mode` option to your `.swiftformat` file.\n\nIf not specified, SwiftFormat uses the default language mode of the specified Swift compiler version. The default language mode in Swift 5.x and Swift 6.x is the Swift 5 language mode. If your project uses the Swift 6 language mode, you should specify `--language-mode 6`.\n\n\nConfig file\n-----------\n\nAlthough it is possible to configure SwiftFormat directly by using the command-line [options](#options) and [rules](#rules) detailed above, it is sometimes more convenient to create a configuration file, which can be added to your project and shared with other developers.\n\nA SwiftFormat configuration file consists of one or more command-line options, split onto separate lines, e.g:\n\n```\n--allman true\n--indent tab\n--disable elseOnSameLine,semicolons\n```\n\nWhile formatting, SwiftFormat will automatically check inside each subdirectory for the presence of a `.swiftformat` file and will apply any options that it finds there to the files in that directory.\n\nThis allows you to override certain rules or formatting options just for a particular directory of files. You can also specify excluded files relative to that directory using `--exclude`, which may be more convenient than specifying them at the top-level:\n\n```\n--exclude Pods,Generated\n```\n\nThe `--exclude` option takes a comma-delimited list of file or directory paths to exclude from formatting. Excluded paths are relative to the config file containing the `--exclude` command. The excluded paths can include wildcards, specified using Unix \"Glob\" syntax, as [documented below](#globs).\n\nConfig files named \".swiftformat\" will be processed automatically, however, you can select an additional configuration file to use for formatting using the `--config \"path/to/config/file\"` command-line argument. A configuration file selected using `--config` does not need to be named \".swiftformat\", and can be located outside of the project directory.\n\nThe config file format is designed to be edited by hand. You may include blank lines for readability, and can also add comments using a hash prefix (#), e.g.\n\n```\n# format options\n--allman true\n--indent tab # tabs FTW!\n\n# file options\n--exclude Pods\n\n# rules\n--disable elseOnSameLine,semicolons\n```\n\nYou can create multiple configuration sections within a single `.swiftformat` file to apply different formatting options to different parts of your project. Each section should specify a `--filter` glob pattern to determine which files the configuration applies to. Options in that section are used when formatting files that match `--filter` glob, in addition to the base options in the file.\n\n```\n--enable indent\n--indent 4\n\n[Tests]\n--filter **/Tests/**\n--enable noForceUnwrapInTests\n--enable noForceTryInTests\n--indent 2\n```\n\nIf you would prefer not to edit the configuration file by hand, you can use the [SwiftFormat for Xcode](#xcode-source-editor-extension) app to edit the configuration and export a configuration file. You can also use the swiftformat command-line-tool's `--inferoptions` command to generate a config file from your existing project, like this:\n\n```bash\n$ cd /path/to/project\n$ swiftformat --infer-options . --output .swiftformat\n```\n\nGlobs\n-----\n\nWhen excluding files from formatting using the `--exclude` option, you may wish to make use of wildcard paths (aka \"Globs\") to match all files that match a particular naming convention without having to manually list them all.\n\nSwiftFormat's glob syntax is based on Ruby's implementation, which varies slightly from the Unix standard. The following patterns are supported:\n\n* `*` - A single star matches zero or more characters in a filename, but *not* a `/`.\n\n* `**` - A double star will match anything, including one or more `/`.\n\n* `?` - A question mark will match any single character except `/`.\n\n* `[abc]` - Matches any single character inside the brackets.\n\n* `[a-z]` - Matches a single character in the specified range in the brackets.\n\n* `{foo,bar}` - Matches any one of the comma-delimited strings inside the braces.\n\nExamples:\n\n* `foo.swift` - Matches the file \"foo.swift\" in the same directory as the config file.\n\n* `*.swift` - Matches any Swift file in the same directory as the config file.\n\n* `foo/bar.swift` - Matches the file \"bar.swift\" in the directory \"foo\".\n\n* `**/foo.swift` - Matches any file named \"foo.swift\" in the project.\n\n* `**/*.swift` - Matches any Swift file in the project.\n\n* `**/Generated` - Matches any folder called `Generated` in the project.\n\n* `**/*_generated.swift` - Matches any Swift file with the suffix \"_generated\" in the project.\n\n\nLinting\n-------\n\nSwiftFormat is primarily designed as a formatter rather than a linter, i.e. it is designed to fix your code rather than tell you what's wrong with it. However, sometimes it can be useful to verify that code has been formatted in a context where it is not desirable to actually change it.\n\nA typical example would be as part of a CI (Continuous Integration) process, where you may wish to have an automated script that checks committed code for style violations. While you can use a separate tool such as [SwiftLint](https://github.com/realm/SwiftLint) for this, it makes sense to be able to validate the formatting against the exact same rules as you are using to apply it.\n\nIn order to run SwiftFormat as a linter, you can use the `--lint` command-line option:\n\n```bash\n$ swiftformat --lint path/to/project\n```\n\nThis runs the same rules as format mode, and all the same configuration options apply, however, no files will be modified. Instead, SwiftFormat will format each file in memory and then compare the result against the input and report the lines that required changes.\n\nThe `--lint` option is similar to `--dry-run`, but `--lint` returns warnings for every line that required changes, and will return a nonzero error code (see [Error codes](#error-codes) below) if any changes are detected, which is useful if you want it to fail a build step on your CI server.\n\nIf you would prefer `--lint` not to fail your build, you can use the `--lenient` option to force SwiftFormat to return success in `--lint` mode even when formatting issues were detected.\n\n```bash\n$ swiftformat --lint --lenient path/to/project\n```\n\nBy default, `--lint` will only report lines that require formatting, but you can use the additional `--verbose` flag to display additional info about which files were checked, even if there were no changes needed.\n\nIf you would prefer not to see a warning for each and every formatting change, you can use the `--quiet` flag to suppress all output except errors.\n\nSometimes you may wish to autoformat some rules, but only lint others. To do that, use the `--lintonly` option in your config file to specify rules that should only be applied in `--lint` mode:\n\n```\n--rules braces,indent\n--lint-only trailingClosures,unusedArguments\n```\n\n\nError codes\n-----------\n\nThe swiftformat command-line tool will always exit with one of the following codes:\n\n* 0 - Success. This code will be returned in the event of a successful formatting run or if `--lint` detects no violations.\n* 1 - Lint failure. This code will be returned when running in `--lint` mode, or when autocorrecting in `--strict` mode, if the input requires formatting.\n* 70 - Program error. This code will be returned if there is a problem with the input or configuration arguments.\n\n\nCache\n------\n\nSwiftFormat uses a cache file to avoid reformatting files that haven't changed. For a large project, this can significantly reduce processing time.\n\nBy default, the cache is stored in `~/Library/Caches/com.charcoaldesign.swiftformat` on macOS, or `/tmp/com.charcoaldesign.swiftformat` on Linux. Use the command-line option `--cache ignore` to ignore the cached version and re-apply formatting to all files. Alternatively, you can use `--cache clear` to delete the cache (or you can just manually delete the cache file).\n\nThe cache is shared between all projects. The file is fairly small, as it only stores the path and size for each file, not the contents. If you do start experiencing slowdown due to the cache growing too large, you might want to consider using a separate cache file for each project.\n\nYou can specify a custom cache file location by passing a path as the `--cache` option value. For example, you might want to store the cache file inside your project directory. It is fine to check in the cache file if you want to share it between different users of your project, as the paths stored in the cache are relative to the location of the formatted files.\n\n\nFile headers\n-------------\n\nSwiftFormat can be configured to strip or replace the header comments in every file with a template. The \"header comment\" is defined as a comment block that begins on the first nonblank line in the file, and is followed by at least one blank line. This may consist of a single comment body, or multiple comments on consecutive lines:\n\n```swift\n// This is a header comment\n```\n\n```swift\n// This is a regular comment\nfunc foo(bar: Int) -> Void { ... }\n```\n\nThe header template is a string that you provide using the `--header` command-line option. Passing a value of `ignore` (the default) will leave the header comments unmodified. Passing `strip` or an empty string `\"\"` will remove them. If you wish to provide a custom header template, the format is as follows:\n\nFor a single-line template: `--header \"Copyright (c) 2017 Foobar Industries\"`\n\nFor a multiline comment, mark linebreaks with `\\n`: `--header \"First line\\nSecond line\"`\n\nYou can optionally include Swift comment markup in the template if you wish: `--header \"/*--- Header comment ---*/\"`\n\nIf you do not include comment markup, each line in the template will be prepended with `//` and a single space.\n\nIt is common practice to include the file name, creation date and/or the current year in a comment header copyright notice. To do that, you can use the following placeholders:\n\n* `{file}` - the name of the file\n* `{year}` - the current year\n* `{created}` - the date on which the file was created\n* `{created.year}` - the year in which the file was created\n* `{author.name}` - the name of the user who first committed the file\n* `{author.email}` - the email of the user who first committed the file \n\nFor example, a header template of:\n\n```bash\n--header \"{file}\\nCopyright (c) {year} Foobar Industries\\nCreated by John Smith on {created}.\"\n```\n\nWill be formatted as:\n\n```swift\n// SomeFile.swift\n// Copyright (c) 2019 Foobar Industries\n// Created by John Smith on 01/02/2016.\n```\n\n**NOTE:** the `{year}` value and `{created}` date format are determined from the current locale and timezone of the machine running the script. `{author.name}` and `{author.email}` requires the project to be version controlled by git.\n\n\nMarkdown formatting\n-------------------\n\nSwiftFormat can format Swift code blocks inside Markdown files (`.md`). This is useful for keeping code examples in documentation, README files, and other markdown content properly formatted.\n\n````diff\n  ### Sample README\n  \n  This is a nice project with lots of cool APIs to know about, including:\n  \n  ```swift\n  func foo(\n- bar: Bar,\n- baaz: Baaz\n+     bar: Bar,\n+     baaz: Baaz\n  ) -> Foo { ... }\n  ```\n````\n\nTo format Swift code blocks in markdown files, use the `--markdown-files` option with either `strict` or `lenient`:\n\n```bash\n$ swiftformat . --markdown-files strict\n$ swiftformat . --markdown-files lenient\n```\n\nOr add it to your `.swiftformat` config file:\n\n```\n--markdown-files strict\n```\n\n**Formatting modes:**\n\nSwiftFormat supports two modes for handling markdown files:\n\n- `lenient` (default): Ignores parsing errors in code blocks and continues formatting\n- `strict`: Fails if any code blocks contain parsing errors\n\nSwiftFormat's tokenizer is more permissive than the Swift compiler and typically only emits errors when encountering unbalanced scope tokens like `(` or `{`.\n\n**Code block options:**\n\nYou can specify options for options for individual code blocks by adding them after the opening delimiter. For example, you can use `no-format` to prevent a code block from being parsed or formatted:\n\n````md\n```swift no-format\nfunc example()\n{\n    doSomething()\n}\n```\n````\n\nYou can also specify SwiftFormat command line options to configure the behavior of individual rules:\n\n````md\n```swift --indent 2\nfunc example() {\n  doSomething()\n}\n```\n\n```swift --disable redundantSelf\nfunc example() {\n    self.doSomething()\n}\n```\n````\n\nFAQ\n-----\n\n*Q. How is this different from SwiftLint?*\n\n> A. SwiftLint is primarily designed to find and report code smells and style violations in your code. SwiftFormat is designed to fix them. While SwiftLint can autocorrect some issues, and SwiftFormat has some support for [linting](#linting), their primary functions are different.\n\n\n*Q. Can SwiftFormat and SwiftLint be used together?*\n\n> A. Absolutely! The style rules encouraged by both tools are quite similar, and SwiftFormat even fixes some style violations that SwiftLint warns about but can't currently autocorrect.\n\n\n*Q. What platforms does SwiftFormat support?*\n\n> A. SwiftFormat works on macOS 10.13 (High Sierra) and above, and also runs on Ubuntu Linux and Windows.\n\n\n*Q. What versions of Swift are supported?*\n\n> A. The SwiftFormat framework and command-line tool can be compiled using Swift 5.3 and above, and can format programs written in Swift 4.x or 5. Swift 3.x is no longer actively supported. If you are still using Swift 3.x or earlier and find that SwiftFormat breaks your code, the best solution is probably to revert to an earlier SwiftFormat release, or enable only a small subset of rules. Use the `--swift-version` argument to enable additional rules specific to later Swift versions.\n\n\n*Q. SwiftFormat made changes I didn't want it to. How can I find out which rules to disable?*\n\n> A. If you run SwiftFormat using the `--verbose` option, it will tell you which rules were applied to each file. You can then selectively disable certain rules using the `--disable` argument (see below).\n\n\n*Q. People on my team have different SwiftFormat versions installed. How can we ensure consistent formatting?\n\n> A. You can specify a `--min-version` argument in your project's .swiftformat` file to fail the build if developers attempt to use an older SwiftFormat version.\n\n\n*Q. How can I modify the formatting rules?*\n\n> A. Many configuration options are exposed in the command-line interface or `.swiftformat` configuration file. You can either set these manually, or use the `--infer-options` argument to automatically generate the configuration from your existing project.\n\n> If there is a rule that you don't like, and which cannot be configured to your liking via the command-line options, you can disable one or more rules by using the `--disable` argument, followed by the name of the rules, separated by commas. You can display a list of all supported rules using the `--rules` argument, and their behaviors are documented above this section in the README.\n\n> If you are using the Xcode source editor extension, rules and options can be configured using the [SwiftFormat for Xcode](#xcode-source-editor-extension) host application. Unfortunately, due to limitation of the Extensions API, there is no way to configure these on a per-project basis.\n\n> If the options you want aren't exposed, and disabling the rule doesn't solve the problem, the rules are implemented in the file `Rules.swift`, so you can modify them and build a new version of the command-line tool. If you think your changes might be generally useful, make a pull request.\n\n\nQ. I don't want to be surprised by new rules added when I upgrade SwiftFormat. How can I prevent this?\n\n> A. You can use the `--rules` argument to specify an exclusive list of rules to run. If new rules are added, they won't be enabled if you have specified a `--rules` list in your SwiftFormat configuration.\n\n\n*Q. Why can't I set the indent width or choose between tabs/spaces in the [SwiftFormat for Xcode](#xcode-source-editor-extension) options?*\n\n> Indent width and tabs/spaces can be configured in Xcode on a per project-basis. You'll find the option under \"Text Settings\" in the Files inspector of the right-hand sidebar.\n\n\n*Q. After applying SwiftFormat, my code won't compile. Is that a bug?*\n\n> A. SwiftFormat should ideally never break your code. Check the [known issues](#known-issues), and if it's not already listed there, or the suggested workaround doesn't solve your problem, please [open an issue on GitHub](https://github.com/nicklockwood/SwiftFormat/issues).\n\n\n*Q. Can I use SwiftFormat to lint my code without changing it?*\n\n> A. Yes, see the [linting](#linting) section above for details.\n\n\n*Q. Can I use the `SwiftFormat.framework` inside another app?*\n\n> A. Yes, the SwiftFormat framework can be included in an app or test target, and used for many kinds of parsing and processing of Swift source code besides formatting. The SwiftFormat framework is available as a [CocoaPod](https://cocoapods.org/pods/SwiftFormat) for easy integration.\n\n*Q. How to create own rule?*\n\n> A. 1) Open `SwiftFormat.xcodeproj`; 2) Add a rule in `Sources/Rules/..`; 3) Add a test in `Tests/Rules/..`; 4) Add an example in `Sources/Examples.swift`; 5) Run all tests.\n\n*Q. How do I run and debug the command line tool in Xcode while developing a new rule?*\n\n> A. You can run the `swiftformat` command line tool via the `Swift Format (Command Line Tool)` scheme, and you can pass in arguments like `/path/to/my/code --config /path/to/my/config` as the `Arguments Passed On Launch` in Xcode's scheme editor. More instructions are available [here](https://github.com/nicklockwood/SwiftFormat/pull/1804#issuecomment-2263079432).\n\nKnown issues\n---------------\n\n* When using the Xcode Source Editor Extension, the SwiftFormat menu sometimes disappears from Xcode. If this happens, try moving or renaming Xcode temporarily and then changing it back. Failing that, the suggestions in [this thread](https://github.com/nicklockwood/SwiftFormat/issues/494) may help.\n\n* The `enumNamespaces` rule replaces classes that have only static members with an `enum`. If the class is subclassed, or if there is code that depends on the class exposing certain runtime behaviors, this may break the program. To solve this you can either fix it on a per-case basis by adding a `// swiftformat:disable:next enumNamespaces` comment directive above the class declaration, or you can add `--enum-namespaces structs-only` to prevent the rule being applied to classes, or you can just disable the `enumNamespaces` rule completely.\n\n* The `redundantVoidReturnType` rule can inadvertently alter the type signature for closures, for example in cases where the closure calls a `@discardableResult` function. To solve this you can either fix it on a per-case basis by adding a `// swiftformat:disable:next redundantVoidReturnType` comment directive to disable the rule for a specific call site, or you can add `--closure-void preserve` to your [configuration](#configuration) to disable the rule completely for closures (regular functions or methods aren't affected).\n\n* The `redundantType` rule can introduce ambiguous code in certain cases when using the default mode of `--redundant-type inferred`. This can be worked around by by using `--redundant-type explicit`, or by manually removing the redundant type reference on the affected line, or by using the `// swiftformat:disable:next redundantType` comment directive to disable the rule at the call site (or just disable the `redundantType` rule completely).\n\n* If a type initializer or factory method returns an implicitly unwrapped optional value then the `redundantType` rule may remove the explicit type in a situation where it's actually required. To work around this you can either use `--redundant-type explicit`, or use the `// swiftformat:disable:next redundantType` comment directive to disable the rule at the call site (or just disable the `redundantType` rule completely).\n\n* When using the `initCoderUnavailable` rule, if an `init` that is marked as unavailable is overridden elsewhere in the program then it will cause a compilation error. The recommended workaround is to remove the override (which shouldn't affect the program behavior if the init was really unused) or use the `// swiftformat:disable:next initCoderUnavailable` comment directive to disable the rule for the overridden init (or just disable the `initCoderUnavailable` rule completely).\n\n* When using the `extensionAccessControl` rule with the `--extension-acl on-extension` option, if you have public methods defined on an internal type defined in another file, the resultant public extension will no longer compile. The recommended solution is to manually remove the `public` modifier (this won't change the program behavior) or disable the `extensionAccessControl` rule.\n\n* When using the `preferKeyPath` rule, conversion of `compactMap { $0.foo }` to `compactMap(\\.foo)` or `flatMap { $0.foo }` to `flatMap(\\.foo)` will result in code that fails to compile if `foo` is not an `Optional` property. This is due to a difference in the way that Swift handles type inference for closures vs keyPaths, as discussed [here](https://bugs.swift.org/browse/SR-13347). The recommended workaround is to replace `compactMap()` or `flatMap()` with `map()` in these cases, which will not change the behavior of the code.\n\n* When using the `--self remove` option, the `redundantSelf` rule will remove references to `self` in autoclosure arguments, which may change the meaning of the code, or cause it not to compile. To work around this issue, use the `--self-required` option to provide a comma-delimited list of methods to be excluded from the rule. The `expect()` function from the popular [Nimble](https://github.com/Quick/Nimble) unit testing framework is already excluded by default. If you are using the `--self insert` option then this is not an issue.\n\n* If you assign `SomeClass.self` to a variable and then instantiate an instance of the class using that variable, Swift requires that you use an explicit `.init()`, however, the `redundantInit` rule is not currently capable of detecting this situation in all cases, and may remove the `.init`. To work around this issue, use the `// swiftformat:disable:next redundantInit` comment directive to disable the rule for any affected lines of code (or just disable the `redundantInit` rule completely).\n\n* The `--self insert` option can only recognize locally declared member variables, not ones inherited from superclasses or extensions in other files, so it cannot insert missing `self` references for those. Note that the reverse is not true: `--self remove` should remove *all* redundant `self` references.\n\n* The `trailingClosures` rule can generate ambiguous code if a function has multiple optional closure arguments, or if multiple functions have signatures differing only by the name of the closure argument. For this reason, the rule is limited to anonymous closure arguments by default. You can use the `--trailing-closures` and `--never-trailing` arguments to explicitly opt in or out of trailing closure support for specific functions.\n\n* The `isEmpty` rule will convert `count == 0` to `isEmpty` even for types that do not have an `isEmpty` method, such as `NSArray`/`NSDictionary`/etc. Use of Foundation collections in Swift code is pretty rare, but just in case, the rule is disabled by default.\n\n* The `preferForLoop` rule will convert `foo.forEach` to `for item in foo` even for types that do not conform to the `Sequence` protocol and cannot be used with a `for ... in` loop. There are no such types built in, but custom types may have this issue.\n\n* If a file begins with a comment, the `stripHeaders` rule will remove it if it is followed by a blank line. To avoid this, make sure that the first comment is directly followed by a line of code.\n\n* When running a version of SwiftFormat built using Xcode 10.2 on macOS 10.14.3 or earlier, you may experience a crash with the error \"dyld: Library not loaded: @rpath/libswiftCore.dylib\". To fix this, you need to install the [Swift 5 Runtime Support for Command Line Tools](https://support.apple.com/kb/DL1998). These tools are included by default in macOS 10.14.4 and later.\n\n* If you have a generic typealias that defines a closure (e.g. `typealias ResultCompletion<T> = (Result<T, Error>) -> Void`) and use this closure as an argument in a generic function (e.g. `func handle<T: Decodable>(_ completion: ResultCompletion<T>)`), the `opaqueGenericParameters` rule may update the function definition to use `some` syntax (e.g. `func handle(_ completion: ResultCompletion<some Decodable>)`). `some` syntax is not permitted in closure parameters, so this will no longer compile. Workarounds include spelling out the closure explicitly in the generic function (instead of using a `typealias`) or disabling the `opaqueGenericParameters` rule (e.g. with `// swiftformat:disable:next opaqueGenericParameters`).\n\n* If compiling for macOS with Xcode 14.0 and configuring SwiftFormat with `--swift-version 5.7`, the `genericExtensions` rule may cause a build failure by updating extensions of the format `extension Collection where Element == Foo` to `extension Collection<Foo>`. This fails to compile for macOS in Xcode 14.0, because the macOS SDK in that version of Xcode [does not include](https://forums.swift.org/t/xcode-14-rc-cannot-specialize-protocol-type/60171) the Swift 5.7 standard library. Workarounds include using `--swift-version 5.6` instead, updating to Xcode 14.1+, or disabling the `genericExtensions` rule (e.g. with `// swiftformat:disable:next genericExtensions`).\n\n* The `propertyTypes` rule can cause a build failure in cases where there are multiple static overloads with the same name but different return types. As a workaround you can rename the overloads to no longer conflict, or exclude the property name with `--preserve-symbols propertyName,otherPropertyName,etc`.\n\n* The `propertyTypes` rule can cause a build failure in cases where the property's type is a protocol / existential like `let shapeStyle: ShapeStyle = .myShapeStyle`, and the value used on the right-hand side is defined in an extension like `extension ShapeStyle where Self == MyShapeStyle { static var myShapeStyle: MyShapeStyle { ... } }`. As a workaround you can use the existential `any` syntax (`let shapeStyle: any ShapeStyle = .myShapeStyle`), which the rule will preserve as-is, or exclude the type name and/or property name with `--preserve-symbols ShapeStyle,myShapeStyle,etc`.\n\n* The `propertyTypes` rule can cause a build failure in cases like `let foo = Foo.bar` where the value is a static member that doesn't return the same time. For example, `let foo: Foo = .bar` would be invalid if the `bar` property was defined as `static var bar: Bar`. As a workaround you can write the name of the type explicitly, like `let foo: Bar = Foo.bar`, or exclude the type name and/or property name with `--preserve-symbols Bar,bar,etc`.\n\n\nTip Jar\n-----------\n\nSwiftFormat is not a commercially-funded product, it's a labor of love given freely to the community. If you find it useful, please consider making a donation.\n\n[![Donate via PayPal](https://www.paypalobjects.com/en_GB/i/btn/btn_donate_LG.gif)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=9ZGWNK5FEZFF6&source=url)\n\n\nCredits\n------------\n\n* [Cal Stephens](https://github.com/calda) - Numerous new formatting rules, options and bug fixes\n* [Tony Arnold](https://github.com/tonyarnold) - SwiftFormat for Xcode\n* [Vincent Bernier](https://github.com/vinceburn) - SwiftFormat for Xcode settings UI\n* [Vikram Kriplaney](https://github.com/markiv) - SwiftFormat for Xcode icon and search feature\n* [Hyperphonic](https://github.com/hyperphonic0) - Xcode 12 compatibility for SwiftFormat\n* [Maxime Marinel](https://github.com/bourvill) - Git pre-commit hook script\n* [Romain Pouclet](https://github.com/palleas) - Homebrew formula\n* [Aerobounce](https://github.com/aerobounce) - Homebrew cask and Sublime Text plugin\n* [Facundo Menzella](https://github.com/facumenzella) - Several new formatting rules and options\n* [Ali Akhtarzada](https://github.com/aliak00) - Several path-related CLI enhancements\n* [Yonas Kolb](https://github.com/yonaskolb) - Swift Package Manager integration\n* [Wolfgang Lutz](https://github.com/Lutzifer) - AppleScript integration instructions\n* [BalÃ¡zs KilvÃ¡dy](https://github.com/balitm) - Xcode lint warning integration\n* [Anthony Miller](https://github.com/AnthonyMDev) - Improvements to wrap/indent logic\n* [Shingo Takagi](https://github.com/zizi4n5) - Several brace-related bug fixes\n* [Benedek Kozma](https://github.com/cyberbeni) - Lint-only rules option\n* [Juri Pakaste](https://github.com/juri) - Filelist feature\n* [Jim Puls](https://github.com/puls) - Big Sur icon update\n* [Daniele Formichelli](https://github.com/danyf90) - JSON reporter\n* [Jonas Boberg](https://github.com/bobergj) - Github actions log reporter\n* [Mahdi Bchatnia](https://github.com/inket) - Linux build workflow\n* [Saleem Abdulrasool](https://github.com/compnerd) - Windows build workflow\n* [Arthur Semenyutin](https://github.com/vox-humana) - Docker image\n* [Marco Eidinger](https://github.com/MarcoEidinger) - Swift Package Manager plugin\n* [Hampus TaÌŠgerud](https://github.com/hampustagerud) - Git integration for fileHeader rule\n* [Nick Lockwood](https://github.com/nicklockwood) - Everything else\n\n([Full list of contributors](https://github.com/nicklockwood/SwiftFormat/graphs/contributors))\n",
      "stars_today": 0
    },
    {
      "id": 16146440,
      "name": "rmarkdown",
      "full_name": "rstudio/rmarkdown",
      "description": "Dynamic Documents for R",
      "html_url": "https://github.com/rstudio/rmarkdown",
      "stars": 3013,
      "forks": 996,
      "language": "R",
      "topics": [
        "literate-programming",
        "markdown",
        "pandoc",
        "r",
        "r-package",
        "rmarkdown"
      ],
      "created_at": "2014-01-22T17:25:19Z",
      "updated_at": "2026-01-21T15:22:20Z",
      "pushed_at": "2025-11-26T19:36:51Z",
      "open_issues": 264,
      "owner": {
        "login": "rstudio",
        "avatar_url": "https://avatars.githubusercontent.com/u/513560?v=4"
      },
      "readme": "# rmarkdown <a href=\"https://pkgs.rstudio.com/rmarkdown/\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" /></a>\n\n\n<!-- badges: start -->\n[![R-CMD-check](https://github.com/rstudio/rmarkdown/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/rstudio/rmarkdown/actions/workflows/R-CMD-check.yaml)\n[![CRAN release](https://www.r-pkg.org/badges/version/rmarkdown)](https://cran.r-project.org/package=rmarkdown)\n[![Codecov test coverage](https://codecov.io/gh/rstudio/rmarkdown/branch/main/graph/badge.svg)](https://app.codecov.io/gh/rstudio/rmarkdown?branch=main)\n<!-- badges: end -->\n\n\nThe **rmarkdown** package helps you create dynamic analysis documents that combine code, rendered output (such as figures), and prose. You bring your data, code, and ideas, and R Markdown renders your content into a polished document that can be used to:\n\n- Do data science interactively within the RStudio IDE,\n\n- Reproduce your analyses,\n\n- Collaborate and share code with others, and\n\n- Communicate your results with others.\n\nR Markdown documents can be rendered to many output formats including HTML documents, PDFs, Word files, slideshows, and more, allowing you to focus on the content while R Markdown takes care of your presentation. \n\n## Books\n\n<a href=\"https://bookdown.org/yihui/rmarkdown/\"><img class=\"book\" src=\"https://bookdown.org/yihui/rmarkdown/images/cover.png\" alt=\"R Markdown: The Definitive Guide\" height=\"400\"></a>\n<a href=\"https://bookdown.org/yihui/rmarkdown-cookbook/\"><img class=\"book\" src=\"https://bookdown.org/yihui/rmarkdown-cookbook/images/cover.png\" alt=\"R Markdown Cookbook\" height=\"400\"></a>\n\nSee more about them in [Get Started](https://pkgs.rstudio.com/rmarkdown/articles/rmarkdown.html).\n\n## Installation\n\nThe easiest way to install the **rmarkdown** package is from within the [RStudio IDE](https://posit.co/download/rstudio-desktop/), but you don't need to explicitly install it or load it, as RStudio automatically does both when needed. A recent version of Pandoc (>= 1.12.3) is also required; RStudio also automatically includes this too so you do not need to download Pandoc if you plan to use rmarkdown from the RStudio IDE.\n\nIf you want to use the rmarkdown package outside of RStudio, you can install the package from CRAN as follows:\n\n```r\ninstall.packages(\"rmarkdown\")\n```\n\nIf you want to use the development version of the rmarkdown package (either with or without RStudio), you can install the package from GitHub via the [**pak** package](https://pak.r-lib.org):\n\n```r\n# install.packages(\"pak\")\npak::pak('rstudio/rmarkdown')\n```\n\nIf not using the RStudio IDE, you'll need to install a recent version of Pandoc (>= 1.12.3); see the [Pandoc installation instructions](https://pandoc.org/installing.html) for help.\n\n## Usage\n\nThe easiest way to make a new R Markdown document is from within RStudio. Go to _File > New File > R Markdown_. From the new file wizard, you may:\n\n+ Provide a document title (_optional but recommended_),\n+ Provide an author name (_optional but recommended_),\n+ Select a default output format- HTML is the recommended format for authoring, and you can switch the output format anytime (_required_), \n+ Click **OK** (_required_).\n\nOnce inside your new `.Rmd` file, you should see some boilerplate text that includes code chunks. Use the \"Knit\" button in the RStudio IDE to render the file and preview the output with a single click or use the keyboard shortcut Cmd/Ctrl + Shift + K. \n\nYou can also delete all the text below the YAML frontmatter and fill in your own `.Rmd` by:\n\n+ Adding code chunks (keyboard shortcut: `Ctrl + Alt + I`; OS X: `Cmd + Option + I`),\n+ Writing prose with [Markdown formatting](https://www.markdowntutorial.com/), and\n+ Running each code chunk interactively by clicking the ![The run button](https://rmarkdown.rstudio.com/images/notebook-run-chunk.png) icon within RStudio. \n\nYou can also click \"Knit to HTML\" again to render the full document with all code chunks. For more help getting started in R Markdown, please see the [R Markdown website](https://rmarkdown.rstudio.com/lesson-1.html) or use the **\"Get Started\"** links at the top of this page.\n\n## Getting help\n\nThere are two main places to get help:\n\n1. The [Posit community](https://forum.posit.co/c/quarto-r-markdown/10) is a friendly place to ask any questions about rmarkdown and the R Markdown family of packages.\n\n1. [Stack Overflow](https://stackoverflow.com/questions/tagged/r-markdown) is a great source of answers to common rmarkdown questions. It is also a great place to get help, once you have created a reproducible example that illustrates your problem.\n\n## Code of Conduct\n\nPlease note that the **rmarkdown** project is released with a [Contributor Code of Conduct](https://pkgs.rstudio.com/rmarkdown/CODE_OF_CONDUCT.html). By contributing to this project, you agree to abide by its terms.\n",
      "stars_today": 0
    },
    {
      "id": 35927665,
      "name": "seurat",
      "full_name": "satijalab/seurat",
      "description": "R toolkit for single cell genomics",
      "html_url": "https://github.com/satijalab/seurat",
      "stars": 2620,
      "forks": 977,
      "language": "R",
      "topics": [
        "cran",
        "human-cell-atlas",
        "single-cell-genomics",
        "single-cell-rna-seq"
      ],
      "created_at": "2015-05-20T05:23:02Z",
      "updated_at": "2026-01-23T15:32:24Z",
      "pushed_at": "2026-01-21T19:54:02Z",
      "open_issues": 314,
      "owner": {
        "login": "satijalab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8411851?v=4"
      },
      "readme": "[![CRAN Version](https://www.r-pkg.org/badges/version/Seurat)](https://cran.r-project.org/package=Seurat)\n[![CRAN Downloads](https://cranlogs.r-pkg.org/badges/Seurat)](https://cran.r-project.org/package=Seurat)\n\n\n# Seurat v5\n\nSeurat is an R toolkit for single cell genomics, developed and maintained by the Satija Lab at NYGC.\n\nWe are excited to release Seurat v5! This updates introduces new functionality for spatial, multimodal, and scalable single-cell analysis.\n\nSeurat v5 is backwards-compatible with previous versions, so that users will continue to be able to re-run existing workflows. \n\nInstructions, documentation, and tutorials can be found at:\n\n* https://satijalab.org/seurat\n\nSeurat is also hosted on GitHub, you can view and clone the repository at\n\n* https://github.com/satijalab/seurat\n\nSeurat has been successfully installed on Mac OS X, Linux, and Windows, using the devtools package to install directly from GitHub\n\nImprovements and new features will be added on a regular basis, please post on the [github page](https://github.com/satijalab/seurat) with any questions or if you would like to contribute\n\nFor a version history/changelog, please see the [NEWS file](https://github.com/satijalab/seurat/blob/master/NEWS.md).\n",
      "stars_today": 0
    },
    {
      "id": 45709704,
      "name": "sf",
      "full_name": "r-spatial/sf",
      "description": "Simple Features for R",
      "html_url": "https://github.com/r-spatial/sf",
      "stars": 1418,
      "forks": 300,
      "language": "R",
      "topics": [
        "gdal",
        "geos",
        "proj",
        "r",
        "r-package",
        "rstats",
        "spatial"
      ],
      "created_at": "2015-11-06T21:49:34Z",
      "updated_at": "2026-01-23T16:30:35Z",
      "pushed_at": "2026-01-22T21:29:46Z",
      "open_issues": 74,
      "owner": {
        "login": "r-spatial",
        "avatar_url": "https://avatars.githubusercontent.com/u/25086656?v=4"
      },
      "readme": "<!-- badges: start -->\n[![R-CMD-check](https://github.com/r-spatial/sf/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/r-spatial/sf/actions/workflows/R-CMD-check.yaml)\n[![tic-db](https://github.com/r-spatial/sf/actions/workflows/tic-db.yml/badge.svg)](https://github.com/r-spatial/sf/actions/workflows/tic-db.yml)\n[![Coverage Status](https://img.shields.io/codecov/c/github/r-spatial/sf/main.svg)](https://app.codecov.io/gh/r-spatial/sf)\n[![License](http://img.shields.io/badge/license-GPL%20%28%3E=%202%29-brightgreen.svg?style=flat)](http://www.gnu.org/licenses/gpl-2.0.html)\n[![CRAN](https://www.r-pkg.org/badges/version/sf)](https://cran.r-project.org/package=sf)\n[![cran checks](https://badges.cranchecks.info/worst/sf.svg)](https://cran.r-project.org/web/checks/check_results_sf.html)\n[![Downloads](https://cranlogs.r-pkg.org/badges/sf?color=brightgreen)](https://www.r-pkg.org/pkg/sf)\n[![status](https://tinyverse.netlify.app/badge/sf)](https://CRAN.R-project.org/package=sf)\n<!-- badges: end -->\n\n# Simple Features for R\n\n<a href=\"https://gist.github.com/edzer/f461a3a95570c4ab7edf3125c2f19d20\"><img align=\"right\" src=\"https://user-images.githubusercontent.com/520851/34887433-ce1d130e-f7c6-11e7-83fc-d60ad4fae6bd.gif\" /></a>\n\nA package that provides [simple features access](https://en.wikipedia.org/wiki/Simple_Features) for R. \n\n[Blogs, links](#blogs-presentations-vignettes-sp-sf-wiki) â€¢ [Cheatsheet](#cheatsheet) â€¢ [Installing](#installing)\nâ€¢ [Contributing](#contributing) â€¢ [Acknowledgment](#acknowledgment) â€¢ [How to cite](#how-to-cite)\n\nPackage sf:\n\n* represents simple features as records in a `data.frame` or `tibble` with a geometry list-column\n* represents natively in R all 17 simple feature types for all dimensions (XY, XYZ, XYM, XYZM)\n* interfaces to [GEOS](https://libgeos.org) for geometrical operations on projected coordinates, and (through R package [s2](https://cran.r-project.org/package=s2)) to [s2geometry](http://s2geometry.io/) for geometrical operations on ellipsoidal coordinates\n* interfaces to [GDAL](https://gdal.org/), supporting all driver options, `Date` and `POSIXct` and list-columns\n* interfaces to [PRÃ˜J](http://proj.org/) for coordinate reference system conversion and transformation\n* uses [well-known-binary](https://en.wikipedia.org/wiki/Well-known_text#Well-known_binary) serialisations written in C++/Rcpp for fast I/O with GDAL and GEOS \n* reads from and writes to spatial databases such as [PostGIS](http://postgis.net/) using [DBI](https://cran.r-project.org/package=DBI)\n* is extended by \n    * [lwgeom](https://github.com/r-spatial/lwgeom/) for selected liblwgeom/PostGIS functions\n    * [stars](https://github.com/r-spatial/stars/) for raster data, and raster or vector data cubes (spatial time series)\n    * [sfnetworks](https://luukvdmeer.github.io/sfnetworks/) for geospatial network data\n\n<a href=\"https://gist.github.com/edzer/442d74a5775abcd5068cf3e73b23687b\"><img align=\"left\" src=\"https://user-images.githubusercontent.com/520851/50280460-e35c1880-044c-11e9-9ed7-cc46754e49db.jpg\" /></a>\n\n(Illustration (c) 2018 by <a href=\"https://twitter.com/allison_horst/status/1071456081308614656\">Allison Horst</a>)\n\n## Books, journal articles, blogs, presentations, vignettes, sp-sf wiki\n\n* an open access [R Journal article](https://journal.r-project.org/archive/2018/RJ-2018-009/index.html) summarizes the package\n* two books: [Spatial Data Science: with applications in R](https://r-spatial.org/book/), [Geocomputation with R](https://r.geocompx.org/)\n* package vignettes: [first](https://r-spatial.github.io/sf/articles/sf1.html), [second](https://r-spatial.github.io/sf/articles/sf2.html), [third](https://r-spatial.github.io/sf/articles/sf3.html), [fourth](https://r-spatial.github.io/sf/articles/sf4.html), [fifth](https://r-spatial.github.io/sf/articles/sf5.html), [sixth](https://r-spatial.github.io/sf/articles/sf6.html), [seventh](https://r-spatial.github.io/sf/articles/sf7.html)\n* blog posts: [first](https://r-spatial.org/r/2016/02/15/simple-features-for-r.html), [second](https://r-spatial.org/r/2016/07/18/sf2.html), [third](https://r-spatial.org/r/2016/11/02/sfcran.html), [fourth](https://r-spatial.org/r/2017/01/12/newssf.html)\n* the original R Consortium ISC [proposal](PROPOSAL.md), the R Consortium [blog post](https://www.r-consortium.org/blog/2017/01/03/simple-features-now-on-cran)\n* presentations: [rstudio::conf 2018](https://edzer.github.io/rstudio_conf/#1) ([video](https://posit.co/resources/videos/tidy-spatial-data-analysis/)), [UseR! 2016](http://pebesma.staff.ifgi.de/pebesma_sfr.pdf)\n* wiki page describing [sp-sf migration](https://github.com/r-spatial/sf/wiki/Migrating)\n\n## Cheatsheet\n[CC 4.0](https://creativecommons.org/licenses/by/4.0/) BY [Ryan Garnett](https://github.com/ryangarnett)  \n\n<a href=\"https://github.com/rstudio/cheatsheets/blob/main/sf.pdf\"><img src=\"https://raw.githubusercontent.com/rstudio/cheatsheets/main/pngs/sf.png\" /></a>\n\n## Installing\n\nInstall either from CRAN with:\n```r\ninstall.packages(\"sf\")\n```\nThis will install binary packages on Windows and MacOS, unless you configured R such that it tries to install source packages; in that case, see below.\n\nInstall development versions from GitHub with:\n```r\nlibrary(remotes)\ninstall_github(\"r-spatial/sf\")\n```\n\n### Windows\n\nInstalling sf from source works under Windows when [Rtools](https://cran.r-project.org/bin/windows/Rtools/) is installed.\n\n### MacOS\n\nMacOS users are strongly encouraged to install the `sf` binary packages from CRAN, unless they are familiar with compilers, linking, C++ source code, and homebrew. If you experience that R tries to install `sf` from source (or otherwise your install fails but you don't understand what is going on) try again by explicitly installing the binary, using\n\n```r\ninstall.packages(\"sf\", type = \"binary\")\n```\n\nThe remainder of this section is for those who understand what source installs mean, and imply.\n\nPerhaps the easiest way of an install from source is to first install `gdal` using Homebrew. Recent versions of Homebrew include a full-featured up-to-date [gdal formula](https://github.com/Homebrew/homebrew-core/blob/master/Formula/g/gdal.rb), which installs `proj` and `gdal` at the same time:\n\n```\nbrew install pkg-config\nbrew install gdal\n```\n\nOnce gdal is installed, you may be able to install `sf` package from source in R. With the current version of `proj` on homebrew, installation requires additional configuration:\n\n```r\ninstall.packages(\"sf\", type = \"source\", configure.args = \"--with-proj-lib=$(brew --prefix)/lib/\")\n```\n\nOr the development version:\n\n```r\nlibrary(remotes)\ninstall_github(\"r-spatial/sf\", configure.args = \"--with-proj-lib=$(brew --prefix)/lib/\")\n```\n\nAlternatively, [these instructions](https://stat.ethz.ch/pipermail/r-sig-mac/2017-June/012429.html) explain how to install gdal using kyngchaos frameworks.\n\nFor Mac OS 11 Big Sur source install instruction, see [here](https://github.com/r-spatial/sf/issues/1536#issuecomment-727342736)\n\n### Linux\n\nFor Unix-alikes, GDAL (>= 2.0.1), GEOS (>= 3.4.0) and Proj.4 (>= 4.8.0) are required.\n\n#### Ubuntu\n\nDependencies for recent versions of Ubuntu (18.04 and later) are available in the official repositories; you can install them with:\n\n```sh\nsudo apt -y update && apt install -y libudunits2-dev libgdal-dev libgeos-dev libproj-dev libsqlite3-dev\n```\n\nHowever, to get more up-to-date versions of dependencies such as GDAL, GEOS and PROJ we recommend adding the [ubuntugis-unstable](http://ppa.launchpad.net/ubuntugis/ubuntugis-unstable/ubuntu/) PPA to the package repositories and installing them as follows:\n\n```sh\nsudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\nsudo apt update\nsudo apt install libudunits2-dev libgdal-dev libgeos-dev libproj-dev libsqlite3-dev\n```\n\nAdding this PPA is required for installing `sf` on older versions of Ubuntu (e.g. Xenial).\n\nAnother option, for advanced users, is to install dependencies from source; see e.g. an older [Travis](https://github.com/r-spatial/sf/blob/593ee48b34001fe3b383ea73ea57063ecf690732/.travis.yml) config file for hints.\n\n#### Fedora\nThe following command installs all required dependencies:\n```sh\nsudo dnf install gdal-devel proj-devel geos-devel sqlite-devel udunits2-devel\n```\n\n#### Arch\n\nGet gdal, proj, geos and podofo from the main repos, and udunits from the AUR:\n\n```\npacman -S gdal proj geos arrow podofo\nyay/pacaur/yaourt/whatever -S udunits\n```\n\n#### `renv` or `conda`\n\nThere are several reports that `sf` fails to install as a source package when R is used with `renv`, or when R is installed in a `conda` environment. If you experience this, please do not raise an issue here, but \n\n* try to sort this out with the `renv` developers or the `conda` maintainers, or\n* try to use binary installs of the `sf` package, e.g. from [r2u](https://github.com/eddelbuettel/r2u), or the Posit package manager\n\n#### Other\n\nTo install on Debian, the [rocker geospatial](https://github.com/rocker-org/geospatial) Dockerfiles may be helpful. Ubuntu Dockerfiles are found [here](https://github.com/r-spatial/sf/tree/main/inst/docker).\n\n### Multiple GDAL, GEOS and/or PROJ versions on your system\n\nIf you use dynamic linking (installation from source) and have multiple versions of these libraries installed (e.g. one from ubuntugis-unstable, another installed from source in `/usr/local/lib`) then this will in general not work, even when setting `LD_LIBRARY_PATH` manually. See [here](https://github.com/r-spatial/sf/issues/844) for the reason why. \n\n### lwgeom\n\nFunctions and methods that require `liblwgeom`, including ellipsoidal (not spherical or Euclidean) metrics (area, distances), are provide by and used from [lwgeom](https://github.com/r-spatial/lwgeom), which is also on [CRAN](https://cran.r-project.org/package=lwgeom).\n\n## Contributing\n\n* Contributions of all sorts are most welcome, issues and pull requests are the preferred ways of sharing them.\n* When contributing pull requests, please adhere to the package style (in package code use `=` rather than `<-`; don't change indentation; tab stops of 4 spaces are preferred).\n* This project is released with a [Contributor Code of Conduct](CONDUCT.md). By participating in this project, you agree to abide by its terms.\n\n## How to cite\n\nPackage `sf` can be cited as: \n\n* Edzer Pebesma, 2018.  Simple Features for R: Standardized Support\nfor Spatial Vector Data. The R Journal [10:1, 439-446.](https://journal.r-project.org/archive/2018/RJ-2018-009/index.html)\n\n* Pebesma, E.; Bivand, R. (2023). [Spatial Data Science: With Applications in R](https://r-spatial.org/book/) \n(1st ed.). 314 pages. [Chapman and Hall/CRC](https://doi.org/10.1201/9780429459016).\n\n## Acknowledgment\n\nThis project gratefully acknowledges financial [support](https://www.r-consortium.org/projects) from the\n\n<a href=\"https://r-consortium.org/all-projects/2016-group-1.html#simple-features-for-r\">\n<img src=\"https://r-consortium.org/images/RConsortium_Horizontal_Pantone.webp\" width=\"300\">\n</a>\n<!--\n<img src=\"http://pebesma.staff.ifgi.de/RConsortium_Horizontal_Pantone.png\" width=\"300\">\n-->\n\n",
      "stars_today": 0
    },
    {
      "id": 20360040,
      "name": "clusterProfiler",
      "full_name": "YuLab-SMU/clusterProfiler",
      "description": ":bar_chart: A universal enrichment tool for interpreting omics data",
      "html_url": "https://github.com/YuLab-SMU/clusterProfiler",
      "stars": 1156,
      "forks": 263,
      "language": "R",
      "topics": [
        "enrichment-analysis",
        "go",
        "gsea",
        "kegg",
        "rstats",
        "visualization"
      ],
      "created_at": "2014-05-31T16:34:32Z",
      "updated_at": "2026-01-22T06:05:51Z",
      "pushed_at": "2026-01-25T00:20:22Z",
      "open_issues": 362,
      "owner": {
        "login": "YuLab-SMU",
        "avatar_url": "https://avatars.githubusercontent.com/u/40430016?v=4"
      },
      "readme": "# clusterProfiler\n\n<img src=\"inst/sticker/clusterProfiler_hex.png\" height=\"200\" align=\"right\" />\n\n[![Project Status: Active - The project has reached a stable, usable\nstate and is being actively\ndeveloped.](http://www.repostatus.org/badges/latest/active.svg)](http://www.repostatus.org/#active)\n[![](https://img.shields.io/badge/release%20version-4.18.4-green.svg)](https://www.bioconductor.org/packages/clusterProfiler)\n[![](https://img.shields.io/badge/devel%20version-4.19.4.006-green.svg)](https://github.com/guangchuangyu/clusterProfiler)\n[![Bioc](http://www.bioconductor.org/shields/years-in-bioc/clusterProfiler.svg)](https://www.bioconductor.org/packages/devel/bioc/html/clusterProfiler.html#since)\n\n[![platform](http://www.bioconductor.org/shields/availability/devel/clusterProfiler.svg)](https://www.bioconductor.org/packages/devel/bioc/html/clusterProfiler.html#archives)\n[![Build\nStatus](http://www.bioconductor.org/shields/build/devel/bioc/clusterProfiler.svg)](https://bioconductor.org/checkResults/devel/bioc-LATEST/clusterProfiler/)\n[![codecov](https://codecov.io/gh/GuangchuangYu/clusterProfiler/branch/master/graph/badge.svg)](https://codecov.io/gh/GuangchuangYu/clusterProfiler/)\n\n<!--\n[![Last-changedate](https://img.shields.io/badge/last%20change-2026--01--21-green.svg)](https://github.com/GuangchuangYu/clusterProfiler/commits/master)\n-->\n\n- [clusterProfiler](http://bioconductor.org/packages/clusterProfiler)\n  supports exploring functional characteristics of both coding and\n  non-coding genomics data for thousands of species with up-to-date gene\n  annotation.\n- It provides a universal interface for gene functional annotation from\n  a variety of sources and thus can be applied in diverse scenarios.\n- It provides a tidy interface to access, manipulate, and visualize\n  enrichment results to help users achieve efficient data interpretation\n- Datasets obtained from multiple treatments and time points can be\n  analyzed and compared in a single run, easily revealing functional\n  consensus and differences among distinct conditions\n\nFor details, please visit:\n\n- <https://yulab-smu.top/contribution-knowledge-mining/>\n- <https://yulab-smu.top/biomedical-knowledge-mining-book/>\n\n<img src=\"graphic-abstract-The-Innovation-2021.jpg\" width=\"890\"/>\n\n## :writing_hand: Authors\n\nGuangchuang YU <https://yulab-smu.top>\n\nSchool of Basic Medical Sciences, Southern Medical University\n\n------------------------------------------------------------------------\n\nIf you use\n[clusterProfiler](http://bioconductor.org/packages/clusterProfiler) in\npublished research, please cite the most appropriate paper(s) from this\nlist:\n\n1.  S Xu<sup>\\#</sup>, E Hu<sup>\\#</sup>, Y Cai<sup>\\#</sup>, Z\n    Xie<sup>\\#</sup>, X Luo<sup>\\#</sup>, L Zhan, W Tang, Q Wang, B Liu,\n    R Wang, W Xie, T Wu, L Xie, **G Yu**<sup>\\*</sup>. Using\n    clusterProfiler to characterise Multi-Omics Data. ***Nature\n    Protocols***. 2024, accepted. doi:\n    [10.1038/s41596-024-01020-z](https://doi.org/10.1038/s41596-024-01020-z)\n2.  T Wu<sup>\\#</sup>, E Hu<sup>\\#</sup>, S Xu, M Chen, P Guo, Z Dai, T\n    Feng, L Zhou, W Tang, L Zhan, X Fu, S Liu, X Bo<sup>\\*</sup>, **G\n    Yu**<sup>\\*</sup>. clusterProfiler 4.0: A universal enrichment tool\n    for interpreting omics data. ***The Innovation***. 2021,\n    2(3):100141. doi:\n    [10.1016/j.xinn.2021.100141](https://doi.org/10.1016/j.xinn.2021.100141)\n3.  **G Yu**<sup>\\*</sup>. Gene Ontology Semantic Similarity Analysis\n    Using GOSemSim. In: Kidder B. (eds) Stem Cell Transcriptional\n    Networks. ***Methods in Molecular Biology***. 2020, 2117:207-215.\n    Humana, New York, NY. doi:\n    [10.1007/978-1-0716-0301-7_11](https://doi.org/10.1007/978-1-0716-0301-7_11)\n4.  **G Yu**<sup>\\*</sup>. Using meshes for MeSH term enrichment and\n    semantic analyses. ***Bioinformatics***. 2018, 34(21):3766â€“3767.\n    doi:\n    [10.1093/bioinformatics/bty410](https://doi.org/10.1093/bioinformatics/bty410)\n5.  **G Yu**, QY He<sup>\\*</sup>. ReactomePA: an R/Bioconductor package\n    for reactome pathway analysis and visualization. ***Molecular\n    BioSystems***. 2016, 12(2):477-479. doi:\n    [10.1039/C5MB00663E](https://doi.org/10.1039/C5MB00663E)\n6.  **G Yu**<sup>\\*</sup>, LG Wang, and QY He<sup>\\*</sup>. ChIPseeker:\n    an R/Bioconductor package for ChIP peak annotation, comparison and\n    visualization. ***Bioinformatics***. 2015, 31(14):2382-2383. doi:\n    [10.1093/bioinformatics/btv145](https://doi.org/10.1093/bioinformatics/btv145)\n7.  **G Yu**<sup>\\*</sup>, LG Wang, GR Yan, QY He<sup>\\*</sup>. DOSE: an\n    R/Bioconductor package for Disease Ontology Semantic and Enrichment\n    analysis. ***Bioinformatics***. 2015, 31(4):608-609. doi:\n    [10.1093/bioinformatics/btu684](https://doi.org/10.1093/bioinformatics/btu684)\n8.  **G Yu**, LG Wang, Y Han and QY He<sup>\\*</sup>. clusterProfiler: an\n    R package for comparing biological themes among gene clusters.\n    ***OMICS: A Journal of Integrative Biology***. 2012, 16(5):284-287.\n    doi: [10.1089/omi.2011.0118](https://doi.org/10.1089/omi.2011.0118)\n9.  **G Yu**, F Li, Y Qin, X Bo<sup>\\*</sup>, Y Wu, S Wang<sup>\\*</sup>.\n    GOSemSim: an R package for measuring semantic similarity among GO\n    terms and gene products. ***Bioinformatics***. 2010, 26(7):976-978.\n    doi:\n    [10.1093/bioinformatics/btq064](https://doi.org/10.1093/bioinformatics/btq064)\n\n<!--\n&#10;\n&#10; r badge_custom(\"1st most cited paper\", \"in OMICS\", \"green\",\n  \"http://online.liebertpub.com/action/showMostCitedArticles?journalCode=omi\")`\n r badge_custom(\"ESI\", \"Highly Cited Paper\", \"green\")`\n r badge_doi(\"10.1089/omi.2011.0118\", \"green\")`\n&#10;\n------------------------------------------------------------------------\n&#10;### Citation\n&#10;\n&#10;\n<img src=\"https://guangchuangyu.github.io/software/citation_trend/clusterProfiler.png\" width=\"890\"/>\n&#10;\n### Download stats\n&#10;r badge_download_bioc(\"clusterProfiler\")\nr badge_bioc_download(\"clusterProfiler\", \"total\", \"blue\")\nr badge_bioc_download(\"clusterProfiler\", \"month\", \"blue\")\n&#10;\n<img src=\"https://guangchuangyu.github.io/software/dlstats/clusterProfiler.png\" width=\"890\"/>\n&#10;-->\n",
      "stars_today": 0
    },
    {
      "id": 259225467,
      "name": "CellChat",
      "full_name": "sqjin/CellChat",
      "description": "R toolkit for inference, visualization and analysis of cell-cell communication from single-cell data",
      "html_url": "https://github.com/sqjin/CellChat",
      "stars": 759,
      "forks": 167,
      "language": "R",
      "topics": [
        "cell-cell-communication",
        "cell-cell-interaction",
        "microenvironment",
        "single-cell-analysis"
      ],
      "created_at": "2020-04-27T06:28:33Z",
      "updated_at": "2026-01-24T22:48:40Z",
      "pushed_at": "2024-01-06T18:23:14Z",
      "open_issues": 455,
      "owner": {
        "login": "sqjin",
        "avatar_url": "https://avatars.githubusercontent.com/u/32399212?v=4"
      },
      "readme": "\n<p align=\"center\">\n  <img width=\"200\"  src=\"https://github.com/sqjin/CellChat/blob/master/CellChat_Logo.png\">\n</p>\n\n# CAUTION\nWe have updated CellChat to v2 and migrated CellChat to a new repository. This repository will be NOT updated and maintained any more. Please check the new repository [jinworks/CellChat](https://github.com/jinworks/CellChat) for the new updates, and the [CellChat v2 paper](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) for a comprehensive protocol of CellChat.  \n\n# About CellChat and CellChatDB\nCellChat is an R package designed for inference, analysis, and visualization of cell-cell communication from single-cell data. CellChat aims to enable users to identify and interpret cell-cell communication within an easily interpretable framework, with the emphasis of clear, attractive, and interpretable visualizations.  \n\nCellChatDB is a manually curated database of literature-supported ligand-receptor interactions in mutiple species, leading to a comprehensive recapitulation of known molecular interaction mechanisms including multi-subunit structure of ligand-receptor complexes and co-factors.\n\nIf you use CellChat in your research, please considering citing our papers: \n- [Suoqin Jin et al., CellChat for systematic analysis of cell-cell communication from single-cell and spatially resolved transcriptomics, bioRxiv 2023](https://biorxiv.org/cgi/content/short/2023.11.05.565674v1) [CellChat v2]\n- [Suoqin Jin et al., Inference and analysis of cell-cell communication using CellChat, Nature Communications 2021](https://www.nature.com/articles/s41467-021-21246-9) [CellChat v1]\n\n# Capabilities\nIn addition to infer the intercellular communication from any given single-cell data, CellChat provides functionality for further data exploration, analysis, and visualization. \n\n- It can quantitatively characterize and compare the inferred cell-cell communication networks using a systems approach by combining social network analysis, pattern recognition, and manifold learning approaches.\n- It provides an easy-to-use tool for extracting and visualizing high-order information of the inferred networks. For example, it allows ready prediction of major signaling inputs and outputs for all cell populations and how these populations and signals coordinate together for functions.\n- It enables comparative analysis of cell-cell communication across different conditions and identification of altered signaling and cell populations. \n- It provides several visualization outputs to facilitate intuitive user-guided data interpretation.\n\n<p align=\"center\">\n  <img width=\"700\"  src=\"https://github.com/sqjin/CellChat/blob/master/overview_CellChat.png\">\n</p>\n\n\n<p align=\"center\">\n  <a href=\"https://clustrmaps.com/site/1bpq2\">\n     <img width=\"200\"  src=\"https://clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=n&d=42WqeykSXznN_NSaBlpf6CtSXQxhqmIs6QusUsguFdY\" />\n   </a>\n</p>\n<p align=\"center\">\n  <a href=\"#\">\n     <img src=\"https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fsqjin%2FCellChat&labelColor=%233499cc&countColor=%2370c168\" />\n   </a>\n</p>\n\n\n\n\n\n",
      "stars_today": 0
    },
    {
      "id": 120286519,
      "name": "nichenetr",
      "full_name": "saeyslab/nichenetr",
      "description": "NicheNet: predict active ligand-target links between interacting cells",
      "html_url": "https://github.com/saeyslab/nichenetr",
      "stars": 610,
      "forks": 134,
      "language": "R",
      "topics": [
        "cell-cell-communication",
        "data-integration",
        "gene-expression",
        "intercellular-communication",
        "ligand-receptor",
        "ligand-target",
        "network-inference",
        "rna-seq",
        "single-cell-omics",
        "single-cell-rna-seq"
      ],
      "created_at": "2018-02-05T09:58:45Z",
      "updated_at": "2026-01-25T00:45:59Z",
      "pushed_at": "2025-11-12T09:07:45Z",
      "open_issues": 25,
      "owner": {
        "login": "saeyslab",
        "avatar_url": "https://avatars.githubusercontent.com/u/18485264?v=4"
      },
      "readme": "\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n<!-- github markdown built using\nrmarkdown::render(\"README.Rmd\",output_format = \"md_document\")\n-->\n\n# nichenetr\n\n<!-- badges: start -->\n\n[![R build\nstatus](https://github.com/saeyslab/nichenetr/workflows/R-CMD-check-bioc/badge.svg)](https://github.com/saeyslab/nichenetr/actions)\n[![Coverage\nStatus](https://codecov.io/gh/saeyslab/nichenetr/branch/master/graph/badge.svg)](https://codecov.io/gh/saeyslab/nichenetr)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3260758.svg)](https://doi.org/10.5281/zenodo.3260758)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7074291.svg)](https://doi.org/10.5281/zenodo.7074291)\n<!-- badges: end -->\n\n**nichenetr: the R implementation of the NicheNet method.** The goal of\nNicheNet is to study intercellular communication from a computational\nperspective. NicheNet uses human or mouse gene expression data of\ninteracting cells as input and combines this with a prior model that\nintegrates existing knowledge on ligand-to-target signaling paths. This\nallows to predict ligand-receptor interactions that might drive gene\nexpression changes in cells of interest.\n\nWe describe the NicheNet algorithm in the following paper: [NicheNet:\nmodeling intercellular communication by linking ligands to target\ngenes](https://www.nature.com/articles/s41592-019-0667-5).\n\nTo help users **customize NicheNet** to their specific biological use-case, we have recently published a **best practices workflow** cultivated over four years of experience and user feedback  \n[Unraveling cell-cell communication with NicheNet by inferring active\nligands from transcriptomics\ndata](https://www.nature.com/articles/s41596-024-01121-9). In the\nstep-by-step protocol, we describe both a â€˜sender-agnosticâ€™ approach\nthat considers ligands from the entire microenvironment and a\nâ€˜sender-focusedâ€™ approach that only considers ligands from cell\npopulations of interest. We also include a new downstream procedure for\nprioritizing cell type-specific ligand-receptor pairs. The code to\nreproduce this protocol and the resulting figures can be found on\n<https://github.com/saeyslab/nichenet_protocol>.\n\n## Installation of nichenetr\n\nInstallation typically takes a few minutes, depending on the number of\ndependencies that has already been installed on your PC. You can install\nnichenetr (and required dependencies) from github with:\n\n``` r\nif(!requireNamespace(\"devtools\", quietly = TRUE)) {\n  install.packages(\"devtools\") \n}\n\ndevtools::install_github(\"saeyslab/nichenetr\")\n```\n\nnichenetr was tested on both Windows and Linux (most recently tested R\nversion: R 4.3.2)\n\n## Overview of NicheNet\n\n<details>\n<summary>\n<h3>\nBackground\n</h3>\n</summary>\n\nNicheNet strongly differs from most computational approaches to study\ncell-cell communication (CCC), as summarized conceptually by the figure\nbelow (**top panel:** current ligand-receptor inference approaches;\n**bottom panel:** NicheNet). Many approaches to study CCC from\nexpression data involve linking ligands expressed by sender cells to\ntheir corresponding receptors expressed by receiver cells. However,\nfunctional understanding of a CCC process also requires knowing how\nthese inferred ligand-receptor interactions result in changes in the\nexpression of downstream target genes within the receiver cells.\nTherefore, we developed NicheNet to consider the gene regulatory effects\nof ligands. <br><br>\n<img src=\"vignettes/images/comparison_other_approaches_2.jpg\"\nwidth=\"450\" /> <br><br>\n\nAt the core of NicheNet is a prior knowledge model, created by\nintegrating three types of databasesâ€”ligand-receptor interactions,\nsignaling pathways, and transcription factor (TF) regulationâ€”to form a\ncomplete communication network spanning from ligands to their downstream\ntarget genes (see figure below). Therefore, this model goes beyond\nligand-receptor interactions and incorporates intracellular signaling\nand transcriptional regulation as well. As a result, NicheNet is able to\npredict which ligands influence the expression in another cell, which\ntarget genes are affected by each ligand, and which signaling mediators\nmay be involved. By generating these novel types of hypotheses, NicheNet\ncan drive an improved functional understanding of a CCC process of\ninterest. Note that although we provide a pre-built prior model, it is\nalso possible to construct your own model (see vignettes below).\n\n<img src=\"vignettes/images/nichenet_prior_model.png\"\nstyle=\"width:70.0%\" />\n</details>\n<details>\n<summary>\n<h3>\nMain functionalities of nichenetr\n</h3>\n</summary>\n\n- Assessing how well ligands expressed by a sender cell can predict\n  changes in gene expression in the receiver cell\n- Prioritizing ligands based on their effect on gene expression\n- Inferring putative ligand-target links active in the system under\n  study\n- Inferring potential signaling paths between ligands and target genes\n  of interest: to generate causal hypotheses and check which data\n  sources support the predictions\n- Validation of the prior ligand-target model\n- Construction of user-defined prior ligand-target models\n\nMoreover, we provide instructions on how to make intuitive\nvisualizations of the main predictions (e.g., via circos plots as shown\nhere below).\n\n<br><br>\n<img src=\"vignettes/images/circos_plot_adapted.jpg\" width=\"600\" />\n\n</details>\n\nAs input to NicheNet, users must provide cell type-annotated expression\ndata that reflects a cell-cell communication (CCC) event. The input can\nbe single-cell or sorted bulk data from human or mouse. As output,\nNicheNet returns the ranking of ligands that best explain the CCC event\nof interest, as well as candidate target genes with high potential to be\nregulated by these ligands. As an intermediate step, we extract the\nthree features required for the analysis: a list of potential ligands, a\ngene set that captures the downstream effects of the CCC event of\ninterest, and a background set of genes. Further explanation on each\nfeature can be found in the introductory vignette.\n\n![](vignettes/images/figure1.svg) <br><br>\n\n## Learning to use nichenetr\n\nThe following vignettes contain the explanation on how to perform a\nbasic NicheNet analysis on a Seurat object. This includes prioritizing\nligands and predicting target genes of prioritized ligands. We recommend\nstarting with the step-by-step analysis, but we also demonstrate the use\nof a single wrapper function. This demo analysis takes only a few\nminutes to run.\n\n- [Perform NicheNet analysis starting from a Seurat object: step-by-step\n  analysis](vignettes/seurat_steps.md):`vignette(\"seurat_steps\", package=\"nichenetr\")`\n- [Perform NicheNet analysis starting from a Seurat\n  object](vignettes/seurat_wrapper.md):`vignette(\"seurat_wrapper\", package=\"nichenetr\")`\n\nCase study on HNSCC tumor which demonstrates the flexibility of\nNicheNet. Here, the gene set of interest was determined by the original\nauthors, and the expression data is a matrix rather than a Seurat\nobject.\n\n- [NicheNetâ€™s ligand activity analysis on a gene set of\n  interest](vignettes/ligand_activity_geneset.md):\n  `vignette(\"ligand_activity_geneset\", package=\"nichenetr\")`\n\nThe following vignettes contain explanation on how to do some follow-up\nanalyses after performing the most basic analysis:\n\n- [Prioritization of ligands based on expression\n  values](vignettes/seurat_steps_prioritization.md):\n  `vignette(\"seurat_steps_prioritization\", package=\"nichenetr\")`\n- [Inferring ligand-to-target signaling\n  paths](vignettes/ligand_target_signaling_path.md):\n  `vignette(\"ligand_target_signaling_path\", package=\"nichenetr\")`\n- [Assess how well top-ranked ligands can predict a gene set of\n  interest](vignettes/target_prediction_evaluation_geneset.md):\n  `vignette(\"target_prediction_evaluation_geneset\", package=\"nichenetr\")`\n- [Single-cell NicheNetâ€™s ligand activity\n  analysis](vignettes/ligand_activity_single_cell.md):\n  `vignette(\"ligand_activity_single_cell\", package=\"nichenetr\")`\n\nIf you want to make a circos plot visualization of the NicheNet output\nto show active ligand-target links between interacting cells, you can\ncheck following vignettes:\n\n- [Seurat Wrapper + circos\n  visualization](vignettes/seurat_wrapper_circos.md):`vignette(\"seurat_wrapper_circos\", package=\"nichenetr\")`.\n- [HNSCC case study + double circos\n  visualization](vignettes/circos.md):`vignette(\"circos\", package=\"nichenetr\")`.\n\nPeople interested in building their own models or benchmarking their own\nmodels against NicheNet can read one of the following vignettes:\n\n- [Model construction](vignettes/model_construction.md):\n  `vignette(\"model_construction\", package=\"nichenetr\")`\n- [Using LIANA ligand-receptor databases to construct the ligand-target\n  model](vignettes/model_construction_with_liana.md):\n  `vignette(\"model_construction_with_liana\", package=\"nichenetr\")`\n- [Model evaluation: target gene and ligand activity\n  prediction](vignettes/model_evaluation.md):\n  `vignette(\"model_evaluation\", package=\"nichenetr\")`\n- [Parameter optimization via\n  NSGAII-R](vignettes/parameter_optimization.md):\n  `vignette(\"parameter_optimization\", package=\"nichenetr\")`\n\n## FAQ\n\nCheck the FAQ page at [FAQ NicheNet](vignettes/faq.md):\n`vignette(\"faq\", package=\"nichenetr\")`\n\n<details>\n<summary>\n<h2>\nPrevious updates\n</h2>\n</summary>\n\n**20-06-2023:**\n\n- MultiNicheNet - a multi-sample, multi-condition extension of\n  NicheNet - is now available on\n  [biorxiv](https://www.biorxiv.org/content/10.1101/2023.06.13.544751v1)\n  and [Github](https://github.com/saeyslab/multinichenetr).\n- MultiNicheNet uses an [updated prior model\n  (v2)](https://zenodo.org/record/7074291/) consisting of additional\n  ligand-receptor interactions from the [Omnipath\n  database](https://omnipathdb.org/) and from [Verschueren et\n  al.Â (2020)](https://www.sciencedirect.com/science/article/pii/S0092867420306942?via%3Dihub).\n  We have now also updated the vignettes of NicheNet to use the new\n  model instead.\n- **New functionality:** we have included additional functions to\n  prioritize ligands not only based on the ligand activity, but also on\n  the ligand and receptor expression, cell type specificity, and\n  condition specificity. This is similar to the criteria used in\n  Differential NicheNet and MultiNicheNet. See the [Prioritizing ligands\n  based on expression values](vignettes/seurat_steps_prioritization.md)\n  vignette for more information.\n- Due to this more generalizable prioritization scheme, we will no\n  longer provide support for Differential NicheNet.\n- We included code for making a ligand-receptor-target circos plot in\n  the [Circos plot visualization](vignettes/circos.md) vignette.\n\n<h5>\nDeprecated vignettes\n</h5>\n\nDifferential NicheNet has been deprecated: we will not longer provide\nsupport or code fixes on Differential NicheNet and its vignettes. You\nmay want to consider using the [general prioritization\nscheme](vignettes/seurat_steps_prioritization.md) instead.\n\n- [Differential NicheNet analysis between niches of\n  interest](vignettes/differential_nichenet.md):`vignette(\"differential_nichenet\", package=\"nichenetr\")`\n- [Differential NicheNet analysis between conditions of\n  interest](vignettes/differential_nichenet_pEMT.md):`vignette(\"differential_nichenet_pEMT\", package=\"nichenetr\")`\n\nIn NicheNet v2, the mouse and human ligand-target models are uploaded\nseparately so symbol conversion is not necessary. If you are still using\nthe NicheNet v1 model, you can check the following vignette on how to\nconvert the model (given in human symbols) to mouse symbols:\n\n- [Converting NicheNetâ€™s model from human to mouse\n  symbols](vignettes/symbol_conversion.md):\n  `vignette(\"symbol_conversion\", package=\"nichenetr\")`\n\n**12-01-2022:** In the Liver Atlas paper from Guilliams et al.: [Spatial\nproteogenomics reveals distinct and evolutionarily conserved hepatic\nmacrophage\nniches](https://www.sciencedirect.com/science/article/pii/S0092867421014811),\nwe used Differential NicheNet, an extension to the default NicheNet\nalgorithm. **Differential NicheNet** can be used to compare cell-cell\ninteractions between different niches and better predict niche-specific\nligand-receptor (L-R) pairs. It was used in that paper to predict\nligand-receptor pairs specific for the Kupffer cell niche in mouse and\nhuman.\n\nThe main difference between the classic NicheNet pipeline and the\nDifferential NicheNet pipeline is that Differential NicheNet also uses\nthe differential expression between the conditions/niches of the\nligand-receptor pairs for prioritization in addition to the ligand\nactivities. The classic NicheNet pipeline on the contrary uses only\nligand acivity for prioritization (and shows differential expression\nonly in visualizations).\n\nSo if you have data of multiple conditions or niches, and you want to\ninclude differential expression of the ligand-receptor pairs in the\nprioritization, we recommend you check out Differential NicheNet (update\nnichenetr to the 1.1.0 version). At the bottom of this page, you can\nfind the links to two vignettes illustrating a Differential NicheNet\nanalysis. We recommend these vignettes if you want to apply Differential\nNicheNet on your own data. If you want to see the code used for the\nanalyses used in the Guilliams et al.Â paper, see\n<https://github.com/saeyslab/NicheNet_LiverCellAtlas>.\n\n**15-10-2019:** Bonnardel, Tâ€™Jonck et al.Â used NicheNet to predict\nupstream niche signals driving Kupffer cell differentiation [Stellate\nCells, Hepatocytes, and Endothelial Cells Imprint the Kupffer Cell\nIdentity on Monocytes Colonizing the Liver Macrophage\nNiche](https://www.cell.com/immunity/fulltext/S1074-7613(19)30368-1).\n\n</details>\n\n## References\n\nBrowaeys, R., Saelens, W. & Saeys, Y. NicheNet: modeling intercellular\ncommunication by linking ligands to target genes. Nat Methods (2019)\n<doi:10.1038/s41592-019-0667-5>\n\nBonnardel et al.Â Stellate Cells, Hepatocytes, and Endothelial Cells\nImprint the Kupffer Cell Identity on Monocytes Colonizing the Liver\nMacrophage Niche. Immunity (2019) <doi:10.1016/j.immuni.2019.08.017>\n\nGuilliams et al.Â Spatial proteogenomics reveals distinct and\nevolutionarily conserved hepatic macrophage niches. Cell (2022)\n<doi:10.1016/j.cell.2021.12.018>\n",
      "stars_today": 0
    },
    {
      "id": 28114218,
      "name": "dada2",
      "full_name": "benjjneb/dada2",
      "description": "Accurate sample inference from amplicon data with single nucleotide resolution",
      "html_url": "https://github.com/benjjneb/dada2",
      "stars": 534,
      "forks": 162,
      "language": "R",
      "topics": [
        "amplicon",
        "bioconductor",
        "bioinformatics",
        "metabarcoding",
        "metagenomics",
        "microbiome",
        "taxonomy"
      ],
      "created_at": "2014-12-17T00:53:58Z",
      "updated_at": "2026-01-23T20:51:05Z",
      "pushed_at": "2025-12-15T19:22:15Z",
      "open_issues": 193,
      "owner": {
        "login": "benjjneb",
        "avatar_url": "https://avatars.githubusercontent.com/u/5797204?v=4"
      },
      "readme": "\n[![Build Status](https://app.travis-ci.com/benjjneb/dada2.svg?branch=master)](https://app.travis-ci.com/benjjneb/dada2)\n\n# dada2\n\nExact sample inference from high-throughput amplicon data. Resolves real variants differing by as little as one nucleotide. Visit [the DADA2 website](https://benjjneb.github.io/dada2/index.html) for the most detailed and up-to-date documentation.\n\n### Installation\n\nThe dada2 package binaries are available through Bioconductor:\n\n```S\n## try http:// if https:// URLs are not supported\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"dada2\")\n```\n\nIn order to install dada2 from source (and get the latest and greatest new features) see our [installation from source instructions](https://benjjneb.github.io/dada2/dada-installation.html).\n\n### Documentation\n\nThe [tutorial walkthrough of the DADA2 pipeline on paired end Illumina Miseq data](https://benjjneb.github.io/dada2/tutorial.html). \n\nThe [dada2 R package manual](https://www.bioconductor.org/packages/3.6/bioc/manuals/dada2/man/dada2.pdf).\n\nFurther documentation is available on [the DADA2 front page](http://benjjneb.github.io/dada2/). \n\n### DADA2 Articles\n\n[DADA2: High resolution sample inference from Illumina amplicon data. Nature Methods, 2016.](http://dx.doi.org/10.1038/nmeth.3869) [(Open Access link.)](http://rdcu.be/ipGh)\n\n[Bioconductor workflow for microbiome data analysis: from raw reads to community analyses. F1000 Research, 2016.](https://f1000research.com/articles/5-1492)\n\n[Exact sequence variants should replace operational taxonomic units in marker-gene data analysis. ISMEJ, 2017.](http://dx.doi.org/10.1038/ismej.2017.119)\n\n[High-throughput amplicon sequencing of the full-length 16S rRNA gene with single-nucleotide resolution. Nucleic Acids Research, 2019.](http://dx.doi.org/10.1093/nar/gkz569)\n\n### Other Resources\n\nPlanned feature improvements are publicly catalogued at the main DADA2 development site on github, specifically on the \"Issues\" page for DADA2:\n\nhttps://github.com/benjjneb/dada2/issues\n\nIf the feature you are hoping for is not listed, you are welcome to add it as a feature request \"issue\" on this page. This request will be publicly available and listed on the page.\n\nBugs and difficulties in using DADA2 are also welcome on [the issue tracker](https://github.com/benjjneb/dada2/issues).\n",
      "stars_today": 0
    },
    {
      "id": 216123064,
      "name": "ArchR",
      "full_name": "GreenleafLab/ArchR",
      "description": "ArchR : Analysis of Regulatory Chromatin in R (www.ArchRProject.com)",
      "html_url": "https://github.com/GreenleafLab/ArchR",
      "stars": 444,
      "forks": 153,
      "language": "R",
      "topics": [],
      "created_at": "2019-10-18T23:35:41Z",
      "updated_at": "2026-01-21T06:31:12Z",
      "pushed_at": "2025-02-18T21:19:00Z",
      "open_issues": 177,
      "owner": {
        "login": "GreenleafLab",
        "avatar_url": "https://avatars.githubusercontent.com/u/8398169?v=4"
      },
      "readme": "<p align=\"center\"><a href =\"https://www.archrproject.com\"><img src=\"Figures/ArchR_Logo_Integrated.png\" alt=\"\" width=\"350\"></a></p>\n<hr>\n\n[![Lifecycle: maturing](https://img.shields.io/badge/lifecycle-maturing-blue.svg)](https://www.tidyverse.org/lifecycle/#maturing)\n\n### ArchR has new features available for scATAC-seq Analysis\n\n**Paired scATAC-seq and scRNA-seq Analysis**\n\nArchR now supports paired scATAC-seq and scRNA-seq Analysis! <br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;See updates with importFeatureMatrix, addGeneExpressionMatrix, addIterativeLSI, addCombinedDims <br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For a brief tutorial of these features : https://greenleaflab.github.io/ArchR_2020/Ex-Analyze-Multiome.html\n\n**Trajectory Analysis**\n\nArchR now directly supports both monocle3 and Slingshot based trajectory analysis! <br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;See updates with getMonocleTrajectories, addMonocleTrajectory, addSlingShotTrajectories <br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For a brief tutorial of these features : https://greenleaflab.github.io/ArchR_2020/Ex-Analyze-Trajectory.html\n\nAdditionally ArchR now enables export of a peak matrix that is compatible with STREAM!<br />\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;See updates with exportPeakMatrixForSTREAM <br />\n\n### ArchR is currently in Beta and will be in active development through the peer review process.\n\nArchR is a full-featured R package for processing and analyzing single-cell ATAC-seq data. ArchR provides the most extensive suite of scATAC-seq analysis tools of any software available. Additionally, ArchR excels in both speed and resource usage, making it possible to analyze 1 million cells in 8 hours on a MacBook Pro laptop.\n\n### For installation instructions and full documentation, visit www.ArchRProject.com.\n\n<hr>\n\n![](Figures/ArchR_Workflow_Horizontal.png)\n\n# Quick Installation of ArchR\nFor a full walk through of installation and frequently related issues please visit www.ArchRProject.com.\n\n**First, install devtools (for installing GitHub packages) if it isn't already installed:**\n``` r\nif (!requireNamespace(\"devtools\", quietly = TRUE)) install.packages(\"devtools\")\n```\n\n**Then, install BiocManager (for installing bioconductor packages) if it isn't already installed:**\n``` r\nif (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\")\n```\n\n**Then, install ArchR:**\n``` r\ndevtools::install_github(\"GreenleafLab/ArchR\", ref=\"master\", repos = BiocManager::repositories())\n```\n\n**Lastly, install all of the ArchR dependencies that aren't installed by default:**\n``` r\nlibrary(ArchR)\nArchR::installExtraPackages()\n```\nIf any of these steps fails, you should identify the offending package and troubleshoot that individual installation before proceeding. Additionally, please see the ArchR website (www.ArchRProject.com) where we have installation troubleshooting tips.\n\n# Pre-compiled ArchR environment\nWe provide two methods in which a user can manage R dependencies.  \n\n### Using renv to manage dependencies\nThe first is by using renv to manage a project's dependencies. To utilize this, make sure that the renv package is installed and loaded.  Before you are ready to use `renv`, you must ensure that you are working on the same R version that we used for the provided renv environment. \nThe R versions we currently support are:\n```\n- R 4.4\n- R 4.1\n```\nSecondly, make sure that the renv package is installed and loaded.\n```\ninstall.packages(\"renv\")\nlibrary(renv)\n```\nSet a working directory for your project\n```\ndir.create(path = \"./<project_name>\", showWarnings = FALSE)\nsetwd(\"./<project_name>\")\n```\nThen, lets download the lock file for the current master branch of ArchR.\nFor R 4.4:\n```\ndownload.file(url = \"https://pub-9ae435458ecc412abbbc9420a502ec38.r2.dev/renv.lock\", destfile = \"./renv.lock\")\n```\nFor R 4.1:\n```\ndownload.file(url = \"https://pub-9ae435458ecc412abbbc9420a502ec38.r2.dev/renv_4_1.lock\", destfile = \"./renv.lock\")\n```\n\nNow, we can initiate our renv project environment, utilizing the renv.lock to bootstrap a new renv environment.\n```\nrenv::init()\n```\n\n### Using Docker to manage dependencies\nWe also provide Docker images, built off of `rocker/rstudio`, that already have ArchR and all dependencies pre-loaded.\n\nThe latest version can be found at:\n```\ngreenleaflab/archr:latest\n```\nand other versions, including images built with differing R versions, can be found at:\n```\nhttps://hub.docker.com/r/greenleaflab/archr/tags\n```\n\nTo utilize these images, the user can first install Docker as mentioned in their [documentation](https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository)\n\nFollowing, create a container using the following command:\n```\ndocker image pull greenleaflab/archr:latest\ndocker run -it --rm -v <your_workspace>:/workspace -p <your_port_of_interest>:8787\n```\nThis will spin up a container that has Rstudio turned on by default. Rstudio can be accessed through:\n```\nlocalhost:<your_port_of_interest>\n```\nIf you would like an interactive bash console instead, the following command can instead be called:\n```\ndocker run -it --rm -v <your_workspace>:/workspace -p <your_port_of_interest>:8787 bash\n```\n\n# Issues using ArchR?\n\nArchR is currently in __beta__. We expect there to be bumps in the road. If you think you have found a bug, please first install the latest version of ArchR via\n``` r\ndevtools::install_github(\"GreenleafLab/ArchR\", ref=\"master\", repos = BiocManager::repositories())\n```\nIf this does not fix your problem, please [report an issue on Github](https://github.com/GreenleafLab/ArchR/issues) with the __Bug Report__ form.\n\nIf you have questions about ArchR usage, please refer to the [the searchable full user's manual](https://www.archrproject.com/bookdown/index.html), [the FAQ section](https://www.archrproject.com/articles/Articles/faq.html), and the [publication](https://greenleaf.stanford.edu/assets/pdf/). If you think the documentation on this website or in the function annotations is unclear, please [submit an issue on Github](https://github.com/GreenleafLab/ArchR/issues) with the __Documentation Request__ form. If there is a feature that you think is missing from ArchR _and you have already searched the user's manual_, [submit an issue on Github](https://github.com/GreenleafLab/ArchR/issues) with the __Feature Request__ form. If none of these options help, [send us an email](mailto:archr.devs@gmail.com). We will do our best to respond to questions that are not otherwise answered in the documentation.\n\n\n",
      "stars_today": 0
    },
    {
      "id": 50672978,
      "name": "gcam-core",
      "full_name": "JGCRI/gcam-core",
      "description": "GCAM -- The Global Change Analysis Model",
      "html_url": "https://github.com/JGCRI/gcam-core",
      "stars": 377,
      "forks": 203,
      "language": "R",
      "topics": [
        "climate",
        "coupled-human-natural-systems",
        "economics",
        "energy",
        "gcam",
        "human-earth-system",
        "integrated-assessment",
        "land",
        "water"
      ],
      "created_at": "2016-01-29T15:57:28Z",
      "updated_at": "2026-01-16T23:31:26Z",
      "pushed_at": "2026-01-22T23:19:22Z",
      "open_issues": 253,
      "owner": {
        "login": "JGCRI",
        "avatar_url": "https://avatars.githubusercontent.com/u/8431983?v=4"
      },
      "readme": "# Global Change Analysis Model (GCAM)\n\nThe Joint Global Change Research Institute (JGCRI) of the Pacific \nNorthwest National Laboratory (PNNL) is the home and primary \ndevelopment institution for GCAM, a multisector model for exploring \nconsequences of and responses to global to local changes and stressors. \nRegional energy, water, land, and economic systems are connected to the\nrest of the globe through trade and interactions with environmental systems.\nThese systems are also connected with each other.\nMultisector models such as GCAM capture these \ninterconnected impacts in an economic framework in order to explore \nthese dynamic interactions and feedbacks between regions and sectors.\n\nGCAM has been developed at PNNL-JGCRI for over 20 years and is a freely\navailable community model and documented online (See below). The team\nat JGCRI is comprised of physical scientists, engineers, economists, energy\nexperts, forest ecologists, agricultural scientists, and environmental system\nscientists who develop the model and apply it to a range of research questions.\nThe JGCRI team works closely with the developers of other Earth system and\necosystem models to integrate the effects of human actions modeled in GCAM\ninto their research.\n\n## Model Overview\n\nGCAM is a dynamic-recursive model with technology-rich representations\nof the economy, energy sector, land use, and water linked to a reduced complexity\nEarth system model that can be used to explore many science and decision-relevant\nquestions including the effects of changes in trade patterns, critical minerals\n& materials availability, and deployment of energy technologies on human and\nEarth systems. Regional population and labor productivity growth assumptions\ndrive the energy and land-use systems, employing numerous technology options to\nproduce, transform, and provide energy services, as well as to produce\nagriculture and forest products, and to determine land use and land cover.\nUsing a run period extending from 1990 â€“ 2100 (historical years through 2021)\nwith annual results computed at 1-5 year intervals, GCAM has been used to\nexplore the potential role of emerging energy supply technologies and\nthe consequences of specific measures or energy technology adoption, including\nbioenergy; critical minerals & materials; hydrogen systems; nuclear energy;\nrenewable energy technologies; carbon capture, storage, and utilization and\nenergy use technology in buildings, industry, and the transportation\nsectors. GCAM outputs include projections of future energy and critical mineral\nsupply, trade, and demand and the resulting radiative forcing and other effects\nof 16 greenhouse gases, aerosols, and short-lived species at 0.5Ã—0.5 degree\nresolution, contingent on assumptions about future population, economy, technology,\ntrade and other polices.\n\n## Community guidelines for peer-reviewed journal articles using GCAM\n\nThis section outlines some suggested language which the GCAM user community \ncan employ to describe GCAM in papers in peer-reviewed journal articles,\nreports, or other public documents using GCAM or versions of GCAM. GCAM is\nunder continuous development. The suggested language for the opening paragraphs\nof a methodology or introduction section of a paper describing GCAM is as\nfollows:\n\n\"The Global Change Analysis Model (GCAM) is a multisector model developed and maintained at the Pacific Northwest National Laboratoryâ€™s Joint Global Change Research Institute (JGCRI, 2023) _\\<include additional citations to previous GCAM studies as relevant\\>_. GCAM is an open-source community model. In this study, we use GCAM v NN. The documentation of the model is available at the GCAM documentation page ([http://jgcri.github.io/gcam-doc](http://jgcri.github.io/gcam-doc)) and the description below is a summary. GCAM includes representations of: economy, energy, agriculture, and water supply in 32 geopolitical regions across the globe; their GHG and air pollutant emissions and global GHG concentrations, radiative forcing, and temperature change; and the associated land allocation, water use, and agriculture production across 396 land sub-regions and 235 water basins.  _\\<If using GCAM-USA, include without quotes: \"This study uses a U.S.-focused version of GCAM called GCAM-USA that includes representation of energy, economy, and water systems for the fifty states and the District of Columbia in addition to 31 regions outside of the United States.â€\\>_. The version of GCAM used in this study is available â€“ along with full source code and instructions for use â€“ in a public repository _\\<include citation including link to the GCAM repository with doi used in paper\\>_. \n\nSubsequent paragraphs of the description might expound on particular capabilities, systems, or sectors of focus in the paper. Details in the GCAM documentation page can be used as a reference to develop these paragraphs.\n\nCommunity users of GCAM might also undertake their own model developments and/or assumptions for papers. It is recommended that these departures from the publicly available version of the model be clearly described. In addition, if these developments are substantial, we suggest making this clear by including an additional phrase (e.g. region name or name of institution) in the name of the model and explicitly calling it out in place of or immediately following the italicized portion in the above paragraphs. For example: _\"This study uses a modified version of GCAM/GCAM-USA called GCAM-\\<institution name\\>/GCAM-USA-\\<institution name\\>. GCAM-\\<institution name\\>/GCAM-USA-\\<institution name\\> incorporates additional details and modified assumptions from GCAM v NN as described subsequently\"_. \n\n## Documentation\n\n* [GCAM Documentation](http://jgcri.github.io/gcam-doc/)\n* [Getting Started with GCAM](http://jgcri.github.io/gcam-doc/user-guide.html)\n* [GCAM Community](https://gcims.pnnl.gov/community)\n* [GCAM Videos and Tutorial Slides](https://gcims.pnnl.gov/community)\n* [GCAM Citation and Co-authorship Guidelines](http://jgcri.github.io/gcam-doc/community-guide.html)\n\n## Selected Publications\n\nCalvin, K., Patel, P., Clarke, L., Asrar, G., Bond-Lamberty, B., Cui, R. Y., Di Vittorio, A., Dorheim, K., Edmonds, J., Hartin, C., Hejazi, M., Horowitz, R., Iyer, G., Kyle, P., Kim, S., Link, R., McJeon, H., Smith, S. J., Snyder, A., Waldhoff, S., and Wise, M.: GCAM v5.1: representing the linkages between energy, water, land, climate, and economic systems, Geosci. Model Dev., 12, 677â€“698, https://doi.org/10.5194/gmd-12-677-2019, 2019.\n\nEdmonds, J., and J. Reilly (1985)Global Energy: Assessing the Future (Oxford University Press, New York) pp.317.\n\nEdmonds, J., M. Wise, H. Pitcher, R. Richels, T. Wigley, and C. MacCracken. (1997) â€œAn Integrated Assessment of Climate Change and the Accelerated Introduction of Advanced Energy Technologiesâ€, Mitigation and Adaptation Strategies for Global Change, 1, pp. 311-39\n\nKim, S.H., J. Edmonds, J. Lurz, S. J. Smith, and M. Wise (2006) â€œThe ObjECTS Framework for Integrated Assessment: Hybrid Modeling of Transportation â€ Energy Journal (Special Issue #2) pp 51-80.\n\n[Full list of GCAM publications](http://jgcri.github.io/gcam-doc/references.html)\n",
      "stars_today": 0
    },
    {
      "id": 308437751,
      "name": "tree-sitter-r",
      "full_name": "r-lib/tree-sitter-r",
      "description": "Tree-sitter grammar for R",
      "html_url": "https://github.com/r-lib/tree-sitter-r",
      "stars": 122,
      "forks": 38,
      "language": "R",
      "topics": [],
      "created_at": "2020-10-29T20:06:05Z",
      "updated_at": "2026-01-20T07:39:41Z",
      "pushed_at": "2025-09-16T20:52:48Z",
      "open_issues": 17,
      "owner": {
        "login": "r-lib",
        "avatar_url": "https://avatars.githubusercontent.com/u/22618716?v=4"
      },
      "readme": "# tree-sitter-r\n\nAn R grammar for [tree-sitter](https://github.com/tree-sitter/tree-sitter).\n\n## R package\n\nThis grammar is available as an [R package](https://cran.r-project.org/web/packages/treesitter.r/index.html).\n\nYou'll also want the [R package providing bindings to tree-sitter](https://davisvaughan.github.io/r-tree-sitter/) itself.\n\n## Rust bindings\n\nThis grammar is available as a [Rust crate on crates.io](https://crates.io/crates/tree-sitter-r).\n\n## Node bindings\n\nThis grammar is available as an [npm package](https://www.npmjs.com/package/@davisvaughan/tree-sitter-r).\n\nNote that it is currently listed as a scoped package under the name `@davisvaughan/tree-sitter-r`.\nWe are working with the npm team to gain ownership of the `tree-sitter-r` package.\nOnce that happens, we will move the npm package there instead.\n\n## References\n\n- [The R Draft Spec](https://cran.r-project.org/doc/manuals/r-release/R-lang.pdf)\n- [gram.y](https://github.com/wch/r-source/blob/trunk/src/main/gram.y)\n\n## Known deviations\n\nThis section describes known deviations from the R grammar.\n\n### `]]` as a literal token\n\nThe following is valid R syntax, note how `]]` has been split over multiple lines.\n\n```r\nx[[\"a\"]\n]\n```\n\nThis applies to `]]`, but not to `[[`, for example, this is not valid R syntax:\n\n```r\nx[\n[\"a\"]]\n```\n\nThe technical reason for this is that [in the grammar](https://github.com/wch/r-source/blob/988774e05497bcf2cfac47bfbec59d551432e3fb/src/main/gram.y#L508) R treats `[[` as a single token, but `]]` is treated as two individual `]` tokens.\nTreating `]]` as two individual `]` tokens allows whitespace, newlines, and even comments to appear between the two `]` tokens:\n\n```r\nx[[\"a\"] # comment\n]\n```\n\nWhile we'd like to precisely support the R grammar, it is also extremely useful to treat all of `(`, `)`, `[`, `]`, `[[`, and `]]` as literal tokens when using the tree-sitter grammar.\nThis allows you to treat call, subset, and subset2 nodes in the same way, since they all have exactly the same node structure.\n\nBecause treating `]]` as a literal token is so useful, and because we've never seen any R code \"in the wild\" written this way, this grammar does not allow whitespace, newlines, or comments between the two `]` tokens.\n",
      "stars_today": 0
    },
    {
      "id": 248836530,
      "name": "scTenifoldKnk",
      "full_name": "cailab-tamu/scTenifoldKnk",
      "description": " R/MATLAB package to perform virtual knockout experiments on single-cell gene regulatory networks.",
      "html_url": "https://github.com/cailab-tamu/scTenifoldKnk",
      "stars": 138,
      "forks": 13,
      "language": "R",
      "topics": [
        "functional-genomics",
        "gene-function",
        "gene-knockout",
        "gene-regulatory-network",
        "virtual-knockout-experiments"
      ],
      "created_at": "2020-03-20T19:31:03Z",
      "updated_at": "2026-01-24T01:44:09Z",
      "pushed_at": "2026-01-23T22:21:05Z",
      "open_issues": 21,
      "owner": {
        "login": "cailab-tamu",
        "avatar_url": "https://avatars.githubusercontent.com/u/31963060?v=4"
      },
      "readme": "scTenifoldKnk\n=============\n\nA R/MATLAB/Python package to perform virtual knockout experiments on single-cell gene regulatory networks. **scTenifoldKnk** is a machine learning workflow that performs virtual knockout experiments using single-cell RNA sequencing (scRNAseq) data from wild-type (WT) control samples as input. Constructs a single-cell gene regulatory network (scGRN) and knocks out a target gene from the adjacency matrix of the WT scGRN by setting the geneâ€™s outdegree edges to zero. **scTenifoldKnk** then compares the knocked out scGRN with the WT scGRN to identify differentially regulated genes, called virtual-knockout perturbed genes, which are used to assess the impact of the gene knockout and reveal the geneâ€™s function in the analyzed cells.\n\nPython version of scTenifoldKnk is available at: https://github.com/qwerty239qwe/scTenifoldpy\n\nMATLAB version is available at: https://github.com/jamesjcai/scGEAToolbox\n\nInstall:\n-------\nYou can install **scTenifoldKnk/R** using the following command:\n\n```{R}\nlibrary(remotes)\ninstall_github('cailab-tamu/scTenifoldKnk')\nlibrary(scTenifoldKnk)\n```\n\nAvailable functions:\n--------------------\n\n|Code| Function |\n|:-|:-|\n|scTenifoldKnk|Perform virtual knockout experiments on single-cell gene regulatory networks|\n\nInput:\n--------\nThe required input for **scTenifoldKnk** is an expression matrix with genes in the rows and cells (barcodes) in the columns. Data is expected to be previously normalized or _not normalized_ if `QC = TRUE`.\n\nRunning time:\n--------\nThe running time of scTenifoldKnk is largely dependent on how long it takes to construct scGRNs from subsampled expression matrices. Time increases proportional to the number of cells and genes in the dataset used as input. Below is a table of running times under different scenarios:\n\n| Number of Cells | Number of Genes | Running Time |\n|-----------------|-----------------|--------------|\n| 300             | 1000            | 3.45 min     |\n| 1000            | 1000            | 4.25 min     |\n| 1000            | 5000            | 171.88 min (2 h 51.6 min) |\n| 2500            | 5000            | 175.29 min (2 h 55.3 min) |\n| 5000            | 5000            | 188.88 min (3 h 8.9 min) |\n| 5000            | 7500            | 189.51 min (3 h 9.5 min)  |\n| 7500            | 5000            | 615.45 min (10 h 15.5 min) |\n| 7500            | 7500            | 616.12 min (10 h 16.1 min)  |\n\n\nOutput:\n--------\nThe output of **scTenifoldKnk** is a list with 3 slots as follows: \n  * **tensorNetworks**: The computed weight-averaged denoised gene regulatory networks after CANDECOMP/PARAFAC (CP) tensor decomposition. It includes two slots with:\n    * **X**: The constructed network for the _X_ sample.\n    * **Y**: The constructed network for the _Y_ sample.\n  * **manifoldAlignment**: The generated low-dimensional features result of the non-linear manifold alignment. It is a data frame with _2 times the number of genes_ in the rows and _d_ (default= 2) dimensions in the columns\n  * **diffRegulation**: The results of the differential regulation analysis. It is a data frame with 6 columns as follows:\n    * **gene**: A character vector with the gene id identified from the manifoldAlignment output.\n    * **distance**: A numeric vector of the Euclidean distance computed between the coordinates of the same gene in both conditions.\n    * **Z**: A numeric vector of the Z-scores computed after Box-Cox power transformation.\n    * **FC**: A numeric vector of the FC computed with respect to the expectation.\n    * **p.value**: A numeric vector of the p-values associated to the fold-changes, probabilities are asigned as P[X > x] using the Chi-square distribution with one degree of freedom.\n    * **p.adj**: A numeric vector of adjusted p-values using Benjamini & Hochberg (1995) FDR correction.\n\n---\nThe function to plot the egocentric KO, the code is available at [https://github.com/dosorio/utilities/blob/master/singleCell/plotKO.R](https://github.com/dosorio/utilities/blob/master/singleCell/plotKO.R), it requires: The object out of Knk (as X), the gene to knockout (gKO).\n\n\nÂ©ï¸ The Texas A & M University System. All rights reserved.\n",
      "stars_today": 0
    }
  ],
  "created_at": "2026-01-25T02:29:09.290071976Z"
}